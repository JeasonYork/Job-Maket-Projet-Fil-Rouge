srouce,title,company,location,link,description,skills,details
LinkedIn,ING√âNIEUR DATA,Akademija Oxford,"Ille-et-Vilaine, Brittany, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-at-akademija-oxford-3912800588?position=2&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=qxkAxO3kCKPFsjtGrF%2F6AA%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous souhaitez int√©grer une √©cole √† taille humaine ? Vous √™tes int√©ress√©.es par la donn√©e ? Sup de Vinci propose une formation compl√®te, en Mast√®re Big Data & Intelligence Artificielle (2 ann√©es en alternance).
L‚Äô√©cole Sup de Vinci, Rennes, accompagne l‚Äôune de ses entreprises partenaires dans son projet de recrutement d‚Äôun profil ing√©nieur data, en alternance pour la rentr√©e 2022.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Hadoop Data Engineer (F/H),Thales,"V√©lizy-Villacoublay, √éle-de-France, France",https://fr.linkedin.com/jobs/view/hadoop-data-engineer-f-h-at-thales-3890949542?position=3&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=NUzkjoDiCgv%2B68vSb9TBHw%3D%3D&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?
Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr√©sents sur tous les continents. Le Groupe investit dans les innovations du num√©rique et de la ¬´ deep tech ¬ª ‚Äì big data, intelligence artificielle, connectivit√©, cybers√©curit√© et quantique ‚Äì pour construire un avenir de confiance, essentiel au d√©veloppement de nos soci√©t√©s, en pla√ßant l‚Äôhumain au c≈ìur des d√©cisions.
Thales propose des solutions, services et produits qui aident ses clients ‚Äì entreprises, organisations, Etats ‚Äì dans cinq grands march√©s vitaux pour le fonctionnement de nos soci√©t√©s : identit√© et s√©curit√© num√©riques, d√©fense, a√©ronautique, espace, et transport.
QUI ETES-VOUS ?
Dipl√¥m√© d‚Äôun Bac+5 en √©cole d‚Äôing√©nieur ou √©quivalent universitaire avec une sp√©cialisation en informatique, vous avez au moins 3 ans d'exp√©rience dans les technologies Big Data.
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
En tant que Data Engineer, vous jouerez un r√¥le cl√© dans la conception, le d√©veloppement et la maintenance de notre infrastructure de donn√©es, ainsi que dans la transformation et la gestion des flux de donn√©es.
VOS MISSIONS :
‚Ä¢ Concevoir, d√©velopper et d√©ployer des solutions Big Data en utilisant les technologies Hadoop.
‚Ä¢ Mettre en place des pipelines de donn√©es performants pour l'ingestion, le traitement et le stockage des donn√©es massives.
‚Ä¢ Collaborer √©troitement avec les √©quipes m√©tier pour comprendre leurs besoins en mati√®re d'analyse de donn√©es et proposer des solutions adapt√©es.
‚Ä¢ Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn√©es.
‚Ä¢ Assurer la qualit√© et la fiabilit√© des donn√©es trait√©es, en mettant en place des processus de validation et de nettoyage.
‚Ä¢ Identifier et r√©soudre les probl√®mes li√©s √† l'infrastructure Big Data et proposer des am√©liorations.
‚Ä¢ Travailler en √©troite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents √† partir des donn√©es.
Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer / D√©veloppeur Big Data # H/F,Air France,"Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-d%C3%A9veloppeur-big-data-%23-h-f-at-air-france-3900080172?position=4&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=r6G3xtDtwyoSIYOezOARsw%3D%3D&trk=public_jobs_jserp-result_search-card,"Description du poste
Intitul√© du poste
Data Engineer / D√©veloppeur Big Data # H/F
M√©tier
Syst√®mes d'informations - D√©veloppement
Cat√©gorie socio-professionnelle
Cadre
Pr√©sentation du contexte
Vous avez peut-√™tre d√©j√† voyag√© avec nous, mais que connaissez-vous de nos m√©tiers et de la richesse des donn√©es qu‚Äôils g√©n√®rent au quotidien ? Comment le traitement et l‚Äôexploitation de ces donn√©es peut contribuer √† notre strat√©gie de Revenue Management, ou encore aux multiples op√©rations √† r√©aliser pour permettre √† un vol de partir √† l‚Äôheure ?
Air France-KLM fait r√™ver 104 millions de passagers par an, en les emmenant vers plus de 250 destinations, gr√¢ce √† une flotte de plus de 500 appareils. Le Groupe emploie 80 000 collaborateurs partout dans le monde :les opportunit√©s sont vastes pour mettre √† profit ses comp√©tences, apprendre et se d√©velopper !
Le d√©partement de d√©veloppement DATA, OR & AI d‚ÄôAir France, au sein de la direction des Syst√®mes d‚ÄôInformation, intervient dans toute la cha√Æne de captation et de traitement des donn√©es du groupe pour d√©livrer √† nos m√©tiers des solutions applicatives cl√©s en main.
Le d√©partement est √©galement en charge de l‚Äôensemble des outils techniques (ETL, DataLakes, DataWarehouses, Data visualisation) et du d√©veloppement des talents et comp√©tences de Data Engineering.
Notre mission ? Transformer la donn√©e brute en d√©cision intelligente, pour mieux optimiser les m√©tiers d‚ÄôAir France ‚Äì KLM !
Pour cela, nous avons chacun un r√¥le essentiel √† jouer, pourquoi le v√¥tre ne serait pas celui de Data Engineer et de d√©veloppeur Big Data ?
Description de la mission
Au sein de notre d√©partement, vous travaillerez main dans la main avec d‚Äôautres Data Engineers et d√©veloppeurs Big Data ainsi qu‚Äôavec des sp√©cialistes des m√©tiers.
Int√©gr√© au sein d‚Äôune product team agile passionn√©e et dynamique :
Vous participez √† l‚Äôanalyse des besoins m√©tiers du commercial, des op√©rations a√©riennes, de l‚Äôexploitation sol en a√©roport, de la maintenance a√©ronautique ou encore du Cargo.
Vous contribuez √† la d√©finition, au d√©veloppement, √† l‚Äôindustrialisation et √† la maintenance d‚Äôapplications Big Data ou en Business Intelligence
Vous pr√©sentez la restitution de vos travaux et accompagnez les utilisateurs d‚Äôun point de vue fonctionnel ou m√©thodologique
Vous serez en contact avec les directions m√©tier du groupe Air France KLM.
Nous attachons beaucoup d'importance au d√©veloppement des comp√©tences de nos collaborateurs ainsi qu‚Äô√† leur offrir des conditions de travail favorables √† l‚Äôautonomie et aux missions √† forte valeur ajout√©e. L'ouverture, le respect, la bienveillance et le partage sont des valeurs humaines port√©es par l'entreprise.
Profil recherch√©
Vous √™tes dipl√¥m√© de niveau Master ou Ing√©nieur dans les domaines informatiques, vous avez acquis une exp√©rience professionnelle dans le d√©veloppement d‚Äôapplications.
Vous disposez d‚Äôune exp√©rience du d√©veloppement indispensable en Backend / Java
Vous ma√Ætrisez les bases de donn√©es relationnelles et le langage SQL
En Compl√©ment, Vous Avez Une Connaissance Ou Une Exp√©rience Dans Tout Ou Partie Des Concepts Ou Outils Suivants
Environnement Big Data (Spark, Hadoop, Elasticsearch, Kafka, ...)
Base de donn√©es noSQL (MongoDB, HBase, REDIS) ou Data Warehouse Teradata
Outil de Datavisualisation (Spotfire, PowerBI, Qlik ou Kibana)
Solutions de Cloud (GCP) et hybride (GCP / AZURE)
(Ces comp√©tences compl√©mentaires ou manquantes pouvant aussi s'acqu√©rir √† travers un parcours de reskilling et de formations aux outils du data engineering dispens√© en interne).
Vous avez particip√© √† des projets organis√©s en Scrum ou Kanban, et avez peut-√™tre m√™me ≈ìuvr√© comme Scrum-Master, ce qui vous permettra de vous int√©grer ais√©ment au sein d‚Äôune Product Team. Votre esprit de synth√®se, votre force de conviction et votre ma√Ætrise de la communication facilitent les d√©cisions avec l‚Äôensemble des collaborateurs de l‚Äô√©quipe, √©ventuellement en langue anglaise, √† l‚Äô√©crit comme √† l‚Äôoral.
Vous √™tes autonome, rigoureux(se), responsable et curieux(se), vous aimez travailler en √©quipe. Vous poss√©dez de bonnes capacit√©s d'√©coute, d'analyse, de synth√®se et de communication.
Et bien s√ªr, vous √™tes passionn√©(e), enthousiaste et ing√©nieux(se)
Ce que nous vous offrons
De la cr√©ation de valeur pour l‚Äôensemble des m√©tiers d‚ÄôAir France KLM
Des challenges et probl√©matiques complexes √† r√©soudre
L‚Äôopportunit√© de d√©ployer des solutions Data industrielles √† l‚Äô√©chelle !
Une grande part de responsabilit√© dans une structure hi√©rarchique horizontale
Un important degr√© de libert√© pour apprendre et d√©velopper son expertise au sein de l‚Äô√©quipe
On vous attend le plus rapidement possible ! Et pour une dur√©e ind√©termin√©e ;)
Type de contrat
CDI
Temps partiel possible
Non
Type d'horaires
Administratif
Profil candidat
Niveau d'√©tudes min. requis
Bac + 5 et plus
Langue
Anglais (4 - Confirm√© / C1)
Localisation du poste
Localisation du poste
France, Provence-Alpes-C√¥te d'Azur, Alpes Maritimes (06)
Site
Valbonne
Show more
Show less","{'ProgLanguage': ['Java', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Hybride', 'Confirm√©'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,APPRENTI DATA ENGINEER (H/F),Akademija Oxford,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/apprenti-data-engineer-h-f-at-akademija-oxford-3917872047?position=5&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=rmaFYM2oHNOKTV4fxpDKVg%3D%3D&trk=public_jobs_jserp-result_search-card,"Une de nos entreprises partenaires, ESN situ√©e √† Paris, recherche un Apprenti Data Engineer (H/F) pr√©parant un bac +4/+5 sp√©cialit√© Big Data pour la rentr√©e de Septembre 2021.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,APPRENTI.E ING√âNIEUR DATA,Akademija Oxford,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/apprenti-e-ing%C3%A9nieur-data-at-akademija-oxford-3912806043?position=6&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=UHqnpuGea9Itifl0Aoj1Lg%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous souhaitez int√©grer une √©cole √† taille humaine ? Vous √™tes int√©ress√© par le secteur du d√©veloppement informatique ? Sup de Vinci propose une formation compl√®te en Mast√®re Big Data.
L‚Äô√©cole Sup de Vinci √† Bordeaux, accompagne l‚Äôune de ses entreprises partenaires dans son projet de recrutement d‚Äôun profil Ing√©nieur Data, en alternance pour la rentr√©e 2022.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer (H/F) | POEI,DataScientest.com,"Puteaux, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-poei-at-datascientest-com-3909358387?position=7&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=dzcO8ZpLWKV7kVqbDMyaZA%3D%3D&trk=public_jobs_jserp-result_search-card,"Data Engineer (H/F) | POEI
Puteaux
CDI
Postuler
Retour
Datascientest Is Hiring!
Data Engineer (H/F) | POEI
√Ä propos
Vous √™tes demandeur d'emploi et vivement int√©ress√©(e) par les m√©tiers de la Data ?
Rejoignez DataScientest en int√©grant une formation 100% financ√©e par P√¥le Emploi afin d‚Äôacqu√©rir les comp√©tences cl√©s qui vous permettront de booster votre carri√®re en tant que Data Engineer Cloud, un m√©tier en tension et en plein essor.
Cette formation est certifi√©e par l'Ecole des Mines ParisTech, et inclut le passage de certifications √©diteurs (AWS, Microsoft Azure ou encore GCP) qui garantissent votre employabilit√©.
Apr√®s avoir suivi notre formation de Cloud Data Engineer, vous rejoindrez, en CDI , notre entreprise partenaire.
Les candidats retenus b√©n√©ficieront d‚Äôune formation intensive, enti√®rement prise en charge par le dispositif POEI (Pr√©paration Op√©rationnelle √† l‚ÄôEmploi Individuel) avec P√¥le-Emploi.
Descriptif du poste
En Tant Que Cloud Data Engineer, Vous Aurez Pour Missions De Proposer Les Meilleures Solutions Aux Entreprises Afin D'optimiser Leur Activit√©, √† Travers Les Missions Suivantes
D√©veloppement de solutions permettant de traiter des volumes importants de donn√©es,
Conception, collection et fabrication des donn√©es brutes,
Cr√©ation d'outils et algorithmes pour le traitement des donn√©es,
Pr√©paration des donn√©es pour le Data Analyst,
S√©curisation des Pipelines donn√©es pour les Data Analysts et Data Scientists,
Organisation de l'architecture du cloud
Profil recherch√©
Ce Que Nous Vous Offrons
Une certification de l'Ecole des Mines ParisTech
Un CDI aupr√®s d'un de nos partenaires, expert europ√©en dans le traitement et l'exploitation des donn√©es
Un salaire attractif √† la cl√© : 35 000‚Ç¨ √† 48 000‚Ç¨ selon le profil
**Votre profil : **
Issu(e) d‚Äôune fili√®re scientifique ou informatique vous disposez d'un bac+5 ou d‚Äôun dipl√¥me d‚Äôing√©nieur,
Vous disposez id√©alement d‚Äôune exp√©rience significative en d√©veloppement informatique, en architecture r√©seaux ou dans la Data,
Vous ma√Ætrisez un langage objet type Java, Python, C++, etc.
Vous √™tes inscrit(e) √† P√¥le Emploi
Informations compl√©mentaires
Type de contrat : CDI
Date de d√©but : 01 septembre 2023
Lieu : Puteaux
Niveau d'√©tudes : Bac +5 / Master
Exp√©rience : > 1 an
T√©l√©travail ponctuel autoris√©
Salaire : entre 35000‚Ç¨ et 48000‚Ç¨ / an
Vous √™tes int√©ress√© par cette offre ?
Postuler
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['35'], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
LinkedIn,"Big Data Engineer ‚Äì Paris, France (H/F)",Astek,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-%E2%80%93-paris-france-h-f-at-astek-3470775874?position=8&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=q4j7hA8VWh11yPRBq9Ju3Q%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Paris - France
Publi√©e il y a 2 mois
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Nous rejoindre en tant que
Big Data Engineer (H/F),
afin d‚Äôaccompagner un op√©rateur t√©l√©coms, Leader en Europe dans la cr√©ation d‚Äôune infrastructure cloud (IAAS) performante, robuste et s√©curis√©e.
Un challenge portant sur des millions d‚Äôutilisateurs dans un environnement technique innovant, strat√©gique et o√π l‚Äôentraide et la bonne humeur priment !
Votre Mission, Si Vous L‚Äôacceptez :
Qualifier les donn√©es et les r√©sultats
Conception technique des solutions
D√©cliner les impacts de la strat√©gie et des innovations technologiques au sein des processus et outils de l‚Äôexploitant SI
Assurer l‚Äôaccompagnement et le d√©ploiement des √©volutions des processus et outils
Contribuer aux programmes de transformation DevOps, Cloud et catalogues des offres SI
D√©velopper des fonctions transverses et les ¬´ uses cases ¬ª
Accompagner la phase de mise en production
Votre Future √âquipe :
Vous int√©grerez une √©quipe √† la fois technique et fonctionnel, qui ≈ìuvre chaque jour pour d√©velopper et maintenir en conditions op√©rationnelles l‚Äôensemble des solutions IT !
L‚Äô√©quipe est en interaction avec des clients √† la fois internes et externes.
Votre stack de jeu
Syst√®me d‚Äôexploitation : Linux
Environnement Big data : Hadoop, Spark, Scala
Cloud computing : GCP ou AWS
Base de donn√©es : No SQL (Cassandra, Mongo DB)
Dataviz : Power BI ou Kibana
Des notions en d√©veloppement feront la diff√©rence !
Les Petits Plus Du Projet :
Vous √©voluerez au sein d‚Äôune √©quipe impliqu√©e et r√©active et interviendrez sur un projet polyvalent et √† forte valeur ajout√©e.
Vous ?
Dipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieur ou √©quivalent de niveau Bac+5.
Vous justifiez id√©alement d‚Äôune exp√©rience d‚Äôau moins 3 ans d‚Äôexp√©riences sur un poste similaire ?
Vous faite preuve de proactivit√© et d‚Äôesprit d‚Äô√©quipe, √™tes dot√©(e) d‚Äôun excellent sens de l‚Äôorganisation et vous aimez les challenges et la r√©solution de probl√®me ?
Alors ce poste est fait pour vous, n‚Äôh√©sitez plus et rejoignez l‚Äôaventure ASTEK !
Astek
Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.
Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de
ses 7800 collaborateurs
qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.
Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.
Tous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Notre projet commun vous plait ?
Postulez √† cette annonce, et soyez transparent !
Maud, notre Talent Acquisition Referent, vous contactera pour un premier √©change.
Puis vous rencontrerez Yoram, votre futur manager, avec lequel vous √©changerez autour d‚ÄôAstek, de votre parcours, de vos attentes et de votre future mission .
Enfin, vous rencontrerez Anthime, notre Directeur d‚Äôagence avec lequel vous pourrez valider votre int√©r√™t et ad√©quation pour le poste et finaliser les √©l√©ments contractuels.
Nos Plus
Astek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo
Une politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversit√©
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì developpement ‚Äì Scala ‚Äì Data
Caract√©ristiques de l'emploi
Cat√©gorie Ing√©nieur
Job Industry T√©l√©com / M√©dia
Postuler en ligne
Nom *
Pr√©nom *
Email *
Un email valide est requis.
T√©l√©phone *
Un num√©ro de t√©l√©phone valide est requis.
Joindre un CV *
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì developpement ‚Äì Scala ‚Äì Data
Show more
Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer - Bordeaux,Capgemini,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-bordeaux-at-capgemini-3889788624?position=9&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=qJ4q4DZbIEQJgFfJAS3paA%3D%3D&trk=public_jobs_jserp-result_search-card,"Choisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations. Avec le soutien et l'inspiration d'une
communaut√© d‚Äôexperts dans le monde entier, vous pourrez r√©√©crire votre futur. Rejoignez-nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la
valeur de la technologie pour les plus grandes organisations et participer √† la construction d‚Äôun monde plus durable et inclusif.
Vos missions :
Vous √™tes passionn√© par le domaine de la Data, vous souhaitez prendre part √† des projets d'envergure, concevoir des solutions, les impl√©menter et les faire √©voluer?
Alors rejoignez notre √©quipe Data Engineering Services au sein de Capgemini Cloud Infrastructure Services en tant que Data Engineer.
Vous avez acquis une exp√©rience solide dans le d√©veloppement, la mise en ≈ìuvre et l‚Äôoptimisation de solutions pour le traitement d'un grand volume de donn√©es, vous √™tes capable de cr√©er des solutions qui r√©pondent aux besoins m√©tiers et IT, alors rejoignez notre √©quipe d‚Äôexperts.
En qualit√© de Data engineer, vos missions sont les suivantes :
‚ñ™ Concevoir et d√©velopper des solutions Data/IA.
‚ñ™ Accompagner les M√©tier dans la compr√©hension et la mise en ≈ìuvre de solution orient√©es donn√©es.
‚ñ™ Collaborer avec les Dev, les Ops, les experts infrastructures dans la construction de solutions et d‚Äôinfrastructures ax√©es sur les donn√©es.
‚ñ™ G√©rer un √©cosyst√®me de partenaires data et assurer un haut niveau d'expertise
‚ñ™ Assurer un r√¥le de veille technologique sur tous les outils autours de la data, de l‚ÄôIA et de la BI.
Votre profil :
Vous √™tes issu d‚Äôune formation ing√©nieur ou √©quivalent bac+5 informatique sp√©cialis√©e en DATA et vous justifiez d‚Äôune exp√©rience de 3 √† 5 ans dans un r√¥le similaire. Expert dans une technologie de base de donn√©es relationnelle (PostgreSQL, Oracle...)
Expert dans une technologie de base NoSQL (MongoDB, Cassandra...)
Vous maitrisez un framework de manipulation de donn√©es (Hadoop, Spark, Kafka...)
Vous maitrisez les concepts DevOps et avez de bonnes notions en scripting et d√©veloppement
Vous avez une exp√©rience des outils BI et de data visualisation (Kibana, PowerBI...)
La maitrise de l'anglais est n√©cessaire.
3 raisons de nous rejoindre :
Qualit√© de vie au travail :
accord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√© professionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.
Apprentissage en continu :
certifications et formations en libre acc√®s, accompagnement sur mesure avec votre career manager, parcours d‚Äôint√©gration sur 9 mois.
Avantages groupe & CSE :
plan actionnariat, tarif pr√©f√©rentiels, remboursement partiel vacances, remboursement de votre abonnement sportif ou culture
Nos engagements et priorit√©s :
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.
√Ä propos de Capgemini :
Capgemini est un leader mondial, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d‚Äôexp√©rience, nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['PostgreSQL', 'Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Big Data Engineer - H/F,Lincoln France,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-h-f-at-lincoln-france-3834466740?position=10&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=2dHhajJA1zlXIU1bYbcHBA%3D%3D&trk=public_jobs_jserp-result_search-card,"Poste CDI : Consultant Big Data Engineer - H/F (Hadoop, Spark, PySpark, Databricks, Kafka, Python, Scala, Java, Hive, MongoDB, etc.)
Lincoln Pure Player Data
üí°: R√©inventant l'analyse
depuis 30 ans
. Experts en Modern BI, Big Data et Science des donn√©es üìä. Nous transformons les donn√©es en solutions pour les grands comptes, des secteurs bancaire, retail, t√©l√©coms, industriel, sant√©, et plus encore üíº.
Description du poste
üéØ
Missions
:
Analyser les besoins clients en mati√®re d'analyse de donn√©es
D√©velopper et optimiser des pipelines de donn√©es distribu√©s
Concevoir et mettre en ≈ìuvre des solutions Big Data adapt√©es
Int√©grer les solutions dans les environnements existants
Fournir un support technique et une expertise tout au long des projets
üîç
Pr√©requis
:
Expertise av√©r√©e en Hadoop, Spark, PySpark, Databricks, Kafka, Hive
Ma√Ætrise de Python, Scala, Java
Connaissance des bases de donn√©es NoSQL (MongoDB, etc.)
Capacit√© √† travailler en √©quipe et √† communiquer efficacement avec les clients
üåü
Avantages :
Environnement collaboratif et innovant
Formations certifiantes et accompagnement individualis√©
T√©l√©travail et horaires flexibles
R√©mun√©ration comp√©titive avec avantages sociaux attrayants
Possibilit√© de mobilit√© √† Lille, Lyon ou Aix-en-Provence
‚ú®
Processus de recrutement
: 2 entretiens (RH et technique)
Si vous √™tes passionn√© par les d√©fis de la Data et que vous souhaitez rejoindre une √©quipe dynamique et innovante,
postulez d√®s maintenant et contribuez √† red√©finir l'avenir de l'analyse de donn√©es chez Lincoln! üòâ
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '30', '30', '30']}"
LinkedIn,Big Data Engineer Databricks Senior - H/F - CDI,Talan,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-databricks-senior-h-f-cdi-at-talan-3909664424?position=11&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=JOUu%2BSuh85U2DmX%2B5oozDw%3D%3D&trk=public_jobs_jserp-result_search-card,"Talan est un groupe international de conseil en transformation et en innovation par la technologie, cr√©√© en 2002.
Nos 5000 consultantes et consultants partagent √† travers le monde l‚Äôaudace d‚Äôinnover, le go√ªt de l‚Äôexcellence, et l‚Äôenvie de relever les d√©fis les plus complexes.
Nous accompagnons les entreprises dans des secteurs vari√©s‚ÄØ: √©nergie, industrie, transport, finance, luxe‚Ä¶ √† travers 3 grandes expertises‚ÄØ:
Le Conseil en Management et Innovation (320 Consultants en France)
La valorisation des donn√©es, leurs structurations, et leurs usages (Data et Technologies)
L‚Äôint√©gration de solutions logicielles (Cloud et Applications Services)
Nos valeurs‚ÄØ: engagement, respect, partage, esprit d‚Äô√©quipe et optimisme.
Talan est une entreprise responsable, reconnue par ses collaborateurs et attach√©e √† la diversit√©. Des am√©nagements peuvent √™tre propos√©s si vous √™tes en situation de handicap.
Retrouvez nos engagements RSEiciet nos actions en faveur de la diversit√©ici
Job Description
Nous sommes √† la recherche d‚Äôun Big Data Engineer Databricks S√©nior qui sera en charge de l‚Äôint√©gration des donn√©es: acquisition, pr√©paration, mod√©lisation et stockage, exposition, . Vous devrez faire preuve d‚Äôun √©tat d‚Äôesprit √† la fois innovant, m√©thodique, orient√© solution (et non probl√®me!), et communiquant.
Responsabilit√©s
Manager des Big Data Engineer et Cloud Engineer
Coacher techniquement les membres de l‚Äô√©quipe: solution et code review sur site, recommandation sur les formations √† suivre, certifications √† r√©aliser, ‚Ä¶
Analyse des besoins techniques m√©tiers, d√©finition de l‚Äôarchitecture solution et logiciel, r√©f√©rent technique, d√©veloppement et optimisation, code review, maintenir les pratiques Devops ‚ÄúYou build IT, You run IT‚Äù, support √† recette et mise en production, documentation, et parfois assumer le r√¥le de Scrum Master,‚Ä¶
Benchmark de solutions et conseil aupr√®s de notre client sur les solutions technologiques √† adopter, en lien avec leurs besoins
Partage de connaissances et formations interne
Qualifications
Issu(e) d‚Äôune formation sup√©rieure (√©cole d‚Äôing√©nieur, master,‚Ä¶)
Vous disposez d‚Äôau moins 4 ann√©es d‚Äôexp√©rience dans le domaine du Big Data (et particuli√®rement sur le framework Spark), et au moins 6 ann√©es d‚Äôexp√©rience dans le d√©veloppement logiciel
Vous ma√Ætrisez led√©veloppement logiciel (Scala, Python ‚Ä¶), et vous disposez de solides exp√©riences dans la mise en place de pipelines de donn√©es
Vous ma√Ætrisez leFramework Spark (id√©alement sur Databricks) etson optimisation
Exp√©rience sur une plateforme Cloud serait un plus et id√©alement AWS
Exp√©rience sur des flux temps r√©elserait un plus : Kafka + Spark Streaming
Vous ma√Ætrisez les bases de donn√©es SQL et le langage SQL
Vous avez de l'exp√©rience sur les m√©thodes de stockage: HDFS, S3,,‚Ä¶
Vous avez de bonnes connaissances en devOps : Jenkins, Gitlab, Maven, ‚Ä¶
La connaissance des concepts suivants serait un +: DataOps, DataVault, DataMesh..
Connaissance de l‚ÄôAgilit√©
Autonome
Organis√©(e)
Sens du partage
Bonne communication
Orientation produit et solution
Additional Information
AVANTAGES
:
Plan de formation pour accompagner votre carri√®re (formations √©diteurs, certifications) gr√¢ce √† nos partenariats nous accordant une position de partenaire privil√©gi√©, et management de proximit√© par des experts
Locaux modernes en centre-ville
Top 5 du Palmar√®s Great Place to Work
T√©l√©travail jusqu‚Äô√† 5 jours selon les missions, prime d‚Äô√©quipement de 100‚Ç¨
Mobilit√© en France et √† l‚Äô√©tranger
Top 1% des entreprises √©valu√©es par Ecovadis dans le domaine social, environnemental et √©thique
Tickets restaurant, prime vacances, 50% transport (abonnement transport public), mutuelle
Permanence handicap (consultant d√©di√© aux collaborateurs en situation de handicap et aux proches aidants)
Actionnariat salari√©
Prime de cooptations
RTT
PROCESS RECRUTEMENT
:
L‚Äô√©quipe recrutement s‚Äôengage √† vous proposer un processus de recrutement rapide et fluide
1 entretien RHpar Teams (45min)
1 test technique
1 entretien technique par Teams (1heure)
1 entretien op√©rationnel avec le responsable de domaine, au si√®ge (1heure)
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer,digiRocks recrute ‚úÖ,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-digirocks-recrute-%E2%9C%85-3903481080?position=12&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=DIzHfjsZbaLVQRKIaO5kzQ%3D%3D&trk=public_jobs_jserp-result_search-card,"üòé Envie d'accompagner des organisations dans leurs strat√©gies, Fan de data?
Rejoins un jeune cabinet de conseil en strat√©gie sp√©cialis√© en data. Le cabinet a √©t√© cr√©√© il y a 4 ans pas des anciens de grands cabinets de conseil en strat√©gie qui ne se reconnaissaient plus dans ce qu'est devenu le ""consulting"". Cependant ils n'ont pas perdu espoir de pouvoir apporter du conseil √† haute valeur ajout√©e dans une ambiance friendly, fa√ßon start-up, sans sacrifier l'excellence.
Jean-Patrick recrute un(e) Consultant Data Engineer √† Paris en CDI
‚úÖ MISSION :
Vous serez responsable de la mise en ≈ìuvre de bout en bout de la pile de donn√©es, de la collecte au reporting, avec un accent sur l'infrastructure et les processus techniques. Vous travaillerez avec des Consultants en Strat√©gie & Data et les soutiendrez dans la r√©solution des d√©fis li√©s aux donn√©es de leurs clients. Vous contribuerez √† la d√©finition des strat√©gies de donn√©es, √† la mise en ≈ìuvre des syst√®mes de donn√©es et vous soutiendrez l'exploitation des donn√©es dans des projets transformationnels. En g√©n√©ral, vous serez responsable de comprendre intimement les probl√®mes, de concevoir une strat√©gie technique pour les adresser et de faciliter une ex√©cution technique de haute qualit√©.
‚úÖ R√âSULTATS ATTENDUS :
üöÄ R√©sultat 1: Unificateur de Donn√©es : Architecturer, assembler, assimiler, nettoyer et conformer de grands ensembles de donn√©es complexes pour livrer des insights commerciaux et alimenter les exp√©riences de produits de donn√©es.
üöÄ R√©sultat 2: Agent de S√©curit√© des Donn√©es : Concevoir et construire une infrastructure de donn√©es fiable et √©volutive avec les techniques de confidentialit√© et de s√©curit√© de pointe pour prot√©ger les donn√©es.
üöÄ R√©sultat 3: DataOps : Poss√©der la pile de donn√©es de bout en bout, y compris la collecte d'√©v√©nements, la gouvernance des donn√©es, les int√©grations de donn√©es et la mod√©lisation.
üöÄ R√©sultat 4: Gardien des Donn√©es : Assurer la coh√©rence et la qualit√© de l'environnement technique et de la structure des donn√©es √† travers des m√©triques, de la documentation, des processus, des tests de donn√©es et de la formation.
Requirements
‚úÖ PROFIL RECHERCH√â :
Dipl√¥m√© d'une Grande Ecole de Commerce ou d'ing√©nieur, avec une premi√®re exp√©rience r√©ussie comme Data Engineer, id√©alement dans un contexte similaire au Conseil,
Connaissance des services de Data Warehouses Cloud. Exp√©rience avec Google BigQuery, Snowflake, AWS Redshift/Athena, Looker, Azure SQL DWH, ou Azure Databricks est tr√®s souhaitable.
Connaissance des architectures de donn√©es relationnelles et de grandes donn√©es, de l'entreposage de donn√©es, de l'int√©gration de donn√©es, de la mod√©lisation de donn√©es, de l'optimisation de donn√©es et des techniques d'analyse de donn√©es.
Exp√©rience dans la construction de pipelines de donn√©es de bout en bout en utilisant des plateformes de donn√©es sur site ou bas√©es sur le cloud.
Exp√©rience pratique dans la livraison de solutions comprenant des bases de donn√©es, SQL avanc√© et d√©veloppement logiciel dans des langues telles que Python.
Int√©ress√© et connaissant les technologies Big Data et les technologies de l'√©cosyst√®me Apache telles que Beam, Spark, Kafka, Airflow, bases de donn√©es, int√©gration, gestion des donn√©es de r√©f√©rence, assurance qualit√©, manipulation de donn√©es et technologies de gouvernance des donn√©es.
Exp√©rience avec les plateformes cloud publiques et l'infrastructure cloud qui est essentielle.
Expos√© aux outils ETL/ELT et de gouvernance.
Int√©ress√© par les technologies et principes IA et ML.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,"Big Data Engineer ‚Äì Lille, France (H/F)",Astek,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-%E2%80%93-lille-france-h-f-at-astek-3839097187?position=13&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=g6Iw%2FVj01V51GKbNbzngpQ%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Lille - France
Publi√©e il y a 2 mois
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Nous rejoindre en tant que
Big Data Engineer (H/F),
afin d‚Äôaccompagner un op√©rateur t√©l√©coms, Leader en Europe dans la cr√©ation d‚Äôune infrastructure cloud (IAAS) performante, robuste et s√©curis√©e.
Un challenge portant sur des millions d‚Äôutilisateurs dans un environnement technique innovant, strat√©gique et o√π l‚Äôentraide et la bonne humeur priment !
Votre Mission, Si Vous L‚Äôacceptez :
Qualifier les donn√©es et les r√©sultats
Conception technique des solutions
D√©cliner les impacts de la strat√©gie et des innovations technologiques au sein des processus et outils de l‚Äôexploitant SI
Assurer l‚Äôaccompagnement et le d√©ploiement des √©volutions des processus et outils
Contribuer aux programmes de transformation DevOps, Cloud et catalogues des offres SI
D√©velopper des fonctions transverses et les ¬´ uses cases ¬ª
Accompagner la phase de mise en production
Votre Future √âquipe :
Vous int√©grerez une √©quipe √† la fois technique et fonctionnel, qui ≈ìuvre chaque jour pour d√©velopper et maintenir en conditions op√©rationnelles l‚Äôensemble des solutions IT !
L‚Äô√©quipe est en interaction avec des clients √† la fois internes et externes.
Votre stack de jeu
Syst√®me d‚Äôexploitation : Linux
Environnement Big data : Hadoop, Spark, Scala
Cloud computing : GCP ou AWS
Base de donn√©es : No SQL (Cassandra, Mongo DB)
Dataviz : Power BI ou Kibana
Des notions en d√©veloppement feront la diff√©rence !
Les Petits Plus Du Projet :
Vous √©voluerez au sein d‚Äôune √©quipe impliqu√©e et r√©active et interviendrez sur un projet polyvalent et √† forte valeur ajout√©e.
Vous ?
Dipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieur ou √©quivalent de niveau Bac+5.
Vous justifiez id√©alement d‚Äôune exp√©rience d‚Äôau moins 3 ans d‚Äôexp√©riences sur un poste similaire ?
Vous faite preuve de proactivit√© et d‚Äôesprit d‚Äô√©quipe, √™tes dot√©(e) d‚Äôun excellent sens de l‚Äôorganisation et vous aimez les challenges et la r√©solution de probl√®me ?
Alors ce poste est fait pour vous, n‚Äôh√©sitez plus et rejoignez l‚Äôaventure ASTEK !
Astek
Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.
Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de
ses 7800 collaborateurs
qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.
Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.
Tous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Notre projet commun vous plait ?
Postulez √† cette annonce, et soyez transparent !
Maud, notre Talent Acquisition Referent, vous contactera pour un premier √©change.
Puis vous rencontrerez Yoram, votre futur manager, avec lequel vous √©changerez autour d‚ÄôAstek, de votre parcours, de vos attentes et de votre future mission .
Enfin, vous rencontrerez Anthime, notre Directeur d‚Äôagence avec lequel vous pourrez valider votre int√©r√™t et ad√©quation pour le poste et finaliser les √©l√©ments contractuels.
Nos Plus
Astek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo
Une politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversit√©
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì developpement ‚Äì Scala ‚Äì Data
Caract√©ristiques de l'emploi
Cat√©gorie Ing√©nieur
Job Industry T√©l√©com / M√©dia
Postuler en ligne
Nom *
Pr√©nom *
Email *
Un email valide est requis.
T√©l√©phone *
Un num√©ro de t√©l√©phone valide est requis.
Joindre un CV *
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì developpement ‚Äì Scala ‚Äì Data
Show more
Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Big Data Engineer Databricks confirm√© - H/F - CDI,Talan,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-databricks-confirm%C3%A9-h-f-cdi-at-talan-3902693062?position=14&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=YqfrGktg2oFxsRwyJ9Dmfg%3D%3D&trk=public_jobs_jserp-result_search-card,"Talan est un cabinet de conseil en innovation et transformation par la technologie.
Depuis 20 ans, Talan conseille les entreprises et les administrations, les accompagne et met en ≈ìuvre leurs projets de transformation et d‚Äôinnovation en France et √† l'international. Pr√©sent sur cinq continents, le groupe pr√©voit de r√©aliser un chiffre d'affaires de 600 millions d'euros en 2022 pour plus de 6000 consultant¬∑e¬∑s et vise √† d√©passer la barre du milliard d‚Äô‚Ç¨ de CA √† horizon 2024.
Le Groupe met l'innovation au c≈ìur de son d√©veloppement et intervient dans les domaines li√©s aux mutations technologiques des grands groupes, comme le Big Data, l'IoT, la Blockchain et l'Intelligence Artificielle.
Pr√©sent dans les √©v√©nements incontournables du secteur, comme Viva Technology, Talan prend r√©guli√®rement la parole sur les enjeux de ces technologies r√©volutionnaires aux c√¥t√©s d'acteurs majeurs du secteur et de parlementaires (Syntec Num√©rique, Forum de l'intelligence artificielle, French Fab Tour, Forum de Giverny‚Ä¶).
Talan est une entreprise responsable, attach√©e √† la diversit√©. Des am√©nagements de poste peuvent √™tre organis√©s pour tenir compte des personnes en situation de handicap.
Retrouvez nos engagementsRSEiciet nos actions en faveur de la diversit√©ici
Job Description
Nous sommes √† la recherche d‚Äôun Big Data Engineer Databricks confirm√© qui sera en charge de l‚Äôint√©gration des donn√©es: acquisition, pr√©paration, mod√©lisation et stockage, exposition, . Vous devrez faire preuve d‚Äôun √©tat d‚Äôesprit √† la fois innovant, m√©thodique, orient√© solution (et non probl√®me!), et communiquant.
Responsabilit√©s
Analyse des besoins techniques m√©tiers, d√©finition de l‚Äôarchitecture solution et logiciel, r√©f√©rent technique, d√©veloppement et optimisation, code review, maintenir les pratiques Devops ‚ÄúYou build IT, You run IT‚Äù, support √† recette et mise en production, documentation, et parfois assumer le r√¥le de Scrum Master,‚Ä¶
Partager techniquement les membres de l‚Äô√©quipe: solutions et code reviews, recommandations, certifications √† r√©aliser, ‚Ä¶
Participation √† des meet-up, coding dogo,‚Ä¶
Communication: √©criture d‚Äôarticles, retours d‚Äôexp√©rience‚Ä¶
Qualifications
Issu d‚Äôune formation sup√©rieure (√©cole d‚Äôing√©nieur, master,‚Ä¶)
Vous disposez d‚Äôau moins 3 ann√©es d‚Äôexp√©rience dans le domaine du Big Data et particuli√®rement sur le framework Spark (id√©alement Databricks)
Ma√Ætrise du d√©veloppement logiciel (Scala, Python,‚Ä¶) et vous disposez de solides exp√©riences dans la mise en place de pipeline de donn√©es
Exp√©rience sur une plateforme Cloud serait un plus et id√©alement AWS
Exp√©rience sur des flux temps r√©elserait un plus : Kafka + Spark Streaming
Maitrise du langage SQL
Exp√©rience sur des m√©thodes de stockage: HDFS, S3, ,‚Ä¶
Bonnes connaissances en devOps : Jenkins, Gitlab, Maven, ‚Ä¶
Connaissance de l‚ÄôAgilit√©
Autonomie, organisation, sens du partage
Bonne communication
Orientation produit et solution
Additional Information
AVANTAGES
:
Plan de formation pour accompagner votre carri√®re (formations √©diteurs, certifications) gr√¢ce √† nos partenariats nous accordant une position de partenaire privil√©gi√©, et management de proximit√© par des experts
Locaux modernes en centre-ville
Top 5 du Palmar√®s Great Place to Work
T√©l√©travail jusqu‚Äô√† 5 jours selon les missions, prime d‚Äô√©quipement de 100‚Ç¨
Mobilit√© en France et √† l‚Äô√©tranger
Top 1% des entreprises √©valu√©es par Ecovadis dans le domaine social, environnemental et √©thique
Tickets restaurant, prime vacances, 50% transport (abonnement transport public), mutuelle
Permanence handicap (consultant d√©di√© aux collaborateurs en situation de handicap et aux proches aidants)
Actionnariat salari√©
Prime de cooptations
RTT
PROCESS RECRUTEMENT
:
L‚Äô√©quipe recrutement s‚Äôengage √† vous proposer un processus de recrutement rapide et fluide
1 entretien RHpar Teams (45min)
1 entretien op√©rationnel avec le responsable de domaine, au si√®ge (1heure)
1 entretien avec le directeur de p√¥le, au si√®ge(1heure)
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Communication', 'Organisation'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Confirm√©'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '20', '20', '20']}"
LinkedIn,Data Engineer ‚Äì SQL & GCP - F/H,Orange Business,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-sql-gcp-f-h-at-orange-business-3916557264?position=15&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=0rGuS34ssXebpVfpSRYJ7w%3D%3D&trk=public_jobs_jserp-result_search-card,"Et si Business & Decision et Orange Business conjuguaient leurs forces pour devenir l‚Äôun des leaders europ√©ens de la Data transformation ?
Nous l‚Äôavons fait ! Notre alchimie nous positionne comme un acteur unique intervenant sur toutes les √©tapes du voyage de la donn√©e.
Depuis 30 ans, Business & Decision, entit√© de Digital Services s'est impos√©e comme un partenaire strat√©gique pour la transformation Data de nombreux clients, dans des secteurs tr√®s vari√©s. Digital Services est aujourd‚Äôhui l‚ÄôESN d‚ÄôOrange Business alliant les expertises historiques Cloud et Digital d‚ÄôOrange ainsi que le c≈ìur de m√©tier Data/IA de Business & Decision. Son but est d‚Äôaccompagner les entreprises et les acteurs publics dans leur transformation gr√¢ce aux 4000 experts pr√©sents dans plusieurs grandes villes fran√ßaises comme Montpellier, Niort, Lyon, Bordeaux, Lille et Toulouse ‚Ä¶
Description du poste
Orange Business, recherche pour son site de Lille, son futur Data Engineer pour rejoindre sa team Data.
Votre quotidien ?
En int√©grant Orange Business, vous pouvez participer √† une grande diversit√© d‚Äôactivit√©s dans la Data. En voici un aper√ßu :
Au d√©marrage du projet :
Recueillir et analyser les besoins du client
R√©diger les sp√©cifications fonctionnelles et techniques
Estimre les charges
Pendant la phase de r√©alisation :
Mod√©liser des datawarehouses et datamart (int√©gration de flux et consolidation des donn√©es)
D√©velopper les proc√©dures d‚Äôalimentation (ETL)
D√©velopper en SQL
/ PLSQL / Shell
Garantir la qualit√© des donn√©es et leur disponibilit√©
Concevoir et d√©velopper des solutions frontend BI √† des fins analytics & dashboarding
R√©aliser la recette et les tests
Suivre et mettre en production
En fonction de votre √©volution et de nos enjeux, vous pouvez aussi √©voluer sur des missions transverses (conseil, coaching, avant-vente, formation, audit, etc.). La prise d‚Äôinitiative est toujours la bienvenue !
Qualifications
Vous poss√©dez 3 ans d'exp√©rience ou plus dans la mise en ≈ìuvre de projets d√©cisionnels et ing√©nierie ou analyse data.
Vous avez de
solides comp√©tences en d√©veloppement SQL
(job, scripting, d√©ploiement), vous avez l‚Äôhabitude de travailler dans un
environnement Google Cloud Plateform
ainsi qu‚Äôavec
Power BI
.
Envie d‚Äôapprendre de nouvelles technos ? Vous souhaitez partager vos comp√©tences et b√©n√©ficier des expertises de la Team Orange Business ?
Outre l‚Äôaspect technique, c‚Äôest une personnalit√© qui est recherch√©e !
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Orange'], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '30', '30', '30']}"
LinkedIn,Data Engineer (F/H),Thales,"V√©lizy-Villacoublay, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-thales-3908228180?position=16&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=SR3wNiEahgqu4gp2aczA2g%3D%3D&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?
Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr√©sents sur tous les continents. Le Groupe investit dans les innovations du num√©rique et de la ¬´ deep tech ¬ª ‚Äì big data, intelligence artificielle, connectivit√©, cybers√©curit√© et quantique ‚Äì pour construire un avenir de confiance, essentiel au d√©veloppement de nos soci√©t√©s, en pla√ßant l‚Äôhumain au c≈ìur des d√©cisions.
Thales propose des solutions, services et produits qui aident ses clients ‚Äì entreprises, organisations, Etats ‚Äì dans cinq grands march√©s vitaux pour le fonctionnement de nos soci√©t√©s : identit√© et s√©curit√© num√©riques, d√©fense, a√©ronautique, espace, et transport.
QUI ETES-VOUS ?
Dipl√¥m√© d‚Äôun Bac+5 en √©cole d‚Äôing√©nieur ou √©quivalent universitaire avec une sp√©cialisation en informatique, vous avez au moins 3 ans d'exp√©rience dans les technologies Big Data.
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
En tant que Data Engineer, vous jouerez un r√¥le cl√© dans la conception, le d√©veloppement et la maintenance de notre infrastructure de donn√©es, ainsi que dans la transformation et la gestion des flux de donn√©es.
VOS MISSIONS :
‚Ä¢ Concevoir, d√©velopper et d√©ployer des solutions Big Data en utilisant les technologies Hadoop.
‚Ä¢ Mettre en place des pipelines de donn√©es performants pour l'ingestion, le traitement et le stockage des donn√©es massives.
‚Ä¢ Collaborer √©troitement avec les √©quipes m√©tier pour comprendre leurs besoins en mati√®re d'analyse de donn√©es et proposer des solutions adapt√©es.
‚Ä¢ Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn√©es.
‚Ä¢ Assurer la qualit√© et la fiabilit√© des donn√©es trait√©es, en mettant en place des processus de validation et de nettoyage.
‚Ä¢ Identifier et r√©soudre les probl√®mes li√©s √† l'infrastructure Big Data et proposer des am√©liorations.
‚Ä¢ Travailler en √©troite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents √† partir des donn√©es.
Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer - Lille,Capgemini,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-lille-at-capgemini-3914228495?position=17&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=tWBPN1TDM2mx5aVvM0uDjQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Capgemini en quelques mots
Choisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations, o√π vous serez soutenu et inspir√© par une communaut√© d‚Äôexperts dans le monde entier, o√π vous pourrez r√©√©crire votre futur. Rejoignez-nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la valeur de la technologie pour les plus grandes organisations et participez √† la construction d‚Äôun monde plus durable et inclusif.
Vos missions
Vous maitrisez au minimum un langage de programmation appliqu√© √† l‚Äôanalyse de donn√©es
(Java, Python, Scala et les environnements Spark et / ou Hadoop).
Vous √™tes passionn√© par le Big Data et le Machine Learning et l‚Äôanalyse de donn√©es
Vous concevez et mettez en ≈ìuvre des strat√©gies s√©curis√©es d'acquisition et d'int√©gration de donn√©es
Vous configurez des r√©f√©rentiels de donn√©es √† la pointe de la technologie dans des environnements distribu√©s
Vous construisez des pipelines de donn√©es pour collecter, transformer et traiter des donn√©es en collaboration avec des scientifiques de donn√©es afin de r√©pondre aux exigences de la mod√©lisation de donn√©es d'analyse avanc√©e
Votre profil
Dipl√¥m√©(e) de Bac+5 en informatique
4 ans d‚Äôexp√©rience
(au sein d‚Äôune ESN ou chez un int√©grateur) en conseil client√®le
Une solide culture technologique
Un bon niveau d‚Äôanglais
3 raisons de nous rejoindre
Qualit√© de vie au travail :
accord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√©
professionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.
Apprentissage en continu :
certifications et formations en libre acc√®s, accompagnement sur mesure avec
votre carreer manager, parcours d‚Äôint√©gration sur 9 mois.
Avantages groupe & CSE :
plan actionnariat, activit√©s √† tarifs pr√©f√©rentiels, remboursement partiel
vacances, remboursement de votre abonnement sportif ou culturel
Nos engagements et priorit√©s
Le groupe Capgemini encourage une
culture inclusive dans un cadre multiculturel et handi-accueillant.
En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des
initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.
Capgemini
est un
leader mondial
, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de
55 ans d‚Äôexp√©rience,
nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le
cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning', 'Cloud'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data Engineer,EarthDaily Agro,"Balma, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-at-earthdaily-agro-3883708013?position=18&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=OstO0NnkVGTi6x0rYb4beg%3D%3D&trk=public_jobs_jserp-result_search-card,"About Us
EarthDaily Agro provides space age data and analytics to the organizations and people who feed the planet!
With 35 years of industry experience, EarthDaily Agro provides customers with the data, analysis and knowledge they need to make more efficient and effective decisions. B2B services range from global risk management and monitoring of agricultural commodities to the marketing of inputs and precision agriculture consulting, using the latest research in agronomy, information technologies and remote sensing.
EarthDaily Agro also develops highly customized business solutions for agricultural lenders, insurers, input suppliers and food companies, with easy-to-use analytics, that help reduce the daily risks of agriculture.
EarthDaily Agro is headquartered in Minneapolis, MN, USA, with offices in France, Brazil, Australia and Switzerland and is a division of EarthDaily Analytics Corp.
EarthDaily Analytics Corp., a vertically-integrated data processing and analytics company, is launching a new constellation of earth observation satellites. The EarthDaily satellite constellation will significantly enhance geospatial analytics capabilities in agriculture, forestry, environment, financial services, and intelligence, among many other verticals.
Main Job Tasks And Responsibilities
As a EarthDailyAgro Data Engineer, your primary responsibility will be to design, develop, and manage data pipelines and infrastructure specialized for geospatial and remote sensing applications. You will work closely with data scientists, geospatial analysts, remote sensing experts, software engineers, and DevOps teams to ensure the successful deployment and scaling of data pipeline to feed geospatial data machine learning models. Your role will be crucial in optimizing the geospatial machine learning ecosystem and ensuring the seamless integration of AI-driven geospatial solutions into real-world applications.
Your Responsibilities Include
Cloud-based data pipeline Conceptualization, Development and Scaling: Build up pipeline to ingest large volumes of geospatial data, pre-process them and meet data scientists‚Äô requirements, in terms of accessibility, speed, format, quality.
Automation and CI/CD: Industrialization of pipeline deployment, orchestration, workflows, and versioning.
Cost & Speed Optimization: Collaborate with infrastructure team to develop, optimize, and fine-tune pipeline.
Cloud and Containerization: Experience with cloud platforms (e.g., AWS, Azure, GCP) and containerization tools.
Infrastructure Management: Utilize containerization technologies and cloud-based services to set up and manage infrastructure, enabling seamless deployment and scalability.
Monitoring and Anomaly Detection: Implement monitoring systems to track pipeline performance and identify anomalies.
Version Control and Data Version Control: Proficient with version control systems like Git and DVC.
Security and Compliance: Ensure the security and privacy of geospatial data, adhering to relevant data protection regulations and industry best practices.
Collaboration and Communication: Collaborate with interdisciplinary teams to integrate data pipeline into existing applications or develop new geospatial products.
Issue Resolution and Troubleshooting: Identify and resolve promptly technical issues related to geospatial data processing, performance, or infrastructure.
Education, Knowledge And Abilities
Requirements
Education: Master's degree in Computer Science, specialisation in Geomatics and/or Remote sensing would be a plus.
Experience: 3+ years experiences with data pipeline processes and deployment is a must-have. Proven hands-on experience in setting up pipelines and data processes with opensource tools (e.g., MLFlow, Argo, Kubeflow) is desirable.
Programming Skills: Proficiency in Python and with data manipulation frameworks (e.g., dataframe, numpy, pandas, xarray, rasterio) and librairies (e.g., Dask).
Problem-Solving Skills: Autonomous, and strong analytical and problem-solving abilities to address complex geospatial data and analysis challenges.
Communication Skills: Excellent communication and interpersonal skills to collaborate effectively with cross-functional teams and stakeholders.
French mandatory (job based in France). Fluent in English (oral and written):‚ÄØmeetings with internal are mostly in‚ÄØEnglish.
Preferred Additional Skills
Experience with Earth Observation (EO) data analysis and processing.
Experience with geospatial data formats (e.g., GeoTIFF, Shapefile, NetCDF).
Spatial Analysis Techniques: Understanding of spatial analysis techniques and algorithms commonly used in geospatial data manipulation.
Remote Sensing Integration: Knowledge of remote sensing data sources (e.g., STAC catalog, satellite imagery, LiDAR, SAR) integration into data pipelines for accurate and up-to-date geospatial analysis.
CONDITIONS
Full time job based in Balma, near Toulouse, France.
Fixed + Bonuses
TR / ""Family"" insurance / CSE
Powered by JazzHR
WrfSXQ5YJg
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'ML', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration', 'Organization', 'Interpersonal Skills']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer H/F,Thales,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-thales-3903089036?position=19&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=l0OHDSxc4s3SzSTrRXtmfg%3D%3D&trk=public_jobs_jserp-result_search-card,"üì¢ Nous recherchons un(e) Data Engineer, bas√©(e) √† Lyon
üëâQuelques mots sur les activit√©s num√©riques de Thales Lyon :
Les activit√©s num√©riques repr√©sentent une entit√© rattach√©e au groupe Thales, sp√©cialis√©e dans l‚ÄôIT et pr√©sente au national.
L‚Äôagence de Lyon adresse divers sujets d‚Äôexpertise : ing√©nierie logiciels, cybers√©curit√©, infog√©rance des infrastructures et transformation digitale.
üéØ
Votre r√¥le et missions
En nous rejoignant, vous int√©grerez le centre de comp√©tences
Augmented data
,
sp√©cialis√© dans la conception, le d√©veloppement et l‚Äô√©volution d‚Äôapplications data centr√©es. Vous y boosterez votre carri√®re en travaillant sur des technologies telles que
Spark, Elasticsearch, Kube ...
le plus souvent dans un environnement
Agile
.
Dans le cadre des projets que nous op√©rons aujourd‚Äôhui :
- Vous contribuerez √† la conception, au maintien, √† la scalabilit√© des plateformes d‚Äôanalyse de donn√©es au travers de votre expertise sur les sujets data (base de donn√©es, gestion de flux, ETL ‚Ä¶)
- Vous contribuerez √† la conception et √† la mise en production des pipelines d‚Äôanalyses et de transformations de donn√©es en veillant √† leur bonne adaptation aux besoins m√©tiers et aux contraintes techniques du client
- Vous pourrez intervenir sur des sujets de visualisations, dans le but de notamment accompagn√©es nos clients sur la conception de Dashboard m√©tier intelligent ‚Ä¶
- Vous serez √©galement amen√©es √† √©changer directement avec des DevOps/Datascientist pour la mise en place, l‚Äôint√©gration des pipelines et l‚Äô√©laboration des algorithmes de traitements de donn√©es.
- A l‚Äô√©chelle du d√©partement, Vous serez un acteur majeur du d√©veloppement de notre activit√© et du lancement de nouveaux projets de valorisation de donn√©es.
üôã‚Äç‚ôÄÔ∏è üôã‚Äç‚ôÇÔ∏è
Votre profil
De formation Bac +5 en informatique (√©cole d‚Äôing√©nieur, Master ou √©quivalent), vous justifiez d‚Äôune premi√®re exp√©rience r√©ussie sur un projet data ? Vous souhaitez participer √† la conception et intervenir sur des solutions de r√©cup√©ration et d‚Äôexploitation de donn√©es m√©tiers dans des contextes critiques et hautement s√©curis√©s ?
Autonome, dynamique, organis√©(e) et proactif(ve), vous souhaitez √©voluer au sein d‚Äô√©quipes passionn√©es par l‚Äôexploration et l‚Äôint√©gration des technologies nouvelles au service des m√©tiers de nos clients ?
Vous avez des comp√©tences qui couvrent les domaines suivants :
Mise en place et gestion de base de donn√©es (SQL, Elasticsearch, Clickhouse ...)
Langages de programmations (Java, Python)
Gestion de flux (Kafka, flink, logstash ‚Ä¶)
Environnements big Data (Spark/hadoop )
Principes et outils de type ETL
Vous √™tes de plus int√©ress√©(e):
Par les environnements containeris√©s (docker, kubernetes, helm ...)
Les concepts DevOps (Ansible, CI/CD...)
Les sujets de Datavisualisation (Vega, Kibana, python librairies...)
Vous aimez travailler en √©quipe ? Vous √™tes reconnu(e) pour vos qualit√©s relationnelles et vos capacit√©s de vulgarisation ?
Alors notre poste d‚ÄôIng√©nieur(e) Data(H/F) est fait pour vous !
üôå
Votre carri√®re chez Thales
Diff√©rentes opportunit√©s vous permettront de d√©couvrir d'autres domaines ou sites. Vous pourrez √©voluer et d√©velopper vos comp√©tences dans diff√©rents domaines.
Explorez un espace attentif au d√©veloppement personnel.
D√©veloppez vos talents dans un autre domaine du groupe Thales, en d√©couvrant de nouveaux produits, de nouveaux clients, un nouveau pays ou en vous orientant vers une solution plus complexe.
Choisissez entre une expertise technique ou un parcours de leadership.
Vous travaillerez dans une entreprise r√©solument humaine avec des valeurs fortes comme la s√©curit√© au travail, l‚Äô√©galit√© Homme/Femme et l‚Äô√©quilibre vie personnelle/professionnelle (Accord T√©l√©travail).
Rattach√©(e) √† la Convention m√©tallurgie, vous b√©n√©ficierez aussi de ses multiples avantages (‚Ä¶)
Vous souhaitez en savoir plus ?
N‚Äôh√©sitez pas √† contacter notre √©quipe de recrutement ou nos √©quipes directement.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'CI/CD'], 'FrSoftSkills': ['Leadership'], 'EnSoftSkils': ['Leadership']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer | Python - Spark - Hadoop | Sp√©cialis√© en Big Data | Paris ou Remote Partiel,Octopus IT - Expert du recrutement tech,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-python-spark-hadoop-sp%C3%A9cialis%C3%A9-en-big-data-paris-ou-remote-partiel-at-octopus-it-expert-du-recrutement-tech-3837194913?position=20&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=pVu5TEtTTwGCsZughQT0Dw%3D%3D&trk=public_jobs_jserp-result_search-card,"La soci√©t√©
Cr√©√©e il y a 7 ans, cette entreprise de conseil en hyper croissance, se compose d'environ 90 personnes. Elle est devenue experte en Data et IA (NLP, Deep Learning, Machine Learning) et accompagne leurs clients sur l‚Äôensemble de leurs projets data √† travers la valorisation de leurs donn√©es.
Leur valeur ajout√©e ? Leur sp√©cialisation en Data ce qui leur permet d'offrir 3 expertises m√©tiers distinctes : la Data Science, la Data Engineering et le Machine Learning Engineering. Autour de ces expertises gravitent bien s√ªr les m√©tiers de Lead et d'Architecte.
Une autre de leur force est leur formation interne (avec des profils de seniors ou d'architectes) et externe (avec des partenaires pour passer les certifications).
Chez eux, le collaborateur est plac√© au centre des pr√©occupations, permettant ainsi de cr√©er une coh√©sion et une v√©ritable culture au sein de l'entreprise. Par exemple la majorit√© des projets se font en √©quipe et non seul.
Connu et reconnu pour leur expertise en Big Data, ils sont devenu le partenaire principal d'un grand groupe du CAC 40 et ont pris le lead sur tous les sujets touchant √† la transformation Big Data de ce groupe.
Pour poursuivre leur croissance, r√©pondre √† leurs ambitions et d√©velopper de nouveaux march√©s, nous recherchons plusieurs profils pour renforcer leurs effectifs.
Le poste
En les rejoignant vous travaillerez sur les probl√©matiques suivantes :
Mise en place et/ou scale d'architectures
Construction de Datalake
Mise en production de model de ML
Pipelining de donn√©es
Streaming de donn√©es et temps r√©el
La stack sur laquelle vous travaillerez :
Python, Scala, Spark, Architectures distribu√©es : Hadoop, HDFS, Cloud : Aws, GCP, Azure
Votre profil
A partir de 3 ans d'exp√©rience en CDI
Vous avez une exp√©rience significative sur des probl√©matiques Big Data
Tr√®s bonne comp√©tences en Python et/ou Scala et en Spark
Vous √™tes familier avec Hadoop, Hive, Hbase
Une logique cloud (Aws, GCP ou Azure)
Le salaire & avantages
50-60 K‚Ç¨ selon exp√©rience
RTT
Carte Swile & Mutuelle
3/4 jours de t√©l√©travail par semaine
Et plus encore‚Ä¶
Ce qu‚Äôon pr√©f√®re
√ätre impliqu√© √† fond dans une aventure avec de nombreux challenges techniques
Belles opportunit√©s d'√©volutions sur des postes d'Architecte, de Lead ou de Ml Ops
Tr√®s bonne ambiance, √©quipe solidaire et orient√©e partage d‚Äôinformations
Beaucoup de workshops en interne et catalogue de formations √† votre guise
Ce poste a √©t√© soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d‚ÄôExperts en Recrutement Tech (CDI et clients finaux uniquement) ‚Äì Visitez nous pour plus d‚Äôopportunit√©s :
www.octopusit.fr
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Senior'], 'TypeContract': ['CDI'], 'Salary': ['50'], 'Level': [], 'Experience': ['a', 'n', 's', '7', '7', '7']}"
LinkedIn,Data Engineer Talend F/H,Orange Business,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-talend-f-h-at-orange-business-3916552363?position=21&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=nWMEAJ97Rkf7axHPJgu4ww%3D%3D&trk=public_jobs_jserp-result_search-card,"L‚Äôambition d‚ÄôOrange Business est de devenir l‚Äôint√©grateur r√©seau et num√©rique de r√©f√©rence en Europe, en nous appuyant sur nos forces autour des solutions de connectivit√© nouvelle g√©n√©ration, du cloud et de la cybers√©curit√©.
Nos 30 000 femmes et hommes pr√©sents dans 65 pays, dont chaque voix compte, sont tous anim√©s par la m√™me d√©termination et le m√™me esprit d‚Äô√©quipe, pour construire les solutions digitales d‚Äôaujourd‚Äôhui et de demain et cr√©er un impact positif pour nos clients, pour leurs salari√©s et pour la plan√®te.
Nous offrons des opportunit√©s passionnantes gr√¢ce √† des projets innovants dans la data et le digital, le cloud, l‚ÄôIA, la cybers√©curit√©, l‚ÄôIoT, ou encore le digital workspace et le big data.
Venez vivre cette aventure avec nous !
Afin de d√©velopper notre √©quipe lilloise, nous recherchons aujourd'hui, un Ing√©nieur DATA √† m√™me d‚Äôaccompagner nos clients dans la structuration de leurs SI autour de la donn√©e.
Vos principales missions seront les suivantes
:
- Concevoir des solutions de traitement et collecter des volumes importants de donn√©es.
- Participer √† des √©tudes de cadrage pour collecter le besoin m√©tier et concevoir les solutions qui r√©pondent au besoin du client.
- Apporter son expertise sur des probl√©matiques pr√©cises rencontr√©es chez les clients.
- Participer √† la veille technologique
- R√©aliser les
d√©veloppements TALEND
- Rester inform√© et former sur les nouvelles solutions DATA
- Contribuer aux phases d'avant-vente et au d√©veloppement business.
- Participer √† la conception, l'√©volution et la pr√©sentation de nos offres DATA.
Vous
:
- √ätes issu(e) de formation bac+5 ?
- Vous justifiez d'au moins 3 ans d'exp√©riences en qualit√© d'Ing√©nieur DATA sur la solution TALEND Enterprise (Data Integration) et avez id√©alement une connaissance des solutions Cloud d'AWS et d'AZURE ?
- Vous √™tes intervenu sur des projets int√©grant des pratiques DevOps et AGILE ?
Alors postulez, ce poste est fait pour vous !
Vos comp√©tences cl√©s
:
- Expertise sur l'outil
ETL TALEND
Enterprise (administration et d√©veloppement)
- Fortes connaissances des solutions de bases de donn√©es (SQL, NoSQL‚Ä¶)
- Connaissances en langages objets ou scripts (notamment Java mais aussi Javascript, Scala, Python‚Ä¶)
- Divers syst√®mes d'exploitation : UNIX, Windows
Autonomie, rigueur, curiosit√©, dynamisme et sens du service sont des qualit√©s n√©cessaires pour ce poste.
Les comp√©tences compl√©mentaires qui seraient appr√©ci√©es :
- Connaissances d'autres modules Talend (MDM, ESB, Data Quality, Cloud‚Ä¶)
- Ma√Ætrise des technologies du Big Data (Hadoop, Spark, Kafka‚Ä¶)
- Expertise sur d'autres outils ETL (Informatica, SSIS, DataStage...)
- Notions en architecture des Syst√®mes d'Information
- Ma√Ætrise de l'anglais (oral et √©crit)
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'JavaScript'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': ['Orange'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': ['Windows'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer | Python - Azure | IA & Machine Learning  | Paris ou Remote Partiel,Octopus IT - Expert du recrutement tech,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-python-azure-ia-machine-learning-paris-ou-remote-partiel-at-octopus-it-expert-du-recrutement-tech-3664568765?position=22&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=moygXwPkYJVD30cyjrlNXw%3D%3D&trk=public_jobs_jserp-result_search-card,"La soci√©tÔøΩÔøΩ
Cr√©√©e il y a plus de 2 ans, cette startup est la premi√®re base de connaissance intelligente d√©di√©e aux services clients. Leur mission ? En finir avec la frustration lorsque l'on contact un Help Desk.
Pour cela, elle propose aux entreprises la possibilit√© de d√©livrer une exp√©rience client d'exception : rapide et de qualit√©. Gr√¢ce √† leur moteur de recherche intelligent, cette entreprise est capable de centraliser toute la connaissance interne de l'entreprise (proc√©dures, produits, modes op√©ratoires, etc.) et la diffuse intelligemment dans les outils de production des conseillers de service client.
R√©sultat :
Plus besoin de chercher l'information
Des r√©ponses instantan√©es et de meilleures qualit√©es
Une autonomie totale des collaborateurs
Apr√®s une croissance fulgurante, elle a su s√©duire √† la fois de nombreuses scale up (Luko, OpenClassrooms, Japhy...) et grands groupes (BNP Paribas, La Poste, Fnac Darty...).
Apr√®s le recrutement de leur Lead Data (r√©aliser ensemble) et suite √† l'annonce de leur lev√©e de 2,5M‚Ç¨ pour tripler la taille de ses √©quipes, le but est maintenant de s'imposer tr√®s vite comme la base de connaissance de r√©f√©rence en France et en Europe. Pour ce faire, nous recherchons un Data Engineer.
Le poste
En travaillant main dans la main avec le Lead Data, ta mission sera de d√©velopper et de maintenir des flux de donn√©es complexes et robustes. La donn√©e √©tant au coeur de l' entreprise, dans le produit comme dans la strat√©gie, tu seras amen√© √† travailler avec un panel d‚Äôinterlocuteurs tr√®s vari√©s :
Data Scientists sur des sujets comme le monitoring des mod√®les de production et l‚Äôenrichissement des donn√©es d‚Äôentrainement.
Product Team sur des sujets de performance et d‚Äôacheminement de donn√©es au service de fonctionnalit√©s produit telles que le dashboard d‚Äôanalytics √† destination de nos clients.
Customer Success / Strategy sur des sujets de pilotage comme le suivi de l‚Äôutilisation de notre plateforme ou la mise en place de KPIs de performance.
Tu travailleras sur les probl√©matiques suivantes :
Tu seras responsable de notre architecture de donn√©es et de son outillage, mais aussi de la mise en place de pipelines de donn√©es complexes et robustes.
Tu seras amen√© √† mettre en place des outils de monitoring et d‚Äôalerting pour suivre de pr√®s nos nombreuses pipelines de donn√©e.
Tu seras garant de la qualit√© de nos donn√©es en assurant l‚Äôapplication des guidelines de code et des tests automatis√©s pour chacune de nos pipelines.
Tu seras amen√© √† mettre en place des outils de reporting / insights √† destination d‚Äôinterlocuteurs vari√©s (Data Science, Product, Customer Success, Clients, etc.).
Tu cr√©eras et d√©velopperas des pipelines de donn√©es avec des outils de scheduling et d‚Äôorchestration.
La stack sur laquelle vous travaillerez :
Langage : Python, Javascript
Framework data : PyTorch, Transformers (Hugging Face), FastAPI
Database : PostgreSQL, MongoDB, ElasticSearch, Redis
Infrastructure : Azure, Docker, Kubernetes, Spark, RabbitMQ, Serverless, Terraform
Environnement / Test : PyTest, Gitlab (git + ci/cd)
BI : Metabase, Superset
Votre profil
Entre 1 et 3 ans d'exp√©rience en CDI
Tu as une exp√©rience significative sur des probl√©matiques de Data engineering
Tu es quelqu'un de pragmatique
Un tr√®s bon niveau en Python et une tr√®s bonne rigueur dans le code
Bonne pratique de dev : clean code, TDD, BDD
Une bonne culture Ops
Une logique cloud (Aws, GCP ou Azure)
Le salaire & avantages
50-7O K‚Ç¨ selon exp√©rience
RTT
Carte Swile & Mutuelle
2/3 jours de t√©l√©travail par semaine
Et plus encore‚Ä¶
Ce qu‚Äôon pr√©f√®re
√ätre impliqu√© √† fond dans une aventure avec de nombreux challenges techniques
Belles opportunit√©s d'√©volutions sur des postes d'Architecte, de Lead ou de Ml Ops
Beaucoup de workshops en interne et catalogue de formations √† votre guise
Une opportunit√© de travailler sur un produit unique qui a d√©j√† s√©duit de tr√®s beaux clients (BNP Paribas, Fnac Darty, Luko, OpenClassrooms)
La possibilit√© de travailler sur une stack tr√®s moderne, des probl√©matiques complexes aussi bien en traitement de donn√©es, qu'en DevOps
Un plan de BSPCE (actions de l'entreprise) tr√®s int√©ressant et motivant !
Une culture d'entreprise fond√©e sur l'apprentissage, l'autonomie, la bienveillance et l'exigence
Le fait de travailler au quotidien avec des fondateurs passionn√©s par leur domaine d'expertise
Ce poste a √©t√© soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d‚ÄôExperts en Recrutement Tech (CDI et clients finaux uniquement) ‚Äì Visitez nous pour plus d‚Äôopportunit√©s :
www.octopusit.fr
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go', 'JavaScript'], 'DataBase': ['SQL', ' MongoDB', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': ['PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'ML', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['50'], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,Data Engineer - Mod√©lisation SQL - F/H,Orange Business,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-mod%C3%A9lisation-sql-f-h-at-orange-business-3916551577?position=23&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=mXyowhaRMxCj2BN%2Bzc7rrw%3D%3D&trk=public_jobs_jserp-result_search-card,"Et si Business & Decision et Orange Business conjuguaient leurs forces pour devenir l‚Äôun des leaders europ√©ens de la Data transformation ?
Nous l‚Äôavons fait ! Notre alchimie nous positionne comme un acteur unique intervenant sur toutes les √©tapes du voyage de la donn√©e.
Depuis 30 ans, Business & Decision, entit√© de Digital Services s'est impos√©e comme un partenaire strat√©gique pour la transformation Data de nombreux clients, dans des secteurs tr√®s vari√©s. Digital Services est aujourd‚Äôhui l‚ÄôESN d‚ÄôOrange Business alliant les expertises historiques Cloud et Digital d‚ÄôOrange ainsi que le c≈ìur de m√©tier Data/IA de Business & Decision. Son but est d‚Äôaccompagner les entreprises et les acteurs publics dans leur transformation gr√¢ce aux 4000 experts pr√©sents dans plusieurs grandes villes fran√ßaises comme Montpellier, Niort, Lyon, Bordeaux, Lille et Toulouse ‚Ä¶
Description du poste
Orange Business, recherche pour son site de Lille, son futur Data Engineer pour rejoindre sa team Data.
Votre quotidien ?
En int√©grant Orange Business, vous pouvez participer √† une grande diversit√© d‚Äôactivit√©s dans la Data. En voici un aper√ßu :
Au d√©marrage du projet :
Recueillir et analyser les besoins du client
R√©diger les sp√©cifications fonctionnelles et techniques
Estimer les charges
Pendant la phase de r√©alisation :
Mod√©liser des datawarehouses et datamart (int√©gration de flux et consolidation des donn√©es)
D√©velopper les proc√©dures d‚Äôalimentation (ETL)
D√©velopper en SQL / PLSQL / Shell
Garantir la qualit√© des donn√©es et leur disponibilit√©
R√©aliser la recette et les tests
Suivre et mettre en production
En fonction de votre √©volution et de nos enjeux, vous pouvez aussi √©voluer sur des missions transverses (conseil, coaching, avant-vente, formation, audit, etc.). La prise d‚Äôinitiative est toujours la bienvenue !
Qualifications
Vous poss√©dez 5 ans d'exp√©rience ou plus dans la mise en ≈ìuvre de projets d√©cisionnels et en mod√©lisation.
Vous avez de s
olides comp√©tences en d√©veloppement SQL
(job, scripting, d√©ploiement) ainsi que sur Python.
Envie d‚Äôapprendre de nouvelles technos ? Vous souhaitez partager vos comp√©tences et b√©n√©ficier des expertises de la Team Orange Business ?
Outre l‚Äôaspect technique, c‚Äôest une personnalit√© qui est recherch√©e !
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Orange'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '30', '30', '30']}"
LinkedIn,DATA ENGINEER (H/F),SFR,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-sfr-3879318123?position=24&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=FMZDHlMn1O%2FB9TWDKjU5bw%3D%3D&trk=public_jobs_jserp-result_search-card,"En tant que Data Ing√©nieur exp√©riment√©, vous occuperez un r√¥le essentiel dans notre √©quipe Data Science.
Vous serez responsable de la conception, du d√©veloppement et de la maintenance des pipelines de donn√©es ainsi que de l'int√©gration de sources de donn√©es multiples.
Votre expertise sera cruciale pour garantir une gestion efficace des flux de donn√©es, ainsi que pour faciliter l'analyse et la visualisation des donn√©es en plus du support aux data scientists vos missions seront les suivantes :
Architecture projet des donn√©es
: Concevoir et d√©velopper des architectures projet de donn√©es robustes, √©volutives et performantes pour int√©grer et g√©rer de grandes quantit√©s de donn√©es provenant de sources multiples. Assurer la fiabilit√©, l'√©volutivit√© et la s√©curit√© des flux de donn√©es entrant d‚Äôun projet Data Science.
Int√©gration des donn√©es
: √âlaborer des pipelines de donn√©es efficaces pour l'extraction, la transformation et le chargement des donn√©es (via notre Framework ELT/ETL interne) provenant de diff√©rentes sources. Mettre en place des processus d'int√©gration automatis√©s et veiller √† la qualit√© des donn√©es.
Gestion des bases de donn√©es
: Concevoir et optimiser des bases de donn√©es pour r√©pondre aux besoins analytiques et de reporting. Assurer la performance, la disponibilit√© et la s√©curit√© des bases de donn√©es, ainsi que la gestion efficace des requ√™tes.
Collaboration interfonctionnelle
: Support des Data Scientists, vous travaillerez avec les √©quipes business pour comprendre leurs besoins et fournir des conseils et des recommandations bas√©s sur les donn√©es.
Optimisation des performances
: Surveiller et optimiser les performances des pipelines de donn√©es, des bases de donn√©es et des requ√™tes. Identifier les goulots d'√©tranglement et les points d'optimisation, et proposer des am√©liorations pour garantir des performances optimales.
S√©curit√© et conformit√©
: Veiller √† ce que les donn√©es soient trait√©es et stock√©es conform√©ment aux normes de s√©curit√© et de confidentialit√©. Mettre en place des m√©canismes de s√©curit√© pour prot√©ger les donn√©es sensibles et garantir la conformit√© aux r√©glementations en vigueur.
Votre profil :
Vous avez un
Dipl√¥me universitaire en informatique, en g√©nie logiciel, en science des donn√©es ou dans un domaine connexe et vous avez √† minima 5 ans d'exp√©rience en tant que Data Ing√©nieur.
Vous poss√©dez √©galement une solide ma√Ætrise des technologies et des outils suivants :
Hadoop, Spark, SQL, Kafka, GCP BigQuery,
De plus vous avez une bonne compr√©hension des architectures, des mod√®les et des concepts de base de donn√©s avec une exp√©rience avanc√©e dans la mise en ≈ìuvre de pipelines ETL et dans la gestion de bases de donn√©es.
Vos connaissances en mati√®re de s√©curit√© des donn√©es, de conformit√© aux r√©glementations ainsi que vos comp√©tences en programmation scripting et en d√©veloppement logiciel seront un plus.
Vos excellentes comp√©tences en communication seront des qualit√©s appr√©ci√©es et
un niveau d'anglais (appliqu√©e au domaine technique) est un plus.
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Data & Cloud Engineer (H/F),fifty-five,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-cloud-engineer-h-f-at-fifty-five-3910028674?position=25&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=VCniSLmV9FdFUbTN8DKrDw%3D%3D&trk=public_jobs_jserp-result_search-card,"Data & Cloud Engineer
fifty-five est une data-company d'un genre nouveau qui aide les marques √† exploiter les donn√©es pour am√©liorer le marketing, les m√©dias et l'exp√©rience client gr√¢ce √† une combinaison de services de conseil et de technologie sp√©cialis√©s.
En tant que pilier data et marketing du Brandtech Group, nous offrons des services qui combinent le conseil en strat√©gie, les services de cloud, le conseil en m√©dia et l'exp√©rience client.
fifty-five, c'est plus de 400 experts du num√©rique. Des digital consultants, des sp√©cialistes du tracking et du m√©dia, des ing√©nieurs et des data scientists, travaillent tous en √©troite collaboration pour fournir des conseils marketing de haut niveau et une assistance technique aux marques, dans tout type d'industrie, partout dans le monde.
Partenaire des annonceurs de la collecte √† l'activation et l'exploitation des donn√©es, nous aidons les organisations √† devenir de v√©ritables entit√©s omnicanales ma√Ætrisant l'efficacit√© de leur √©cosyst√®me digital et ses synergies avec le monde physique.
Bas√© √† Paris, nous op√©rons sur 3 fuseaux horaires depuis nos 10 bureaux, situ√©s √† Paris, Londres, Gen√®ve, Milan, Shanghai, Hong Kong, Shenzhen, Taipei, Singapour et New York. fifty-five attache une importance particuli√®re au bien-√™tre de ses collaborateurs, ce qui lui a permis de figurer dans le classement Best Workplaces France en 2018.
Contexte :
L'√©quipe d'ing√©nierie d√©veloppe et met en ≈ìuvre les solutions techniques permettant la r√©alisation de pipelines de donn√©es et l'impl√©mentation de data platform pour nos clients : r√©cup√©ration de datas sur de multiples sources de donn√©es (APIs, files, etc.), data cleaning, data processing, automation et monitoring de l'ensemble. L'√©quipe s'appuie sur des technologies r√©centes (docker, kubernetes, terraform, notebooks, etc.) et met en place ses projets dans les diff√©rents clouds du march√© (GCP, Azure, AWS...).
Mission :
Nous sommes √† la recherche d'une personne capable de r√©aliser des projets techniques pour r√©pondre aux besoins de nos clients (par exemple: syst√®me de recommandations de produits, d√©tection d'anomalies, ranking). Les activit√©s vont du chiffrage et du sizing technique √† la mise en ≈ìuvre des architectures, en passant par la revue des sp√©cifications fonctionnelles et la production de code. Le Data & Cloud Engineer sera √©paul√© par un Lead dans ses missions. Il sera √©galement amen√© √† participer √† la R&D et √† accompagner les √©quipes transverses dans la mise en place d'outils de travail internes (librairies pour les data scientists, environnement Notebooks pour les data analysts et data scientists, d√©veloppement de frameworks sur diff√©rents cloud providers, etc.).
Nous souhaitons trouver la bonne personne pour faire √©voluer ou cr√©er de nouvelles solutions dans ce cadre. Les missions comprennent aussi bien du prototypage rapide pour des d√©monstrateurs, que de la production de code robuste qui tourne en production tous les jours.
Comp√©tences et exp√©riences :
2 ans d'exp√©rience en tant que Data Engineer
Ma√Ætrise de Python, SQL
Ma√Ætrise des environnements Cloud. Id√©alement certifi√© GCP, Azure ou AWS
Bonne connaissance de Docker/Kubernetes
Bonne connaissance d'au moins un data warehouse (BigQuery, Snowflake, etc)
Connaissance autour des Notebooks (Jupyter)
A l'aise avec des concepts li√©s aux APIs (OAuth, REST, etc.)
A l'aise avec les notions d'Infrastructure as Code (Terraform)
Au courant des pratiques GitOps et connaissances des concepts autour du CI/CD
La ma√Ætrise d'un orchestrateur, comme Apache Airflow, est un plus
Esprit d'√©quipe (collaborer aux tests unitaires, revue de code, partage de code, sprints)
Bon niveau en fran√ßais et en anglais
A d√©j√† travaill√© en mode projet avec des interlocuteurs vari√©s (consultant, data analyst, data scientist)
Une exp√©rience en marketing digital est un plus
Nous proposons :
un bureau au centre de Paris avec terrasse et jardin
un environnement multiculturel avec des collaborateurs aux nationalit√©s multiples (France, Royaume-Uni, Etats-Unis, Chine, Tunisie, Italie et plus)
des projets avec nos bureaux √† Londres, Hong Kong, New York, Shanghai, Gen√®ve, Shenzhen et Taipei
des TGIF et supers soir√©es
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Apache Airflow'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,Data Engineer ‚Äì Grenoble,Capgemini,"Grenoble, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-grenoble-at-capgemini-3905836212?position=26&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=phBx1%2BYFP%2BE7q4Dxg28eJw%3D%3D&trk=public_jobs_jserp-result_search-card,"Choisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations. Avec le soutien et l'inspiration d'une communaut√© d‚Äôexperts dans le monde entier, vous pourrez r√©√©crire votre futur. Rejoignez-nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la valeur de la technologie pour les plus grandes organisations et participer √† la construction d‚Äôun monde plus durable et inclusif.
Vos missions :
En tant que Data Engineer au sein d'une √©quipe multidisciplinaire, vos responsabilit√©s principales seront les suivantes :
Intervenir sur les diff√©rentes phases d'un projet dans un environnement Cloud et Agile.
Contribuer √† la gestion de la qualit√© des donn√©es et extraction et analyse de celle-ci, ainsi qu‚Äô√† la pr√©sentation des donn√©es dans leur forme raffin√©e.
Proposer des nouvelles lectures de donn√©es via un travail de fouille sur les gisements d‚Äôinformation, notamment client.
Adopter une posture de consultant : proposer de nouvelles solutions et accompagner le client dans ses choix.
Votre profil :
Titulaire d'un Bac+5 en √©cole d‚Äôing√©nieur ou en universit√©.
Connaissances approfondies des ETL (Talend, Informatica ou SSIS), du traitement de donn√©es (Spark, Python, Scala) ainsi que des bases de donn√©es (Oracle, SQL Server, Postgres).
Facult√© pour se montrer curieux, autonome et proactif dans la r√©alisation de ses t√¢ches.
Capacit√© √† faire preuve de rigueur et √† travailler en √©quipe.
Bon niveau d‚Äôanglais (B2 minimum).
3 raisons de nous rejoindre :
Qualit√© de vie au travail
: accord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√© professionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.
Apprentissage en continu
: certifications et formations en libre acc√®s, accompagnement sur mesure avec votre career manager, parcours d‚Äôint√©gration sur 9 mois.
Avantages groupe & CSE
: plan actionnariat, tarif pr√©f√©rentiels, remboursement partiel vacances, remboursement de votre abonnement sportif ou culturel.
Nos engagements et priorit√©s
:
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.
√Ä propos de Capgemini :
Capgemini est un leader mondial, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d‚Äôexp√©rience, nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Oracle', 'SQL Server'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '55', '55', '55']}"
LinkedIn,Data Engineer,eXalt Value,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-exalt-value-3897767649?position=27&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=NbB%2F19lo6taC1wWs893b8w%3D%3D&trk=public_jobs_jserp-result_search-card,"eXalt
est un cabinet de conseil IT
Pure player Data
& IA bas√© √† Paris.
Notre offre s‚Äôarticule autour de 4 piliers r√©unis au sein d‚Äôune m√™me communaut√© pour un accompagnement √† 360¬∞ alliant une expertise technique et m√©thodologique √† une approche conseil m√©tier:
Data Gouvernance & Project
Data Engineering & Big Data
Data Performance & Analytics
Data Science & IA
Filiale du groupe eXalt, cr√©√© en 2018,
regroupant plus de
950 collaborateurs en France
(Paris, Lyon, Bordeaux, Lille, Nantes, Marseille)
et √† l‚Äôinternational
(Colombie, Etats-Unis, Espagne, Belgique),
eXalt Value
apporte une
expertise approfondie
dans le domaine de la Data & IA et conseille les entreprises dans le d√©ploiement de leurs strat√©gies data-driven.
B√©n√©ficiant du support du groupe eXalt
(1er dans la cat√©gorie Conseil & Audit au classement des Champions de la Croissance 2024), eXalt Value
est en pleine croissance et regroupe aujourd‚Äôhui une communaut√© d‚Äôexpertise de plus de 60 collaborateurs en r√©gion parisienne.
Nos consultants interviennent sur d
es projets d‚Äôenvergure
dans divers secteurs d‚Äôactivit√©,
Banque & Assurance, M√©dias, Transports, Retail, Tourisme, etc.
Nous recherchons un
Data Engineer Confirm√© H/F (minimum 4 ans d'exp√©rience dans la fonction)
pour rejoindre notre communaut√© sur le
pilier Data Engineering & Big Data.
Vos missions:
Concevoir et d√©velopper des pipelines et des flux de donn√©es.
Int√©grer et transformer des donn√©es provenant de diff√©rentes sources.
D√©velopper et mettre en ≈ìuvre des algorithmes de traitement de donn√©es avanc√©s.
Collaborer √©troitement avec les √©quipes clients pour comprendre leurs besoins et fournir des solutions adapt√©es.
Assurer la qualit√© et la fiabilit√© des solutions d√©velopp√©es.
Conseiller les √©quipes clients sur les solutions √† mettre en place.
Les Pr√©requis :
Titulaire d'un Bac+5, Ecole d'Ing√©nieur
Ma√Ætrise d'un ou plusieurs langages de programmation (
Python, Scala, Spark, etc
.).
Exp√©rience approfondie des technologies
Big Data (Hadoop, Spark, Kafka, Talend, etc.)
Exp√©rience av√©r√©e
en
environnement Cloud (AWS, GCP, ou Azure)
.
Solides comp√©tences en conception et en optimisation de pipelines de donn√©es.
Exp√©rience de travail en
m√©thode Agile
Capacit√© √† travailler de mani√®re autonome et en √©quipe.
Excellentes comp√©tences en communication et en r√©solution de probl√®mes.
Ma√Ætrise de l‚Äôanglais (oral & √©crit dans un contexte international professionnel).
Votre environnement eXalt√©:
Un environnement de travail Collaboratif
favorisant les initiatives et projets transverses √† la Practice Data & IA (Lab IA, Data Hub, etc.).
Un collectif de consultants passionn√©s,
s‚Äôint√©ressant aux tendances innovantes du secteur.
Une Practice de proximit√©,
privil√©giant la mont√©e en comp√©tence de ses collaborateurs (formations, coachings, mentorats, etc.)
Un suivi individualis√© et de proximit√©
par un.e Data Sales Manager r√©f√©rent du compte client, un.e Charg√©.e RH et un.e Practice Manager
Une √©quipe ouverte et dynamique,
qui privil√©gie les moments de partage et de convivialit√© (s√©minaires, eXaltemps, meet-up, d√©jeuners d‚Äô√©quipe, etc.)
Notre processus de recrutement :
Un entretien RH avec Estelle,
√† la suite duquel vous saurez tout (ou presque) d‚ÄôeXalt Value,
Un entretien technique avec un Manager assorti d‚Äôun test technique,
lors duquel vous aurez l‚Äôoccasion de d√©montrer vos talents mais aussi d‚Äôapprendre avant m√™me de dire oui,
Un entretien final avec la Directrice Associ√©e ou le Directeur Op√©rationnel,
pour finir de vous convaincre de nous rejoindre üòä
Nous avons h√¢te de recevoir vos CV, et de faire votre connaissance!
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Communication', 'R√©solution de probl√®mes'], 'EnSoftSkils': ['Communication', 'Initiative']}","{'JobDetail': ['Confirm√©'], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data Engineer | Python - Spark - Hadoop | Sp√©cialis√© en Big Data | Paris ou Remote Partiel,Octopus IT - Expert du recrutement tech,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-python-spark-hadoop-sp%C3%A9cialis%C3%A9-en-big-data-paris-ou-remote-partiel-at-octopus-it-expert-du-recrutement-tech-3685740787?position=28&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=95UUn0EtXS4JBMe178TvPw%3D%3D&trk=public_jobs_jserp-result_search-card,"La soci√©t√©
Cr√©√©e il y a 7 ans, cette entreprise de conseil en hyper croissance, se compose d'environ 90 personnes. Elle est devenue experte en Data et IA (NLP, Deep Learning, Machine Learning) et accompagne leurs clients sur l‚Äôensemble de leurs projets data √† travers la valorisation de leurs donn√©es.
Leur valeur ajout√©e ? Leur sp√©cialisation en Data ce qui leur permet d'offrir 3 expertises m√©tiers distinctes : la Data Science, la Data Engineering et le Machine Learning Engineering. Autour de ces expertises gravitent bien s√ªr les m√©tiers de Lead et d'Architecte.
Une autre de leur force est leur formation interne (avec des profils de seniors ou d'architectes) et externe (avec des partenaires pour passer les certifications).
Chez eux, le collaborateur est plac√© au centre des pr√©occupations, permettant ainsi de cr√©er une coh√©sion et une v√©ritable culture au sein de l'entreprise. Par exemple la majorit√© des projets se font en √©quipe et non seul.
Connu et reconnu pour leur expertise en Big Data, ils sont devenu le partenaire principal d'un grand groupe du CAC 40 et ont pris le lead sur tous les sujets touchant √† la transformation Big Data de ce groupe.
Pour poursuivre leur croissance, r√©pondre √† leurs ambitions et d√©velopper de nouveaux march√©s, nous recherchons plusieurs profils pour renforcer leurs effectifs.
Le poste
En les rejoignant vous travaillerez sur les probl√©matiques suivantes :
Mise en place et/ou scale d'architectures
Construction de Datalake
Mise en production de model de ML
Pipelining de donn√©es
Streaming de donn√©es et temps r√©el
La stack sur laquelle vous travaillerez :
Python, Scala, Spark, Architectures distribu√©es : Hadoop, HDFS, Cloud : Aws, GCP, Azure
Votre profil
A partir de 3 ans d'exp√©rience en CDI
Vous avez une exp√©rience significative sur des probl√©matiques Big Data
Tr√®s bonne comp√©tences en Python et/ou Scala et en Spark
Vous √™tes familier avec Hadoop, Hive, Hbase
Une logique cloud (Aws, GCP ou Azure)
Le salaire & avantages
50-60 K‚Ç¨ selon exp√©rience
RTT
Carte Swile & Mutuelle
3/4 jours de t√©l√©travail par semaine
Et plus encore‚Ä¶
Ce qu‚Äôon pr√©f√®re
√ätre impliqu√© √† fond dans une aventure avec de nombreux challenges techniques
Belles opportunit√©s d'√©volutions sur des postes d'Architecte, de Lead ou de Ml Ops
Tr√®s bonne ambiance, √©quipe solidaire et orient√©e partage d‚Äôinformations
Beaucoup de workshops en interne et catalogue de formations √† votre guise
Ce poste a √©t√© soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d‚ÄôExperts en Recrutement Tech (CDI et clients finaux uniquement) ‚Äì Visitez nous pour plus d‚Äôopportunit√©s :
www.octopusit.fr
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Senior'], 'TypeContract': ['CDI'], 'Salary': ['50'], 'Level': [], 'Experience': ['a', 'n', 's', '7', '7', '7']}"
LinkedIn,Data Engineer (H/F),MP DATA,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-mp-data-3908719610?position=29&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=wOEylaAHBy4c%2BGNI5PQ6tg%3D%3D&trk=public_jobs_jserp-result_search-card,"MP DATA est une soci√©t√© sp√©cialis√©e dans l‚Äôacquisition, le traitement, et la valorisation des donn√©es.
Depuis sa cr√©ation en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance et l‚Äôexploitation de leurs donn√©es.
Les collaborateurs, tous issus de grandes √©coles, incarnent au quotidien les valeurs d‚ÄôExcellence, de Partage et d‚ÄôEngagement.
Ils associent savoir-faire technique, m√©thodologie et passion et mettent leurs comp√©tences au service de missions et projets au sein de grands groupes fran√ßais.
MP DATA accompagne ses clients sur toute la chaine au travers de 3 p√¥les d‚Äôexpertise : Conseil et Strat√©gie, Infrastructure & CloudOPS, Data Science.
Chez MP DATA, les √©quipes commerciales cherchent des missions en fonction des envies des collaborateurs et non pas l‚Äôinverse. Les consultants sont accompagn√©s dans tous leurs projets, de la mobilit√© g√©ographique, au changement de secteur d‚Äôactivit√© en passant par le d√©veloppement de nouvelles comp√©tences.
Rejoindre MP DATA, c‚Äôest la garantie de travailler sur des sujets passionnants avec un cadre technique fort.
Descriptif du poste :
Nous recherchons un Data Engineer exp√©riment√© pour rejoindre notre √©quipe.
En tant que Data Engineer, vous serez responsable de la conception, du d√©veloppement et de la mise en ≈ìuvre de pipelines de traitement de donn√©es en temps r√©el √† grande √©chelle.
Vous travaillerez avec des technologies telles que Kafka, Flink, Kinesis et vous utiliserez les services du cloud AWS pour stocker et traiter les donn√©es.
Vos responsabilit√©s :
Utiliser Kafka pour le traitement de flux de donn√©es en temps r√©el √† grande √©chelle, en travaillant avec les producteurs, les consommateurs et les topics.
Mettre en ≈ìuvre des pipelines de traitement de donn√©es en streaming avec Flink, en appliquant des transformations complexes et en g√©rant les √©tats.
√âcrire du code efficace et maintenable en Java / Python pour manipuler et analyser les donn√©es en temps r√©el.
Utiliser Kubernetes pour d√©ployer et g√©rer des applications conteneuris√©es √† grande √©chelle, en assurant la r√©silience et l‚Äô√©volutivit√© des services.
Utiliser les services AWS tels que Amazon S3, AWS Lambda, Elastic Kubernetes Service (EKS), Elastic Container Service (ECS) et Elastic Compute Cloud (EC2) pour le stockage, le traitement et le calcul des donn√©es en temps r√©el.
Suivre les meilleures pratiques pour une utilisation efficace du cloud, en assurant la gestion des co√ªts, la s√©curit√© des donn√©es et la disponibilit√© des services.
Collaborer avec l‚Äô√©quipe de d√©veloppement logiciel et la gestion de projets pour assurer un flux de d√©veloppement fluide et une livraison efficace des fonctionnalit√©s.
Bon √† savoir :
CDI / ASAP / Toulouse
Profil recherch√©:
Nous recherchons un candidat dipl√¥m√© d'une grande √©cole d'Ing√©nieur avec une premi√®re exp√©rience.
Comp√©tences n√©cessaires :
Exp√©rience significative dans un environnement industriel en mode DevOps, avec des outils tels que CICD, gitlab, Jenkins, Sonar, Nexus, XLdeploy, Camunda, etc.
Ma√Ætrise des langages de programmation tels que Python, Java et expertise dans l‚Äô√©criture et l‚Äôoptimisation du code SQL
Ma√Ætrise du fran√ßais et bonne maitrise de l‚Äôanglais.
Capacit√© √† travailler en √©quipe et esprit d‚Äô√©quipe.
Le processus de recrutement se d√©roule en 3 entretiens :
Prise de contact
1er entretien : Pr√©sentation et projet du candidat + pr√©sentation MP DATA
2√®me entretien : Entretien de qualification technique
3√®me entretien : Rencontre avec les √©quipes dans les locaux MP DATA + Proposition de collaboration
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer (H/F),Technology & Strategy,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-technology-strategy-3881556102?position=30&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=6Bqksdqvzmsz9cNBZny65A%3D%3D&trk=public_jobs_jserp-result_search-card,"D√©couvrez Novencia
:
Expert en Data et Intelligence Artificielle, nous aidons nos clients √† exploiter et √† valoriser leurs donn√©es sous toutes ses formes en les accompagnant sur des projets de Data Analyse, Data Gourvernance, Data Architecture, Data Science, et Data Engineering‚Ä¶
Vous avez une solide exp√©rience de minimum 2 ans dans l'ing√©nierie des donn√©es et vous √™tes √† la recherche de nouveaux d√©fis ? Bouclez votre ceinture, la suite est pour vous !
Type de contrat : CDI
Lieu : Lyon
En qualit√© de Data Engineer (H/F), votre r√¥le sera :
Concevoir et proposer les solutions de d√©veloppement r√©pondant aux besoins fonctionnels et techniques des projets big data.
Tu participes √† la conception de solutions permettant le traitement de volumes importants de pipelines donn√©es.
R√©aliser ces solutions par l‚Äô√©criture de code, en respectant les m√©thodes et proc√©dures qualit√©s d√©finies au sein du d√©partement Technique.
Mise √† disposition s√©curis√© et lisible de la data.
S‚Äôassurer de la conformit√© fonctionnelle et technique de ces r√©alisations en effectuant les tests automatis√©s n√©cessaire et la mise en place de monitoring (syst√®me et qualit√©).
Assurer la maintenance des applicatifs / plateforme data science
Assurer une veille technologique
Vous disposez des comp√©tences suivantes :
Maitrise des plateformes Cloud (AWS, GCP ou Azure), de Scala et de SQL.
Un.e touche √† tout : poss√©dant des comp√©tences en langage Python/Spark, de bonnes capacit√©s de mod√©lisation, une forte app√©tence pour le Big Data
Fin.e connaisseur.euse : Data Engineer convaincu, tr√®s peu de secrets pour les clusters et pour les calculs parall√®les
Explorateur.trice : d√©couvre de nouvelles technos gr√¢ce √† une veille r√©guli√®re
D√©brouillard.e : rel√®ve de nouveaux d√©fis
Notre objectif commun est de co-construire votre carri√®re en fonction de vos aspirations et de vos comp√©tences.
Contactez-moi en message priv√© ou par mail √† s.ziki@technologyandstrategy.com !
Let's make it possible #together
*Nos postes sont ouverts aux personnes b√©n√©ficiant d‚Äôune Reconnaissance de la Qualit√© de Travailleur Handicap√© (RQTH). T&S Groupe encourage la diversit√© et l‚Äô√©galit√© sur le lieu de travail. Tous les candidats qualifi√©s H/F/* sont pris en consid√©ration pour un emploi sur un m√™me pied d'√©galit√©.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,Stage - Data Engineer - ML (H/F),Withings,"Issy-les-Moulineaux, √éle-de-France, France",https://fr.linkedin.com/jobs/view/stage-data-engineer-ml-h-f-at-withings-3613476264?position=31&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=KmvpsR%2BWm3jN8lzOCziUBA%3D%3D&trk=public_jobs_jserp-result_search-card,"Chez Withings, nous d√©veloppons des appareils de sant√© connect√©e : nos balances connect√©es, montres hybrides, tensiom√®tres, moniteurs de sommeil et tous les dispositifs de notre gamme sont aujourd'hui utilis√©s par des millions d'utilisateurs. Notre objectif est de permettre la pr√©vention, le d√©pistage et l'accompagnement d'un certain nombre de maladies chroniques via des produits et des services innovants afin de r√©volutionner la mani√®re dont on prend soin de notre sant√©.
Au sein de l'√©quipe Machine Learning, nous d√©veloppons des algorithmes pour extraire des informations physiologiques et m√©dicales pour nos utilisateurs tels que le SPO2, la fr√©quence cardiaque, la d√©tection de diverses pathologies comme la fibrillation atriale, l'apn√©e du sommeil...
Int√©gr√©.e au sein de l'√©quipe Machine Learning, tu auras une ou plusieurs des responsabilit√©s suivantes :
D√©velopper un outil de monitoring de la dette technique, des mauvaises pratiques de code, des failles de s√©curit√© ;
Construire des dashboards de visualisation ;
Construire un syst√®me d'alerte pour notifier les contributeurs d'√©ventuels probl√®mes ;
D√©velopper des outils permettant de corriger les √©ventuels probl√®mes de fa√ßon automatis√©e ;
Requirements
√Ä la recherche d'un stage d'une dur√©e de 3 √† 6 mois ;
Pr√©paration d'un Master en √©cole d'ing√©nieur ou √©quivalent / ann√©e de c√©sure possible ;
Ma√Ætrise de Python ;
Ma√Ætrise de Debian ou de Ubuntu, de Shell et de l'environnement Linux ;
Premi√®re exp√©rience sur du d√©veloppement logiciel ;
Culture DevOps (omnipr√©sence du monitoring, automatisation des t√¢ches, ...)
Compr√©hension de la culture et des besoins des diff√©rents membres de l'√©quipe ;
Rigueur, autonomie, prise d'initiative, curiosit√©
Benefits
Rejoindre l'aventure Withings, c'est :
Int√©grer un des pionniers et leaders mondiaux de la sant√© connect√©e, plusieurs fois prim√© au Consumer Electronic Show
Contribuer √† des projets innovants et ambitieux pour la sant√© de demain dans un environnement agile et en constante √©volution
Int√©grer une entreprise internationale, membre de la FrenchTech 120, dont les √©quipes sont bas√©es √† Issy-les-Moulineaux, Boston, Hong-Kong et Shenzhen
Participer √† l'am√©lioration continue de nos produits et services en les b√™ta-testant avant leur sortie, notamment lors de nos nombreuses sessions sportives entre coll√®gues
Participer √† la Withings Med Academy en assistant √† des conf√©rences de professionnels de sant√© afin de renforcer ses connaissances dans le domaine m√©dical
Collaborer avec des coll√®gues passionn√©s et c√©l√©brer ensemble chacune de nos r√©ussites !
Toutes les candidatures re√ßues sont √©tudi√©es ind√©pendamment de l'origine ethnique, des croyances, de la religion, du genre, de l'orientation sexuelle ou de la sant√© des candidats. Withings aspire √† offrir et garantir l'√©galit√© des chances aux candidats et seules les personnes habilit√©es (RH et Management) auront acc√®s aux informations concernant votre candidature.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Machine Learning'], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': ['Hybride'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer,Thales,"Ollioules, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-at-thales-3902424527?position=32&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=Fv5mtAMxP79Qn3C6UTqogg%3D%3D&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?
Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr√©sents sur tous les continents. Le Groupe investit dans les innovations du num√©rique et de la ¬´ deep tech ¬ª ‚Äì big data, intelligence artificielle, connectivit√©, cybers√©curit√© et quantique ‚Äì pour construire un avenir de confiance, essentiel au d√©veloppement de nos soci√©t√©s, en pla√ßant l‚Äôhumain au c≈ìur des d√©cisions.
Thales propose des solutions, services et produits qui aident ses clients ‚Äì entreprises, organisations, Etats ‚Äì dans cinq grands march√©s vitaux pour le fonctionnement de nos soci√©t√©s : identit√© et s√©curit√© num√©riques, d√©fense, a√©ronautique, espace, et transport.
QUI ETES-VOUS ?
Dipl√¥m√© d‚Äôun Bac+5 en √©cole d‚Äôing√©nieur ou √©quivalent universitaire avec une sp√©cialisation en informatique, vous avez a
u moins 3 ans d'exp√©rience
dans les technologies Big Data.
Passionn√© par le
secteur de la D√©fense et du Naval.
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
En tant que
Data Engineer,
vous jouerez un r√¥le cl√© dans la conception, le d√©veloppement et la maintenance de notre infrastructure de donn√©es, ainsi que dans la transformation et la gestion des flux de donn√©es.
VOS MISSIONS :
‚Ä¢ Concevoir, d√©velopper et d√©ployer des solutions Big Data en utilisant les technologies
Hadoop, Spark, Scala
.
‚Ä¢ Mettre en place des pipelines de donn√©es performants pour l'ingestion, le traitement et le stockage des donn√©es massives.
‚Ä¢ Collaborer √©troitement avec les √©quipes m√©tier pour comprendre leurs besoins en mati√®re d'analyse de donn√©es et proposer des solutions adapt√©es.
‚Ä¢ Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn√©es.
‚Ä¢ Assurer la qualit√© et la fiabilit√© des donn√©es trait√©es, en mettant en place des processus de validation et de nettoyage.
‚Ä¢ Identifier et r√©soudre les probl√®mes li√©s √† l'infrastructure Big Data et proposer des am√©liorations.
Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.
Show more
Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer - Nantes,Capgemini,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-nantes-at-capgemini-3803998213?position=33&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=AYRkKdnEYMdhl33uV621Ow%3D%3D&trk=public_jobs_jserp-result_search-card,"Capgemini
Choisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations, o√π vous serez soutenu et inspir√© par une communaut√© d‚Äôexperts dans le monde entier, o√π vous pourrez r√©√©crire votre futur. Rejoignez-nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la valeur de la technologie pour les plus grandes organisations et participez √† la construction d‚Äôun monde plus durable et inclusif.
Vos missions :
Int√©gr√©(e) au sein d'une √©quipe projets intervenant pour des clients dans des secteurs d'activit√©s vari√©es, vous serez notamment en charge des missions suivantes :
Concevoir et mettre en oeuvre des strat√©gies s√©curis√©es d'acquisition et d'int√©gration de donn√©es,
Configurer des r√©f√©rentiels de donn√©es √† la pointe de la technologie dans des environnements distribu√©s, majoritairement dans le cloud (Google Cloud Platform, Azure Databricks, AWS) et/ou en environnement Hadoop (distribution MapR, Cloudera, Hortonworks),
Construire des pipelines de donn√©es pour collecter, transformer et traiter des donn√©es en collaboration avec des scientifiques de donn√©es afin de r√©pondre aux exigences de la mod√©lisation de donn√©es d'analyse avanc√©e.
Votre profil :
Dipl√¥me d‚Äôing√©nieur ou √©quivalent universitaire
Minimum 3 ans d'exp√©rience
Anglais courant
Ma√Ætrise des langages Java, Scala ou Python et expertise sur les framework Spark et/ou Hadoop.
Expertise sur les services Cloud Data Platform suivants : Azure Data Lake, Azure synapse, Azure Data Factory, Azure Data Explorer, GCP, AWS, Snowflake, Databricks‚Ä¶
3 raisons de nous rejoindre :
Qualit√© de vie au travail : accord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√©
professionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.
Apprentissage en continu : certifications et formations en libre acc√®s, accompagnement sur mesure avec votre carreer manager, parcours d‚Äôint√©gration sur 9 mois.
Avantages groupe & CSE : plan actionnariat, activit√©s √† tarifs pr√©f√©rentiels, remboursement partiel
vacances, remboursement de votre abonnement sportif ou culturel.
Nos engagements et priorit√©s :
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.
Capgemini
Capgemini est un leader mondial, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d‚Äôexp√©rience, nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Big Data engineer ‚Äì Ing√©nieur des donn√©es massives (H/F),DGSE - Direction G√©n√©rale de la S√©curit√© Ext√©rieure,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-%E2%80%93-ing%C3%A9nieur-des-donn%C3%A9es-massives-h-f-at-dgse-direction-g%C3%A9n%C3%A9rale-de-la-s%C3%A9curit%C3%A9-ext%C3%A9rieure-3778473628?position=34&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=C68Ytx6N93azegb462EtDw%3D%3D&trk=public_jobs_jserp-result_search-card,"Introduction
La Direction G√©n√©rale de la S√©curit√© Ext√©rieure, DGSE, recrute Big Data engineer ‚Äì Ing√©nieur des donn√©es massives (H/F).
Le poste est situ√© √† Paris.
La nationalit√© fran√ßaise est obligatoire.
Domaine m√©tier
Sciences et Technologies
Votre environnement de travail
Le flux de donn√©es trait√©es par la DGSE est √©quivalent √† celui des GAFAM. Ces donn√©es sont au centre du travail des analystes de renseignement, qui doivent pouvoir compter sur des syst√®mes leur permettant de rechercher, croiser, traiter ces donn√©es, en temps r√©el ou en batch. Dans ce contexte, la DGSE cherche √† renforcer ses √©quipes de traitement de la donn√©e massive.
Au sein d'un service centr√© sur le stockage, l'exploitation et la valorisation des donn√©es, nous vous proposons d'int√©grer les √©quipes en charge des plateformes de stockage ou des traitements temps r√©el des donn√©es. Ces √©quipes pluridisciplinaires d√©veloppent et maintiennent de bout en bout diverses plateformes reposant sur les technologies Kafka, Yarn, Hadoop, HBase ou encore Elasticsearch. Plus sp√©cifiquement, l‚Äô√©quipe Stockage administre des entrep√¥ts Big Data ainsi que des couches d‚Äôacc√®s √† leurs donn√©es. L‚Äô√©quipe Temps r√©el con√ßoit des algorithmes r√©pondant √† des besoins de temps de r√©action tr√®s courts (lev√©e d‚Äôalertes, enrichissement √† la vol√©e, r√©ponse √† des besoins op√©rationnels).
En nous rejoignant, vous d√©couvrirez :
un environnement unique, qu'aucune autre structure ne peut vous proposer,
un m√©tier proche du renseignement et de l'op√©rationnel,
une action sur l'int√©gralit√© de la cha√Æne, du d√©veloppement au d√©ploiement en production,
un minimum de 48 jours de cong√©s par an,
une ambiance propice √† l‚Äô√©panouissement professionnel.
Vos missions
Les missions des √©quipes auxquelles vous serez amen√©s √† contribuer seront d√©termin√©es en fonction de votre exp√©rience et de vos app√©tences.
Vous serez en charge de plusieurs activit√©s parmi les suivantes :
concevoir, impl√©menter et optimiser des algorithmes de traitement de donn√©es distribu√©s (Scala, Spark, Java),
garantir le bon fonctionnement, la disponibilit√© et la performance des plateformes de traitement,
participer √† l‚Äô√©volution de l‚Äôarchitecture, en int√©grant de nouveaux composants (frameworks, biblioth√®ques, ‚Ä¶) permettant de mieux r√©pondre aux besoins,
assurer une veille technologique constante pour rester au plus haut niveau et garantir une ad√©quation des clusters existants avec l‚Äô√©tat de l‚Äôart du domaine,
contribuer √† l'am√©lioration continue de l'√©quipe,
interagir avec l‚Äô√©quipe SRE/Devops pour am√©liorer la fiabilit√© des architectures, l‚Äôautomatisation des d√©ploiements et l'observabilit√© des syst√®mes mis en ≈ìuvre.
Votre profil
Vous √™tes titulaire d‚Äôun dipl√¥me en informatique, niveau master ou √©cole d‚Äôing√©nieur, ou pouvez d√©montrer une exp√©rience √©quivalente.
Vous devez poss√©der les comp√©tences et qualit√©s suivantes :
bonnes connaissances fondamentales logicielles (structures de donn√©es, algorithmique, architecture),
ma√Ætrise des langages Scala, Java ou python, vous n'avez pas peur de monter en comp√©tences sur ceux que vous ne ma√Ætrisez pas,
adepte de l'int√©gration continue, vous √™tes familier de Gitlab CI, Github Actions ou Jenkins,
familier avec les bonnes pratiques de d√©veloppement collaboratif (usage de git, pratique de relecture de code).
En bonus :
premi√®re exp√©rience avec un framework de traitement en streaming (SparkStreaming, KStream, Storm, Flink, ...),
convaincu de l'importance de l'observabilit√© des syst√®mes qui regroupe m√©trologie, logging et tracing, vous avez d√©j√† mis en place une stack de ce type (Prometheus, Telegraph, OpenTelemetry, Jaeger, ELK, ‚Ä¶),
familier avec un outil de gestion de configuration (Ansible, Puppet, ...),
exp√©rience sur les clusters Kafka, Hadoop, HBase ou Elasticsearch de plusieurs n≈ìuds.
Les plus de l‚Äôoffre
Contexte d‚Äôactivit√©s unique
Diversit√© des projets
Technologies √† la pointe
Contact
Envoyez-nous votre candidature √† l‚Äôadresse :
dgse-macandidature.cer.fct@intradef.gouv.fr
Plus d‚Äôinformation sur www.dgse.gouv.fr > Nous rejoindre.
RESTEZ DISCRET SUR VOTRE CANDIDATURE A LA DGSE
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Ansible', 'Puppet'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer (F/H),Aubay,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-aubay-3573871076?position=35&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=h3dJGitbn9AqvYtDTfW1hQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Passionn√© par la Data, tu souhaites rejoindre une communaut√© d‚Äôexperts dans le domaine afin de d√©velopper tes comp√©tences en Data Engineering. Aubay renforce ses √©quipes Data et recherche des Data Engineers pour int√©grer des dispositifs de projets pointus et vari√©s.
Ton quotidien en tant que Data Engineer chez Aubay, :
D√©finition de la strat√©gie de stockage et mise en ≈ìuvre des technologie appropri√©es (base de donn√©es SQL, NoSQL, stockage distribu√©,‚Ä¶)
Ingestion des donn√©es (structur√©es, semi-structur√©es ou non-structur√©es) selon diff√©rentes fr√©quences : batch, micro-batch ou temps r√©el
Conception et mise en ≈ìuvre de pipelines de donn√©es afin de fournir des donn√©es pr√™tes √† l‚Äôemploi aux consommateurs : uniformisation, mise en qualit√©, enrichissement, calcul d‚Äôindicateurs,‚Ä¶
Conception et d√©veloppement d‚ÄôAPI pour exposer les donn√©es aupr√®s d‚Äôapplications tierces
Appui aux Data Scientists pour industrialiser et optimiser les algorithmes de Machine Learning
Pr√©paration et animation d‚Äôateliers de travail avec des interlocuteurs vari√©s : recueil/approfondissement des besoins m√©tiers, avancement/restitution des travaux, transfert de comp√©tences,‚Ä¶
Ton profil :
Tu dispose d‚Äôune formation niveau BAC+5 (Master 2 ou √©cole d‚Äôing√©nieur) sp√©cialis√©e en informatique
Tu as d√©j√† une premi√®re exp√©rience significative (a minima 2 ans) en Data Engineering sur des technologies Big Data
Les technologies telles que Hadoop, Spark ou Kafka sont tes technologies de pr√©dilection
La programmation n‚Äôa plus de secret pour toi et tu maitrise parfaitement un ou plusieurs langages de programmation suivants : Java, Scala et Python
Tu ma√Ætrises les tenants et aboutissants de la philosophie DevOps et des outils orient√©s CI/CD
Tu es soucieux de la qualit√© et de la performance de tes d√©veloppements et tu t'int√©resse √† l‚Äôinnovation frugale
Tu es un expert technique dans ton domaine sans pour autant oublier l‚Äôimportance d‚Äôune communication orale et √©crite de qualit√© et adapt√©e √† chacun de tes interlocuteurs
Tu travaille au quotidien en mode agile et tu en maitrise les fondements
Ce qui nous caract√©rise :
Des missions et projets dans le domaine du Data Engineering en nombre et dans des secteurs vari√©s (Banque, Assurance, Telecom, Industrie,‚Ä¶) qui permettent √† nos collaborateurs de monter en comp√©tences et de devenir des experts Data reconnus
De l‚Äôapprentissage en continu avec des formations et des certifications sur les technologies Data d‚Äôaujourd‚Äôhui et de demain
Des experts Data mobilisables pour accompagner et soutenir techniquement les collaborateurs sur leurs projets
Des communaut√©s de savoir-faire Data proposant de mani√®re r√©guli√®re aux collaborateurs d‚ÄôAubay du contenu et des √©v√®nements de partage (webinar, meetup/afterwork, BBL,‚Ä¶) sur les th√©matiques suivantes : Data Engineering, Data Viz, Data Science/IA, Data Platform & Architecture,‚Ä¶
Aubay encourage la diversit√© sous toutes ses formes et garantit l'√©galit√© des chances √† tous les candidats. Tous nos postes sont ouverts aux personnes en situation de handicap et nous proposons tous les am√©nagements n√©cessaires.
Ta carri√®re chez Aubay :
Tu auras la possibilit√© de d√©velopper et certifier tes comp√©tences sur les derni√®res technologies Data avec un focus fort sur les plateformes Data Cloud telles qu‚ÄôAzure Synapse Analytics, Google Cloud Platform, Snowflake et Databricks
Tu pourras rejoindre la BU d‚Äôexcellence Data et √©voluer au sein d‚Äôun environnement humain et professionnel de haut niveau. Tu profiteras d‚Äôun management sur-mesure pour t'accompagner dans ta trajectoire de carri√®re
Au sein de la BU d‚Äôexcellence, de multiples perspectives s‚Äôoffriront √† toi :
R√¥le de ¬´ Lead ¬ª : Vous pourrez gagner en responsabilit√© sur le plan technologique et devenir un r√©f√©rent aupr√®s de nos clients et des collaborateurs de la communaut√© Data Engineering
R√¥le de ¬´ Champion ¬ª : Vous repr√©senterez Aubay aupr√®s d‚Äôun ou plusieurs de nos partenaires √©diteurs strat√©giques et vous participerez activement √† l‚Äôanimation de la relation sur le plan technologique
R√¥le de ¬´ Head ¬ª : Vous pourrez prendre la responsabilit√© du savoir-faire Data Engineering et de ses offres et en assurer le d√©veloppement au sens large (d√©veloppement business, recrutement, management de collaborateurs, d√©finition de la strat√©gie et animation de la communaut√© au sein du groupe Aubay,‚Ä¶)
Besoin d‚Äôen savoir plus sur le processus de recrutement ?
Un √©change macro au niveau RH avec Doriane
Un entretien technique avec Marius ou Peter, deux de nos r√©f√©rents techniques
Un √©change manag√©rial avec le Directeur de la BU Modern BI & Data
A savoir que l‚Äôordre des √©tapes peut varier selon tes envies (ex : √©change manag√©rial avec l‚Äô√©change technique)
Aubay encourage la diversit√© sous toutes ses formes et garantit l'√©galit√© des chances √† tous les candidats. Tous nos postes sont ouverts aux personnes en situation de handicap et nous proposons tous les am√©nagements n√©cessaires.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure', 'Google Cloud Platform'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,Data engineer - F / H,United Robotics Group,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-united-robotics-group-3891680780?position=36&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=nFxE35kmFCphA0TLbxr9wg%3D%3D&trk=public_jobs_jserp-result_search-card,"Bienvenue chez
Aldebaran
, leader europ√©en de la robotique
au sein du groupe
United Robotics Group
.
Nous concevons et industrialisons des robots innovants avec une vision soci√©tale ambitieuse pour fa√ßonner un monde plus humain. Depuis 2005, nous sommes √† l'avant-garde de l'interaction homme-robot avec des produits embl√©matiques tels que NAO et Pepper.
Notre dernier-n√©,
Plato
,
incarne notre engagement envers la technologie de pointe et la s√©curit√©,
fabriqu√© en France avec des composants europ√©ens.
Rejoignez nos √©quipes multiculturelles et dynamiques pour √™tre au c≈ìur de la r√©volution de la robotique.
Si vous √™tes passionn√©.e par la robotique et l'intelligence artificielle, et que vous souhaitez contribuer √† fa√ßonner l'avenir, nous vous offrons une exp√©rience enrichissante et stimulante.
En tant que membre de notre √©quipe, vous b√©n√©ficierez d'une culture d'entreprise ax√©e sur le sens de ce que nous faisons et valorisant la responsabilit√© sociale et environnementale.
Chez Aldebaran, nous valorisons l'innovation, la diversit√© et l'√©galit√© et encourageons chacun.e √† √™tre ouvert.e, authentique, courageux.se, responsable et engag√©.e.
Finalit√© du poste
Au sein de l'√©quipe Cloud-Online Services, le Data engineer int√©grera l'√©quipe Data, responsable du d√©veloppement des produits destin√©s √† la collecte, aux process et √† l'exploitation des donn√©es de nos robots.
Il aura pour r√¥le de d√©finir et d'impl√©menter des services data, sur une infrastructure Cloud AWS, supportant des services en ligne qui g√®rent les robots du groupe.
Missions principales
Le Data engineer aura pour responsabilit√©s de :
√©valuer les choix d'architecture et de solutions techniques lors de la mise en place de PoC,
concevoir et d√©velopper des services Data en respectant la sp√©cification fonctionnelle et la m√©thodologie agile,
agr√©ger et stocker de grandes quantit√©s de donn√©es,
mettre en place des solutions de data processing,
int√©grer/d√©velopper des outils de visualisation de donn√©es et analyser les KPI,
d√©velopper, tester, s√©lectionner et mettre en production des algorithmes qui permettent de r√©pondre aux besoins,
r√©aliser des analyses de donn√©es,
mettre en place des tests de charge et fonctionnels pour les solutions Data,
investiguer et corriger les bugs remont√©s par les utilisateurs,
contribuer √† la mise en place de l'infrastructure et outil de d√©ploiement (CI/CD)
Rejoignez-nous pour faire partie d'une aventure passionnante o√π Pepper, NAO, Plato et leurs futurs successeurs attendent votre contribution pour repousser les limites de la technologie robotique !
Requirements
Pour la bonne ex√©cution des missions confi√©es, vous t√©moignez d'au moins 6 ans d'exp√©rience en tant que d√©veloppeur sur des projets data en Cloud en Python et Spark et avec comme Cloud provider AWS.
Comp√©tences demand√©es :
Bonne compr√©hension des technologies d'infrastructure et de d√©ploiement,
Comp√©tences techniques sur les services AWS : IOT core , Glue, lambda, Kinesis, S3, RDS,
Bonne compr√©hension technique dans la mise en place et l'automatisation de tests de charge et fonctionnels,
Bonne maitrise d'outils BI ou de dashboarding (POWER BI, TABLEAU, QUICKSIGHT)
Bonne connaissance et une exp√©rience pratique de Scrum\Scrumban et des m√©thodes agiles,
Une certification AWS sera appr√©ci√©e,
Un niveau de fran√ßais et d'anglais courant est indispensable,
Des exp√©riences dans des environnements fortement internationaux sont un plus
Benefits
Nos principaux avantages :
Une culture du bien-√™tre en entreprise qui a fait ses preuves (budget c√©l√©bration et moments de convivialit√© par √©quipes et directions, restauration collective de qualit√©, environnement de travail agr√©able)
Un engagement fort en mati√®re de responsabilit√© sociale et environnementale (promotion de l'√©galit√© professionnelle, performance de notre plan diversit√© et inclusion, r√©f√©rent handicap, fresque du num√©rique)
Une culture du t√©l√©travail encadr√©e de mani√®re appropri√©e !
Tous nos postes sont ouverts aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '6', '6', '6']}"
LinkedIn,Data Engineer H/F,Chantelle,"Cachan, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-chantelle-3909775663?position=37&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=B7M58zT%2F%2FcerBjMK2k9%2F7g%3D%3D&trk=public_jobs_jserp-result_search-card,"La Direction des Syst√®mes d'Information et du Digital du groupe Chantelle recherche son/sa futur.e Data Engineer H/F, pour le lancement du grand chantier de r√©novation de l'architecture Data : la bascule de l'int√©gralit√© de son Data Warehouse vers Google Big Query.
Nous souhaitons recruter un Data Engineer H/F confirm√©.e, charg√©.e de contribuer √† la d√©finition de la feuille de route de la Chantelle Data Plaform. En tant que Data Engineer vous travaillerez au sein de l'√©quipe Data Int√©gration en charge de la Chantelle Data Platform.
Vos Missions :
- Mettre en ≈ìuvre une infrastructure autour de Google Cloud Platform permettant de collecter (airbyte, API, ...) , transformer (dataform, Bigquery ...), exposer (dataviz, API, applications, ...) et historiser les donn√©es g√©n√©r√©es par l'entreprise.
- Travailler en √©troite proximit√© avec les responsables des diff√©rents domaines fonctionnels (R√©f√©rentiels, Supply Chain, Manufacturing, B2B, Retail & e-commerce, Finance, ...), avec notre √©quipe de Data Analysts ainsi qu'avec l'√©quipe technique en charge des infrastructures transverses
- √ätre force de proposition sur tous les sujets d'architecture et de mod√©lisation (choix de mise en place de pipeline temps r√©els ou au contraire de flux de donn√©es en mode batch, ou bien encore stockage sur Big Query / Big Table en fonction des cas d'usage).
- D√©finir les √©l√©ments structurants, en justifiant vos choix, et les mettre en ≈ìuvre.
- Rationaliser et moderniser notre architecture d'int√©gration inter-applicative; se projeter sur la cr√©ation d'un mod√®le de donn√©es de type Datamesh.
- Faire la refonte de la BI de nombreux use cases tels que le pilotage de nos stocks, personnalisation de nos sites e-commerce en temps r√©el en fonction de nos profils client, etc‚Ä¶
Stack technique : Google Cloud Platform, BigQuery, DataForm, DataFlow, PubSub, Airbyte, Github ...
Bonne ma√Ætrise des langages Python et SQL
Pourquoi travailler chez Chantelle ?
Une flexibilit√© dans votre lieu de travail, selon la politique de t√©l√©travail de l'entreprise.
11 jours de RTT/an ainsi qu'un 13√®me mois.
Une culture d'entreprise familiale bas√©e sur des valeurs de respect, de cr√©ativit√©, de durabilit√© et de transparence
Une aventure dans laquelle vous pourrez vous √©panouir, apprendre et entreprendre, avec une grande vari√©t√© de missions et beaucoup d'autonomie
Des √©quipes ressources humaines et des managers √† votre √©coute pour vous accompagner dans votre parcours professionnel
Des r√©ductions sur nos produits et des ventes au personnel
Des avantages dans votre qualit√© de vie au travail : une conciergerie compl√®te proposant un large panel de services, des activit√©s en interne, un CSE.
Vous souhaitez rejoindre un Groupe familial, innovant, engag√© et leader dans son secteur en France comme √† l'international et vous souhaitez apporter votre expertise et authenticit√© pour guider votre √©quipe vers le succ√®s : postulez et rejoignez le Groupe Chantelle !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery', 'Big Query'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Cr√©ativit√©', 'Flexibilit√©'], 'EnSoftSkils': []}","{'JobDetail': ['Confirm√©'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer / Developpeur Talend,Siderlog Conseil,"Niort, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-developpeur-talend-at-siderlog-conseil-3861714639?position=38&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=OI1YfXE1D5T6TJRZFOucYA%3D%3D&trk=public_jobs_jserp-result_search-card,"Siderlog est un cabinet de conseil sp√©cialis√© implant√© √† Niort depuis 2004 qui accompagne les directions m√©tiers et SI sur des projets de:
- Business et Data Analyse
- Management de projets
- Conduite du changement
Pour soutenir notre croissance, nous pr√©voyons √† Niort le recrutement de 20 consultants d'ici 2025.
Nos consultants b√©n√©ficient d'un mod√®le qui favorise l'√©panouissement professionnel et le bien √™tre:
üçÉUn processus d'int√©gration sp√©cifique et un suivi r√©gulier
üçÉUne √©coute active des attentes, notamment en terme de formations, certifications
üçÉDes d√©jeuners et √©v√®nements mensuels
üçÉUn management et un accompagnement de proximit√©
üçÉUn package salarial attractif
üçÉLa possibilit√© de contribuer aux projets d'entreprise ( RSE, communaut√©s m√©tiers, p√¥le conseil et expertise)
üçÉEntreprise labellis√©e Happy At Work, charte T√©l√©travail...
üçÉDe nombreux autres avantages que nous vous invitons √† venir d√©couvrir
Siderlog recherche pour renforcer son √©quipe, √† Niort un(e) consultant(e) Data Engineer / Developpeur Talend.
Dans ce cadre vous devrez :
‚úîÔ∏èConcevoir et d√©velopper des traitements/job de donn√©es complexes √† l'aide de Talend pour l'ingestion, le nettoyage, la transformation et la distribution des donn√©es.
‚úîÔ∏èCollaborer √©troitement avec les √©quipes m√©tier pour comprendre les besoins en mati√®re de donn√©es et concevoir des solutions adapt√©es.
‚úîÔ∏èMettre en ≈ìuvre des bonnes pratiques de d√©veloppement ETL, y compris la documentation, les tests unitaires et l'int√©gration continue.
‚úîÔ∏èAssurer la surveillance et la maintenance des traitements/job de donn√©es en production, en r√©solvant les incidents et en effectuant des mises √† jour si n√©cessaire.
üìã Qualifications et comp√©tences :
üëâExp√©rience av√©r√©e dans le d√©veloppement de solutions de gestion et d'int√©gration de donn√©es, sur Talend.
üëâMa√Ætrise des langages de requ√™te SQL pour l'extraction et la manipulation des donn√©es.
üëâConnaissance approfondie des bases de donn√©es relationnelles et des entrep√¥ts de donn√©es.
üëâComp√©tences en programmation avec Java, Python ou d'autres langages similaires.
üëâCapacit√© √† travailler de mani√®re autonome tout en collaborant efficacement avec les membres de l'√©quipe.
üëâExcellentes comp√©tences en communication √©crite et verbale.
üëâMaitrise de l'outil ETL Talend.
üëâExp√©rience avec d'autres outils d'int√©gration de donn√©es tels que Informatica, BODS, Alt√©ryx.
üëâCertification Talend serait un plus.
üëâExp√©rience dans le domaine de l'assurance souhait√©e
Cette offre vous int√©resse ! Postulez !
üèÜüôèüöÄüéâ !
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['Package'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,DATA Engineer (H/F),Boulanger,"Lesquin, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-boulanger-3854554057?position=39&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=rzwJ7eGfBAYHY19wsvY09w%3D%3D&trk=public_jobs_jserp-result_search-card,"Au sein de la direction informatique, le p√¥le DATA a pour missions de maximiser la mise en valeur des donn√©es de BOULANGER ,ELECTRO-DEPOT et KREFEL/HIFI afin d‚Äôaider nos d√©cideurs √† agir sur les leviers de leur performance par des processus d√©cisionnels efficients.
Au sein de ce p√¥le, tu prendras en charge un large domaine m√©tier qu'il te faudra maitriser de bout en bout : de la donn√©es brutes, sa transformation jusqu'√† son exposition dans les reporting. Cela afin d'en assurer le bon fonctionnement, les √©volutions constantes et sa p√©rennit√©
Tes t√¢ches principales portent sur :
Le pilotage et la mise en ≈ìuvre de projets DATA.
La collecte, le stockage et l‚Äôexploitation fluides des donn√©es par le d√©veloppement de solutions
Missions
Maitriser les r√®gles fonctionnelles et les KPI de ton domaine afin de challenger les m√©tiers dans les √©volutions et les nouveaux projets
Accompagner des √©quipes m√©tiers dans leurs travaux d‚Äôidentification et expression des besoins sur la data
Participer aux ateliers de conception et d√©veloppement des applications data
Mod√©liser la solution √† mettre en ≈ìuvre
Concevoir et mettre (ou faire mettre) en ≈ìuvre des flux les pipelines d‚Äôint√©gration (en mode batch ou fil de l'eau) de donn√©es structur√©es/semi-structur√©es
Transformer les donn√©es : consolider, enrichir et optimiser les donn√©es, qui seront exploit√©es par le m√©tier
Cr√©er, faire √©voluer et optimiser les restitutions
Suivre et animer les d√©veloppeurs (ETL, restitution, self-BI internes ou externes)
G√©rer le RUN
Maitrise le SQL et la base de donn√©es (Oracle, Snowflake)
Ma√Ætrise d‚Äôoutils de restitution (tel que Business Object (BO), PowerBI‚Ä¶)
Capacit√© relationnelle, rigueur et dynamisme
Ma√Ætrise un ou plusieurs outils de pr√©paration et traitement de la donn√©e (DataStage, Stambia, ...)
Capacit√© √† s‚Äôadapter √† tout type d‚Äôinterlocuteurs (technique, m√©tiers, Direction)
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['Oracle', 'Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Ing√©nieur Data Talend (F/H),Thales,"V√©lizy-Villacoublay, √éle-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-talend-f-h-at-thales-3890948785?position=40&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=joJb400uS2PS7%2FhJB7d5wA%3D%3D&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?
Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr√©sents sur tous les continents. Le Groupe investit dans les innovations du num√©rique et de la ¬´ deep tech ¬ª ‚Äì big data, intelligence artificielle, connectivit√©, cybers√©curit√© et quantique ‚Äì pour construire un avenir de confiance, essentiel au d√©veloppement de nos soci√©t√©s, en pla√ßant l‚Äôhumain au c≈ìur des d√©cisions.
Thales propose des solutions, services et produits qui aident ses clients ‚Äì entreprises, organisations, Etats ‚Äì dans cinq grands march√©s vitaux pour le fonctionnement de nos soci√©t√©s : identit√© et s√©curit√© num√©riques, d√©fense, a√©ronautique, espace, et transport.
QUI ETES-VOUS ?
Dipl√¥m√© d‚Äôun Bac+5 en √©cole d‚Äôing√©nieur ou √©quivalent universitaire avec une sp√©cialisation en informatique, vous avez au moins 3 ans d'exp√©rience dans les technologies Big Data.
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
En tant que Data Engineer, vous jouerez un r√¥le cl√© dans la conception, le d√©veloppement et la maintenance de notre infrastructure de donn√©es, ainsi que dans la transformation et la gestion des flux de donn√©es.
VOS MISSIONS :
‚Ä¢ Concevoir, d√©velopper et d√©ployer des solutions Big Data en utilisant les technologies Talend.
‚Ä¢ Mettre en place des pipelines de donn√©es performants pour l'ingestion, le traitement et le stockage des donn√©es massives.
‚Ä¢ Collaborer √©troitement avec les √©quipes m√©tier pour comprendre leurs besoins en mati√®re d'analyse de donn√©es et proposer des solutions adapt√©es.
‚Ä¢ Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn√©es.
‚Ä¢ Assurer la qualit√© et la fiabilit√© des donn√©es trait√©es, en mettant en place des processus de validation et de nettoyage.
‚Ä¢ Identifier et r√©soudre les probl√®mes li√©s √† l'infrastructure Big Data et proposer des am√©liorations.
‚Ä¢ Travailler en √©troite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents √† partir des donn√©es.
Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer (Snowflake),MindPal,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-snowflake-at-mindpal-3896992742?position=41&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=tSBp1Wb79voGnfrm%2F3nyZg%3D%3D&trk=public_jobs_jserp-result_search-card,"We are looking for experienced
Data Engineers
with knowledge of
Snowflake
platform.
Responsibilities
Creating and managing data in the Snowflake environment
Designing and implementing ETL (Extract, Transform, Load) solutions for transferring data between various sources and platforms
Optimizing the performance of Snowflake databases, including designing and implementing data structures and using indexes appropriately
Automating data processing workflows using tools such as Airflow or other workflow management tools
Deploying and configuring tools to monitor and report on the performance of the Snowflake system
Requirements
Minimum 1 year of experience as a Data Engineer
Ability to use Snowflake
Very good knowledge of SQL and programming in Python
Ability to work with databases, including the Snowflake platform
Knowledge of ETL tools and data integration
Ability to work in a team and good communication skills
Fluent English in speaking and writing
We Offer
B2B contract type
Full-time job
Remote and flexible working hours
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer Snowflake,Key Performance Consulting (KPC),"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-snowflake-at-key-performance-consulting-kpc-3915036342?position=42&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=87iaB3Zrtg5V1NO0NwSbCQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Rejoignez la plus grosse √©quipe SNOWFLAKE certifi√©e en France !
KPC est Partner Elite Snowflake, le plus haut niveau de certification.
Vous souhaitez int√©grer une ESN √† taille humaine vous permettant de travailler sur des projets challengeant et de monter en comp√©tences ? Ce poste est pour vous !
VOS MISSIONS :
Elaboration d'architectures optimis√©es dans un contexte Snowflake,
Conception et mise en place des ingestions de donn√©es (temps r√©el, Kafka, Snowpipe),
Mod√©lisation de donn√©es (Star Sch√©ma, DataVault, DataMesh, virtualisation) - DataOps
Mise en oeuvre des transformations et de la valorisation des donn√©es (SQL, Python, Java, Scala) - DataOps
Optimisation des performances et des co√ªts d utilisation Snowflake (FinOps)
VOTRE PROFIL :
Vous √™tes issu d'une √©cole d'ing√©nieur ou d'un Master 2
Vous avez une premi√®re exp√©rience sur du Snowflake ou au moins 2 ans de SQL
DEVENEZ NOTRE PROCHAIN(E) Data Engineer Snowflake !
Vous recherchez une entreprise o√π vous pouvez t√©l√©travailler tout en gardant un lien de proximit√©, qui laisse de l‚Äôautonomie, et o√π il fait bon travailler, alors nous vous souhaitons la bienvenue chez KPC.
Vous avez une exp√©rience d'au moins 2 ans en d√©veloppement SQL ou une premi√®re exp√©rience sur Snowflake ?
Vous souhaitez travailler au sein d‚Äôune √©quipe d'experts technico-fonctionnels ?
Rejoignez l‚Äôentreprise KPC ! Une entreprise √† taille humaine avec un mode de management dynamique et de proximit√©.
Notre c≈ìur de m√©tier de KPC : la business intelligence. Nous sommes int√©grateurs de solutions GOLD PARTENAIRE de SAP, Qlik, Microsoft BI, Tableau, Snowflake, Semarchy etc.
Notre gold partenariat nous permet d'offrir des formations certifiantes pour nos collaborateurs, d'avoir des liens de proximit√©s avec les √©diteurs et de revendre leurs solutions.
Rejoignez la plus grosse √©quipe SNOWFLAKE certifi√©e en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification.
Vous souhaitez int√©grer une ESN √† taille humaine vous permettant de travailler sur des projets challengeant et de monter en comp√©tences ? Ce poste est pour vous !
VOS MISSIONS :
Elaboration d'architectures optimis√©es dans un contexte Snowflake,
Conception et mise en place des ingestions de donn√©es (temps r√©el, Kafka, Snowpipe),
Mod√©lisation de donn√©es (Star Sch√©ma, DataVault, DataMesh, virtualisation) - DataOps
Mise en oeuvre des transformations et de la valorisation des donn√©es (SQL, Python, Java, Scala) - DataOps
Optimisation des performances et des co√ªts d utilisation Snowflake (FinOps)
VOTRE PROFIL :
Vous √™tes issu d'une √©cole d'ing√©nieur ou d'un Master 2
Vous avez une premi√®re exp√©rience sur du Snowflake ou deux/trois ans de SQL
PROCESSUS DE RECRUTEMENT :
Vous pensez √™tre celui, celle qu‚Äôil nous faut et vous vous √™tes reconnu dans notre organisation, alors venez vivre votre premi√®re exp√©rience KPC en postulant √† cette offre :
Vous serez appel√©(e) par Ludivine (charg√©e de recrutement) pour une premi√®re prise de contact
Nous pourrons poursuivre les √©changes avec Olivier (Directeur Sud-Ouest) pour l‚Äôapproche projet et technique
Pour clore ce processus de recrutement, nous vous inviterons √† rencontrer Gabriel (Directeur Sud-Ouest)
Et tout √ßa dans un temps record üòä : 15 jours en moyenne pour allier r√©activit√© et efficacit√©.
Nous garantissons l‚Äô√©galit√© des chances pour toutes et tous car pour nous la diversit√© est une force !
KPC EN QUELQUES MOTS ?
Nous sommes une entreprise sp√©cialis√©e dans la Data.
Depuis treize ans, nous accompagnons nos clients √† valoriser leurs donn√©es de mani√®re innovante et efficace pour d√©velopper leur performance, am√©liorer leurs processus et exp√©riences utilisateurs. Nous intervenons en mode projet (50% r√©gie, 50% forfait)
Nous avons d√©velopp√© 3 grandes activit√©s :
ANALYTICS (BI, Data Science/Big Data, Data Gouvernance, EPM, Digital)
ERP SAP
CRM
Pour cela, nous travaillons en partenariat avec les plus grands √©diteurs du march√© tels que : SAP, QLIK, DATAGALAXY, SALESFORCES, SNOWFLAKE, TALEND, MICROSOFT, ONESTREAM, IMAGINO.
En forte croissance, nous cherchons de nouveaux talents pour participer √† cette aventure humaine au service des entreprises de demain.
KPC EN QUELQUES CHIFFRES :
300 collaborateurs
20 % Croissance annuelle
8 agences en France (Aix-en-Provence, Nice, Montpellier, Lyon, Toulouse, Bordeaux, Paris et Nantes)
Des grands groupes en tant que clients : CMA CGM, PERNOD RICARD, AIRBUS, CDISCOUNT, CULTURA, GIFI, POLE EMPLOI, L'OREAL ...
VOS AVANTAGES :
Organisation du travail 100% flexible avec du t√©l√©travail, participation aux frais t√©l√©phonique et internet et un forfait √©quipement fourniture
Un parcours d'int√©gration
Des formations et des certifications avec les √©diteurs sur les technos de pointe
IK voiture, v√©lo
Carte resto, mutuelle, pr√©voyance sant√©
Prime ¬´ Vacances ¬ª
POURQUOI NOUS REJOINDRE ?
Une entreprise √† taille humaine
Un mode de management dynamique, agile et de proximit√©
Une vie d'agence anim√©e, engag√©e et conviviale dans des locaux sympas
Une attention particuli√®re √† un √©quilibre de vie pro / perso
Une entreprise qui encourage les initiatives et l'autonomie
Une entreprise certifi√©e Ecovadis Silver pour des actions concr√®tes en termes de RSE
Un cadre de travail agr√©able prenant en compte les enjeux soci√©taux et environnementaux
Vous √™tes ou voulez √™tre consultant(e), chef de projet, expert(e) technique, manager ? Notre promesse : vous accompagner de fa√ßon personnalis√©e et continue quel que soit votre projet √† court, moyen et long terme.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,Data Engineer (H/F),iPepperGroup,"Valbonne, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ipeppergroup-3894091360?position=43&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=tEwLeqmjPSQfhAClCp4pfA%3D%3D&trk=public_jobs_jserp-result_search-card,"iPepper recrute pour l'un de ses clients une PME √©diteur de logiciel dans le domaine du voyage, un
Data Engineer (H/F)
passionn√©(e) et exp√©riment√©(e) pour rejoindre une √©quipe dynamique.
En tant qu'Ing√©nieur(e) Data, vous serez en charge d'extraire et de transformer des donn√©es, de construire et d'optimiser des pipelines de donn√©es, ainsi que de concevoir des visualisations de donn√©es intuitives et informatives.
Responsabilit√©s :
Concevoir, construire et maintenir des pipelines de donn√©es √©volutifs et efficaces pour transf√©rer des donn√©es entre des bases de donn√©es SQL et NoSQL.
D√©velopper et mettre en ≈ìuvre des processus ETL pour extraire, transformer et charger des donn√©es √† partir de diff√©rentes sources dans notre entrep√¥t de donn√©es.
Collaborer avec des √©quipes pluridisciplinaires pour comprendre les besoins en donn√©es et garantir la fourniture r√©ussie de solutions de donn√©es.
Optimiser et ajuster les pipelines de donn√©es existants pour la performance et la fiabilit√©.
Concevoir et d√©velopper des visualisations de donn√©es et des tableaux de bord pour fournir des insights exploitables aux parties prenantes.
Surveiller et r√©soudre les probl√®mes de pipelines de donn√©es, en veillant √† la qualit√© et √† l'int√©grit√© des donn√©es.
Profil recherch√© :
Dipl√¥me universitaire en informatique, en ing√©nierie ou dans un domaine connexe.
Exp√©rience av√©r√©e en tant que Data Engineer ou dans un r√¥le similaire, avec un accent particulier sur la construction de pipelines de donn√©es et de processus ETL.
Compr√©hension solide des bases de donn√©es
SQL
et
NoSQL
, y compris la mod√©lisation des donn√©es et la conception de sch√©mas.
Ma√Ætrise des langages de programmation tels que
Python, Java ou Scala.
Exp√©rience avec des outils de visualisation de donn√©es tels que
Tableau, Power BI.
Solides comp√©tences en analyse et en r√©solution de probl√®mes, avec la capacit√© de traduire des donn√©es complexes en insights exploitables.
Excellentes comp√©tences en communication et en collaboration, avec la capacit√© de travailler efficacement dans un environnement d'√©quipe pluridisciplinaire.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication', 'R√©solution de probl√®mes', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Ing√©nieur Data (H/F) | POEI,DataScientest.com,"Puteaux, √éle-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-h-f-poei-at-datascientest-com-3909360157?position=44&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=FHcjn5vGWt2bAC0sneS4jg%3D%3D&trk=public_jobs_jserp-result_search-card,"Ing√©nieur Data (H/F) | POEI
Puteaux
CDI
Postuler
Retour
Datascientest Is Hiring!
Ing√©nieur Data (H/F) | POEI
√Ä propos
DATASCIENTEST ? LA REFERENCE EN DATASCIENCE
Cr√©√©e en 2017, DataScientest r√©volutionne la formation en Data Science et devient leader en France !
Notre √©cole compte plus de 6 000 apprenants √† son actif, et a s√©duit 50 entreprises dont une trentaine du CAC40 et des leaders internationaux (BCG, Allianz, Christian Dior, Axa‚Ä¶),
Nous formons aussi les demandeurs d'emploi en leur offrant un CDI au sein de nos entreprises partenaires
Pr√©sents en Espagne et en Allemagne, notre p√©dagogie repose sur une structure hybride :
Qui allie l‚Äôadaptabilit√© du distanciel avec une plateforme enti√®rement con√ßue par nous-m√™me et
La motivation du pr√©sentiel avec des s√©ances de coaching anim√©es par nos enseignants data scientists !
Descriptif du poste
En Tant Qu'Ing√©nieur Data, Vous Serez Charg√©(e) De Proposer Les Meilleures Solutions √† L'entreprise En Leur Permettant D'optimiser Leur Activit√©, √† Travers Quelques Missions Principales
D√©velopper des solutions pour traiter des volumes importants de donn√©es,
Concevoir, collecter et fabriquer des donn√©es brutes,
Cr√©er des outils et algorithmes pour le traitement des donn√©es,
Pr√©parer des donn√©es pour le Data Analyst,
S√©curiser des Pipelines donn√©es pour les Data Analysts et Data Scientists,
Organiser l'architecture du cloud,
Contribuer √† l'effort d'animation technique, de veille technologique et d'innovation
Profil recherch√©
Et si nous parlions de vous ?
Issu(e) d‚Äôune fili√®re scientifique bac+5 ou d‚Äôun dipl√¥me d‚Äôing√©nieur,
Vous disposez id√©alement d‚Äôune exp√©rience significative en d√©veloppement informatique, en architecture r√©seaux ou dans la Data,
Vous ma√Ætrisez un langage objet type Java, Python, C++, etc.
Vous √™tes demandeur d'emploi
N'attendez plus, envoyez nous votre CV, nos √©quipes se feront un plaisir de vous contacter et de vous accompagner pour pr√©parer vos entretiens avec notre entreprise partenaire.
Informations compl√©mentaires
Type de contrat : CDI
Lieu : Puteaux
Niveau d'√©tudes : Bac +5 / Master
Exp√©rience : > 1 an
T√©l√©travail ponctuel autoris√©
Salaire : entre 38000‚Ç¨ et 48000‚Ç¨ / an
Vous √™tes int√©ress√© par cette offre ?
Postuler
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Adaptabilit√©'], 'EnSoftSkils': []}","{'JobDetail': ['Hybride'], 'TypeContract': ['CDI'], 'Salary': ['38000'], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer DevOps H/F,Inetum,"Courbevoie, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-devops-h-f-at-inetum-3843956952?position=45&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=LN1KQRS61sKKEPaDT%2FUBBA%3D%3D&trk=public_jobs_jserp-result_search-card,"D√©tail de l'offre
Informations g√©n√©rales
Entit√© de rattachement
Nous sommes une ESN agile, un groupe international certifi√© Top Employer Europe 2024.
A l'√®re de la post-transformation digitale, nous mettons tout en ≈ìuvre pour que chacun de nos 28 000 athl√®tes du digital puisse se renouveler perp√©tuellement, en vivant positivement son propre flow digital.
Chacun de nos talents peut ainsi fa√ßonner son parcours de carri√®re selon ses app√©tences, entreprendre de mani√®re pragmatique avec ses clients pour un monde √† impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-√™tre personnel.
Rejoignez Inetum. Live your positive digital flow.
Tous nos postes sont ouverts aux personnes en situation de handicap.
Description du poste
M√©tier
Conseil et Int√©gration - Business Consulting
Intitul√© du poste
Data Engineer DevOps H/F
Contrat
CDI
Description De La Mission
Qui sommes-nous ?
Nous sommes une ESN agile et un groupe international. A l'√®re de la post-transformation digitale, nous mettons tout en ≈ìuvre pour que chacun de nos 27 000 collaborateurs puisse se renouveler perp√©tuellement, en vivant positivement son propre flow digital. Chacun d'entre eux peut ainsi fa√ßonner son parcours de carri√®re selon ses app√©tences, entreprendre de mani√®re pragmatique avec ses clients pour un monde plus positif, innover localement dans 26 pays et harmoniser son investissement professionnel et son bien-√™tre personnel.
Rejoignez
Capital Market, entit√© Inetum en Finance de March√©
. Nous accompagnons les acteurs majeurs du secteur de la finance en France et √† l‚ÄôInternational.
Cultivant la double comp√©tence technique et fonctionnelle, nous intervenons sur des projets innovants √† haute valeur ajout√©e.
Quelles sont nos valeurs ?
üèÜ Excellence Notre culture de l‚Äôexcellence na√Æt de notre audace.
ü§ù Engagement S‚Äôassocier et grandir ensemble !
üõ∞ Innovation Nos FabLab au service de la transformation digitale de nos clients.
Missions propos√©es
Pour accompagner notre forte croissance, nous recherchons des
Data Engineer DevOps
pour le compte d‚Äôun acteur majeur de la finance de march√© en Europe et dans le monde. Dans ce contexte international et exigeant, vous travaillez sur la conception de solutions Big Data afin de r√©pondre aux besoins des op√©rationnels m√©tiers.
Pour mener √† bien ce projet, vous aurez pour responsabilit√©s de
Comprendre les enjeux des √©quipes Data et les accompagner. Faire le lien entre les environnements (datalake, datawarehouse et environnement de d√©ploiement du mod√®le) gr√¢ce √† des pipelines sophistiqu√©s
√ätre r√©f√©rent et garant des bonnes pratiques pour le d√©veloppement des langages utilis√©s par l'√©quipe. Accompagner les Data Scientists dans l'optimisation de leurs algorithmes
Assurer la viabilit√© des solutions de datamining et de machine learning de l'√©quipe Data et les mettre en production.Construire et optimiser des pipelines de donn√©es complexes (ETL et ELT)
Coordonner le d√©veloppement et les op√©rations gr√¢ce √† l‚Äôautomatisation des flux de travail, la cr√©ation de services Web pr√©dictifs.
D√©ployez ces mod√®les en utilisant les derni√®res techniques et pratiques (API REST, Docker, Tensorflow Serving, etc.)
Analyser et r√©soudre les anomalies li√©es aux performances et √† l‚Äô√©volutivit√© des solutions Cloud BI et Big Data
Profil
Profil souhait√©
De formation Ing√©nieur Grande Ecole ou √©quivalent, vous poss√©dez une premi√®re exp√©rience r√©ussite de trois ans minimum sur un poste √©quivalent id√©alement en banque d‚Äôinvestissement ou asset management.
Vous √™tes familier avec l‚Äôenvironnement Big Data (data grids, compute grids, REST based architectures, SGBDR, No-SQL Databases, GPUs)
Vous avez d√©j√† travaill√© avec la m√©thodologie Agile
Une certaine aisance technique est √©galement requise (Jenkins, Docker, Ansible, Git, Scala, Kubernetes, Python/Java, Maven)
Une double comp√©tence Cloud (AWS, Google Cloud, Azure) serait un v√©ritable plus
Evoluant dans un contexte international, la ma√Ætrise de l'Anglais est n√©cessaire.
L‚Äôaisance relationnelle, de l‚Äôautonomie, la gestion des priorit√©s, des capacit√©s d‚Äôanalyse et de synth√®se, ‚Ä¶ le savoir-√™tre est une composante importante dans notre processus de recrutement.
Tous nos postes sont ouverts aux personnes en situation de handicap.
Et pourquoi Inetum Capital Market ?
üòÑ Des missions int√©ressantes
ü§© Des perspectives d'√©volutions professionnelles et financi√®res
üòé Les avantages d'un grand groupe international
üòâ Un suivi r√©gulier
‚úàÔ∏è Une aide √† la mobilit√© g√©ographique que vous soyez localis√© en France ou √† l'√©tranger
üë®‚Äçüéì Des formations certifiantes
ü•≥ Des moments de FUN !
Localisation du poste
Localisation du poste
France, Ile-de-France, 75 Paris
Ville
Courbevoie
Crit√®res candidat
Niveau d'√©tudes min. requis
Bac+5
Niveau d'exp√©rience min. requis
Plus de 2 ans
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['TensorFlow'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,D√©veloppeur Big Data Junior H/F,Inetum,"St.-Ouen, √éle-de-France, France",https://fr.linkedin.com/jobs/view/d%C3%A9veloppeur-big-data-junior-h-f-at-inetum-3887272015?position=46&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=GY4l3RNWLP3B0lXdrBu2dw%3D%3D&trk=public_jobs_jserp-result_search-card,"D√©tail de l'offre
Informations g√©n√©rales
Entit√© de rattachement
Inetum est un leader europ√©en des services num√©riques. Pour les entreprises, les acteurs publics et la soci√©t√© dans son ensemble, les 28 000 consultants et sp√©cialistes du groupe visent chaque jour l'impact digital des solutions qui contribuent √† la performance, √† l'innovation et au bien commun.
Pr√©sent dans 19 pays au plus pr√®s des territoires, et avec ses grands partenaires √©diteurs de logiciels, Inetum r√©pond aux enjeux de la transformation digitale avec proximit√© et flexibilit√©.
Port√© par son ambition de croissance et d'industrialisation, Inetum a g√©n√©r√© en 2023 un chiffre d'affaires de 2,5 milliards d'‚Ç¨.
Pour r√©pondre √† un march√© en croissance continue depuis plus de 30ans, Inetum a fait le choix d√©lib√©r√© de se recentrer sur 4 m√©tiers afin de gagner en puissance et proposer des solutions sur mesure, adapt√©es aux besoins sp√©cifiques de ses clients le conseil (Inetum Consulting), la gestion des infrastructures et applications √† fa√ßon (Inetum Technologies), l'impl√©mentation de progiciels (Inetum Solutions) et sa propre activit√© d'√©diteur de logiciels (Inetum Software). Inetum a conclu des partenariats strat√©giques avec 4 grands √©diteurs mondiaux - Salesforce, ServiceNow, Microsoft et SAP et poursuit une strat√©gie d'acquisitions d√©di√©e afin d'entrer dans le top 5 europ√©en sur ces technologies et proposer la meilleure expertise √† ses clients.
Tous nos postes sont ouverts aux personnes en situation de handicap.
Description du poste
M√©tier
Conseil et Int√©gration - Conseil Technique
Intitul√© du poste
D√©veloppeur Big Data Junior H/F
Contrat
CDI
Description De La Mission
Nous sommes une ESN agile, un groupe international certifi√© Top Employer Europe 2023.
A l'√®re de la post-transformation digitale, nous mettons tout en ≈ìuvre pour que chacun de nos 28 000 athl√®tes du digital puisse se renouveler perp√©tuellement, en vivant positivement son propre flow digital.
Chacun de nos talents peut ainsi fa√ßonner son parcours de carri√®re selon ses app√©tences, entreprendre de mani√®re pragmatique avec ses clients pour un monde √† impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-√™tre personnel.
Rejoignez Inetum. Live your positive digital flow.
Tous nos postes sont ouverts aux personnes en situation de handicap
A la recherche de d√©veloppeurs Big Data juniors pour rejoindre notre √©quipe. Les candidats doivent √™tre des ing√©nieurs Big Data passionn√©s et motiv√©s, capables de travailler en √©quipe et de r√©soudre des probl√®mes complexes.
Responsabilit√©s
Participer √† la conception et au d√©veloppement de solutions Big Data
Travailler en √©troite collaboration avec les √©quipes de d√©veloppement pour int√©grer les solutions Big Data dans les applications existantes
Participer √† la mise en place de l'architecture Big Data
D√©velopper des scripts et des programmes pour automatiser les t√¢ches de traitement de donn√©es
Participer √† la maintenance et √† l'am√©lioration des solutions Big Data existantes
Profil
Comp√©tences requises
Connaissance des technologies Big Data telles que Hadoop, Hive, Iceberg, Kafka, Spark, Cloudera, Databricks, Snowflake
Ma√Ætrise d'au moins un langage de programmation parmi Scala et Java
Connaissance des environnements Cloud tels que AWS, Azure serait un plus
Dipl√¥me d'ing√©nieur ou Master 2 en informatique ou en statistiques
Une premi√®re exp√©rience en d√©veloppement Big Data serait un plus
Profil recherch√©
Nous recherchons des candidats passionn√©s par les technologies Big Data, ayant une bonne capacit√© d'analyse et de r√©solution de probl√®mes. Les candidats doivent √™tre capables de travailler en √©quipe et de communiquer efficacement avec les autres membres de l'√©quipe.
Pourquoi nous rejoindre ?
Rejoindre Inetum, Certifi√© TOP EMPLOYER EUROPE 2024, c'est
Faire partie d'une √©quipe √† taille humaine, soud√©e, encourageant la diversit√© des profils et des exp√©riences et favorisant l'autonomie et l'initiative de chacun ;
Avoir un impact chez nos clients en √©tant responsabilis√© dans le cadre de missions √† forts enjeux et sur un large panel d'activit√©s ;
S'int√©grer dans une dynamique de croissance et de d√©veloppement de notre marque de conseil.
Nous vous proposons
Une trajectoire de carri√®re personnalis√©e et adapt√©e √† vos souhaits d'√©volution gr√¢ce √† une implantation √† l‚Äôinternational (26 pays, 7 Fablab), des formations cibl√©es et des projets couvrant l‚Äôensemble de la cha√Æne de valeur IT (+25 fili√®res m√©tiers)
Int√©grer un collectif d‚Äôexperts partageant des valeurs de solidarit√© et d‚Äôexcellence
Une culture de la proximit√© au sein de nos 45 agences en France
Localisation du poste
Localisation du poste
France, Ile-de-France, 75 Paris
Ville
5-7 rue Touzet Gaillard - 93400 Saint-Ouen-sur-Seine
Crit√®res candidat
Niveau d'√©tudes min. requis
Bac+5
Niveau d'exp√©rience min. requis
Moins de 2 ans
Show more
Show less","{'ProgLanguage': ['Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Statistiques', 'Cloud'], 'FrSoftSkills': ['R√©solution de probl√®mes', 'Collaboration', 'Flexibilit√©'], 'EnSoftSkils': ['Collaboration', 'Initiative']}","{'JobDetail': ['Junior'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '30', '30', '30']}"
LinkedIn,Data engineer python,FINAXYS,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-python-at-finaxys-3887107285?position=47&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=eBg06AwxyNxRUXDsMZTakg%3D%3D&trk=public_jobs_jserp-result_search-card,"LE CONTEXTE
Leader en
IT
, dans les domaines Banque
,
Finance
et
Assurance
,
Finaxys
est un cabinet de
conseil
cr√©√© en 2008. Nous accompagnons au quotidien les plus grandes banques du pays sur leur
transformation digitale
(BNP Paribas, Soci√©t√© G√©n√©rale, Cr√©dit Agricole, Natixis, etc.)
Nos clients bancaires travaillent √©galement dans des contextes Big Data sur des applications centrales rattach√©es aux Datalakes.
LES MISSIONS
D√©veloppement et traitements sur des applications Big Data (Python)
√ätre force de proposition sur les choix techniques les plus pertinents
Maintenir la qualit√© des solutions, mesure de cette qualit√©, alerte sur les non-conformit√©s et validation des solutions d√©finitives.
Analyser des risques li√©s aux solutions envisag√©es et proposition des actions de rem√©diation.
Apporter des solutions IT r√©pondant au mieux aux besoins du business port√© par la/le Product Owner (M√©tiers/Fonctions) en cherchant toujours la maximisation de la valeur g√©n√©r√©e
Accompagner les √©quipes dans les migrations Cloud
ENVIRONNEMENT TECHNIQUE
Python
Pandas
Scirpting Big Data
Culture DevOps (Jenkins, Maven, Ansible)
PROFIL
Comp√©tences Techniques et Fonctionnelles requises
Maitrise obligatoire de l‚Äôanglais
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer (F/H),Renault Digital,"Boulogne-Billancourt, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-renault-digital-3911202728?position=48&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=ZkQXgjIjA2SgSdRtYuvyYA%3D%3D&trk=public_jobs_jserp-result_search-card,"Contexte :
Dans le cadre de son programme Industrie 4.0, Renault d√©veloppe depuis 2017 sa propre plateforme pour connecter et agr√©ger les donn√©es industrielles des 22 sites du Groupe et de plus de 2500 machines.
Fort de partenariats strat√©giques sign√©s avec Google Cloud (stack data full GCP), Renault Digital est √† la recherche d‚Äôun(e) Data Engineer au sein du P√¥le Architecture et Data pour mettre en place des cha√Ænes de traitement de donn√©es r√©pondant √† de nouveaux besoins m√©tiers.
Vous collaborerez au jour le jour avec les √©quipes m√©tiers ainsi qu‚Äôavec les autres fonctions du P√¥le Architecture & Data (Data Analysts et Scientists, architectes, ‚Ä¶), exploitant des t√©raoctets de donn√©es (√©v√©nements en mode streaming, traitements en batch et temps r√©els et les appels aux APIs) afin entre autres d‚Äôalimenter des mod√®les de machine learning (segmentation clients, d√©tection automatiquement des pannes des v√©hicules, ‚Ä¶).
Responsabilit√©s principales :
Vous participez aux phases de framing, MVP et release des produits, services et APIs orient√©s data ;
Vous argumentez les choix d‚Äôarchitecture des projets et de la plateforme datalake sur GCP ;
Vous contribuez √† la valeur m√©tier des produits orient√©s Data s‚Äôappuyant sur le Datalake, en mettant en place des cha√Ænes bout en bout de traitement de la data, de l‚Äôingestion √† l‚Äôexposition d‚ÄôAPIs et √† la visualisation des donn√©es et des solutions ML/DS ;
Vous √™tes garant de la qualit√© des donn√©es transform√©es dans le Datalake, du bon fonctionnement des cha√Ænes de traitement et de l‚Äôoptimisation de l‚Äôutilisation des ressources des ressources cloud ;
Vous proposez des standards d‚Äôarchitecture et de d√©veloppement ;
Vous √™tes force de proposition, innovant(e) et bienveillant(e).
Environement technique :
Spark, Scala, Python, Java, Airflow, SQL, Google Cloud Platform (BigQuery, Cloud Storage, PubSub, Beam, Dataflow, Cloud ML, TensorFlow, Kubernetes), Git, Docker, JSON, Bash, Spotfire
Profil recherch√© :
Vous avez minimum 5 ans d‚Äôexp√©rience en tant que Data Engineer ;
Vous disposez d‚Äôune exp√©rience en d√©veloppement Spark, Scala, Python et requ√™tage SQL sur des gros volumes de donn√©es ;
Vous avez une app√©tence pour la data : validation, transformation, analyse, valorisation ;
Vous poss√©dez une exp√©rience de d√©veloppement et orchestration de chaines ETL complexes via Airflow ou √©quivalent ;
Vous pratiquez la m√©thodologie agile (Agile Scrum et/ou Kanban) ;
Vous utilisez les services cloud (pr√©f√©rablement GCP) ;
Vous √™tes capable d‚Äô√©changer en anglais technique √©crit et oral.
Informations compl√©mentaires :
Votre poste sera bas√© √† Boulogne-Billancourt (France) en CDI (temps plein)
Vous b√©n√©ficiez de 2 √† 3 jours de t√©l√©travail par semaine
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go', 'Bash'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': ['TensorFlow'], 'DataSerialization': ['Json'], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Temps plein', 'Full'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Data Engineer - Internship,Equativ,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-internship-at-equativ-3821045783?position=49&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=%2FuGqbRz65o7d93Q2HdgHZQ%3D%3D&trk=public_jobs_jserp-result_search-card,"üë´ About the team
At Equativ, we‚Äôre on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 3 millions requests per second managed by 3,000 servers.
Our innovation team based in Paris, Nantes, Limoges, Krakow and Berlin is composed of 100+ straightforward and energetic engineers working in an Agile environment and ready to tackle the most complex technical challenges.
Our data engineering team is composed of 8 skilled engineers and is based in Paris. We are part of the R&D department which is composed of 120+ engineers spread across Paris, Nantes, Limoges, Krakow and Berlin all working in an Agile environment and ready to tackle the most complex technical challenges.
The data engineers are split in two sub-teams working in close collaboration:
Pipeline team: Maintaining and enhancing the operationality of our on-premise and cloud data pipelines which feed our warehouses and APIs
Feature team: Apply best in class data modeling and orchestrating data transformations in our warehouses, leading the day-to-day management of these warehouses
Our Mission üëá
Our Data Engineering team is central to Equativ‚Äôs data centric business and is responsible to ingest, transform, model and redistribute all data coming from our ad tech platform.
We aim at building scalable and robust Big Data platforms from ingestion to business actionable consumption. Our Big Data ecosystem must handle huge volumes (15 Tb per day), short & long term data storage, complex data modeling, real-time and batch ELT as well as providing external access through dedicated APIs.
We enhance and deliver Equativ data directly to our customers and throughout the company whether it is for BI analysis, data science models feeding, customer reporting, invoicing and more.
We rely on a top tier on-premise & cloud stack (Kafka, Flink, ClickHouse, Bigquery, Dataflow, Airflow, DBT‚Ä¶) and work hard to increase reporting capabilities, lower maintenance time, improve performances and simplify the access to our raw data.
What you'll do ‚úèÔ∏è
As a data engineer intern, you will be supporting one of the two sub-team (pipeline or feature) in their tasks and projects:
Take a leading part on a data engineering project such as but not limited to:
Proof of Concept of Clickhouse Cloud
Improvement of the data transformation process with DBT, BigQuery and Airflow
Development of new functionalities on our internal tools (APIs, software applications)
Setup a data lineage application (castor doc)
Support the data engineering team in their day-to-day activities:
Enhance our DevOps process with CI/CD and testing framework
Monitor performances and workflow of our applications using reporting tool (Grafana)
Take part in improving and deploying data engineering standards, documentation and operational guidelines around data usage at Equativ
üí™ About you
Master degree in Computer Science or similar technical field of study
Prior experience in data or software development related environment is desired
Experience with a cloud datawarehouse (BigQuery, Snowflake, Databrick,..) is a plus
Good knowledge of SQL and one other data programming language (Java preferred, Python, Scala..).
Knowledge on the software development process (Git, CI/CD, test, scrum)
Working proficiency and communication skills in verbal and written English
Strong interest in big data and cloud computing technologies.
üëã About us
Equativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus ‚Äî four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.
Headquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.
The company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times‚Äô FT 1000: Europe‚Äôs Fastest-Growing Companies.
Equativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.
Come and lead the charge with us in building a transparent ecosystem based on quality!
Equativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'Big Data', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer (H/F) - Lille - CDI,METEOJOB by CleverConnect,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-lille-cdi-at-meteojob-by-cleverconnect-3858145866?position=50&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=Yq6xoHndecJYfbsKu%2F1jGg%3D%3D&trk=public_jobs_jserp-result_search-card,"Entreprise
Chez LJE Solutions, nous pla√ßons l‚Äôhumain au c≈ìur de chaque projet. Au-del√† des comp√©tences, nous valorisons les
aspirations
et les
valeurs
de chaque individu.
Nous intervenons dans tous les secteurs d'activit√© en France et en Suisse.
Description Du Poste
LJE Solutions recherche pour un de ses clients bas√© √† Lille, un/une Data Engineer.
Notre client est une
ESN dynamique bas√©e √† Lille, qui se distingue dans l'int√©gration et la restitution de donn√©es. Partenaire privil√©gi√© de technologies de pointe comme Power BI, Tableau et Qlik, il recherche des talents d√©sireux de participer √† notre aventure entrepreneuriale.
Nous recherchons un Data Engineer curieux et motiv√© pour jouer un r√¥le cl√© dans l'organisation et le d√©veloppement de l'agence. Ce poste offre une opportunit√© unique de travailler directement avec les fondateurs, experts en technologies, et de contribuer significativement √† la formation interne et √† l'expertise chez nos clients.
Vos Responsabilit√©s
Travailler en √©troite collaboration avec les fondateurs sur des projets d'int√©gration et de restitution de donn√©es,
Participer activement √† la croissance de l'entreprise en apportant des id√©es innovantes et en prenant part √† des projets vari√©s,
Monter en comp√©tence techniquement, avec la possibilit√© d'√©voluer vers des r√¥les de Team Lead ou Tech Lead selon vos aspirations.
Cette entreprise offre un environnement convivial et ambitieux, encourageant la prise d'initiative. Leur structure √† taille humaine valorise chaque collaborateur, avec une approche personnalis√©e et une hi√©rarchie plate qui favorise l'expression et la participation active de tous.
R√©mun√©ration Et Avantages
Poste bas√© √† Lille, avec possibilit√© de t√©l√©travail partiel,
R√©mun√©ration comp√©titive bas√©e sur l'exp√©rience, fourchette indicative de 44k √† 48k ‚Ç¨ en fixe, + variables,
Tickets restaurant,
Mutuelle d'entreprise.
Description Du Profil
Passion pour les technologies de la data, avec une expertise ou un int√©r√™t pour XDi et Talend, sans exclure d'autres ETL du march√©,
Plus de 4 ans d'exp√©rience dans le domaine de la data engineering,
Curiosit√© intellectuelle, agilit√©, excellent savoir-√™tre, forte capacit√© de travail en √©quipe et de partage de connaissances,
Localisation √† Lille ou disposition √† d√©m√©nager, avec une pr√©f√©rence pour les candidats de la r√©gion pour faciliter la collaboration et le partage au sein de notre agence physique.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data Engineer,Digital Waffle,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-digital-waffle-3913824888?position=51&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=8uQpOuoHSTAxlgIAc6XcKw%3D%3D&trk=public_jobs_jserp-result_search-card,"Digital Waffle is proud to have partnered with an innovative tech startup in Paris, who are looking for a talented Data Engineer to join their growing team!
They are made up of a powerhouse of experts, combining
data engineers, business process gurus, and Project managers
who leverage the most advanced solutions available; utilising process mining, automation tools, and smart execution systems.
Looking for an experienced Data Engineer (3-5 years)
What You'll Do:
This is a full-time,
hybrid role (Paris-based)
where you'll wear many hats: data exploration, system integration, data prep, data modeling, and implementing data solutions.
Experience:
Expertise in data engineering, data modeling, and ETL (Extract, Transform, Load) processes
Data warehousing and data analytics skills
Experience handling large, complex datasets
Proficiency in SQL and programming languages like Python or Java
Stellar problem-solving and analytical skills
Top-notch communication and collaboration abilities
Bachelor's or Master's in Computer Science, Information Systems, or a similar field (a plus for process mining or intelligent process automation experience)
If you are an experienced and driven Data Engineer, please apply here!
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': ['Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer H/F,Ippon Technologies,Greater Nantes Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ippon-technologies-3902436649?position=52&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=DqSfWwLB6EnRE5u%2BjZ6DkA%3D%3D&trk=public_jobs_jserp-result_search-card,"Envie de rejoindre la communaut√© DATA la plus dynamique de France ?
Notre sp√©cialit√© est de construire des data platform dans le Cloud public avec les meilleurs technos du moment : Snowflake, Databricks, Matillion, DBT.
Membre de la Practice Data, le/la futur(e) Data Engineer sera int√©gr√©(e) √† nos √©quipes de conseil et sera suivi(e) par un(e) mentor qui l‚Äôaidera √† monter en comp√©tences.
Votre champs d‚Äôexpertise :
Intervenir sur les data platforms de nos clients pour d√©velopper de nouveaux pipelines de donn√©es (ingestion, traitement, exposition).
Travailler en collaboration avec les m√©tiers et les data scientists pour leur fournir un support √† l‚Äôindustrialisation de leurs travaux (tests, int√©gration continue, scalabilit√© des mod√®les, craftsmanship etc‚Ä¶)
D√©ployer des infrastructures cloud full
infra-as-code
(Terraform, CloudFormation).
Participer aux √©v√®nements internes √† la communaut√© data (BBL, webinar, datap√©ro interne, meetup, blog, dojos) et externes (Salon du Big Data, GCP Summit, Spark Summit, AWS Summit, Devoxx, workshop partenaire, meetups).
Capitaliser sur les missions et les diff√©rents √©v√®nements de la communaut√© au travers d‚Äôarticles de blogs, REX, BBL interne.
Vos connaissances :
Un framework de calcul distribu√© tel que Spark, Storm, Flink.
Un ou plusieurs langages de programmation (Python, Scala, Java...)
Diff√©rents syst√®mes de stockage de donn√©es (SQL ou NoSQL) et bien s√ªr le langage SQL.
La connaissance de Snowflake est bienvenue ;-)
Un framework de streaming de donn√©es tel que Kafka ou Amazon Kinesis.
Une exp√©rience sur les technologies Cloud : AWS, GCP, Azure
Le delivery et les projets en production faisant partie de notre ADN, vous √™tes capable de livrer du code de qualit√© dans des environnements agiles.
De plus en plus de nos projets se font en remote avec des clients du monde entier, il devient n√©cessaire d‚Äô√™tre √† l‚Äôaise en Anglais.
Ippon technologies c‚Äôest aussi :
üëç B√©n√©ficier d'un suivi de proximit√© r√©alis√© par votre manager technique : points r√©guliers pour votre suivi en mission, votre formation et votre √©volution de carri√®re
‚úåÔ∏è Rejoindre une entreprise o√π les valeurs du sport sont nos leitmotiv : d√©passement de soi, travail en √©quipe, bienveillance.
üóíÔ∏è Apprendre via notre programme de formation BlackBelt : https://bit.ly/3ByqcIL
üòÅ Travailler en pair programming ou avec un.e mentor pour gravir les √©chelons !
üí™ Pouvoir participer √† une aventure humaine au sein de notre Fondation Ippon pour r√©duire la fracture num√©rique dans le monde !
ü§ù Participer √† nos ap√©ros et divers √©v√®nements internes pour consolider la coh√©sion d‚Äô√©quipe
Et apr√®s ?
Et oui alors ? Que se passe-t-il une fois que vous √™tes convaincu d‚Äôavoir lu l‚Äôoffre d‚Äôemploi qui vous correspond bien ?
Nous vous proposons de prendre contact et de nous rencontrer !
Les Next Steps :
1 call RH
1 √©change RH
1 √©change Technique
Si le match est bon des deux c√¥t√©s : Hadjim√© ! Vous vous lancerez sur le tatami Ippon !
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks', 'Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform', 'CloudFormation'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,"Data Engineer ‚Äì Antibes, France (H/F)",Astek,"Antibes, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-antibes-france-h-f-at-astek-3909192086?position=53&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=ln5VxaOXXVRJsDTyWf0TrQ%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Antibes - France
Publi√©e il y a 2 semaines
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Intervenir dans la conception, le d√©veloppement, les tests unitaires, la qualification, l‚Äôint√©gration continue et la mise en production d‚Äô√©volutions sur les projets du p√¥le produits scoring (un p√¥le visant √† d√©velopper des solutions permettant de g√©n√©rer des scores ou des segments d‚Äôinformation pertinents dans divers domaines, notamment : profiling TV, PUB, SAB, MMDM, Voscastview) chez l‚Äôun de nos partenaires sp√©cialis√© dans le secteur des t√©l√©coms.
Votre Mission, Si Vous L‚Äôacceptez :
En collaboration avec les autres membres de l‚Äô√©quipe, vous devrez prendre en charge le RUN des applications du p√¥le produit scoring.
Conception d‚Äôune solution se basant sur les d√©veloppements existants et les besoins m√©tiers remont√©s par le Product Owner.
R√©alisation et d√©veloppement de nouvelles fonctionnalit√©s sur les composants des applications du p√¥le produits scoring et environnement CGP.
Votre Future √âquipe :
Au sein d‚Äôun environnement riche et complexe, vous √©voluerez avec des experts passionn√©s √† la fois techniques et fonctionnels (Ing√©nieurs sp√©cialis√©s, chef de projet, scrum master, product owner, analystes ‚Ä¶).
Votre stack de jeu
D ans un environnement SAFE sous cloud GCP, Big Query, OnPrime, Grafana, Python et Ansible.
Vous ?
De formation Ing√©nieur, vous justifiez d‚Äôune premi√®re exp√©rience sur un poste de Data engineer. Vous poss√©dez des comp√©tences d‚Äôautonomie et d‚Äôadaptabilit√© et vous avez une capacit√© √† communiquer efficacement au sein d‚Äôune √©quipe.
Le Groupe Astek
Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.
Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de
ses 7800 collaborateurs
qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.
Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.
Tous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies, pr√©sent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.
Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de ses 7800 collaborateurs qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.
Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde et ayant r√©alis√© un chiffre d‚Äôaffaires hors
acquisitions de 600M‚Ç¨ en 2023.
Tous les d√©tails sur le Groupe sur le site
Nos Plus
Astek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo
Une politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversit√©
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì Data engineer ‚Äì Big Data
Caract√©ristiques de l'emploi
Cat√©gorie Ing√©nieur
Job Industry T√©l√©com / M√©dia
Postuler en ligne
Nom *
Pr√©nom *
Email *
Un email valide est requis.
T√©l√©phone *
Un num√©ro de t√©l√©phone valide est requis.
Joindre un CV *
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì Data engineer ‚Äì Big Data
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Big Query'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Adaptabilit√©', 'Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer - Profils exp√©riment√©s H/F,LCL,"Villejuif, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-profils-exp%C3%A9riment%C3%A9s-h-f-at-lcl-3888403052?position=54&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=B2xAp1M9k1B%2FmH5%2FSOf%2BVg%3D%3D&trk=public_jobs_jserp-result_search-card,"üè¶ LCL, c‚Äôest LA banque urbaine du Groupe Cr√©dit Agricole - avec nous, accompagnez la transformation, le d√©veloppement et le maintien technologiques de nos outils avec une vision business et de satisfaction de nos 6 millions de clients.
En tant qu‚Äôacteur majeur de la banque de d√©tail, nous nous adaptons chaque jour aux nouveaux modes de consommation et les projets de nos de clients internes et externes tout en garantissant le besoin de s√©curit√© et de d√©veloppement technologique qu‚Äôimpliquent nos activit√©s.
üí°Organis√©es en mode Agile, les 8 squads de la tribu DATA (6 squads M√©tier et 2 squads transverses) ≈ìuvrent au quotidien pour r√©pondre √† un enjeu majeur pour la banque : la collecte, le stockage, la gestion et l‚Äôusage de la donn√©e. En interaction permanente avec les autres tribus IT et les m√©tiers, elles √©tudient et proposent les solutions et architectures √† d√©ployer pour r√©pondre au mieux aux strat√©gies de d√©veloppement et de pilotage de l‚Äôensemble des m√©tiers de la banque.
Rejoignez-nous si vous souhaitez participer aux r√©flexions et au d√©veloppement de la trajectoire technique et DataCentric du SI LCL et plus largement du Groupe CA. Vous c√¥toierez et serez au c≈ìur de l‚Äôimpl√©mentation de technologies vari√©es telles que les plateformes Teradata, les solutions d‚Äôarchitecture applicative des technologies BigData ou IA, des environnements analytiques ou encore des solutions de datavisualisation. Vous assurerez le traitement de donn√©es en temps r√©el ou en batch et exposerez les donn√©es sous diff√©rentes formes.
Que vous souhaitiez devenir expert sur les socles technologiques ou relever le challenge de la gestion de projets M√©tier, nous vous aiderons √† atteindre vos propres objectifs.
Vous rejoindrez une √©quipe pluridisciplinaire, clairement orient√©e vers le d√©veloppement de ses collaborateurs √† de nouvelles technologies !
üéØ En tant que Data Engineer :
¬∑ Vous aimez analyser les besoins avec les m√©tiers, challenger, identifier les sources de donn√©es dans les diff√©rents univers technologiques, industrialiser des algorithmes, concevoir et d√©velopper des Datalab ou des Datamart sur les plateformes ? Vous saurez relever les challenges propos√©s par les squads m√©tier !
¬∑ Vous pr√©f√©rez travailler √† l‚Äôarchitecture et au d√©ploiement de nouvelles plateformes, √† la lev√©e de la dette technologique ou encore r√©aliser de la veille au service de notre trajectoire ? La squad Socles Data est faite pour vous !
¬∑ Au-del√† des projets que vous g√©rerez, garant du bon fonctionnement de votre parc applicatif, vous attacherez une grande attention √† la mise en ≈ìuvre de solutions optimis√©es.
¬∑ La rigueur, la communication, l‚Äôesprit d‚Äô√©quipe mais aussi la curiosit√© et la cr√©ativit√© font partie de vos soft skills ! ils vous permettront de r√©pondre aux enjeux de s√©curit√©, de qualit√©, de transmission de la connaissance et contribueront √† l‚Äôatteinte des objectifs de l‚ÄôIT et plus largement de LCL, au service de ses clients.
üíª Voici les principales technologies utilis√©es au sein de la tribu, si certaines vous sont famili√®res, nous vous aiderons √† monter en comp√©tence sur d‚Äôautres !
Langages utilis√©s : SQL, Python, Scala
SGBD : Teradata et utilitaires (TPT, BTEQ, ‚Ä¶)
Streaming : Kafka
Search : ElasticSearch, SolR
Environnement : Unix
Solutions Big Data : Hadoop Cloudera, DataIku, HDFS, Hive, Impala,
Devops : GitLab, Jenkins, Nexus
Outils de visualisation : MS BI (SSIS, SSAS, SSRS) Qlik Sens, BO
Mod√©lisation : MEGA
Outils collaboratifs : GIT, Jira, Confluence, Teams
‚ö°Si les nouveaux enjeux bancaires vous int√©ressent, que vous souhaitez int√©grer une √©quipe Agile au service des m√©tiers dans laquelle vous serez force de proposition et que vous aimez travailler dans un environnement motivant et dynamique, rejoignez-nous, cette offre est faite pour vous !
üî• Les + de notre entreprise :
Acc√®s au Plan d‚Äô√©pargne Groupe, int√©ressement et participation aux b√©n√©fices de l‚Äôentreprise + abondement
Prix pr√©f√©rentiels bancaires et avantages CSE
Parcours √©volutif dans l‚Äôentreprise et/ou dans le Groupe CA.S.A
T√©l√©travail (jusqu'√† 2 jours de t√©l√©travail par semaine)
De multiples commodit√©s sur le campus (restaurants d'entreprise, salle de sport, cr√®che, centre m√©dical, m√©diath√®que...)
Forfait et avantages pratiques ¬´ mobilit√© durable ¬ª pour les velotafeurs
Des √©quipes aussi diversifi√©es que structur√©es dans une dynamique de transformation
LCL s‚Äôengage en faveur de la diversit√© et nous encourageons tout(e) candidat(e) ayant l‚Äôexp√©rience requise √† postuler √† nos offres. Tous nos postes sont ouverts aux personnes en situation de handicap.
Nous avons encore de nombreuses raisons √† vous pr√©senter pour vous convaincre de nous rejoindre mais pour cela, il faudra postuler ici !
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['JIRA', 'Confluence', 'Teams'], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Communication', 'Cr√©ativit√©'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,"Big Data Engineer Confirm√© ‚Äì Paris, France (H/F)",Astek,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-confirm%C3%A9-%E2%80%93-paris-france-h-f-at-astek-3839098103?position=55&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=Zls1eavoxiIyF27%2BQNvkaw%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Paris - France
Publi√©e il y a 2 mois
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Nous rejoindre en tant que
Big Data Engineer Confirm√© (H/F),
afin d‚Äôaccompagner un op√©rateur t√©l√©coms, Leader en Europe dans l‚Äôassistance et le support applicatif de niveau 3 (r√©solution des probl√®mes utilisateurs, exploitation des environnements hors production).
Un challenge portant sur des millions d‚Äôutilisateurs dans un environnement technique innovant, strat√©gique et o√π l‚Äôentraide et la bonne humeur priment !
Votre Mission, Si Vous L‚Äôacceptez :
Supervision et d√©tection et r√©solution des probl√®mes utilisateurs (d√©veloppeurs, exploitants et data exploreurs)
D√©veloppement de solutions de self-service ou d‚Äôune solution de r√©solutions automatiques des probl√®mes
Qualifier les donn√©es et les r√©sultats
Conception technique des solutions
Assurer l‚Äôaccompagnement et le d√©ploiement des √©volutions des processus et outils
Accompagner la phase de mise en production
Votre Future √âquipe :
Vous int√©grerez une √©quipe √† la fois technique et fonctionnel, qui ≈ìuvre chaque jour pour d√©velopper et maintenir en conditions op√©rationnelles l‚Äôensemble des solutions IT !
L‚Äô√©quipe est en interaction avec des clients √† la fois internes et externes.
Votre stack de jeu
Syst√®me d‚Äôexploitation : Linux
Outils des distributions : HDP, HDF, ELK
Environnement Big data : Hadoop, Spark,
Langage : Scala, Shell, Python
Cloud computing : GCP ou AWS
Base de donn√©es : No SQL (Cassandra, Mongo DB), Shell, Ansible
Dataviz : Power BI ou Kibana
Des notions en R√©seau et Syst√®mes feront la diff√©rence !
Les Petits Plus Du Projet :
Vous √©voluerez au sein d‚Äôune √©quipe impliqu√©e et r√©active et interviendrez sur un projet polyvalent et √† forte valeur ajout√©e.
Vous ?
Dipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieur ou √©quivalent de niveau Bac+5.
Vous justifiez id√©alement d‚Äôune exp√©rience d‚Äôau moins 3 ans d‚Äôexp√©riences sur un poste similaire ?
Vous faite preuve de proactivit√© et d‚Äôesprit d‚Äô√©quipe, √™tes dot√©(e) d‚Äôun excellent sens de l‚Äôorganisation et vous aimez les challenges et la r√©solution de probl√®me ?
Alors ce poste est fait pour vous, n‚Äôh√©sitez plus et rejoignez l‚Äôaventure ASTEK !
Astek
Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.
Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de
ses 7800 collaborateurs
qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.
Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.
Tous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Notre projet commun vous plait ?
Postulez √† cette annonce, et soyez transparent !
Maud, notre Talent Acquisition Referent, vous contactera pour un premier √©change.
Puis vous rencontrerez Martin, votre futur manager, avec lequel vous √©changerez autour d‚ÄôAstek, de votre parcours, de vos attentes et de votre future mission .
Enfin, vous rencontrerez J√©r√©my, notre Directeur d‚Äôagence avec lequel vous pourrez valider votre int√©r√™t et ad√©quation pour le poste et finaliser les √©l√©ments contractuels.
Nos Plus
Astek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo
Une politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversit√©
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì Hadoop ‚Äì Scala ‚Äì Data
Caract√©ristiques de l'emploi
Cat√©gorie Ing√©nieur
Job Industry T√©l√©com / M√©dia
Postuler en ligne
Nom *
Pr√©nom *
Email *
Un email valide est requis.
T√©l√©phone *
Un num√©ro de t√©l√©phone valide est requis.
Joindre un CV *
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì Hadoop ‚Äì Scala ‚Äì Data
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': ['Confirm√©'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer (H/F) - Lille,Logic@l Conseils,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-lille-at-logic%40l-conseils-3811575649?position=56&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=dy9XohBb6wp2uWIn1KF0hw%3D%3D&trk=public_jobs_jserp-result_search-card,"Dans le cadre du d√©veloppement de nos activit√©s sur la m√©tropole Lilloise, nous recherchons un
consultant data engineer
(H/F) pour intervenir chez l'un de nos grands comptes clients.
Vos missions :
Recueillir
les besoins m√©tiers et des √©quipes data
Concevoir et mettre en place les
traitements de donn√©es
R√©aliser les
tests de validation
Assurer
l‚Äôalimentation du dataware
R√©aliser les
ordonnancements des traitements
Etre garant de la
mise en place
, du
suivi
et de l‚Äô
exploitation
des outils d√©ploy√©s
Assurer
une veille technologique
r√©guli√®re
Environnement technique :
D√©veloppement :
Python, Scala, R, Java,
Framework :
Spark,
Hadoop,
Outils Big data :
Yarn, Pig, Hive, Kafka, Splunk
Bases de donn√©es :
MongoDB, HBase, Cassandra
ETL :
Talend, Stambia
Plateforme :
Hortonworks, Cloudera, Map Reduce
,
AWS, GCP, Azure
Votre profil :
Vous disposez d‚Äôune exp√©rience
d‚Äôau moins 2 ans en tant que data engineer
ou dans le domaine de l‚Äôanalyse et du traitement de donn√©es.
V√©ritable
passionn√© de la data
, vous √™tes
force de proposition
sur les solutions techniques √† mettre en ≈ìuvre. Vous maitrisez l‚Äôanglais dans un contexte professionnel.
Comp√©tences requises :
Analyses qualitatives et quantitatives (Interm√©diaire)
Anglais (Interm√©diaire)
Architecture fonctionnelle SI (D√©butant)
D√©veloppement d'ouvrages, produits ou √©v√©nements (D√©butant)
Gestion des contr√¥les, tests et diagnostics (D√©butant)
Gestion des risques (Interm√©diaire)
Ma√Ætrise des logiciels (Interm√©diaire)
Mise en exploitation / Production et maintenance (D√©butant)
Nos valeurs
Nous avons d√©cid√© de renverser la pyramide du management pour placer nos collaborateurs en t√™te des priorit√©s de l‚Äôentreprise.
En effet, attach√© √† des valeurs fortes, telles que la proximit√©, la sinc√©rit√©, la fid√©lit√©, la confiance et le respect, nous sommes persuad√©s que la r√©ussite r√©side dans le bien-√™tre de nos collaborateurs.
Cela se traduit par un accompagnement de proximit√©, de la transparence sans langue de bois, des √©changes r√©guliers avec les managers r√©f√©rents, un accompagnement dans le d√©veloppement de carri√®re qui est construit et jalonn√© avec les formations et certifications n√©cessaires et les missions en ad√©quation, pour mener √† bien l‚Äô√©volution de carri√®re.
Pour vous convaincre de nous rejoindre, nos avantages salari√©s compl√©mentaires :
Environnement bienveillant et stimulant au sein de 3 p√¥les d‚Äôexpertises
Formations et Certifications √† la demande
Tickets restaurants : 13‚Ç¨ par ticket
Remboursement √† 100 % des abonnements de transports en commun
Mutuelle frais de sant√© avec de hautes garanties
Prise en charge √† 100% de l‚Äôassurance Pr√©voyance
Ch√®que Cadeau Culture 120 ‚Ç¨
Compte CSE avec une cagnotte de 390 ‚Ç¨
Compte CE : billetterie, voyages, culture, sorties, √† des tarifs pr√©f√©rentiels
Des √©v√®nements chaque mois : activit√©s associatives, sportives, afterwork, s√©minaire,
Partenariat Losc (participation aux match dans la loge VIP logical conseils ‚Äì (Une Vingtaine de match par an)
Possibilit√© de t√©l√©travail
En int√©grant Logic@l Conseils, vous participez √† une r√©elle aventure humaine, alors pour postuler, il suffit de cliquer ci-dessous !
Tous nos postes sont ouverts, √† comp√©tences √©gales, aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['Cassandra', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,Data Engineer,CGI,"Niort, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-at-cgi-3902057928?position=57&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=nya1Wu5YHzOoOY6TKfTIXA%3D%3D&trk=public_jobs_jserp-result_search-card,"Description de poste
Big Data, Data Science, Data analyse, Data architecture ... √áa n‚Äôa pas de secret pour vous ?
Que vous commenciez votre carri√®re professionnelle ou que vous soyez sp√©cialiste de l‚Äôune de ces disciplines, int√©grer notre communaut√© Data, c‚Äôest l‚Äôassurance de progresser, innover, partager, vous certifier et rendre service √† nos clients.
Si vous souhaitez int√©grer nos √©quipes √† Niort et accompagner les plus grands acteurs du secteur des Assurances, cette annonce est susceptible de vous int√©resser.
En tant que Data Engineer, vous serez responsable de la conception, du d√©veloppement, de la gestion et de l'int√©gration des syst√®mes bas√©s sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop. Ce r√¥le implique la mise en place d'architectures √©volutives et hautement disponibles pour r√©pondre aux besoins de traitement et de stockage de donn√©es de l'entreprise.
Fonctions et responsabilit√©s
Vos responsabilit√©s seront les suivantes:
-Maintenir et d√©velopper des solutions bas√©es sur les services AWS pour le stockage, le traitement et l'analyse de donn√©es
-Utiliser les services AWS appropri√©s tels que Amazon EC2, S3, RDS, Lambda, etc., pour r√©pondre aux exigences du projet.
-Cr√©er et maintenir les configurations Terraform pour la gestion de l'infrastructure en tant que code (IaC) sur AWS
-Participer √† la maintenance et √† la mise en place d'environnements OpenShift pour l'h√©bergement d'applications et de services
-G√©rer et administrer les clusters Kafka pour garantir la disponibilit√©, la performance et la s√©curit√© du syst√®me de messagerie
Participer √† l‚Äôassistance utilisateurs sur les briques de la plateforme Hadoop Cloudera Data
-Travailler avec les projets et les devOps pour assurer un traitement efficace des donn√©es
En rejoignant CGI, vous b√©n√©ficiez notamment d‚Äôune offre compl√®te de formations (techniques, m√©tiers, d√©veloppement personnel,‚Ä¶), de flexibilit√© gr√¢ce √† notre accord t√©l√©travail (jusqu‚Äô√† 3 jours de t√©l√©travail par semaine), d‚Äôune politique de cong√©s avantageuse (27 jours de cong√©s pay√©s, RTT, cong√©s anciennet√© et enfant malade,‚Ä¶) et d‚Äôun package d‚Äôavantages int√©ressant (r√©gime d‚Äôachats d‚Äôactions, participation, CSE,...).
Qualit√©s requises pour r√©ussir dans ce r√¥le
Ayant une premi√®re exp√©rience en tant que Data Engineer, vous avez une premi√®re exp√©rience relative aux points suivants:
-D√©veloppement et int√©gration sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop
-Connaissance avanc√©e de l'administration Kafka, y compris la configuration, la gestion et la r√©solution des probl√®mes
-Mise en ≈ìuvre de l'infrastructure en tant que code √† l'aide de Terraform
-Bonne compr√©hension des bonnes pratiques de s√©curit√© pour les syst√®mes cloud, les clusters Kafka et les plateformes Hadoop
CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, √† l‚Äô√©volution de carri√®res des hommes et des femmes et au bien-√™tre de nos salari√©s LGBT+. Dans un souci d‚Äôaccessibilit√© et de clart√©, le point m√©dian n‚Äôest pas utilis√© dans cette annonce. Tous les termes employ√©s se r√©f√®rent aussi bien au genre f√©minin que masculin.
Ensemble, en tant que propri√©taires, mettons notre savoir-faire √† l‚Äô≈ìuvre.
La vie chez CGI est ancr√©e dans l‚Äôactionnariat, le travail d‚Äô√©quipe, le respect et un sentiment d‚Äôappartenance. Chez nous, vous pourrez exploiter votre plein potentiel parce que‚Ä¶
Nous vous invitons √† devenir propri√©taire d√®s le jour 1 alors que nous travaillons ensemble √† faire de notre r√™ve une r√©alit√©. C‚Äôest pourquoi nous nous d√©signons comme associ√©s de CGI, plut√¥t que comme employ√©s. Nous tirons profit des retomb√©es de notre succ√®s collectif et contribuons activement √† l‚Äôorientation et √† la strat√©gie de notre entreprise.
Votre travail cr√©e de la valeur. Vous √©laborerez des solutions novatrices et d√©velopperez des relations durables avec vos coll√®gues et clients, tout en ayant acc√®s √† des capacit√©s mondiales pour concr√©tiser vos id√©es, saisir de nouvelles opportunit√©s, et b√©n√©ficier d‚Äôune expertise sectorielle et technologique de pointe.
Vous ferez √©voluer votre carri√®re en vous joignant √† une entreprise b√¢tie pour cro√Ætre et durer. Vous serez soutenus par des leaders qui ont votre sant√© et bien-√™tre √† c≈ìur et qui vous permettront de saisir des occasions afin de parfaire vos comp√©tences et √©largir les horizons.
Joignez-vous √† nous, l‚Äôune des plus importantes entreprises de conseil en technologie de l‚Äôinformation (TI) et en management au monde.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['OpenShift'], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Flexibilit√©'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['1'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer (H/F),ternair,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ternair-3915757963?position=58&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=dWBVkZEg5jT0dB6SX9Q7Mg%3D%3D&trk=public_jobs_jserp-result_search-card,"üë®‚ÄçüöÄ MISSION : üë©‚ÄçüöÄ
En coh√©rence avec la strat√©gie d‚Äôentreprise et la roadmap data, vous aurez pour principales missions de :
En lien avec l‚Äô√©quipe DevOps, construire, maintenir et faire √©voluer la plateforme de donn√©es;
D√©finir et piloter la coh√©rence de la collecte, la gestion et l‚Äôalimentation des donn√©es internes et externes, en diff√©rents modes : batch, streaming, API (architecture micro-services);
Pr√©parer et mettre en qualit√© les donn√©es pour les rendre disponibles dans les diff√©rents environnements de travail (datalake, datawarehouse, datamart);
V√©rifier la qualit√© des donn√©es, de leur bonne et r√©guli√®re ex√©cution ainsi que de leur utilisation ad√©quate (gestion des co√ªts);
Travailler en √©troite collaboration avec les data analysts, scientists et data stewards et business de l‚Äôentreprise ;
En lien avec l‚ÄôIT et la s√©curit√©, veiller aux r√®gles d'int√©grit√© et de s√©curit√© des donn√©es;
Veille technologique.
üßÆ Les outils :
Plateforme data : Google Cloud Platform (Big Query, Airflow)
D√©veloppement : Github/GitLab, Docker, Terraform, Python
Analytiques : Qlik
Gestion de projet s: Jira, Confluence, Miro, Drive, Docs, Sheets, Slides
ü§© Profil recherch√© : ü§©
Exp√©rience d'au moins 4-5 ans (apr√®s √©tudes) en data ing√©nierie (flux, mod√©lisation, run)
A l‚Äôaise avec l‚Äôenvironnement Cloud et les infrastructures digitales
Communiquant, p√©dagogue et fortes capacit√©s relationnelles
Anglais (√† l‚Äô√©crit)
R√©mun√©ration : 42-60 k‚Ç¨ en package selon exp√©rience
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Big Query'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': ['JIRA', 'Confluence'], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['Package'], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Data Solutions Engineer (Data & AI),LVMH,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-solutions-engineer-data-ai-at-lvmh-3900392289?position=59&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=Ii5OaSH%2Bx4fLih9wC%2BWMmA%3D%3D&trk=public_jobs_jserp-result_search-card,"LVMH is the #1 Luxury group and is currently accelerating rapidly on digitalisation. It is bringing technology and innovation in the core of the established 75+ Maisons by inventing unique and powerful products and services.
We are looking for talented solution engineers (Software, Cloud, Data and AI) to join our team and be part of this tech revolution of bringing the Group and its Maisons to the next level.
If you believe Data and AI can enhance the retail industry, from the day-to-day operational tasks to the long term customer experience,
If you think that the Cloud technologies (we love Google Cloud) is a revolution for Data and AI products,
If you like building tech solutions having direct impacts on billion-dollar-valued businesses,
If you have good communication skills and like sharing your knowledge,
Apply now, and join us!
The mission
The Solution Engineer is providing advices and technical assets to the Maisons having Data & AI projects.
Our team (Group Data team) is building a technical framework for all the Maisons to implement easily and quickly Data and AI use cases. Your mission will be to support the Maisons to convert their use case needs to concrete and production ready technical solutions using our framework and tools.
You will cover a portfolio of Maisons, in direct contact with their business analysts, data scientists and IT teams. You will be their dedicated referent on the Data & AI technical topics (Data platform, AI/ML softwares, data transport and transformations, data quality).
Main responsibilities
You will be responsible of providing support and advices to a portfolio of Maisons on Data & AI tech topics (Cloud, Data stacks, Data transformations, Data transfers, ML ops).
You will keep a recurrent discussion with the Maisons to accelerate their projects and immediately provide our support when it's needed.
You will follow-up the engaged productions in the Maisons and report them to the global group data strategy committees.
Applying the quality and security standards. Making them evolve if necessary.
Producing realistic, understandable and documented solutions following the group guidelines.
Sharing and learning from the team by communicating difficulties and successes, taking and bringing honest feedbacks and improving the identified pain points.
Taking responsibility as member of the team on the product performances (delivery and long term usage)
Required expertise and knowledge
Ability to build technical solutions answering concrete usage (User Stories) and communicate them to the team.
Dimension and evaluate complexity for technical solution productions.
Extensive knowledge and experience with good learning and sharing abilities.
Evaluate quickly risks and opportunities about technical choices.
Solid oral, written, presentation and interpersonal communication and relationship skills.
Problem-solving skills on Data and AI, coding and software development
Tech lover
Feedback taker and giver
Team player
Key benefits to join our team
Attractive packages
Offices in the 8th arrondissement near the Champs Elys√©es
Flexibility on the working hours
Remote work possible (~40%)
7 weeks of holidays (cong√©s pay√©s + RTT)
LVMH brands exclusive private sales
Great employee committee and health insurance (CE, mutuelle)
Last generation MacBooks
Part of a young, motivated and tech savvy team. Get prepared for the Thursday drinks and the tech meet-ups!
You‚Äôre eligible if
You have a strong experience (3+ years) in cloud data architecting or consultancy.
You graduated from an engineering (or equivalent) with a master‚Äôs degree. Computer Science knowledge is mandatory.
Experience on data stacks and/or Google Cloud (built in components) is a huge plus.
French and English both written and oral (Maisons are all over the world)
You‚Äôre thrilled to support the #1 luxury group to get even better.
Hiring Process
Call with our HR partner dedicated to the Tech Team
Technical interview with the Solution Engineering Manager
Technical test
Interview with the Head of Engineering
Still here? Apply now!!
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['ML', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication', 'Flexibility']}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': ['40'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,"Big Data Engineer ‚Äì Secteur T√©l√©com ‚Äì Paris, France (H/F)",Astek,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-%E2%80%93-secteur-t%C3%A9l%C3%A9com-%E2%80%93-paris-france-h-f-at-astek-3832149765?position=60&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=Z8j5uhBScZ1Pfkab7NeYTg%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Paris - France
Publi√©e il y a 2 semaines
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Nous rejoindre en tant que
Big Data Engineer (H/F),
afin d‚Äôaccompagner un op√©rateur t√©l√©coms, Leader en Europe dans la gestion de ses portails clients grands publics (multimarques mobile et internet).
Un challenge portant sur des millions d‚Äôutilisateurs dans un environnement technique innovant et strat√©gique.
Votre Mission, Si Vous L‚Äôacceptez :
Qualifier les donn√©es et les r√©sultats
Conception technique des solutions
D√©cliner les impacts de la strat√©gie et des innovations technologiques au sein des processus et outils de l‚Äôexploitant SI
Assurer l‚Äôaccompagnement et le d√©ploiement des √©volutions des processus et outils
Contribuer aux programmes de transformation DevOps, Cloud et catalogues des offres SI
D√©velopper des fonctions transverses et les ¬´ uses cases ¬ª
Accompagner la phase de mise en production
Votre Future √âquipe :
Au sein d‚Äôun environnement riche et complexe, vous √©voluerez avec des experts passionn√©(e)s √† la fois techniques et fonctionnels (Ing√©nieurs sp√©cialis√©es, chef de projet, scrum master, product owner, analystes‚Ä¶).
L‚Äô√©quipe est en interaction avec des clients √† la fois internes et externes.
Votre stack de jeu
Syst√®me d‚Äôexploitation Linux
Big data (Hadoop, Spark, Scala)
Cloud computing (GCP‚Ä¶)
S QL, No SQL (Cassandra, Mongo DB)
Dataviz : Power BI ou Kibana
Des notions en d√©veloppement feront la diff√©rence !
Les Petits Plus Du Projet :
Vous √©voluerez au sein d‚Äôune √©quipe impliqu√©e et r√©active et interviendrez sur un projet polyvalent et √† forte valeur ajout√©e.
Vous ?
Dipl√¥m√©(e) d‚Äôune
√©cole d‚Äôing√©nieur
ou √©quivalent de niveau Bac+5. Vous justifiez id√©alement d‚Äôune exp√©rience d‚Äôau moins 2 ans sur un poste similaire.
Ce descriptif vous interpelle ?
Alors ce poste est fait pour vous, n‚Äôh√©sitez plus et rejoignez l‚Äôaventure ASTEK !
Astek
Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.
Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de
ses 7800 collaborateurs
qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.
Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.
Tous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Vous vous √™tes reconnu(e) sur l‚Äôannonce et Astek vous pla√Æt !
Julie , Talent Acquisition Officer vous contactera pour en savoir plus sur vous.
Par La Suite, 2 √âchanges Maximum :
Le premier avec Mathieu (votre futur N+1, avec lequel vous √©changerez autour d‚ÄôASTEK, de votre parcours, de vos attentes et de la mission)
Le second avec Anthime (Notre Directeur d‚Äôagence pour valider votre int√©r√™t pour le poste et vous pr√©senter les √©l√©ments contractuels).
Nos Plus
Astek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo
Une politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversit√©
Bienvenue dans la team ! Allez-y, maintenant c‚Äôest √† vous de jouer !
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì big data engineer
Caract√©ristiques de l'emploi
Cat√©gorie Ing√©nieur
Job Industry T√©l√©com / M√©dia
Postuler en ligne
Nom *
Pr√©nom *
Email *
Un email valide est requis.
T√©l√©phone *
Un num√©ro de t√©l√©phone valide est requis.
Joindre un CV *
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì big data engineer
Show more
Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,Data Engineer ‚Äì Grenoble,Capgemini,"Grenoble, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-grenoble-at-capgemini-3905836212?position=1&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=rVM%2FWT4txhii7kUBqMd4jw%3D%3D&trk=public_jobs_jserp-result_search-card,"Choisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations. Avec le soutien et l'inspiration d'une communaut√© d‚Äôexperts dans le monde entier, vous pourrez r√©√©crire votre futur. Rejoignez-nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la valeur de la technologie pour les plus grandes organisations et participer √† la construction d‚Äôun monde plus durable et inclusif.
Vos missions :
En tant que Data Engineer au sein d'une √©quipe multidisciplinaire, vos responsabilit√©s principales seront les suivantes :
Intervenir sur les diff√©rentes phases d'un projet dans un environnement Cloud et Agile.
Contribuer √† la gestion de la qualit√© des donn√©es et extraction et analyse de celle-ci, ainsi qu‚Äô√† la pr√©sentation des donn√©es dans leur forme raffin√©e.
Proposer des nouvelles lectures de donn√©es via un travail de fouille sur les gisements d‚Äôinformation, notamment client.
Adopter une posture de consultant : proposer de nouvelles solutions et accompagner le client dans ses choix.
Votre profil :
Titulaire d'un Bac+5 en √©cole d‚Äôing√©nieur ou en universit√©.
Connaissances approfondies des ETL (Talend, Informatica ou SSIS), du traitement de donn√©es (Spark, Python, Scala) ainsi que des bases de donn√©es (Oracle, SQL Server, Postgres).
Facult√© pour se montrer curieux, autonome et proactif dans la r√©alisation de ses t√¢ches.
Capacit√© √† faire preuve de rigueur et √† travailler en √©quipe.
Bon niveau d‚Äôanglais (B2 minimum).
3 raisons de nous rejoindre :
Qualit√© de vie au travail
: accord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√© professionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.
Apprentissage en continu
: certifications et formations en libre acc√®s, accompagnement sur mesure avec votre career manager, parcours d‚Äôint√©gration sur 9 mois.
Avantages groupe & CSE
: plan actionnariat, tarif pr√©f√©rentiels, remboursement partiel vacances, remboursement de votre abonnement sportif ou culturel.
Nos engagements et priorit√©s
:
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.
√Ä propos de Capgemini :
Capgemini est un leader mondial, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d‚Äôexp√©rience, nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Oracle', 'SQL Server'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '55', '55', '55']}"
LinkedIn,Data Engineer,eXalt Value,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-exalt-value-3897767649?position=2&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=iUyZScP6JnVgtR9o6D%2Bz8w%3D%3D&trk=public_jobs_jserp-result_search-card,"eXalt
est un cabinet de conseil IT
Pure player Data
& IA bas√© √† Paris.
Notre offre s‚Äôarticule autour de 4 piliers r√©unis au sein d‚Äôune m√™me communaut√© pour un accompagnement √† 360¬∞ alliant une expertise technique et m√©thodologique √† une approche conseil m√©tier:
Data Gouvernance & Project
Data Engineering & Big Data
Data Performance & Analytics
Data Science & IA
Filiale du groupe eXalt, cr√©√© en 2018,
regroupant plus de
950 collaborateurs en France
(Paris, Lyon, Bordeaux, Lille, Nantes, Marseille)
et √† l‚Äôinternational
(Colombie, Etats-Unis, Espagne, Belgique),
eXalt Value
apporte une
expertise approfondie
dans le domaine de la Data & IA et conseille les entreprises dans le d√©ploiement de leurs strat√©gies data-driven.
B√©n√©ficiant du support du groupe eXalt
(1er dans la cat√©gorie Conseil & Audit au classement des Champions de la Croissance 2024), eXalt Value
est en pleine croissance et regroupe aujourd‚Äôhui une communaut√© d‚Äôexpertise de plus de 60 collaborateurs en r√©gion parisienne.
Nos consultants interviennent sur d
es projets d‚Äôenvergure
dans divers secteurs d‚Äôactivit√©,
Banque & Assurance, M√©dias, Transports, Retail, Tourisme, etc.
Nous recherchons un
Data Engineer Confirm√© H/F (minimum 4 ans d'exp√©rience dans la fonction)
pour rejoindre notre communaut√© sur le
pilier Data Engineering & Big Data.
Vos missions:
Concevoir et d√©velopper des pipelines et des flux de donn√©es.
Int√©grer et transformer des donn√©es provenant de diff√©rentes sources.
D√©velopper et mettre en ≈ìuvre des algorithmes de traitement de donn√©es avanc√©s.
Collaborer √©troitement avec les √©quipes clients pour comprendre leurs besoins et fournir des solutions adapt√©es.
Assurer la qualit√© et la fiabilit√© des solutions d√©velopp√©es.
Conseiller les √©quipes clients sur les solutions √† mettre en place.
Les Pr√©requis :
Titulaire d'un Bac+5, Ecole d'Ing√©nieur
Ma√Ætrise d'un ou plusieurs langages de programmation (
Python, Scala, Spark, etc
.).
Exp√©rience approfondie des technologies
Big Data (Hadoop, Spark, Kafka, Talend, etc.)
Exp√©rience av√©r√©e
en
environnement Cloud (AWS, GCP, ou Azure)
.
Solides comp√©tences en conception et en optimisation de pipelines de donn√©es.
Exp√©rience de travail en
m√©thode Agile
Capacit√© √† travailler de mani√®re autonome et en √©quipe.
Excellentes comp√©tences en communication et en r√©solution de probl√®mes.
Ma√Ætrise de l‚Äôanglais (oral & √©crit dans un contexte international professionnel).
Votre environnement eXalt√©:
Un environnement de travail Collaboratif
favorisant les initiatives et projets transverses √† la Practice Data & IA (Lab IA, Data Hub, etc.).
Un collectif de consultants passionn√©s,
s‚Äôint√©ressant aux tendances innovantes du secteur.
Une Practice de proximit√©,
privil√©giant la mont√©e en comp√©tence de ses collaborateurs (formations, coachings, mentorats, etc.)
Un suivi individualis√© et de proximit√©
par un.e Data Sales Manager r√©f√©rent du compte client, un.e Charg√©.e RH et un.e Practice Manager
Une √©quipe ouverte et dynamique,
qui privil√©gie les moments de partage et de convivialit√© (s√©minaires, eXaltemps, meet-up, d√©jeuners d‚Äô√©quipe, etc.)
Notre processus de recrutement :
Un entretien RH avec Estelle,
√† la suite duquel vous saurez tout (ou presque) d‚ÄôeXalt Value,
Un entretien technique avec un Manager assorti d‚Äôun test technique,
lors duquel vous aurez l‚Äôoccasion de d√©montrer vos talents mais aussi d‚Äôapprendre avant m√™me de dire oui,
Un entretien final avec la Directrice Associ√©e ou le Directeur Op√©rationnel,
pour finir de vous convaincre de nous rejoindre üòä
Nous avons h√¢te de recevoir vos CV, et de faire votre connaissance!
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Communication', 'R√©solution de probl√®mes'], 'EnSoftSkils': ['Communication', 'Initiative']}","{'JobDetail': ['Confirm√©'], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data Engineer | Python - Spark - Hadoop | Sp√©cialis√© en Big Data | Paris ou Remote Partiel,Octopus IT - Expert du recrutement tech,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-python-spark-hadoop-sp%C3%A9cialis%C3%A9-en-big-data-paris-ou-remote-partiel-at-octopus-it-expert-du-recrutement-tech-3685740787?position=3&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=2wRnF1bj7F62V7tFqLDvzA%3D%3D&trk=public_jobs_jserp-result_search-card,"La soci√©t√©
Cr√©√©e il y a 7 ans, cette entreprise de conseil en hyper croissance, se compose d'environ 90 personnes. Elle est devenue experte en Data et IA (NLP, Deep Learning, Machine Learning) et accompagne leurs clients sur l‚Äôensemble de leurs projets data √† travers la valorisation de leurs donn√©es.
Leur valeur ajout√©e ? Leur sp√©cialisation en Data ce qui leur permet d'offrir 3 expertises m√©tiers distinctes : la Data Science, la Data Engineering et le Machine Learning Engineering. Autour de ces expertises gravitent bien s√ªr les m√©tiers de Lead et d'Architecte.
Une autre de leur force est leur formation interne (avec des profils de seniors ou d'architectes) et externe (avec des partenaires pour passer les certifications).
Chez eux, le collaborateur est plac√© au centre des pr√©occupations, permettant ainsi de cr√©er une coh√©sion et une v√©ritable culture au sein de l'entreprise. Par exemple la majorit√© des projets se font en √©quipe et non seul.
Connu et reconnu pour leur expertise en Big Data, ils sont devenu le partenaire principal d'un grand groupe du CAC 40 et ont pris le lead sur tous les sujets touchant √† la transformation Big Data de ce groupe.
Pour poursuivre leur croissance, r√©pondre √† leurs ambitions et d√©velopper de nouveaux march√©s, nous recherchons plusieurs profils pour renforcer leurs effectifs.
Le poste
En les rejoignant vous travaillerez sur les probl√©matiques suivantes :
Mise en place et/ou scale d'architectures
Construction de Datalake
Mise en production de model de ML
Pipelining de donn√©es
Streaming de donn√©es et temps r√©el
La stack sur laquelle vous travaillerez :
Python, Scala, Spark, Architectures distribu√©es : Hadoop, HDFS, Cloud : Aws, GCP, Azure
Votre profil
A partir de 3 ans d'exp√©rience en CDI
Vous avez une exp√©rience significative sur des probl√©matiques Big Data
Tr√®s bonne comp√©tences en Python et/ou Scala et en Spark
Vous √™tes familier avec Hadoop, Hive, Hbase
Une logique cloud (Aws, GCP ou Azure)
Le salaire & avantages
50-60 K‚Ç¨ selon exp√©rience
RTT
Carte Swile & Mutuelle
3/4 jours de t√©l√©travail par semaine
Et plus encore‚Ä¶
Ce qu‚Äôon pr√©f√®re
√ätre impliqu√© √† fond dans une aventure avec de nombreux challenges techniques
Belles opportunit√©s d'√©volutions sur des postes d'Architecte, de Lead ou de Ml Ops
Tr√®s bonne ambiance, √©quipe solidaire et orient√©e partage d‚Äôinformations
Beaucoup de workshops en interne et catalogue de formations √† votre guise
Ce poste a √©t√© soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d‚ÄôExperts en Recrutement Tech (CDI et clients finaux uniquement) ‚Äì Visitez nous pour plus d‚Äôopportunit√©s :
www.octopusit.fr
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Senior'], 'TypeContract': ['CDI'], 'Salary': ['50'], 'Level': [], 'Experience': ['a', 'n', 's', '7', '7', '7']}"
LinkedIn,Data Engineer (H/F),MP DATA,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-mp-data-3908719610?position=4&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=B0719RxYRCpvjHVP51zIXQ%3D%3D&trk=public_jobs_jserp-result_search-card,"MP DATA est une soci√©t√© sp√©cialis√©e dans l‚Äôacquisition, le traitement, et la valorisation des donn√©es.
Depuis sa cr√©ation en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance et l‚Äôexploitation de leurs donn√©es.
Les collaborateurs, tous issus de grandes √©coles, incarnent au quotidien les valeurs d‚ÄôExcellence, de Partage et d‚ÄôEngagement.
Ils associent savoir-faire technique, m√©thodologie et passion et mettent leurs comp√©tences au service de missions et projets au sein de grands groupes fran√ßais.
MP DATA accompagne ses clients sur toute la chaine au travers de 3 p√¥les d‚Äôexpertise : Conseil et Strat√©gie, Infrastructure & CloudOPS, Data Science.
Chez MP DATA, les √©quipes commerciales cherchent des missions en fonction des envies des collaborateurs et non pas l‚Äôinverse. Les consultants sont accompagn√©s dans tous leurs projets, de la mobilit√© g√©ographique, au changement de secteur d‚Äôactivit√© en passant par le d√©veloppement de nouvelles comp√©tences.
Rejoindre MP DATA, c‚Äôest la garantie de travailler sur des sujets passionnants avec un cadre technique fort.
Descriptif du poste :
Nous recherchons un Data Engineer exp√©riment√© pour rejoindre notre √©quipe.
En tant que Data Engineer, vous serez responsable de la conception, du d√©veloppement et de la mise en ≈ìuvre de pipelines de traitement de donn√©es en temps r√©el √† grande √©chelle.
Vous travaillerez avec des technologies telles que Kafka, Flink, Kinesis et vous utiliserez les services du cloud AWS pour stocker et traiter les donn√©es.
Vos responsabilit√©s :
Utiliser Kafka pour le traitement de flux de donn√©es en temps r√©el √† grande √©chelle, en travaillant avec les producteurs, les consommateurs et les topics.
Mettre en ≈ìuvre des pipelines de traitement de donn√©es en streaming avec Flink, en appliquant des transformations complexes et en g√©rant les √©tats.
√âcrire du code efficace et maintenable en Java / Python pour manipuler et analyser les donn√©es en temps r√©el.
Utiliser Kubernetes pour d√©ployer et g√©rer des applications conteneuris√©es √† grande √©chelle, en assurant la r√©silience et l‚Äô√©volutivit√© des services.
Utiliser les services AWS tels que Amazon S3, AWS Lambda, Elastic Kubernetes Service (EKS), Elastic Container Service (ECS) et Elastic Compute Cloud (EC2) pour le stockage, le traitement et le calcul des donn√©es en temps r√©el.
Suivre les meilleures pratiques pour une utilisation efficace du cloud, en assurant la gestion des co√ªts, la s√©curit√© des donn√©es et la disponibilit√© des services.
Collaborer avec l‚Äô√©quipe de d√©veloppement logiciel et la gestion de projets pour assurer un flux de d√©veloppement fluide et une livraison efficace des fonctionnalit√©s.
Bon √† savoir :
CDI / ASAP / Toulouse
Profil recherch√©:
Nous recherchons un candidat dipl√¥m√© d'une grande √©cole d'Ing√©nieur avec une premi√®re exp√©rience.
Comp√©tences n√©cessaires :
Exp√©rience significative dans un environnement industriel en mode DevOps, avec des outils tels que CICD, gitlab, Jenkins, Sonar, Nexus, XLdeploy, Camunda, etc.
Ma√Ætrise des langages de programmation tels que Python, Java et expertise dans l‚Äô√©criture et l‚Äôoptimisation du code SQL
Ma√Ætrise du fran√ßais et bonne maitrise de l‚Äôanglais.
Capacit√© √† travailler en √©quipe et esprit d‚Äô√©quipe.
Le processus de recrutement se d√©roule en 3 entretiens :
Prise de contact
1er entretien : Pr√©sentation et projet du candidat + pr√©sentation MP DATA
2√®me entretien : Entretien de qualification technique
3√®me entretien : Rencontre avec les √©quipes dans les locaux MP DATA + Proposition de collaboration
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer (H/F),Technology & Strategy,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-technology-strategy-3881556102?position=5&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=Tp%2BxV8D3CpC1FtkRjSsGJA%3D%3D&trk=public_jobs_jserp-result_search-card,"D√©couvrez Novencia
:
Expert en Data et Intelligence Artificielle, nous aidons nos clients √† exploiter et √† valoriser leurs donn√©es sous toutes ses formes en les accompagnant sur des projets de Data Analyse, Data Gourvernance, Data Architecture, Data Science, et Data Engineering‚Ä¶
Vous avez une solide exp√©rience de minimum 2 ans dans l'ing√©nierie des donn√©es et vous √™tes √† la recherche de nouveaux d√©fis ? Bouclez votre ceinture, la suite est pour vous !
Type de contrat : CDI
Lieu : Lyon
En qualit√© de Data Engineer (H/F), votre r√¥le sera :
Concevoir et proposer les solutions de d√©veloppement r√©pondant aux besoins fonctionnels et techniques des projets big data.
Tu participes √† la conception de solutions permettant le traitement de volumes importants de pipelines donn√©es.
R√©aliser ces solutions par l‚Äô√©criture de code, en respectant les m√©thodes et proc√©dures qualit√©s d√©finies au sein du d√©partement Technique.
Mise √† disposition s√©curis√© et lisible de la data.
S‚Äôassurer de la conformit√© fonctionnelle et technique de ces r√©alisations en effectuant les tests automatis√©s n√©cessaire et la mise en place de monitoring (syst√®me et qualit√©).
Assurer la maintenance des applicatifs / plateforme data science
Assurer une veille technologique
Vous disposez des comp√©tences suivantes :
Maitrise des plateformes Cloud (AWS, GCP ou Azure), de Scala et de SQL.
Un.e touche √† tout : poss√©dant des comp√©tences en langage Python/Spark, de bonnes capacit√©s de mod√©lisation, une forte app√©tence pour le Big Data
Fin.e connaisseur.euse : Data Engineer convaincu, tr√®s peu de secrets pour les clusters et pour les calculs parall√®les
Explorateur.trice : d√©couvre de nouvelles technos gr√¢ce √† une veille r√©guli√®re
D√©brouillard.e : rel√®ve de nouveaux d√©fis
Notre objectif commun est de co-construire votre carri√®re en fonction de vos aspirations et de vos comp√©tences.
Contactez-moi en message priv√© ou par mail √† s.ziki@technologyandstrategy.com !
Let's make it possible #together
*Nos postes sont ouverts aux personnes b√©n√©ficiant d‚Äôune Reconnaissance de la Qualit√© de Travailleur Handicap√© (RQTH). T&S Groupe encourage la diversit√© et l‚Äô√©galit√© sur le lieu de travail. Tous les candidats qualifi√©s H/F/* sont pris en consid√©ration pour un emploi sur un m√™me pied d'√©galit√©.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,Stage - Data Engineer - ML (H/F),Withings,"Issy-les-Moulineaux, √éle-de-France, France",https://fr.linkedin.com/jobs/view/stage-data-engineer-ml-h-f-at-withings-3613476264?position=6&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=wgKY5I%2FqN%2BXtVHXYWR5xEw%3D%3D&trk=public_jobs_jserp-result_search-card,"Chez Withings, nous d√©veloppons des appareils de sant√© connect√©e : nos balances connect√©es, montres hybrides, tensiom√®tres, moniteurs de sommeil et tous les dispositifs de notre gamme sont aujourd'hui utilis√©s par des millions d'utilisateurs. Notre objectif est de permettre la pr√©vention, le d√©pistage et l'accompagnement d'un certain nombre de maladies chroniques via des produits et des services innovants afin de r√©volutionner la mani√®re dont on prend soin de notre sant√©.
Au sein de l'√©quipe Machine Learning, nous d√©veloppons des algorithmes pour extraire des informations physiologiques et m√©dicales pour nos utilisateurs tels que le SPO2, la fr√©quence cardiaque, la d√©tection de diverses pathologies comme la fibrillation atriale, l'apn√©e du sommeil...
Int√©gr√©.e au sein de l'√©quipe Machine Learning, tu auras une ou plusieurs des responsabilit√©s suivantes :
D√©velopper un outil de monitoring de la dette technique, des mauvaises pratiques de code, des failles de s√©curit√© ;
Construire des dashboards de visualisation ;
Construire un syst√®me d'alerte pour notifier les contributeurs d'√©ventuels probl√®mes ;
D√©velopper des outils permettant de corriger les √©ventuels probl√®mes de fa√ßon automatis√©e ;
Requirements
√Ä la recherche d'un stage d'une dur√©e de 3 √† 6 mois ;
Pr√©paration d'un Master en √©cole d'ing√©nieur ou √©quivalent / ann√©e de c√©sure possible ;
Ma√Ætrise de Python ;
Ma√Ætrise de Debian ou de Ubuntu, de Shell et de l'environnement Linux ;
Premi√®re exp√©rience sur du d√©veloppement logiciel ;
Culture DevOps (omnipr√©sence du monitoring, automatisation des t√¢ches, ...)
Compr√©hension de la culture et des besoins des diff√©rents membres de l'√©quipe ;
Rigueur, autonomie, prise d'initiative, curiosit√©
Benefits
Rejoindre l'aventure Withings, c'est :
Int√©grer un des pionniers et leaders mondiaux de la sant√© connect√©e, plusieurs fois prim√© au Consumer Electronic Show
Contribuer √† des projets innovants et ambitieux pour la sant√© de demain dans un environnement agile et en constante √©volution
Int√©grer une entreprise internationale, membre de la FrenchTech 120, dont les √©quipes sont bas√©es √† Issy-les-Moulineaux, Boston, Hong-Kong et Shenzhen
Participer √† l'am√©lioration continue de nos produits et services en les b√™ta-testant avant leur sortie, notamment lors de nos nombreuses sessions sportives entre coll√®gues
Participer √† la Withings Med Academy en assistant √† des conf√©rences de professionnels de sant√© afin de renforcer ses connaissances dans le domaine m√©dical
Collaborer avec des coll√®gues passionn√©s et c√©l√©brer ensemble chacune de nos r√©ussites !
Toutes les candidatures re√ßues sont √©tudi√©es ind√©pendamment de l'origine ethnique, des croyances, de la religion, du genre, de l'orientation sexuelle ou de la sant√© des candidats. Withings aspire √† offrir et garantir l'√©galit√© des chances aux candidats et seules les personnes habilit√©es (RH et Management) auront acc√®s aux informations concernant votre candidature.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Machine Learning'], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': ['Hybride'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer,Thales,"Ollioules, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-at-thales-3902424527?position=7&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=0nf93AXX17MnZHS4OFuw%2Fw%3D%3D&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?
Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr√©sents sur tous les continents. Le Groupe investit dans les innovations du num√©rique et de la ¬´ deep tech ¬ª ‚Äì big data, intelligence artificielle, connectivit√©, cybers√©curit√© et quantique ‚Äì pour construire un avenir de confiance, essentiel au d√©veloppement de nos soci√©t√©s, en pla√ßant l‚Äôhumain au c≈ìur des d√©cisions.
Thales propose des solutions, services et produits qui aident ses clients ‚Äì entreprises, organisations, Etats ‚Äì dans cinq grands march√©s vitaux pour le fonctionnement de nos soci√©t√©s : identit√© et s√©curit√© num√©riques, d√©fense, a√©ronautique, espace, et transport.
QUI ETES-VOUS ?
Dipl√¥m√© d‚Äôun Bac+5 en √©cole d‚Äôing√©nieur ou √©quivalent universitaire avec une sp√©cialisation en informatique, vous avez a
u moins 3 ans d'exp√©rience
dans les technologies Big Data.
Passionn√© par le
secteur de la D√©fense et du Naval.
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
En tant que
Data Engineer,
vous jouerez un r√¥le cl√© dans la conception, le d√©veloppement et la maintenance de notre infrastructure de donn√©es, ainsi que dans la transformation et la gestion des flux de donn√©es.
VOS MISSIONS :
‚Ä¢ Concevoir, d√©velopper et d√©ployer des solutions Big Data en utilisant les technologies
Hadoop, Spark, Scala
.
‚Ä¢ Mettre en place des pipelines de donn√©es performants pour l'ingestion, le traitement et le stockage des donn√©es massives.
‚Ä¢ Collaborer √©troitement avec les √©quipes m√©tier pour comprendre leurs besoins en mati√®re d'analyse de donn√©es et proposer des solutions adapt√©es.
‚Ä¢ Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn√©es.
‚Ä¢ Assurer la qualit√© et la fiabilit√© des donn√©es trait√©es, en mettant en place des processus de validation et de nettoyage.
‚Ä¢ Identifier et r√©soudre les probl√®mes li√©s √† l'infrastructure Big Data et proposer des am√©liorations.
Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.
Show more
Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer - Nantes,Capgemini,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-nantes-at-capgemini-3803998213?position=8&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=Mef8ntH2ikGhIaILEuhGJw%3D%3D&trk=public_jobs_jserp-result_search-card,"Capgemini
Choisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations, o√π vous serez soutenu et inspir√© par une communaut√© d‚Äôexperts dans le monde entier, o√π vous pourrez r√©√©crire votre futur. Rejoignez-nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la valeur de la technologie pour les plus grandes organisations et participez √† la construction d‚Äôun monde plus durable et inclusif.
Vos missions :
Int√©gr√©(e) au sein d'une √©quipe projets intervenant pour des clients dans des secteurs d'activit√©s vari√©es, vous serez notamment en charge des missions suivantes :
Concevoir et mettre en oeuvre des strat√©gies s√©curis√©es d'acquisition et d'int√©gration de donn√©es,
Configurer des r√©f√©rentiels de donn√©es √† la pointe de la technologie dans des environnements distribu√©s, majoritairement dans le cloud (Google Cloud Platform, Azure Databricks, AWS) et/ou en environnement Hadoop (distribution MapR, Cloudera, Hortonworks),
Construire des pipelines de donn√©es pour collecter, transformer et traiter des donn√©es en collaboration avec des scientifiques de donn√©es afin de r√©pondre aux exigences de la mod√©lisation de donn√©es d'analyse avanc√©e.
Votre profil :
Dipl√¥me d‚Äôing√©nieur ou √©quivalent universitaire
Minimum 3 ans d'exp√©rience
Anglais courant
Ma√Ætrise des langages Java, Scala ou Python et expertise sur les framework Spark et/ou Hadoop.
Expertise sur les services Cloud Data Platform suivants : Azure Data Lake, Azure synapse, Azure Data Factory, Azure Data Explorer, GCP, AWS, Snowflake, Databricks‚Ä¶
3 raisons de nous rejoindre :
Qualit√© de vie au travail : accord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√©
professionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.
Apprentissage en continu : certifications et formations en libre acc√®s, accompagnement sur mesure avec votre carreer manager, parcours d‚Äôint√©gration sur 9 mois.
Avantages groupe & CSE : plan actionnariat, activit√©s √† tarifs pr√©f√©rentiels, remboursement partiel
vacances, remboursement de votre abonnement sportif ou culturel.
Nos engagements et priorit√©s :
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.
Capgemini
Capgemini est un leader mondial, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d‚Äôexp√©rience, nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Big Data engineer ‚Äì Ing√©nieur des donn√©es massives (H/F),DGSE - Direction G√©n√©rale de la S√©curit√© Ext√©rieure,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-%E2%80%93-ing%C3%A9nieur-des-donn%C3%A9es-massives-h-f-at-dgse-direction-g%C3%A9n%C3%A9rale-de-la-s%C3%A9curit%C3%A9-ext%C3%A9rieure-3778473628?position=9&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=6VmCvsOgk1%2BOB3QFaDw2dg%3D%3D&trk=public_jobs_jserp-result_search-card,"Introduction
La Direction G√©n√©rale de la S√©curit√© Ext√©rieure, DGSE, recrute Big Data engineer ‚Äì Ing√©nieur des donn√©es massives (H/F).
Le poste est situ√© √† Paris.
La nationalit√© fran√ßaise est obligatoire.
Domaine m√©tier
Sciences et Technologies
Votre environnement de travail
Le flux de donn√©es trait√©es par la DGSE est √©quivalent √† celui des GAFAM. Ces donn√©es sont au centre du travail des analystes de renseignement, qui doivent pouvoir compter sur des syst√®mes leur permettant de rechercher, croiser, traiter ces donn√©es, en temps r√©el ou en batch. Dans ce contexte, la DGSE cherche √† renforcer ses √©quipes de traitement de la donn√©e massive.
Au sein d'un service centr√© sur le stockage, l'exploitation et la valorisation des donn√©es, nous vous proposons d'int√©grer les √©quipes en charge des plateformes de stockage ou des traitements temps r√©el des donn√©es. Ces √©quipes pluridisciplinaires d√©veloppent et maintiennent de bout en bout diverses plateformes reposant sur les technologies Kafka, Yarn, Hadoop, HBase ou encore Elasticsearch. Plus sp√©cifiquement, l‚Äô√©quipe Stockage administre des entrep√¥ts Big Data ainsi que des couches d‚Äôacc√®s √† leurs donn√©es. L‚Äô√©quipe Temps r√©el con√ßoit des algorithmes r√©pondant √† des besoins de temps de r√©action tr√®s courts (lev√©e d‚Äôalertes, enrichissement √† la vol√©e, r√©ponse √† des besoins op√©rationnels).
En nous rejoignant, vous d√©couvrirez :
un environnement unique, qu'aucune autre structure ne peut vous proposer,
un m√©tier proche du renseignement et de l'op√©rationnel,
une action sur l'int√©gralit√© de la cha√Æne, du d√©veloppement au d√©ploiement en production,
un minimum de 48 jours de cong√©s par an,
une ambiance propice √† l‚Äô√©panouissement professionnel.
Vos missions
Les missions des √©quipes auxquelles vous serez amen√©s √† contribuer seront d√©termin√©es en fonction de votre exp√©rience et de vos app√©tences.
Vous serez en charge de plusieurs activit√©s parmi les suivantes :
concevoir, impl√©menter et optimiser des algorithmes de traitement de donn√©es distribu√©s (Scala, Spark, Java),
garantir le bon fonctionnement, la disponibilit√© et la performance des plateformes de traitement,
participer √† l‚Äô√©volution de l‚Äôarchitecture, en int√©grant de nouveaux composants (frameworks, biblioth√®ques, ‚Ä¶) permettant de mieux r√©pondre aux besoins,
assurer une veille technologique constante pour rester au plus haut niveau et garantir une ad√©quation des clusters existants avec l‚Äô√©tat de l‚Äôart du domaine,
contribuer √† l'am√©lioration continue de l'√©quipe,
interagir avec l‚Äô√©quipe SRE/Devops pour am√©liorer la fiabilit√© des architectures, l‚Äôautomatisation des d√©ploiements et l'observabilit√© des syst√®mes mis en ≈ìuvre.
Votre profil
Vous √™tes titulaire d‚Äôun dipl√¥me en informatique, niveau master ou √©cole d‚Äôing√©nieur, ou pouvez d√©montrer une exp√©rience √©quivalente.
Vous devez poss√©der les comp√©tences et qualit√©s suivantes :
bonnes connaissances fondamentales logicielles (structures de donn√©es, algorithmique, architecture),
ma√Ætrise des langages Scala, Java ou python, vous n'avez pas peur de monter en comp√©tences sur ceux que vous ne ma√Ætrisez pas,
adepte de l'int√©gration continue, vous √™tes familier de Gitlab CI, Github Actions ou Jenkins,
familier avec les bonnes pratiques de d√©veloppement collaboratif (usage de git, pratique de relecture de code).
En bonus :
premi√®re exp√©rience avec un framework de traitement en streaming (SparkStreaming, KStream, Storm, Flink, ...),
convaincu de l'importance de l'observabilit√© des syst√®mes qui regroupe m√©trologie, logging et tracing, vous avez d√©j√† mis en place une stack de ce type (Prometheus, Telegraph, OpenTelemetry, Jaeger, ELK, ‚Ä¶),
familier avec un outil de gestion de configuration (Ansible, Puppet, ...),
exp√©rience sur les clusters Kafka, Hadoop, HBase ou Elasticsearch de plusieurs n≈ìuds.
Les plus de l‚Äôoffre
Contexte d‚Äôactivit√©s unique
Diversit√© des projets
Technologies √† la pointe
Contact
Envoyez-nous votre candidature √† l‚Äôadresse :
dgse-macandidature.cer.fct@intradef.gouv.fr
Plus d‚Äôinformation sur www.dgse.gouv.fr > Nous rejoindre.
RESTEZ DISCRET SUR VOTRE CANDIDATURE A LA DGSE
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Ansible', 'Puppet'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer (F/H),Aubay,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-aubay-3573871076?position=10&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=Fi2i%2BPsUT%2FrkOzoKgGwkpQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Passionn√© par la Data, tu souhaites rejoindre une communaut√© d‚Äôexperts dans le domaine afin de d√©velopper tes comp√©tences en Data Engineering. Aubay renforce ses √©quipes Data et recherche des Data Engineers pour int√©grer des dispositifs de projets pointus et vari√©s.
Ton quotidien en tant que Data Engineer chez Aubay, :
D√©finition de la strat√©gie de stockage et mise en ≈ìuvre des technologie appropri√©es (base de donn√©es SQL, NoSQL, stockage distribu√©,‚Ä¶)
Ingestion des donn√©es (structur√©es, semi-structur√©es ou non-structur√©es) selon diff√©rentes fr√©quences : batch, micro-batch ou temps r√©el
Conception et mise en ≈ìuvre de pipelines de donn√©es afin de fournir des donn√©es pr√™tes √† l‚Äôemploi aux consommateurs : uniformisation, mise en qualit√©, enrichissement, calcul d‚Äôindicateurs,‚Ä¶
Conception et d√©veloppement d‚ÄôAPI pour exposer les donn√©es aupr√®s d‚Äôapplications tierces
Appui aux Data Scientists pour industrialiser et optimiser les algorithmes de Machine Learning
Pr√©paration et animation d‚Äôateliers de travail avec des interlocuteurs vari√©s : recueil/approfondissement des besoins m√©tiers, avancement/restitution des travaux, transfert de comp√©tences,‚Ä¶
Ton profil :
Tu dispose d‚Äôune formation niveau BAC+5 (Master 2 ou √©cole d‚Äôing√©nieur) sp√©cialis√©e en informatique
Tu as d√©j√† une premi√®re exp√©rience significative (a minima 2 ans) en Data Engineering sur des technologies Big Data
Les technologies telles que Hadoop, Spark ou Kafka sont tes technologies de pr√©dilection
La programmation n‚Äôa plus de secret pour toi et tu maitrise parfaitement un ou plusieurs langages de programmation suivants : Java, Scala et Python
Tu ma√Ætrises les tenants et aboutissants de la philosophie DevOps et des outils orient√©s CI/CD
Tu es soucieux de la qualit√© et de la performance de tes d√©veloppements et tu t'int√©resse √† l‚Äôinnovation frugale
Tu es un expert technique dans ton domaine sans pour autant oublier l‚Äôimportance d‚Äôune communication orale et √©crite de qualit√© et adapt√©e √† chacun de tes interlocuteurs
Tu travaille au quotidien en mode agile et tu en maitrise les fondements
Ce qui nous caract√©rise :
Des missions et projets dans le domaine du Data Engineering en nombre et dans des secteurs vari√©s (Banque, Assurance, Telecom, Industrie,‚Ä¶) qui permettent √† nos collaborateurs de monter en comp√©tences et de devenir des experts Data reconnus
De l‚Äôapprentissage en continu avec des formations et des certifications sur les technologies Data d‚Äôaujourd‚Äôhui et de demain
Des experts Data mobilisables pour accompagner et soutenir techniquement les collaborateurs sur leurs projets
Des communaut√©s de savoir-faire Data proposant de mani√®re r√©guli√®re aux collaborateurs d‚ÄôAubay du contenu et des √©v√®nements de partage (webinar, meetup/afterwork, BBL,‚Ä¶) sur les th√©matiques suivantes : Data Engineering, Data Viz, Data Science/IA, Data Platform & Architecture,‚Ä¶
Aubay encourage la diversit√© sous toutes ses formes et garantit l'√©galit√© des chances √† tous les candidats. Tous nos postes sont ouverts aux personnes en situation de handicap et nous proposons tous les am√©nagements n√©cessaires.
Ta carri√®re chez Aubay :
Tu auras la possibilit√© de d√©velopper et certifier tes comp√©tences sur les derni√®res technologies Data avec un focus fort sur les plateformes Data Cloud telles qu‚ÄôAzure Synapse Analytics, Google Cloud Platform, Snowflake et Databricks
Tu pourras rejoindre la BU d‚Äôexcellence Data et √©voluer au sein d‚Äôun environnement humain et professionnel de haut niveau. Tu profiteras d‚Äôun management sur-mesure pour t'accompagner dans ta trajectoire de carri√®re
Au sein de la BU d‚Äôexcellence, de multiples perspectives s‚Äôoffriront √† toi :
R√¥le de ¬´ Lead ¬ª : Vous pourrez gagner en responsabilit√© sur le plan technologique et devenir un r√©f√©rent aupr√®s de nos clients et des collaborateurs de la communaut√© Data Engineering
R√¥le de ¬´ Champion ¬ª : Vous repr√©senterez Aubay aupr√®s d‚Äôun ou plusieurs de nos partenaires √©diteurs strat√©giques et vous participerez activement √† l‚Äôanimation de la relation sur le plan technologique
R√¥le de ¬´ Head ¬ª : Vous pourrez prendre la responsabilit√© du savoir-faire Data Engineering et de ses offres et en assurer le d√©veloppement au sens large (d√©veloppement business, recrutement, management de collaborateurs, d√©finition de la strat√©gie et animation de la communaut√© au sein du groupe Aubay,‚Ä¶)
Besoin d‚Äôen savoir plus sur le processus de recrutement ?
Un √©change macro au niveau RH avec Doriane
Un entretien technique avec Marius ou Peter, deux de nos r√©f√©rents techniques
Un √©change manag√©rial avec le Directeur de la BU Modern BI & Data
A savoir que l‚Äôordre des √©tapes peut varier selon tes envies (ex : √©change manag√©rial avec l‚Äô√©change technique)
Aubay encourage la diversit√© sous toutes ses formes et garantit l'√©galit√© des chances √† tous les candidats. Tous nos postes sont ouverts aux personnes en situation de handicap et nous proposons tous les am√©nagements n√©cessaires.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure', 'Google Cloud Platform'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,Data Engineer,Digital Waffle,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-digital-waffle-3913824888?position=1&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=CIbs7PPg0iqB6Iyk37LUGw%3D%3D&trk=public_jobs_jserp-result_search-card,"Digital Waffle is proud to have partnered with an innovative tech startup in Paris, who are looking for a talented Data Engineer to join their growing team!
They are made up of a powerhouse of experts, combining
data engineers, business process gurus, and Project managers
who leverage the most advanced solutions available; utilising process mining, automation tools, and smart execution systems.
Looking for an experienced Data Engineer (3-5 years)
What You'll Do:
This is a full-time,
hybrid role (Paris-based)
where you'll wear many hats: data exploration, system integration, data prep, data modeling, and implementing data solutions.
Experience:
Expertise in data engineering, data modeling, and ETL (Extract, Transform, Load) processes
Data warehousing and data analytics skills
Experience handling large, complex datasets
Proficiency in SQL and programming languages like Python or Java
Stellar problem-solving and analytical skills
Top-notch communication and collaboration abilities
Bachelor's or Master's in Computer Science, Information Systems, or a similar field (a plus for process mining or intelligent process automation experience)
If you are an experienced and driven Data Engineer, please apply here!
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': ['Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer H/F,Ippon Technologies,Greater Nantes Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ippon-technologies-3902436649?position=2&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=GH7vg4huWWuTwG0Xe%2FwWPg%3D%3D&trk=public_jobs_jserp-result_search-card,"Envie de rejoindre la communaut√© DATA la plus dynamique de France ?
Notre sp√©cialit√© est de construire des data platform dans le Cloud public avec les meilleurs technos du moment : Snowflake, Databricks, Matillion, DBT.
Membre de la Practice Data, le/la futur(e) Data Engineer sera int√©gr√©(e) √† nos √©quipes de conseil et sera suivi(e) par un(e) mentor qui l‚Äôaidera √† monter en comp√©tences.
Votre champs d‚Äôexpertise :
Intervenir sur les data platforms de nos clients pour d√©velopper de nouveaux pipelines de donn√©es (ingestion, traitement, exposition).
Travailler en collaboration avec les m√©tiers et les data scientists pour leur fournir un support √† l‚Äôindustrialisation de leurs travaux (tests, int√©gration continue, scalabilit√© des mod√®les, craftsmanship etc‚Ä¶)
D√©ployer des infrastructures cloud full
infra-as-code
(Terraform, CloudFormation).
Participer aux √©v√®nements internes √† la communaut√© data (BBL, webinar, datap√©ro interne, meetup, blog, dojos) et externes (Salon du Big Data, GCP Summit, Spark Summit, AWS Summit, Devoxx, workshop partenaire, meetups).
Capitaliser sur les missions et les diff√©rents √©v√®nements de la communaut√© au travers d‚Äôarticles de blogs, REX, BBL interne.
Vos connaissances :
Un framework de calcul distribu√© tel que Spark, Storm, Flink.
Un ou plusieurs langages de programmation (Python, Scala, Java...)
Diff√©rents syst√®mes de stockage de donn√©es (SQL ou NoSQL) et bien s√ªr le langage SQL.
La connaissance de Snowflake est bienvenue ;-)
Un framework de streaming de donn√©es tel que Kafka ou Amazon Kinesis.
Une exp√©rience sur les technologies Cloud : AWS, GCP, Azure
Le delivery et les projets en production faisant partie de notre ADN, vous √™tes capable de livrer du code de qualit√© dans des environnements agiles.
De plus en plus de nos projets se font en remote avec des clients du monde entier, il devient n√©cessaire d‚Äô√™tre √† l‚Äôaise en Anglais.
Ippon technologies c‚Äôest aussi :
üëç B√©n√©ficier d'un suivi de proximit√© r√©alis√© par votre manager technique : points r√©guliers pour votre suivi en mission, votre formation et votre √©volution de carri√®re
‚úåÔ∏è Rejoindre une entreprise o√π les valeurs du sport sont nos leitmotiv : d√©passement de soi, travail en √©quipe, bienveillance.
üóíÔ∏è Apprendre via notre programme de formation BlackBelt : https://bit.ly/3ByqcIL
üòÅ Travailler en pair programming ou avec un.e mentor pour gravir les √©chelons !
üí™ Pouvoir participer √† une aventure humaine au sein de notre Fondation Ippon pour r√©duire la fracture num√©rique dans le monde !
ü§ù Participer √† nos ap√©ros et divers √©v√®nements internes pour consolider la coh√©sion d‚Äô√©quipe
Et apr√®s ?
Et oui alors ? Que se passe-t-il une fois que vous √™tes convaincu d‚Äôavoir lu l‚Äôoffre d‚Äôemploi qui vous correspond bien ?
Nous vous proposons de prendre contact et de nous rencontrer !
Les Next Steps :
1 call RH
1 √©change RH
1 √©change Technique
Si le match est bon des deux c√¥t√©s : Hadjim√© ! Vous vous lancerez sur le tatami Ippon !
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks', 'Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform', 'CloudFormation'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,"Data Engineer ‚Äì Antibes, France (H/F)",Astek,"Antibes, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-antibes-france-h-f-at-astek-3909192086?position=3&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=UlDBekVCS59%2Ffa2Hrk0odA%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Antibes - France
Publi√©e il y a 2 semaines
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Intervenir dans la conception, le d√©veloppement, les tests unitaires, la qualification, l‚Äôint√©gration continue et la mise en production d‚Äô√©volutions sur les projets du p√¥le produits scoring (un p√¥le visant √† d√©velopper des solutions permettant de g√©n√©rer des scores ou des segments d‚Äôinformation pertinents dans divers domaines, notamment : profiling TV, PUB, SAB, MMDM, Voscastview) chez l‚Äôun de nos partenaires sp√©cialis√© dans le secteur des t√©l√©coms.
Votre Mission, Si Vous L‚Äôacceptez :
En collaboration avec les autres membres de l‚Äô√©quipe, vous devrez prendre en charge le RUN des applications du p√¥le produit scoring.
Conception d‚Äôune solution se basant sur les d√©veloppements existants et les besoins m√©tiers remont√©s par le Product Owner.
R√©alisation et d√©veloppement de nouvelles fonctionnalit√©s sur les composants des applications du p√¥le produits scoring et environnement CGP.
Votre Future √âquipe :
Au sein d‚Äôun environnement riche et complexe, vous √©voluerez avec des experts passionn√©s √† la fois techniques et fonctionnels (Ing√©nieurs sp√©cialis√©s, chef de projet, scrum master, product owner, analystes ‚Ä¶).
Votre stack de jeu
D ans un environnement SAFE sous cloud GCP, Big Query, OnPrime, Grafana, Python et Ansible.
Vous ?
De formation Ing√©nieur, vous justifiez d‚Äôune premi√®re exp√©rience sur un poste de Data engineer. Vous poss√©dez des comp√©tences d‚Äôautonomie et d‚Äôadaptabilit√© et vous avez une capacit√© √† communiquer efficacement au sein d‚Äôune √©quipe.
Le Groupe Astek
Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.
Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de
ses 7800 collaborateurs
qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.
Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.
Tous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies, pr√©sent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.
Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de ses 7800 collaborateurs qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.
Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde et ayant r√©alis√© un chiffre d‚Äôaffaires hors
acquisitions de 600M‚Ç¨ en 2023.
Tous les d√©tails sur le Groupe sur le site
Nos Plus
Astek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo
Une politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversit√©
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì Data engineer ‚Äì Big Data
Caract√©ristiques de l'emploi
Cat√©gorie Ing√©nieur
Job Industry T√©l√©com / M√©dia
Postuler en ligne
Nom *
Pr√©nom *
Email *
Un email valide est requis.
T√©l√©phone *
Un num√©ro de t√©l√©phone valide est requis.
Joindre un CV *
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì Data engineer ‚Äì Big Data
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Big Query'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Adaptabilit√©', 'Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer - Profils exp√©riment√©s H/F,LCL,"Villejuif, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-profils-exp%C3%A9riment%C3%A9s-h-f-at-lcl-3888403052?position=4&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=gIHYgeFCEYY8kCc8uBBh3Q%3D%3D&trk=public_jobs_jserp-result_search-card,"üè¶ LCL, c‚Äôest LA banque urbaine du Groupe Cr√©dit Agricole - avec nous, accompagnez la transformation, le d√©veloppement et le maintien technologiques de nos outils avec une vision business et de satisfaction de nos 6 millions de clients.
En tant qu‚Äôacteur majeur de la banque de d√©tail, nous nous adaptons chaque jour aux nouveaux modes de consommation et les projets de nos de clients internes et externes tout en garantissant le besoin de s√©curit√© et de d√©veloppement technologique qu‚Äôimpliquent nos activit√©s.
üí°Organis√©es en mode Agile, les 8 squads de la tribu DATA (6 squads M√©tier et 2 squads transverses) ≈ìuvrent au quotidien pour r√©pondre √† un enjeu majeur pour la banque : la collecte, le stockage, la gestion et l‚Äôusage de la donn√©e. En interaction permanente avec les autres tribus IT et les m√©tiers, elles √©tudient et proposent les solutions et architectures √† d√©ployer pour r√©pondre au mieux aux strat√©gies de d√©veloppement et de pilotage de l‚Äôensemble des m√©tiers de la banque.
Rejoignez-nous si vous souhaitez participer aux r√©flexions et au d√©veloppement de la trajectoire technique et DataCentric du SI LCL et plus largement du Groupe CA. Vous c√¥toierez et serez au c≈ìur de l‚Äôimpl√©mentation de technologies vari√©es telles que les plateformes Teradata, les solutions d‚Äôarchitecture applicative des technologies BigData ou IA, des environnements analytiques ou encore des solutions de datavisualisation. Vous assurerez le traitement de donn√©es en temps r√©el ou en batch et exposerez les donn√©es sous diff√©rentes formes.
Que vous souhaitiez devenir expert sur les socles technologiques ou relever le challenge de la gestion de projets M√©tier, nous vous aiderons √† atteindre vos propres objectifs.
Vous rejoindrez une √©quipe pluridisciplinaire, clairement orient√©e vers le d√©veloppement de ses collaborateurs √† de nouvelles technologies !
üéØ En tant que Data Engineer :
¬∑ Vous aimez analyser les besoins avec les m√©tiers, challenger, identifier les sources de donn√©es dans les diff√©rents univers technologiques, industrialiser des algorithmes, concevoir et d√©velopper des Datalab ou des Datamart sur les plateformes ? Vous saurez relever les challenges propos√©s par les squads m√©tier !
¬∑ Vous pr√©f√©rez travailler √† l‚Äôarchitecture et au d√©ploiement de nouvelles plateformes, √† la lev√©e de la dette technologique ou encore r√©aliser de la veille au service de notre trajectoire ? La squad Socles Data est faite pour vous !
¬∑ Au-del√† des projets que vous g√©rerez, garant du bon fonctionnement de votre parc applicatif, vous attacherez une grande attention √† la mise en ≈ìuvre de solutions optimis√©es.
¬∑ La rigueur, la communication, l‚Äôesprit d‚Äô√©quipe mais aussi la curiosit√© et la cr√©ativit√© font partie de vos soft skills ! ils vous permettront de r√©pondre aux enjeux de s√©curit√©, de qualit√©, de transmission de la connaissance et contribueront √† l‚Äôatteinte des objectifs de l‚ÄôIT et plus largement de LCL, au service de ses clients.
üíª Voici les principales technologies utilis√©es au sein de la tribu, si certaines vous sont famili√®res, nous vous aiderons √† monter en comp√©tence sur d‚Äôautres !
Langages utilis√©s : SQL, Python, Scala
SGBD : Teradata et utilitaires (TPT, BTEQ, ‚Ä¶)
Streaming : Kafka
Search : ElasticSearch, SolR
Environnement : Unix
Solutions Big Data : Hadoop Cloudera, DataIku, HDFS, Hive, Impala,
Devops : GitLab, Jenkins, Nexus
Outils de visualisation : MS BI (SSIS, SSAS, SSRS) Qlik Sens, BO
Mod√©lisation : MEGA
Outils collaboratifs : GIT, Jira, Confluence, Teams
‚ö°Si les nouveaux enjeux bancaires vous int√©ressent, que vous souhaitez int√©grer une √©quipe Agile au service des m√©tiers dans laquelle vous serez force de proposition et que vous aimez travailler dans un environnement motivant et dynamique, rejoignez-nous, cette offre est faite pour vous !
üî• Les + de notre entreprise :
Acc√®s au Plan d‚Äô√©pargne Groupe, int√©ressement et participation aux b√©n√©fices de l‚Äôentreprise + abondement
Prix pr√©f√©rentiels bancaires et avantages CSE
Parcours √©volutif dans l‚Äôentreprise et/ou dans le Groupe CA.S.A
T√©l√©travail (jusqu'√† 2 jours de t√©l√©travail par semaine)
De multiples commodit√©s sur le campus (restaurants d'entreprise, salle de sport, cr√®che, centre m√©dical, m√©diath√®que...)
Forfait et avantages pratiques ¬´ mobilit√© durable ¬ª pour les velotafeurs
Des √©quipes aussi diversifi√©es que structur√©es dans une dynamique de transformation
LCL s‚Äôengage en faveur de la diversit√© et nous encourageons tout(e) candidat(e) ayant l‚Äôexp√©rience requise √† postuler √† nos offres. Tous nos postes sont ouverts aux personnes en situation de handicap.
Nous avons encore de nombreuses raisons √† vous pr√©senter pour vous convaincre de nous rejoindre mais pour cela, il faudra postuler ici !
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['JIRA', 'Confluence', 'Teams'], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Communication', 'Cr√©ativit√©'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,"Big Data Engineer Confirm√© ‚Äì Paris, France (H/F)",Astek,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-confirm%C3%A9-%E2%80%93-paris-france-h-f-at-astek-3839098103?position=5&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=%2Fgv3ywdDRdhT0vOlps7OZw%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Paris - France
Publi√©e il y a 2 mois
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Nous rejoindre en tant que
Big Data Engineer Confirm√© (H/F),
afin d‚Äôaccompagner un op√©rateur t√©l√©coms, Leader en Europe dans l‚Äôassistance et le support applicatif de niveau 3 (r√©solution des probl√®mes utilisateurs, exploitation des environnements hors production).
Un challenge portant sur des millions d‚Äôutilisateurs dans un environnement technique innovant, strat√©gique et o√π l‚Äôentraide et la bonne humeur priment !
Votre Mission, Si Vous L‚Äôacceptez :
Supervision et d√©tection et r√©solution des probl√®mes utilisateurs (d√©veloppeurs, exploitants et data exploreurs)
D√©veloppement de solutions de self-service ou d‚Äôune solution de r√©solutions automatiques des probl√®mes
Qualifier les donn√©es et les r√©sultats
Conception technique des solutions
Assurer l‚Äôaccompagnement et le d√©ploiement des √©volutions des processus et outils
Accompagner la phase de mise en production
Votre Future √âquipe :
Vous int√©grerez une √©quipe √† la fois technique et fonctionnel, qui ≈ìuvre chaque jour pour d√©velopper et maintenir en conditions op√©rationnelles l‚Äôensemble des solutions IT !
L‚Äô√©quipe est en interaction avec des clients √† la fois internes et externes.
Votre stack de jeu
Syst√®me d‚Äôexploitation : Linux
Outils des distributions : HDP, HDF, ELK
Environnement Big data : Hadoop, Spark,
Langage : Scala, Shell, Python
Cloud computing : GCP ou AWS
Base de donn√©es : No SQL (Cassandra, Mongo DB), Shell, Ansible
Dataviz : Power BI ou Kibana
Des notions en R√©seau et Syst√®mes feront la diff√©rence !
Les Petits Plus Du Projet :
Vous √©voluerez au sein d‚Äôune √©quipe impliqu√©e et r√©active et interviendrez sur un projet polyvalent et √† forte valeur ajout√©e.
Vous ?
Dipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieur ou √©quivalent de niveau Bac+5.
Vous justifiez id√©alement d‚Äôune exp√©rience d‚Äôau moins 3 ans d‚Äôexp√©riences sur un poste similaire ?
Vous faite preuve de proactivit√© et d‚Äôesprit d‚Äô√©quipe, √™tes dot√©(e) d‚Äôun excellent sens de l‚Äôorganisation et vous aimez les challenges et la r√©solution de probl√®me ?
Alors ce poste est fait pour vous, n‚Äôh√©sitez plus et rejoignez l‚Äôaventure ASTEK !
Astek
Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.
Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de
ses 7800 collaborateurs
qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.
Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.
Tous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Notre projet commun vous plait ?
Postulez √† cette annonce, et soyez transparent !
Maud, notre Talent Acquisition Referent, vous contactera pour un premier √©change.
Puis vous rencontrerez Martin, votre futur manager, avec lequel vous √©changerez autour d‚ÄôAstek, de votre parcours, de vos attentes et de votre future mission .
Enfin, vous rencontrerez J√©r√©my, notre Directeur d‚Äôagence avec lequel vous pourrez valider votre int√©r√™t et ad√©quation pour le poste et finaliser les √©l√©ments contractuels.
Nos Plus
Astek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo
Une politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversit√©
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì Hadoop ‚Äì Scala ‚Äì Data
Caract√©ristiques de l'emploi
Cat√©gorie Ing√©nieur
Job Industry T√©l√©com / M√©dia
Postuler en ligne
Nom *
Pr√©nom *
Email *
Un email valide est requis.
T√©l√©phone *
Un num√©ro de t√©l√©phone valide est requis.
Joindre un CV *
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì Hadoop ‚Äì Scala ‚Äì Data
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': ['Confirm√©'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer (H/F) - Lille,Logic@l Conseils,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-lille-at-logic%40l-conseils-3811575649?position=6&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=lsnSMaZYOtp54jPBFAW7cQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Dans le cadre du d√©veloppement de nos activit√©s sur la m√©tropole Lilloise, nous recherchons un
consultant data engineer
(H/F) pour intervenir chez l'un de nos grands comptes clients.
Vos missions :
Recueillir
les besoins m√©tiers et des √©quipes data
Concevoir et mettre en place les
traitements de donn√©es
R√©aliser les
tests de validation
Assurer
l‚Äôalimentation du dataware
R√©aliser les
ordonnancements des traitements
Etre garant de la
mise en place
, du
suivi
et de l‚Äô
exploitation
des outils d√©ploy√©s
Assurer
une veille technologique
r√©guli√®re
Environnement technique :
D√©veloppement :
Python, Scala, R, Java,
Framework :
Spark,
Hadoop,
Outils Big data :
Yarn, Pig, Hive, Kafka, Splunk
Bases de donn√©es :
MongoDB, HBase, Cassandra
ETL :
Talend, Stambia
Plateforme :
Hortonworks, Cloudera, Map Reduce
,
AWS, GCP, Azure
Votre profil :
Vous disposez d‚Äôune exp√©rience
d‚Äôau moins 2 ans en tant que data engineer
ou dans le domaine de l‚Äôanalyse et du traitement de donn√©es.
V√©ritable
passionn√© de la data
, vous √™tes
force de proposition
sur les solutions techniques √† mettre en ≈ìuvre. Vous maitrisez l‚Äôanglais dans un contexte professionnel.
Comp√©tences requises :
Analyses qualitatives et quantitatives (Interm√©diaire)
Anglais (Interm√©diaire)
Architecture fonctionnelle SI (D√©butant)
D√©veloppement d'ouvrages, produits ou √©v√©nements (D√©butant)
Gestion des contr√¥les, tests et diagnostics (D√©butant)
Gestion des risques (Interm√©diaire)
Ma√Ætrise des logiciels (Interm√©diaire)
Mise en exploitation / Production et maintenance (D√©butant)
Nos valeurs
Nous avons d√©cid√© de renverser la pyramide du management pour placer nos collaborateurs en t√™te des priorit√©s de l‚Äôentreprise.
En effet, attach√© √† des valeurs fortes, telles que la proximit√©, la sinc√©rit√©, la fid√©lit√©, la confiance et le respect, nous sommes persuad√©s que la r√©ussite r√©side dans le bien-√™tre de nos collaborateurs.
Cela se traduit par un accompagnement de proximit√©, de la transparence sans langue de bois, des √©changes r√©guliers avec les managers r√©f√©rents, un accompagnement dans le d√©veloppement de carri√®re qui est construit et jalonn√© avec les formations et certifications n√©cessaires et les missions en ad√©quation, pour mener √† bien l‚Äô√©volution de carri√®re.
Pour vous convaincre de nous rejoindre, nos avantages salari√©s compl√©mentaires :
Environnement bienveillant et stimulant au sein de 3 p√¥les d‚Äôexpertises
Formations et Certifications √† la demande
Tickets restaurants : 13‚Ç¨ par ticket
Remboursement √† 100 % des abonnements de transports en commun
Mutuelle frais de sant√© avec de hautes garanties
Prise en charge √† 100% de l‚Äôassurance Pr√©voyance
Ch√®que Cadeau Culture 120 ‚Ç¨
Compte CSE avec une cagnotte de 390 ‚Ç¨
Compte CE : billetterie, voyages, culture, sorties, √† des tarifs pr√©f√©rentiels
Des √©v√®nements chaque mois : activit√©s associatives, sportives, afterwork, s√©minaire,
Partenariat Losc (participation aux match dans la loge VIP logical conseils ‚Äì (Une Vingtaine de match par an)
Possibilit√© de t√©l√©travail
En int√©grant Logic@l Conseils, vous participez √† une r√©elle aventure humaine, alors pour postuler, il suffit de cliquer ci-dessous !
Tous nos postes sont ouverts, √† comp√©tences √©gales, aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['Cassandra', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,Data Engineer,CGI,"Niort, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-at-cgi-3902057928?position=7&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=rAZwnI6BIvOJVViuEWO5Cw%3D%3D&trk=public_jobs_jserp-result_search-card,"Description de poste
Big Data, Data Science, Data analyse, Data architecture ... √áa n‚Äôa pas de secret pour vous ?
Que vous commenciez votre carri√®re professionnelle ou que vous soyez sp√©cialiste de l‚Äôune de ces disciplines, int√©grer notre communaut√© Data, c‚Äôest l‚Äôassurance de progresser, innover, partager, vous certifier et rendre service √† nos clients.
Si vous souhaitez int√©grer nos √©quipes √† Niort et accompagner les plus grands acteurs du secteur des Assurances, cette annonce est susceptible de vous int√©resser.
En tant que Data Engineer, vous serez responsable de la conception, du d√©veloppement, de la gestion et de l'int√©gration des syst√®mes bas√©s sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop. Ce r√¥le implique la mise en place d'architectures √©volutives et hautement disponibles pour r√©pondre aux besoins de traitement et de stockage de donn√©es de l'entreprise.
Fonctions et responsabilit√©s
Vos responsabilit√©s seront les suivantes:
-Maintenir et d√©velopper des solutions bas√©es sur les services AWS pour le stockage, le traitement et l'analyse de donn√©es
-Utiliser les services AWS appropri√©s tels que Amazon EC2, S3, RDS, Lambda, etc., pour r√©pondre aux exigences du projet.
-Cr√©er et maintenir les configurations Terraform pour la gestion de l'infrastructure en tant que code (IaC) sur AWS
-Participer √† la maintenance et √† la mise en place d'environnements OpenShift pour l'h√©bergement d'applications et de services
-G√©rer et administrer les clusters Kafka pour garantir la disponibilit√©, la performance et la s√©curit√© du syst√®me de messagerie
Participer √† l‚Äôassistance utilisateurs sur les briques de la plateforme Hadoop Cloudera Data
-Travailler avec les projets et les devOps pour assurer un traitement efficace des donn√©es
En rejoignant CGI, vous b√©n√©ficiez notamment d‚Äôune offre compl√®te de formations (techniques, m√©tiers, d√©veloppement personnel,‚Ä¶), de flexibilit√© gr√¢ce √† notre accord t√©l√©travail (jusqu‚Äô√† 3 jours de t√©l√©travail par semaine), d‚Äôune politique de cong√©s avantageuse (27 jours de cong√©s pay√©s, RTT, cong√©s anciennet√© et enfant malade,‚Ä¶) et d‚Äôun package d‚Äôavantages int√©ressant (r√©gime d‚Äôachats d‚Äôactions, participation, CSE,...).
Qualit√©s requises pour r√©ussir dans ce r√¥le
Ayant une premi√®re exp√©rience en tant que Data Engineer, vous avez une premi√®re exp√©rience relative aux points suivants:
-D√©veloppement et int√©gration sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop
-Connaissance avanc√©e de l'administration Kafka, y compris la configuration, la gestion et la r√©solution des probl√®mes
-Mise en ≈ìuvre de l'infrastructure en tant que code √† l'aide de Terraform
-Bonne compr√©hension des bonnes pratiques de s√©curit√© pour les syst√®mes cloud, les clusters Kafka et les plateformes Hadoop
CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, √† l‚Äô√©volution de carri√®res des hommes et des femmes et au bien-√™tre de nos salari√©s LGBT+. Dans un souci d‚Äôaccessibilit√© et de clart√©, le point m√©dian n‚Äôest pas utilis√© dans cette annonce. Tous les termes employ√©s se r√©f√®rent aussi bien au genre f√©minin que masculin.
Ensemble, en tant que propri√©taires, mettons notre savoir-faire √† l‚Äô≈ìuvre.
La vie chez CGI est ancr√©e dans l‚Äôactionnariat, le travail d‚Äô√©quipe, le respect et un sentiment d‚Äôappartenance. Chez nous, vous pourrez exploiter votre plein potentiel parce que‚Ä¶
Nous vous invitons √† devenir propri√©taire d√®s le jour 1 alors que nous travaillons ensemble √† faire de notre r√™ve une r√©alit√©. C‚Äôest pourquoi nous nous d√©signons comme associ√©s de CGI, plut√¥t que comme employ√©s. Nous tirons profit des retomb√©es de notre succ√®s collectif et contribuons activement √† l‚Äôorientation et √† la strat√©gie de notre entreprise.
Votre travail cr√©e de la valeur. Vous √©laborerez des solutions novatrices et d√©velopperez des relations durables avec vos coll√®gues et clients, tout en ayant acc√®s √† des capacit√©s mondiales pour concr√©tiser vos id√©es, saisir de nouvelles opportunit√©s, et b√©n√©ficier d‚Äôune expertise sectorielle et technologique de pointe.
Vous ferez √©voluer votre carri√®re en vous joignant √† une entreprise b√¢tie pour cro√Ætre et durer. Vous serez soutenus par des leaders qui ont votre sant√© et bien-√™tre √† c≈ìur et qui vous permettront de saisir des occasions afin de parfaire vos comp√©tences et √©largir les horizons.
Joignez-vous √† nous, l‚Äôune des plus importantes entreprises de conseil en technologie de l‚Äôinformation (TI) et en management au monde.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['OpenShift'], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Flexibilit√©'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['1'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer (H/F),ternair,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ternair-3915757963?position=8&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=fnWL1RHsXOUn1571MFK17A%3D%3D&trk=public_jobs_jserp-result_search-card,"üë®‚ÄçüöÄ MISSION : üë©‚ÄçüöÄ
En coh√©rence avec la strat√©gie d‚Äôentreprise et la roadmap data, vous aurez pour principales missions de :
En lien avec l‚Äô√©quipe DevOps, construire, maintenir et faire √©voluer la plateforme de donn√©es;
D√©finir et piloter la coh√©rence de la collecte, la gestion et l‚Äôalimentation des donn√©es internes et externes, en diff√©rents modes : batch, streaming, API (architecture micro-services);
Pr√©parer et mettre en qualit√© les donn√©es pour les rendre disponibles dans les diff√©rents environnements de travail (datalake, datawarehouse, datamart);
V√©rifier la qualit√© des donn√©es, de leur bonne et r√©guli√®re ex√©cution ainsi que de leur utilisation ad√©quate (gestion des co√ªts);
Travailler en √©troite collaboration avec les data analysts, scientists et data stewards et business de l‚Äôentreprise ;
En lien avec l‚ÄôIT et la s√©curit√©, veiller aux r√®gles d'int√©grit√© et de s√©curit√© des donn√©es;
Veille technologique.
üßÆ Les outils :
Plateforme data : Google Cloud Platform (Big Query, Airflow)
D√©veloppement : Github/GitLab, Docker, Terraform, Python
Analytiques : Qlik
Gestion de projet s: Jira, Confluence, Miro, Drive, Docs, Sheets, Slides
ü§© Profil recherch√© : ü§©
Exp√©rience d'au moins 4-5 ans (apr√®s √©tudes) en data ing√©nierie (flux, mod√©lisation, run)
A l‚Äôaise avec l‚Äôenvironnement Cloud et les infrastructures digitales
Communiquant, p√©dagogue et fortes capacit√©s relationnelles
Anglais (√† l‚Äô√©crit)
R√©mun√©ration : 42-60 k‚Ç¨ en package selon exp√©rience
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Big Query'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': ['JIRA', 'Confluence'], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['Package'], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Data Solutions Engineer (Data & AI),LVMH,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-solutions-engineer-data-ai-at-lvmh-3900392289?position=9&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=IQD19zGtUnDkMOS73%2BJYWQ%3D%3D&trk=public_jobs_jserp-result_search-card,"LVMH is the #1 Luxury group and is currently accelerating rapidly on digitalisation. It is bringing technology and innovation in the core of the established 75+ Maisons by inventing unique and powerful products and services.
We are looking for talented solution engineers (Software, Cloud, Data and AI) to join our team and be part of this tech revolution of bringing the Group and its Maisons to the next level.
If you believe Data and AI can enhance the retail industry, from the day-to-day operational tasks to the long term customer experience,
If you think that the Cloud technologies (we love Google Cloud) is a revolution for Data and AI products,
If you like building tech solutions having direct impacts on billion-dollar-valued businesses,
If you have good communication skills and like sharing your knowledge,
Apply now, and join us!
The mission
The Solution Engineer is providing advices and technical assets to the Maisons having Data & AI projects.
Our team (Group Data team) is building a technical framework for all the Maisons to implement easily and quickly Data and AI use cases. Your mission will be to support the Maisons to convert their use case needs to concrete and production ready technical solutions using our framework and tools.
You will cover a portfolio of Maisons, in direct contact with their business analysts, data scientists and IT teams. You will be their dedicated referent on the Data & AI technical topics (Data platform, AI/ML softwares, data transport and transformations, data quality).
Main responsibilities
You will be responsible of providing support and advices to a portfolio of Maisons on Data & AI tech topics (Cloud, Data stacks, Data transformations, Data transfers, ML ops).
You will keep a recurrent discussion with the Maisons to accelerate their projects and immediately provide our support when it's needed.
You will follow-up the engaged productions in the Maisons and report them to the global group data strategy committees.
Applying the quality and security standards. Making them evolve if necessary.
Producing realistic, understandable and documented solutions following the group guidelines.
Sharing and learning from the team by communicating difficulties and successes, taking and bringing honest feedbacks and improving the identified pain points.
Taking responsibility as member of the team on the product performances (delivery and long term usage)
Required expertise and knowledge
Ability to build technical solutions answering concrete usage (User Stories) and communicate them to the team.
Dimension and evaluate complexity for technical solution productions.
Extensive knowledge and experience with good learning and sharing abilities.
Evaluate quickly risks and opportunities about technical choices.
Solid oral, written, presentation and interpersonal communication and relationship skills.
Problem-solving skills on Data and AI, coding and software development
Tech lover
Feedback taker and giver
Team player
Key benefits to join our team
Attractive packages
Offices in the 8th arrondissement near the Champs Elys√©es
Flexibility on the working hours
Remote work possible (~40%)
7 weeks of holidays (cong√©s pay√©s + RTT)
LVMH brands exclusive private sales
Great employee committee and health insurance (CE, mutuelle)
Last generation MacBooks
Part of a young, motivated and tech savvy team. Get prepared for the Thursday drinks and the tech meet-ups!
You‚Äôre eligible if
You have a strong experience (3+ years) in cloud data architecting or consultancy.
You graduated from an engineering (or equivalent) with a master‚Äôs degree. Computer Science knowledge is mandatory.
Experience on data stacks and/or Google Cloud (built in components) is a huge plus.
French and English both written and oral (Maisons are all over the world)
You‚Äôre thrilled to support the #1 luxury group to get even better.
Hiring Process
Call with our HR partner dedicated to the Tech Team
Technical interview with the Solution Engineering Manager
Technical test
Interview with the Head of Engineering
Still here? Apply now!!
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['ML', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication', 'Flexibility']}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': ['40'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,"Big Data Engineer ‚Äì Secteur T√©l√©com ‚Äì Paris, France (H/F)",Astek,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-%E2%80%93-secteur-t%C3%A9l%C3%A9com-%E2%80%93-paris-france-h-f-at-astek-3832149765?position=10&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=%2Fgwdg%2BYdGKwK5zWpSPfDOg%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Paris - France
Publi√©e il y a 2 semaines
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Nous rejoindre en tant que
Big Data Engineer (H/F),
afin d‚Äôaccompagner un op√©rateur t√©l√©coms, Leader en Europe dans la gestion de ses portails clients grands publics (multimarques mobile et internet).
Un challenge portant sur des millions d‚Äôutilisateurs dans un environnement technique innovant et strat√©gique.
Votre Mission, Si Vous L‚Äôacceptez :
Qualifier les donn√©es et les r√©sultats
Conception technique des solutions
D√©cliner les impacts de la strat√©gie et des innovations technologiques au sein des processus et outils de l‚Äôexploitant SI
Assurer l‚Äôaccompagnement et le d√©ploiement des √©volutions des processus et outils
Contribuer aux programmes de transformation DevOps, Cloud et catalogues des offres SI
D√©velopper des fonctions transverses et les ¬´ uses cases ¬ª
Accompagner la phase de mise en production
Votre Future √âquipe :
Au sein d‚Äôun environnement riche et complexe, vous √©voluerez avec des experts passionn√©(e)s √† la fois techniques et fonctionnels (Ing√©nieurs sp√©cialis√©es, chef de projet, scrum master, product owner, analystes‚Ä¶).
L‚Äô√©quipe est en interaction avec des clients √† la fois internes et externes.
Votre stack de jeu
Syst√®me d‚Äôexploitation Linux
Big data (Hadoop, Spark, Scala)
Cloud computing (GCP‚Ä¶)
S QL, No SQL (Cassandra, Mongo DB)
Dataviz : Power BI ou Kibana
Des notions en d√©veloppement feront la diff√©rence !
Les Petits Plus Du Projet :
Vous √©voluerez au sein d‚Äôune √©quipe impliqu√©e et r√©active et interviendrez sur un projet polyvalent et √† forte valeur ajout√©e.
Vous ?
Dipl√¥m√©(e) d‚Äôune
√©cole d‚Äôing√©nieur
ou √©quivalent de niveau Bac+5. Vous justifiez id√©alement d‚Äôune exp√©rience d‚Äôau moins 2 ans sur un poste similaire.
Ce descriptif vous interpelle ?
Alors ce poste est fait pour vous, n‚Äôh√©sitez plus et rejoignez l‚Äôaventure ASTEK !
Astek
Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.
Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de
ses 7800 collaborateurs
qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.
Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.
Tous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Vous vous √™tes reconnu(e) sur l‚Äôannonce et Astek vous pla√Æt !
Julie , Talent Acquisition Officer vous contactera pour en savoir plus sur vous.
Par La Suite, 2 √âchanges Maximum :
Le premier avec Mathieu (votre futur N+1, avec lequel vous √©changerez autour d‚ÄôASTEK, de votre parcours, de vos attentes et de la mission)
Le second avec Anthime (Notre Directeur d‚Äôagence pour valider votre int√©r√™t pour le poste et vous pr√©senter les √©l√©ments contractuels).
Nos Plus
Astek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo
Une politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversit√©
Bienvenue dans la team ! Allez-y, maintenant c‚Äôest √† vous de jouer !
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì big data engineer
Caract√©ristiques de l'emploi
Cat√©gorie Ing√©nieur
Job Industry T√©l√©com / M√©dia
Postuler en ligne
Nom *
Pr√©nom *
Email *
Un email valide est requis.
T√©l√©phone *
Un num√©ro de t√©l√©phone valide est requis.
Joindre un CV *
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì big data engineer
Show more
Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,DATA ENGINEER S√âCURIT√â H/F,Akademija Oxford,"Boulogne-Billancourt, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-s%C3%A9curit%C3%A9-h-f-at-akademija-oxford-3917866657?position=1&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=Mk9nataTJV4b3v8yeh%2BlWQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Une entreprise du secteur de la protection de l‚Äôenvironnement et bas√©e dans les Hauts-De-Seine recherche un.e Data Engineer S√©curit√© dans le cadre d‚Äôun contrat d‚Äôapprentissage.
Au sein de son Data Service, votre r√¥le sera d‚Äô√©tablir la strat√©gie des architectures data sur les aspects s√©curit√© en lien avec la strat√©gie globale m√©tier et contribuer √† la d√©clinaison des principes du mod√®le de s√©curit√© globale.
Vous devrez √©galement √©laborer des mod√®les de r√©f√©rence pour les architectures data, mais aussi contribuer √† la d√©clinaison des politiques de s√©curit√© en standards de s√©curit√© op√©rationnels.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer,MindPal,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-mindpal-3919800161?position=2&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=l1UUPOQsgk8%2BcVvdL4FkwA%3D%3D&trk=public_jobs_jserp-result_search-card,"We are looking for
Data Engineer!
Responsibilities
Designing, creating, and maintaining data processing systems
Analyzing and optimizing data processing workflows
Collaborating with the team to ensure data quality and efficiency
Testing and implementing new solutions
Requirements
At least 2 years of experience in designing and creating data processing systems
Proficiency in tools and programming languages related to data engineering (e.g. Hadoop, Spark, Scala, Python)
Excellent knowledge of databases and SQL language
Ability to work in a team and communicate effectively with other departments
Communicative English skills
Experience with AWS/AWS Glue is a plus
We Offer
B2B contract
Full-time job
Remote work and flexible hours
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer (H/F),Web Transition,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-web-transition-3909147172?position=3&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=WhWEfSHP6nlUfjNFUtD%2BOw%3D%3D&trk=public_jobs_jserp-result_search-card,"Web Transition, c‚Äôest qui ?
Fond√©e en 2011,
Web transition
est une entreprise de services num√©riques op√©rant sur le march√© de l‚ÄôIT/Digital !
Constituant une part essentielle de
MoOngy Digital Lab
, Web Transition accompagne ses clients grands comptes sur leurs projets de Webmarketing, de Design, Gestion de projet et √©galement en Data !
Notre objectif : nous implanter comme un acteur principal sur le march√© de la Transformation Digitale en accompagnant et valorisant les comp√©tences de nos collaborateurs !
Nous sommes convaincus que le succ√®s de MoOngy Digital Lab r√©side dans la somme des potentiels de nos √©quipes ü§ù
Ton √©quipe : La tribu Data
Parce qu‚Äôil est indispensable que tu puisses partager tes connaissances mais aussi en acqu√©rir de nouvelles, tu feras partie de l‚Äôune de nos tribus : celle de la Data. De plus, cela te permettra d‚Äô√™tre acteur dans le d√©veloppement et la strat√©gie de Web Transition. Ce syst√®me de co-r√©flexion et co-construction est un fondement essentiel chez nous !
Dans cette aventure, tu :
T‚Äôassures
de la ma√Ætrise de la donn√©e et est garant de la qualit√© de son utilisation (r√©f√©rencement, normalisation, et qualification)
Travailles
√† la compr√©hension et l'int√©gration des donn√©es en provenance des diff√©rents formats
des interfaces de flux
√©galement √† la d√©finition de la politique de la donn√©e et √† la structuration de son cycle de vie dans le respect des r√©glementations en vigueur
la supervision et l'int√©gration des donn√©es de diverse nature qui proviennent de ces sources multiples et v√©rifie la qualit√© des donn√©es qui entrent dans le Data Lake
Garantis
l'acc√®s qualitatif aux sources de donn√©es
Facilites
l‚Äôacc√®s aux donn√©es pour tes coll√®gues (data scientists, data analysts‚Ä¶)
Assistes
les autres √©quipes dans l'acc√®s et la compr√©hension des donn√©es des socles.
Rejoins-nous si tu as :
Exp√©rience d‚Äôau-moins 4 ans dans la Data
App√©tence √† la qualit√© des donn√©es.
Connaissance famili√®re des Datawarehouses.
Maitrise de Python, Oracle SQL, GCP/Power BI
Aisance avec les indicateurs, tu as une bonne capacit√© d'analyse et de r√©daction.
Ton savoir-√™tre :
Ouvert d‚Äôesprit
Rigoureux
Autonome
Respectueux des diff√©rences de chacun
Curieux
Proactif
Agile
Par o√π on commence ?
Un premier entretien RH d‚Äô1h pour comprendre ton parcours et tes aspirations
Un second entretien de 45 minutes avec l‚Äôun de nos Business Manager afin de valider tes comp√©tences et qu‚Äôil se projette sur l‚Äôune des missions qu‚Äôil pourrait te proposer
Un troisi√®me entretien de quelques minutes avec notre responsable d‚Äôagence pour te proposer d‚Äôint√©grer notre superbe Team Web !
3 entretiens en peu de temps, si ton profil correspond tu int√®greras tr√®s vite nos √©quipes üòâ
Pr√™t pour embarquer dans notre grande aventure humaine ? Deviens notre futur Weber en postulant √† cette offre ! Voici les avantages qui t‚Äôattendent en tant que Weber :
ü§© Des coll√®gues incroyables
üèÜ Certifi√©e Great Place to Work
üéÆ Des bureaux sympas (o√π vous serez toujours les bienvenus)
üéâ Des teambuilding et √©vents tous les mois
üíª Des tributs m√©tiers pour √©changer entre Weber du m√™me m√©tier
Des missions chez le client qui sont accompagn√©es et coach√©es par ton manager
Un accompagnement dans ton plan de carri√®re et tes envies de re skilling
ü§ì Un catalogue de formations certifiantes ouvert √† tous les salari√©s
üçΩÔ∏è Une carte tickets restaurant MyEdenred
‚ù§Ô∏è Une mutuelle GrasSavoye
üöé Une prise en charge des frais de transport √† 100%
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data Engineer / Ops H/F,Chantelle,"Cachan, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-ops-h-f-at-chantelle-3909858815?position=4&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=L4rwOAa52tSFHDVPvaDZeg%3D%3D&trk=public_jobs_jserp-result_search-card,"La Direction des Syst√®mes d'Information et du Digital du groupe Chantelle recherche son/sa futur.e Data Engineer / Ops H/F, pour le lancement du grand chantier de r√©novation de l'architecture Data : la bascule de l'int√©gralit√© de son Data Warehouse vers Google Big Query.
Vos Missions Sont Les Suivantes
Vous concevez et mettez en ≈ìuvre une infrastructure autour de Google Cloud Platform permettant de collecter, transformer, charger et historiser les donn√©es g√©n√©r√©es par l'entreprise.
Vous travaillez en √©troite proximit√© avec le lead data engineer de l'√©quipe, l'√©quipe
int√©gration en charge du d√©veloppement des interfaces, avec notre √©quipe de Data Analysts qui sont en charge d'exposer cette donn√©e au reste de l'entreprise ainsi qu'avec l'√©quipe technique en charge des infrastructures transverses.
Vous collaborez avec l'ensemble des domaines fonctionnels de la DSI (MasterData, Supply Chain, Manufacturing, B2B, et B2C, Finance ...) dans le cadre des projets men√©s par le Groupe.
Vous apportez l'assertivit√© technique sur tous les sujets d'architecture data, et √™tes force de proposition, par exemple choix de mise en place de pipeline temps r√©els ou au contraire de flux de donn√©es en mode batch, ou bien encore stockage sur Big Query / Big Table en fonction des cas d'usage.
Vous d√©finissez ces √©l√©ments structurants, en justifiant vos choix, et les
mettez en ≈ìuvre.
Les enjeux sont forts et les use cases nombreux √† l'√©chelle du groupe : am√©lioration du pilotage de nos stocks en dimensionnant mieux nos quantit√©s √† produire et nos assortiments, par magasin, meilleure ad√©quation des achats mati√®res premi√®res vs objectifs de stocks, produits finis, personnalisation de nos sites e-commerce en temps r√©el en fonction de nos profils client, refonte de nos flux / Apisation, ...
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Big Query'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer (F/H/X),Goaheadspace,"Pantin, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-x-at-goaheadspace-3915359112?position=5&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=l%2FLvWhMpcc6a1c7uxwyTjQ%3D%3D&trk=public_jobs_jserp-result_search-card,"MFG Labs est une soci√©t√© de conseil et r√©alisation experte en data, qui aide les entreprises √† am√©liorer leurs prises de d√©cision, √† automatiser leurs processus et √† cr√©er de nouveaux services gr√¢ce √† la data science, au design et √† l'utilisation des derni√®res technologies.
MFG Labs intervient √† toutes les √©tapes de votre transformation data : de la cr√©ation d'une feuille de route de projets data, √† la d√©couverte d'insights, √† la mod√©lisation de probl√©matiques complexes, de la cr√©ation d'un mod√®le pr√©dictif √† l'impl√©mentation technique d'une solution data sur-mesure
MFG Labs accompagne ses clients de diff√©rentes mani√®res :
Strat√©gie
Solutions
Fondations
MFG Labs d√©ploie une approche holistique pluridisciplinaire, en m√™lant des data scientists, des designers, des data engineers et des consultants, afin d'apporter des solutions compl√®tes de bout en bout √† des probl√©matiques complexes.
Dans le cadre du d√©veloppement de l‚Äô√©quipe, nous recherchons un.e Data Engineer √†
Pantin (magasins g√©n√©raux).
Au sein de l‚Äô√©quipe Data Technology, vous aurez pour mission de travailler sur des probl√©matiques de collecte de la donn√©e sur tout type de support digital : web, mobile, application, voire IoT.
Votre r√¥le au sein de l‚Äô√©quipe :
Faire partie d‚Äôune √©quipe pluridisciplinaire avec des talents en Design de Service, Consulting et Data science.
D√©velopper des applications de production int√©grant diff√©rents outils : des Math√©matiques Appliqu√©s, Machine (Deep) Learning, Recherche Op√©rationnelle, Statistiques.
D√©velopper des pipelines de traitement de donn√©es avec l‚Äô√©quipe de Data Science pour : ing√©rer, transformer et d√©livrer des donn√©es et modÔøΩÔøΩles √† nos applications.
D√©ployer des applications utilisant les derniers outils mis √† disposition par les diff√©rents Clouds publics.
√Ä propos de vous :
Vous √™tes titulaire d'un niveau Bac +4/Bac +5 d'une √©cole d'ing√©nieur
Vous avez au minimum deux ans d'exp√©rience hors stage ou alternance
Vous √™tes rigoureux¬∑se vis-√†-vis de vous-m√™me et des autres quant √† la qualit√© du code.
Vous avez quelques connaissances et comp√©tences solides en d√©veloppement et en en Data Ing√©nierie au sens large.
En
d√©veloppement
Python 3 et SQL
Framework de traitement de donn√©es (Spark ou √©quivalent)
Docker
GIT
En +
Framework permettant de d√©ployer des APIs (Flask ou √©quivalent)
CI/CD
La pratique d'au moins un cloud (AWS, GCP ou Azure) est appr√©ci√©e
En Data Ing√©nierie
Datawarehouse ou Datalake
Data Pipelines Batch et/ou Straming
En +
Outils de BI (Tableau, Power BI‚Ä¶)
Outils MLOps (Sagemaker, VertexAI, etc.)
Si vous vous reconnaissez dans cette annonce, n'h√©sitez pas √† postuler !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': [], 'Other': ['ML', 'Statistiques', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer / Big Data,ALTEN,"Antibes, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-big-data-at-alten-3896177673?position=6&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=y%2FMsM8w7nqJAVlPH8FLpHg%3D%3D&trk=public_jobs_jserp-result_search-card,"Alten is one of the 3 main consulting societies in France. It is present in more than 30 countries in the word. Sophia-Antipolis is the first and largest technopole in Europe, located in the South of France between Nice and Cannes, near Antibes. It‚Äôs also called the European Silicon Valley.
Reporting to our consulting team, you will work in an IT environment as an IT Business Analyst, taking part in projects in an Agile environment.
Job Description
The mission consists in taking part toprojectsthat are collecting, processing, and converting raw data into information (Flat Data + KPIs) that can be interpreted by data/business analysts.
TheData accessibilityis the ultimate goal of this mission, by enabling the Digital data users to utilize data for their business decisions.
This role is more Pipeline-centric, for which you need in-depth knowledge of distributed systems and computer science.
The mission scope will encompass the design and delivery of some key components of the Digital Data platform(Spark environment, Scala language) including following activities:
Participate to specifications reviews, propose technical solutions and perform feasibility studies.
Acquire datasets that align with business needs.
Develop algorithms to transform data into useful, actionable information.
Develop, construct, test, and maintain optimal data pipeline architectures.
Create new data validation methods and data analysis tools.
Ensure compliance with data governance and security policies.
Identify ways to improve data reliability, efficiency, and quality.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Prepare data for predictive and prescriptive modeling.
Work with data and analytics experts to strive for greater functionality in our data systems; which requires a closed collaboration with the other trains.
Develop software according to Amadeus Standards, including documentation
Perform code reviews in line with Amadeus quality standards.
Conduct unit, package and performance tests of the software and ensure a level of quality in line with the Amadeus guidelines.
Participate in the validation / acceptance phase of the product cycle ensuring the fine-tuning necessary to finalize the product.
Produce software documentation necessary for the application and issue it to the requesting departments.
Support the end user in the Production phase by debugging existing software solutions in response to Problem Tracking Records (PTR) and Change Requests (CR) issued from Product Management or Product Definition.
As part of the team, the consultant will, as well, work as DevOps, releasing the software load to production, monitoring jobs and being involved in maintenance activities. Quality analyst activities are also handled by the Devs.
Our current data platform is a MapR architecture, and we are in the process to migrate the whole platform to the Azure cloud., which is one of the key focuses for the team in the upcoming months. This will trigger easier adoption of data and foster collaboration within Amadeus around data.
Qualifications
Technical skills:
Previous experience as a data engineer or in a similar role
Experience building or optimizing ‚Äúbig data‚Äù data pipelines, architectures and data sets.
Hands-on experience with Scala (>2 years or a strong experience with Java/C++ with a good knowledge level of Scala)
Experience with big data tool: Spark, Kafka, MapR , Hadoop
Understanding extract, transform, and load ETL systems
Knowledge of cloud services: MS Azure
Soft skills:
Agile Mindset: must be comfortable working with Agile values and artifacts
Fast learning: must be able to adapt quickly to the existing environment and new changes
Analytical thinking and problem-solving mindset: must be able to quickly identify, implement work-around to solve incidents and work on long term data solutions
Team spirit, knowledge sharing, Empathy: must be able to work in a team and to communicate clearly with the other team members and users
Pro-activity, Professionalism, Opennessand Innovative mindset
Various:
English: professional level
Knowledge of Scrum framework and Agile methodologies.
Knowledge of airline business is a plus
Additional Information
ALTEN places the career development of the Engineers at the heart of its model and allows you to quickly take on responsibilities and evolve in line with your professional objective. It's the promise of growing your skills on concrete subjects in a project team, with a permanent contract as an ALTEN consultant!
Do you recognize yourself in this description? Then send us your CV.
Our teams will be delighted to study your application and meet you!
Show more
Show less","{'ProgLanguage': ['Java', 'C++', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Empathy', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['2'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer (H/F),Wewyse,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-wewyse-3912830682?position=7&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=NaOlOQcNmnyGl8uU35Ujaw%3D%3D&trk=public_jobs_jserp-result_search-card,"Cette offre d‚Äôemploi est fournie par P√¥le emploi
Description
Wewyse est un cabinet de conseil sp√©cialis√© en Data et en Intelligence Artificielle. C'est aussi et surtout une communaut√© de passionn√©s partageant l'ambition de grandir ensemble et d'ouvrir le champ des possibles dans leurs domaines. Si vous pensez que la Data et l'Intelligence Artificielle ont beaucoup √† offrir au monde de demain, et si vous souhaitez apporter votre contribution √† ce monde, avec humilit√© et enthousiasme, alors vous √™tes un Wyser en puissance. √ätre Data Engineer chez Wewyse c'est : Int√©grer une communaut√© d'experts Data passionn√©s. Recevoir et partager de la connaissance et des savoirs-faire lors de nombreux √©v√®nements. Intervenir chez des clients pour y porter l'expertise Wewyse dans des contextes et des secteurs vari√©s. Participer √† des projets innovants au sein de notre Datalab, avec des Wysers mais aussi avec des partenaires acad√©miques et des start up. Viser l'excellence des d√©veloppement en s'appuyant sur le Software craftsmanship Concevoir des architectures logicielles modernes. Penser DevOps pour l'automatisation des d√©ploiements et la continuit√© des services. √ätre encourag√©, conseill√© et accompagn√© dans un parcours de formation adapt√© √† vos ambitions professionnelles. Faire partie de la famille Wemanity avec ses √©v√®nements et ses multiples opportunit√©s de carri√®re. Ce que nous aimons : Les personnalit√©s ouvertes, curieuses, ambitieuses Les langages Scala, Python et Java Le cloud : AWS, GCP, Azure Les √©cosyst√®mes : Hadoop et Spark La conteneurisation : Docker et Kubernetes Les m√©thodes Agiles Le SQL et le NoSQL . L'approche DevOps : Jenkins, Ansible et Terraform Le versionning : Git L'anglais Vous vous reconnaissez ? Alors n'h√©sitez pas √† postuler !
PROFIL SOUHAIT√â
Exp√©rience
D√©butant accept√©
Source: Pole emploi (https://www.pole-emploi.fr)
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer H/F,Dalkia,"Angers, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-dalkia-3907349741?position=8&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=z4UpMnjSuKlynOh279nU7Q%3D%3D&trk=public_jobs_jserp-result_search-card,"Descriptif du poste
Et si vous faisiez √©quipe avec nous ? Rejoindre Dalkia, c'est plus de sens et d'implication contre le r√©chauffement climatique ; plus de relations humaines, avec un m√©tier de service anim√© par l'esprit d'√©quipe ; plus de technicit√©, avec des projets ambitieux et innovants fond√©s sur nos expertises ; plus d'employabilit√©, avec des parcours diversifi√©s et individualis√©s. Rejoindre Dalkia, c'est rejoindre plus qu'une entreprise : un collectif de 20 000 collaborateurs engag√©s en faveur de la transition √©nerg√©tique.
Dalkia Froid Solutions, acteur majeur de la r√©frig√©ration, sp√©cialis√© dans les services √©nerg√©tiques pour les process industriels et tertiaires, recherche un(e) Data Engineer
(H/F)
. Rattach√© (e) au Responsable Data au sein de la Direction des Syst√®mes D'Informations, vous √™tes le garant du bon d√©roulement des d√©veloppements de flux de donn√©es et de leur pr√©paration pour leur analyse. Vous aurez l'opportunit√© de rejoindre une √©quipe en construction.
Candidater chez Dalkia Froid Solutions, c‚Äôest avoir l‚Äôenvie d‚Äôint√©grer un grand groupe √† l‚Äôesprit familial. L‚Äôhumain est au c≈ìur de nos m√©tiers, nous donnons la chance √† tous, afin de d√©couvrir nos talents de demain. Venez renforcer notre Direction des Syst√®mes d'Informations et contribuez √† l'optimisation √©nerg√©tique √† travers la data !
Vos Principales Missions
D√©finir l'architecture ETL et d√©velopper les jobs d'int√©gration de donn√©es pour notre environnement Big Data.
Assurer le monitoring quotidien des jobs et optimiser les performances de traitement.
Garantir la qualit√© et l'int√©grit√© des donn√©es en industrialisant leur nettoyage.
Adapter les DataMarts pour le reporting en collaboration avec les √©quipes m√©tiers : comprendre et analyser les besoins utilisateurs, et r√©diger les sp√©cifications fonctionnelles et techniques.
Vous serez √©galement ammen√© √† collaborer avec l'√©quipe Infrastructure pour d√©finir les besoins techniques et planifier les investissements. En lien avec votre √©quipe vous conduirez des projets vari√©s et participerez √† la mise en oeuvre de rapports BI et de mod√®les de machine learning.
Lieu :
Si√®ge Social - Angers / T√©l√©travail possible √† raison de 2 jours par semaine apr√®s p√©riode d'essaie
Votre profil
Dipl√¥m√© (e) d'un bac + 5 minimum sp√©cialis√© en Data Engineer ,vous avez de bonnes qualit√©s relationnelles afin d'accompagner le d√©ploiement des projets. Votre rigueur et votre logique sont incontestables. Vous aimez travailler en √©quipe pour accompagner l'entreprise vers l'excellence op√©rationnelle.
C√¥t√© Outils ? Vous maitrisez les langages SQL et Pyhton et vous avez d√©j√† pratiqu√© les outils DBT et GitLab. Une premi√®re exp√©rience avec un outil de BI/Datavisualisation est souhait√©e.
La connaissance des outils Qlik Sense ou Talend serait un plus!
Pr√™t(e) √† faire une diff√©rence avec nous ? Postulez d√®s maintenant !
Ensemble, nous contribuons collectivement √† la transition √©nerg√©tique. C'est pourquoi chez Dalkia Froid Solutions, nous sommes convaincus que chacun peut participer √† relever ce d√©fi. De ce fait, chaque candidature recevra la m√™me attention.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer,Ramify,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-at-ramify-3896146641?position=9&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=yafYlDeSmYQN1tAFxdDJVA%3D%3D&trk=public_jobs_jserp-result_search-card,"ABOUT
Ramify‚Äôs mission is to help people achieve financial freedom, no matter who they are and how much they have. We are revolutionizing the private wealth management industry by making smart and affordable financial products for everyone.
No more standardized solutions, hidden fees and complicated words, Ramify enables everyone to become a smart investor. The team combines elements of its research with technology to design customized investment portfolios composed of world-class financial products.
The team comprises around 15 talented individuals. Ramify is looking for talented people in all sectors, who want to have a huge impact, move fast and deliver.
JOB DESCRIPTION
The Quantitative Investment Solutions (QIS) Team is dedicated to designing innovative investment portfolio models and developing cutting-edge investment features within our product suite. Moreover, the QIS Team is at the forefront of driving AI-based solutions for Ramify. This involves conceptualizing and implementing transformative AI solutions tailored to meet the diverse needs of various teams within Ramify.
As a Data Engineer on our QIS Team, you will play a pivotal role in shaping the future of investment strategies through data-driven insights and AI-based solutions. Collaborating closely with our talented team of quantitative researchers, and investment experts, your responsibilities will encompass architecting and implementing robust data pipelines. These pipelines will facilitate the seamless integration of diverse data sources, empowering Ramify teams to make informed decision-making.
Key Responsibilities:
Design, build and launch data pipelines at scale to move data across Ramify platform with SQL technologies.
Design and implement processes and tools for data onboarding and quality, helping to deliver an industry best-practice solution for managing the data lifecycle.
Produce stand-alone tools that can be used by other teams to automate data quality and discover faults.
Build analytical tools that provide insight into business metrics across Ramify.
Architect and lead the implementation of AI based solutions within Ramify
PREFERRED EXPERIENCE
We're looking for people who:
Want to make a difference. We are a small team effectively reshaping how people look at the industry. We need people who 'get it' and want to play an integral part in helping us accomplish this mission and are persistent in getting the job done.
Skills we're looking for:
Master‚Äôs or upper-year undergraduate-level coursework in either Computer Science, Management Information Systems, Business Information Systems, Mathematics or Finance related field.
2+ years of professional experience in data engineering.
2+ years of experience with one or more coding languages such as Python (is a must), Java.
Experience with data modeling and ETL design, implementation and maintenance.
Demonstrable mastery of industry best practices in the data lifecycle, including data quality automation and tooling.
Excellent written and verbal communication skills with ability to communicate complex designs and solutions to non-technical and highly technical audiences alike.
Good attention to detail.
Strong analytics and strategic thinking skills
Nice-to-haves :
Understanding of ML/ Generative AI technologies and their applications.
Possess a passion, curiosity, and energy for finance + investing. You understand the ins and outs of the wealth management, trading, and more importantly - know how to explain these concepts simply
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['ML'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer,Beelix,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-beelix-3865239426?position=10&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=pX8nmXsW8q1tbsDo0F4T0A%3D%3D&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ?
Depuis 2016, nous accompagnons nos clients sur des probl√©matiques de Product Management, Data et Design Thinking. Beelix contribue √† fa√ßonner le monde de demain en participant aux grandes avanc√©es des secteurs suivants:
üöóAutomobile
‚ö°Energie
üì°M√©dias & T√©l√©coms
üëóLuxe & Retail
üí∂ Banque, Finance & Assurance
‚úàÔ∏èD√©fense
Aujourd‚Äôhui, Beelix compte plus de 200 collaborateurs motiv√©s et dynamiques. Lab√©lis√©e Great Place To work en 2023, Beelix est aussi une entreprise engag√©e o√π il fait bon vivre.
Dans le cadre de notre d√©veloppement, nous recherchons un Data Engineer en √éle-de-France.
Quelles missions au quotidien ?
Vous aurez pour missions principales de d√©velopper les projets Big Data demand√©s par le m√©tier, et notamment :
Passer de la donn√©e brute √† de la donn√©e exploitable, expos√©e sous forme de tables requ√™tables dans le Datalake
Consolider ces donn√©es au fur et √† mesure de leur alimentation r√©currente dans le Datalake
Les exploiter pour atteindre la finalit√© business (exposition de Business View, r√©int√©gration des r√©sultats dans le SI, service de scoring, ‚Ä¶)
De mettre en place et de garantir le respect dans la dur√©e d'un processus qualit√© sur l'ensemble du cycle de DEV (documents, tests unitaires / int√©gration / fonctionnels, commentaires, versionning, etc.)
Accompagner les Data Engineers sur son p√©rim√®tre pour garantir la qualit√© des livrables
Expertise souhait√©e
Expertise en SPARK et PySpark
Expertise sur Databricks
Une exp√©rience sur un cloud provider public comme Azure (id√©alement), AWS, ou GCP
Connaissances avanc√©es d'outils de BI comme PowerBI (id√©alement) ou Spotfire
Capacit√© √† interagir avec des parties prenantes diverses : Business analyst, Architectes, M√©tier
Etre expert dans les pratiques du Software Craftsmanship (Test Driven Development, Behavior Driven Development, Clean Code, Code Reviews, etc.)
Des Connaissances sur Azure DevOps, Azure Pipeline, GIT
Maitrise des Traitements Big Data en mode Streaming
Maitrise des Bases de donn√©es relationnelles et NoSQL
Une exp√©rience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory
A propos de vous ?
Dipl√¥m√© d'une √©cole d'ing√©nieurs ou √©quivalent
Au moins 3 ans d'exp√©rience en tant que Data Engineer
Exp√©rience en mode de Delivery Agile (Scrum, Kanban, etc.‚Ä¶)
Vous avez un bon niveau d‚Äôanglais tant √† l‚Äô√©crit qu‚Äô√† l‚Äôoral
Pourquoi nous rejoindre ?
Un suivi et un accompagnement au quotidien
Un organisme de formation certifi√© Qualiopi, un abonnement linkedin learning pour chaque salari√© et des partenariats avec des sp√©cialistes pour d‚Äôautres expertises
De nombreux √©v√©nements : Afterworks, Communaut√©s m√©tiers, Happy talks‚Ä¶
une Exp√©rience personnalis√©e bas√©e sur vos besoins gr√¢ce au Pr√©dictive Index
Notre package ¬´ unBeelievable ¬ª : 100% du titre de transport, Tickets restaurants, CSE, Prime de participation ...
Nombreux √©v√®nements (afterworks, sport, etc) et des communaut√©s m√©tiers dynamiques
Le processus de recrutement ?
√âchange t√©l√©phonique (15 min)
Entretien 1 RH pour apprendre √† vous conna√Ætre
Entretien 2 avec votre futur N+1 pour appr√©hender la relation manag√©riale
Entretien 3 avec un Responsable commercial pour avoir la vision strat√©gique
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['100'], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer / Data Ops,FRG Technology Consulting,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-data-ops-at-frg-technology-consulting-3913842168?position=1&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=G1%2BA824Nb12%2FuKAKVjCsiA%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous √™tes un expert passionn√© par la Data et √† la recherche de d√©fis excitants ? Mon client recherche actuellement un
Data Engineer
/ Data Ops
talentueux pour rejoindre une √©quipe dynamique et humaine.
Missions principales :
Participation active au d√©ploiement de la nouvelle plateforme sur Azure & Snowflake
Forte autonomie et gestion compl√®te des projets data
Analyse des besoins actuels et futurs
Cr√©ation de sp√©cifications fonctionnelles et techniques
Mod√©lisation de donn√©es
D√©veloppement de packages SSIS
Int√©gration des donn√©es dans SnowFlake & Azure,
Cr√©ation de rapports avec Power BI et Excel
Profil recherch√© :
3 √† 4 ans d'exp√©rience
minimum
dans la BI (SSIS, SQLServer, SSAS, SSRS) et/ou le cloud (Azure , Snowflake) ainsi qu'en SQL
Comp√©tences en
architecture sur Snowflake
fortement appr√©ci√©es
1 √† 2 ans d'exp√©rience en tant que DevOps ( CI/CD ; GitLab)
Autonome, rigoureux et anglais courant
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['3'], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data Engineer,ADVANCED Schema,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-at-advanced-schema-3539059697?position=2&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=xYdxyEx6HBpgfQXeuvfj1g%3D%3D&trk=public_jobs_jserp-result_search-card,"ADVANCED SCHEMA
est une soci√©t√© de services informatiques
sp√©cialis√©e dans la donn√©e.
Depuis 20 ans, nous cr√©ons des plateformes data sur mesure pour nos clients, orient√©es usages et alliant qualit√©, performance, s√©curit√© et gouvernance.
ADVANCED SCHEMA
a d√©velopp√© de nouvelles activit√©s pour r√©aliser l'ambition du groupe : devenir
une entreprise end-to-end,
en proposant une offre √† 360¬∞ √† nos clients pour les
accompagner √† chaque √©tape de leurs projets.
√Ä ce jour, nous sommes pr√®s de 220 passionn√©s r√©partis entre Paris, Lille, Nantes, Lyon mettant √† profit leur expertises aussi bien dans le domaine du retail, de la finance/assurance, du luxe, des m√©dias, de la sant√© et de l'industrie.
Aujourd‚Äôhui, nous souhaitons int√©grer de nouveaux renforts dans nos √©quipes Lilloises.
En tant que Data Engineer, vous aurez les missions suivantes :
Concevoir des modeÃÅlisations physiques
Construire des mappings techniques et r√©daction de sp√©cifications d‚Äôalimentation.
D√©velopper des flux des donn√©es
Contribuer au pilotage de projets, de proof of concepts
Participer aÃÄ des missions d‚Äôexpertise
Comp√©tences professionnelles & niveau d'√©tudes requis :
Vous √™tes titulaire d'un dipl√¥me Bac +3 minimum dans le domaine de la data
Vous poss√©dez minimum 2 ans d'exp√©rience dans le m√©tier
Positif(ve), curieux(se), rigoureux(se) et dot√©(e) d'une bonne aisance relationnelle
√ätre enthousiaste √† l'id√©e d'apprendre de nouvelles technologies
Exp√©rience de la m√©thodologie Agile / Scrum
Capacit√© √† planifier et √† prioriser les t√¢ches et les activit√©s confi√©es en autonomie
Ma√Ætrise de l‚Äôanglais oral et technique obligatoire
Exp√©rience av√©r√©e dans l'√©criture de code propre avec 2 ou plusieurs des technologies suivantes : BASH, SQL, Java, Python, NoSQL
Notre proposition :
Temps plein en
CDI
avec un
salaire attractif
+ participation aux b√©n√©fices + prime(s) sur investissement personnel
Mode de
travail hybride
(agence, site, t√©l√©travail selon projets/clients)
Ticket restaurant (Sodexo)
Mutuelle financ√©e √† 50%
Pr√©voyance
Comit√© entreprise
5 jours d‚Äôonboarding plein temps via la
ADVANCED SCHEMA Academy
Notre investissement :
Chez
ADVANCED SCHEMA
, nous t‚Äôoffrons un environnement de travail stimulant et collaboratif ainsi que des possibilit√©s de croissance et de d√©veloppement professionnel. √âgalement un
accompagnement/support au quotidien
pour te faire grandir et monter en comp√©tences, sur des projets qui r√©pondent √† de
vrais enjeux pour nos clients
. Si tu es passionn√©(e) par les donn√©es et pr√™t(e) √† relever de nouveaux d√©fis, alors nous aussi nous aimerions te rencontrer
Process de recrutement :
Si ta candidature retient notre attention, nous te proposons :
Un premier √©change t√©l√©phonique/visio
Un entretien physique (+questionnaire d‚Äô√©valuation) avec un senior manager
Un entretien final √† notre si√®ge Parisien afin de rencontrer le DG
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go', 'Bash'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Hybride', 'Temps plein', 'Senior'], 'TypeContract': ['CDI'], 'Salary': ['50'], 'Level': [], 'Experience': ['a', 'n', 's', '20', '20', '20']}"
LinkedIn,(Senior) Data Engineer,Mirakl,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-at-mirakl-3904071960?position=3&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=Q7xsnmeByL9zBjTSiMtetQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Mirakl, leader et pionnier de l‚Äô√©conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'acc√©l√©rer de fa√ßon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avanc√©e, s√©curis√©e et √©volutive leur permettant de digitaliser leur activit√© et d'√©largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacit√©, offrir une exp√©rience d'achat personnalis√©e √† leurs clients, et augmenter leurs profits gr√¢ce au retail media. Bas√©e √† Paris et Boston, Mirakl est certifi√©e Great Place to Work.
A propos de Mirakl Labs
Nos √©quipes techniques et produits, nomm√©es Mirakl Labs, sont principalement r√©parties entre nos 2 hubs situ√©s √† Paris et √† Bordeaux. Elles collaborent au quotidien afin d'adresser les probl√©matiques de nos clients et utilisateurs en r√©pondant √† diff√©rents challenges li√©s aux nouvelles fonctionnalit√©s, √† la scalabilit√©, la s√©curit√© et l‚Äôergonomie‚Ä¶
Elles op√®rent en mode agile et s'organisent en Squads compos√©es d'un Squad Lead, de 5 d√©veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est sp√©cialis√©e sur un scope fonctionnel afin de concevoir et r√©aliser de nouvelles features, leurs √©volutions et des APIs (avec un d√©coupage en micro-services). Nos √©quipes Infrastructure, Architecture, S√©curit√©, Documentation, Product Design, Data et Support op√®rent en transverse en apportant leur expertise et de la coh√©rence sur l‚Äôensemble des produits.
Toutes les √©quipes sont responsables de leur p√©rim√®tre et chacun des collaborateurs apporte son exp√©rience et ses id√©es. Innovation, feedback et implication dans les prises de d√©cision sont au c≈ìur de notre philosophie.
Et pour favoriser ce partage avec d‚Äôautres passionn√©s, nous sommes sponsors, speakers, et h√¥tes de diff√©rents √©v√©nements, meetups, et associations de la sc√®ne Tech en France. Au cours des derni√®res ann√©es, nous avons particip√© √† des √©v√©nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.
A propos du job
La solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commer√ßants √† travers le monde. Cette solution g√®re et produit de gros volumes de donn√©es qui pr√©sentent des challenges extr√™mement int√©ressants pour les sp√©cialistes de la donn√©e (produits, commandes, clients, niveaux de stock, prix, messages, appels API, donn√©es de navigation, s√©ries temporelles, donn√©es g√©olocalis√©es etc.).
En tant que (Senior) Data Engineer au sein de l‚Äô√©quipe Data Mirakl, vos principales missions seront de :
contribuer √† l'enrichissement de la Data Platform (ETL)
am√©liorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inf√©rence real time etc.)
Int√©gr√©(e) dans une √©quipe de sp√©cialistes de la donn√©e (data engineers, machine learning engineers, data scientists, data analysts), vous √™tes un des acteurs cl√©s pour garantir la place de Mirakl comme solution dominante sur son march√©.
Notre stack et nos outils
Apache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, Ansible
Au quotidien, vous allez :
Participer √† la d√©finition et √† l‚Äôimpl√©mentation d‚Äôune architecture performante, robuste, scalable et aux co√ªts ma√Ætris√©s pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (√©valuation des feature stores, refactoring de DAG Airflow)
Accompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practices
Optimiser et am√©liorer la CI/CD de l‚Äô√©quipe en collaboration avec l‚Äô√©quipe SRE
Assurer la mont√©e en comp√©tence des membres de l‚Äô√©quipe sur les sujets de MLOps et Data Engineering
R√©fl√©chir √† la meilleure fa√ßon d'int√©grer les donn√©es Google Analytics dans la data platform
Partager ses connaissances et pr√©senter les travaux devant toutes les √©quipes Labs
Ce qu‚Äôon peut vous apporter :
Des projets data driven, divers et vari√©s (traitements massifs d‚Äôimages, de textes, time series etc.) pour des produits diff√©rents de Mirakl
Une culture orient√©e sur la veille technologique
Des projets qui ont un vrai impact business devant √™tre d√©ploy√©s sur des centaines de clients dans un contexte multilingue
Quelques exemples de sujets en cours :
Enrichissement des donn√©es produit √† partir des images et des descriptions
Mod√©ration automatique des produits
Mapping automatique des donn√©es produit
Identification des produits √† fort potentiels
D√©tection de comportements frauduleux
Sentiment analysis sur les messages √©chang√©s entre clients et vendeurs et dans les √©valuations
D√©termination de prix optimaux
Monitoring de la qualit√© de service des vendeurs
Des applications d‚Äôinf√©rence en synchrone de nos mod√®les de ML
Vous aimerez ce job si :
Vous √™tes passionn√©(e) par la data et les technologies modernes permettant d'en tirer partie
Vous vous int√©ressez √† la data science et avez des connaissances g√©n√©rales sur les algorithmes de Machine Learning
Vous avez un background en d√©veloppement et avez √©volu√© dans un environnement Data
Vous avez a minima 4 ans d‚Äôexp√©rience en environnement Machine Learning et/ou Data
Vous avez mis en production avec succ√®s des applications Big Data faisant appel √† du Machine Learning, du NLP, du traitement d‚Äôimages dans des projets d'envergure, √† fort volume de donn√©es
Votre ma√Ætrisez Python, √™tes un pro des frameworks data de la fondation Apache et √™tes √† l'aise dans un environnement AWS
Vous ma√Ætrisez au moins un outil d‚Äôorchestration (Airflow, Data Pipeline ou tout autre outil similaire)
Vous pr√©sentez vos travaux de mani√®re simple et accessible
Vous fa√Ætes preuve d'un bon relationnel et vous aimez mentorer des collaborateurs
Vous parlez couramment anglais et fran√ßais
Les plus pour le poste :
Vous avez une exp√©rience significative dans le domaine du e-commerce
Vous avez d√©j√† mis en place un Data Lake, Data Warehouse ou une Data Platform
Vous avez d√©ploy√© des applicatifs en environnement Kubernetes
Vous avez mis en place des pipelines d'ingestion de donn√©es avec une approche CDC √† l'aide de Debezium ou autre
Vous ma√Ætrisez Java/Scala
Mirakl est engag√©e en faveur de la diversit√©, de l‚Äô√©galit√© des chances et de l‚Äôinclusion. Nous c√©l√©brons nos diff√©rences car nous sommes convaincus que les qualit√©s visibles et invisibles de chaque Mirakl Worker sont une source de force et d‚Äôinnovation. Dans le cadre de cet engagement, nous √©tudions toutes les candidatures sans distinction de : genre, ethnicit√©, religion, orientation sexuelle, handicap, √¢ge ou toute autre caract√©ristique prot√©g√©e par la loi.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Machine Learning', 'CI/CD'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data Engineer (H/F),Scalian,"Valbonne, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-scalian-3819563847?position=4&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=inh7goY5tExGCo%2B1yjcFcg%3D%3D&trk=public_jobs_jserp-result_search-card,"Ing√©nieur DATA / Data engineer (H/F)
Valbonne/Sophia-Antipolis
Type : CDI
Lieu : Locaux Scalian Sophia-Antipolis
T√©l√©travail : En fonction des possibilit√©s
Date de prise de poste : imm√©diatement ou en fonction de votre pr√©avis
Salaire : en fonction du profil - entre 40 et 48K Brut annuels (hors avantages Scalian)
Avantages Scalian : Accord d'entreprise t√©l√©travail, Tickets restaurants, Mutuelle groupe, accord am√©nagement temps de travail, compte √©pargne temps, accord de participation et int√©ressement groupe, programme cooptation et apports d'affaires, accompagnement parentalit√©, avantages CSE
Vous √™tes data engineer ou vous souhaitez le devenir !
Quel sera votre r√¥le ?
La port√©e de la mission comprend (sans toutefois s'y limiter) :
Science des donn√©es
Ing√©nierie des donn√©es
Analyse des donn√©es
G√©nie logiciel
Ce que cette exp√©rience va vous apporter
Vous √™tes autonome, vous avez le sens du service et de l‚Äôanalyse, vous √™tes impliqu√©, nous vous offrons une ouverture sur des projets complexes et une rapide √©volution de carri√®re. Vous rejoignez notre business unit √† Sophia Antipolis compos√©e d'environ 50 consultants, avec possibilit√© de t√©l√©travail en fonction des sujets.
Nous co-construisons votre trajectoire professionnelle et assurons votre mont√©e en comp√©tences.
Nous nous inscrivons ensemble dans la dur√©e, nous assurons votre mont√©e en comp√©tences et disposons d'une vari√©t√© de sujets passionnants.
Ce que nous recherchons chez vous
De formation sup√©rieure (Bac+5, √©cole ou universit√©), vous poss√©dez id√©alement une premi√®re exp√©rience r√©ussie dans ce domaine (d√©butants accept√©s), vous aimez le travail en √©quipe.
Comp√©tences requises
:
Etape d‚Äôanalyse : Comprendre l‚Äôarchitecture technique, les sources de donn√©es, les objectifs fonctionnels.
Etape de conception : Solution de conception avec un fort centrage sur les pipelines de donn√©es et les mod√®les ML et l‚Äôexposition des KPI via API
Mise en ≈ìuvre : Apr√®s les phases d‚Äôanalyse et de conception, proc√©der √† a mise en ≈ìuvre dans des technologies s√©lectionn√©es (Java,Scala,Python,Spark)
Cr√©er un code test√© et document√©
Techno : Linux, Shell, Hadoop, Scrum, Python, Spark, Scala
Pourquoi feriez-vous le grand saut ?
Parce que Scalian vous accompagne dans le d√©veloppement de votre carri√®re :
Programme d'onboarding complet sur 1 an avec votre manager et votre RH
Programme de formation (Scalian Academy, e-learning, webinaires et formations externes)
Communaut√©s techniques (Squads, Practices) afin de valoriser et d√©velopper votre expertise
√âv√©nements internes (Afterworks, Awards Dinner, Kick Off, Live Event du COMEX, Stand Up) et externes (participation √† des salons et forums sp√©cialis√©s dans nos domaines d‚Äôactivit√©s‚Ä¶)
Dispositif d‚Äôacc√©l√©ration d‚Äôacc√®s √† la mobilit√© interne et √† des √©changes internationaux type Erasmus
Parce que Scalian favorise la Qualit√© de Vie au Travail :
Certifications Great Place to Work¬Æ et Best Workplaces for Women¬Æ
Prime de cooptation, prime vacances, prise en charge par l‚Äôemployeur de 60% des titres-restaurant, Accord t√©l√©travail (jusqu‚Äô√† 2,5 jours par semaine indemnis√©s), RTT (dont une partie mon√©tisable), CSE (activit√©s ludiques, ch√®ques-cadeaux, ch√®ques vacances)
Berceaux en cr√®ches inter-entreprises
Don ou r√©ception de jours de cong√©s en cas de difficult√©s personnelles
Parce que Scalian d√©veloppe une politique RSE concr√®te et ambitieuse :
Mobilit√© durable (indemnit√© kilom√©trique v√©lo, leasing de v√©los √† assistance √©lectrique)
Actions environnementales (Fresque du Climat, Reforest'Action, Clean Up Day, m√©c√©nat ONF)
Postes ouverts aux personnes en situation de Handicap
Diverses politiques de diversit√©, d‚Äôinclusion et d‚Äôint√©gration mises en place
Scalian c‚Äôest aussi :
Une entreprise en tr√®s forte croissance qui, cr√©√©e en 1989, compte aujourd‚Äôhui plus de 5500 personnes
Des r√©f√©rences clients √† forte valeur ajout√©e aupr√®s de grands industriels fran√ßais (du CAC40) et internationaux
Un terrain de jeu o√π l‚Äôexpertise se conjugue avec audace, libert√© d‚Äôentreprendre et convivialit√©
Si vous aspirez √† un environnement de travail qui valorise autant votre bien-√™tre que votre d√©veloppement professionnel,
rejoignez-nous et exprimez pleinement votre talent !
Envie d'√©largir le cadre ?
Je suis Liza Djehel, Talent Acquisition Officer.
Si votre CV est retenu, je vous contacte pour un premier √©change t√©l√©phonique de 15 √† 20 minutes.
Nous d√©terminons ensemble si ce poste est en ad√©quation avec vos comp√©tences et surtout, avec vos attentes.
L'√©change est positif ? Nous convenons d'un entretien de 1h (en pr√©sentiel ou en visio) avec Lucas Daunar, Business Manager √† Sophia-Antipolis. Cet √©change permet de revenir en d√©tail sur vos comp√©tences, vos attentes, de vous pr√©senter le poste plus en d√©tail, et d'√©voquer d'autres opportunit√©s.
Nous pr√©voyons ensuite un rendez-vous technique de 1h (en pr√©sentiel ou en visio) avec un de nos responsable technique.
Enfin, nous vous pr√©sentons notre proposition d'embauche.
Notre processus de recrutement dure entre 15 et 30 jours
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['40'], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer confirm√© (H/F),BforBank,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-h-f-at-bforbank-3918327555?position=5&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=YLN7BIC2OVrtG%2B8DPUdn2Q%3D%3D&trk=public_jobs_jserp-result_search-card,"Sur le mod√®le d'une
""Tech company"",
BforBank place
l'humain et le digital
au c≈ìur de sa transformation. Notre mission,
offrir √† nos clients une exp√©rience bancaire incomparable
pour r√©pondre √† leurs besoins et usages mobile. üåü üì±
Rejoindre BforBank c‚Äôest
rejoindre une √©quipe engag√©e
dans un
grand projet de d√©veloppement strat√©gique en France et en Europe.
Nous sommes aujourd‚Äôhui 350 passionn√©(e)s et
recherchons nos talents pour construire la banque de demain
. üöÄ
Nous croyons en la force du collectif, chaque jour rassembl√©s autour de nos valeurs, de simplicit√©, d'optimisme et d‚Äôengagement, encourageant chacun √† oser, essayer et accepter d‚Äô√©chouer.
üéØ Au sein de la Direction Technologie, la Data Factory a pour objectifs de piloter, d√©finir, d√©ployer et op√©rer les meilleures solutions technologiques r√©pondant aux cas d‚Äôusage data et d‚Äôautomatisations de processus de la banque au travers de plateformes. √âgalement, la Data Factory contribue au d√©veloppement des produits, √† la cristallisation et √† la diffusion des pratiques au sein des Squads BforBank sur les usages data dans la banque.
Tu rejoindras une squad en charge de r√©soudre des probl√©matiques m√©tiers en cr√©ant des solutions applicatives utilisant les donn√©es, des data products, avec pour finalit√©s la prise de d√©cision via des moteurs de calcul ou des dashboards, la cr√©ation de flux r√©glementaires, la cr√©ation de data layer ou de reportings.
üöÄ Tes missions principales sont les suivantes :
¬∑ Participer aux analyses, √©tudes d‚Äôimpacts et cadrage techniques
¬∑ Concevoir des solutions en respectant les bonnes pratiques d‚Äôarchitecture data et d√©veloppement
¬∑ R√©aliser le d√©veloppement de nouveaux data products et assurer la maintenance √©volutive et corrective des data products existants
¬∑ R√©diger la documentation technique des data products
¬∑ Assurer un support aux testeurs
¬∑ Reporter de ton activit√© √† ta Squad et travailler dans une d√©marche d‚Äôefficacit√© collective
Concr√®tement tu seras amen√©(e) √† produire les livrables suivants :
¬∑ R√©aliser du code applicatif √† l‚Äô√©tat de l‚Äôart sur notre nouvelle Data Platform
¬∑ Cr√©er des data layer et des rapports sur notre outil de Data Visualisation
¬∑ R√©diger les documentations techniques li√©es √† ta solution, incluant le mod√®le de donn√©es, les proc√©dures, l‚Äôordonnancement
Ce que tu ma√Ætrises :
¬∑ Maitrise des services manag√©s de GCP (BigQuery, dataproc, dataflow, CloudSQL ‚Ä¶)
¬∑ Maitrise du langage Python, Pandas, Spark
¬∑ Maitrise de la mod√©lisation de base de donn√©es et du langage SQL
¬∑ Maitrise d‚Äôune chaine CI/CD (GitLab‚Ä¶)
¬∑ Bonne connaissance de Kafka
¬∑ Bonne connaissance d‚Äôun outil d‚Äôint√©gration de donn√©es type ETL (Informatica‚Ä¶)
¬∑ Connaissance de l‚Äôinfra as code (Terraform)
¬∑ Connaissance d‚Äôun outil de reporting (Looker, BO‚Ä¶)
ü§ù Ce poste est fait pour toi si :
¬∑ Tu es passionn√©(e) par la Data et leurs usages
¬∑ Tu es orient√© r√©solution de probl√®me, est curieux(se) et force de proposition
¬∑ Tu appr√©cies le travail en √©quipe
¬∑ Tu as un bon relationnel et est rigoureux(se)
¬∑ Tu as une bonne capacit√© d‚Äôanalyse et r√©dactionnelle
¬∑ Tu t‚Äôadaptes rapidement aux changements
üéì
Formation :
Tu es dipl√¥m√©(e) d‚Äôun master en √©cole de commerce, √©cole d‚Äôing√©nieur ou √©quivalent.
Chez BforBank nous recherchons avant tout des comp√©tences. Tu ne disposes pas du dipl√¥me requis mais as des exp√©riences √©quivalentes ? N'h√©site pas √† postuler !
üíº
Exp√©rience :
Exp√©rience confirm√©e de 3 ans en tant que Data Engineer.
En rejoignant BforBank tu trouveras‚Ä¶
¬∑ Un projet ambitieux de transformation digitale et culturelle √† l‚Äô√©chelon europ√©en, terrain d‚Äôinnovation et d‚Äôouverture d‚Äôesprit
¬∑ Une organisation apprenante, proposant un large choix de formations toute l‚Äôann√©e, et qui favorise l‚Äô√©change avec les autres marques du Groupe
¬∑ Une promo RSE multi-m√©tiers qui fait √©voluer en continu les actions de BforBank vers une banque plus responsable
¬∑ Une organisation du travail en mode Agile, impliquant un degr√© √©lev√© de collaboration et d'autonomie tout en travaillant avec un groupe de pairs diversifi√©s.
¬∑ Une Direction Technologie en pleine expansion, porteuse de nombreux d√©fis strat√©giques
Mais aussi‚Ä¶
De 2 jours √† 5 jours de t√©l√©travail modulables par semaine, dans la limite de 84 jours par an (frais de fonctionnement pris en charge)
25 jours de cong√©s + 16 jours de RTT
80% du co√ªt de la mutuelle d‚Äôentreprise pris en charge / couvert
Avantages collaborateurs Cr√©dit Agricole : taux et tarifs pr√©f√©rentiels
Des frais de transports rembours√©s √† 75%
Un restaurant d‚Äôentreprise
Des douches pour les sportifs et un tarif avantageux aupr√®s d‚Äôune salle de sport toute proche
üìç Le poste est bas√© √† La D√©fense, dans des locaux flambant neufs !
BforBank s'engage √† garantir l'√©galit√© des chances aux candidats car nous sommes convaincus de la richesse apport√©e par la diversit√© et l'inclusion dans nos √©quipes.
Rencontrons-nous !
Le processus de recrutement se d√©roule en 4 √©tapes :
üßëüèº‚Äçüíª
Call de 30 minutes avec notre √©quipe Talent Acquisition
Echange avec le Data Factory Manager et notre √©quipe Talent Acquisition (pr√©sentiel)
Echange avec une personne de l‚Äô√©quipe avec qui tu seras amen√© √† travailler (visio)
Echange avec le CTO (visio ou pr√©sentiel)
Notre processus de recrutement dure en moyenne 3 semaines et l‚Äô√©quipe Talent Acquisition se tiendra √† ta disposition pour te donner un maximum de visibilit√© sur l‚Äôavanc√©e du process.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Confirm√©'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,DATA ENGINEER,Action for Market Transformation - A4MT,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-action-for-market-transformation-a4mt-3910049004?position=6&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=a5VzP6Z29J%2BQGi4BQ1%2F3Dg%3D%3D&trk=public_jobs_jserp-result_search-card,"A4MT ‚Äì Action pour la Transformation des March√©s
A4MT con√ßoit et impl√©mente des programmes d‚Äôengagement et de ¬´ Market Transformation ¬ª qui visent √† g√©n√©raliser des pratiques vertueuses ‚Äì au sens environnemental et soci√©tal ‚Äì en modifiant la donne du march√©, en reconfigurant le jeu d‚Äôacteurs, g√©n√©ralement via des actions collectives.
Ces programmes agissent sur la demande en suscitant de nouvelles pratiques individuelles et collectives. A4MT assure le r√¥le de pilote, orchestrant les plans d‚Äôaction des parties prenantes gr√¢ce √† une √©quipe de qualit√© √† caract√®re international, un savoir-faire sur la mise en ≈ìuvre des programmes, une connaissance technico-√©conomique experte des sujets trait√©s, et une capacit√© √† interpeller les d√©cideurs √† bon niveau.
Championnat de France des √©conomies d‚Äô√©nergie
A4MT avec ses partenaires op√®re l‚Äôensemble des concours CUBE en France (Championnat de France des Economies d‚ÄôEnergies) et assure son d√©veloppement international (Europe, Asie, etc.). CUBE est un concours original d‚Äô√©conomies d‚Äô√©nergie et de CO2 pour les b√¢timents tertiaires et r√©sidentiels qui acc√©l√®re fortement l‚Äôaction de terrain gr√¢ce √† une intelligence collective sur le terrain.
Le concours est aujourd‚Äôhui pr√©sent dans 8 pays et se d√©veloppe encore. Au-del√† des √©conomies les plus faciles, il s‚Äôagit de mettre en ≈ìuvre la trajectoire de gestion immobili√®re et d‚Äôinvestissement qui permettra, au-del√† des avanc√©es dans ce programme √† faible investissement, de progresser sur la trajectoire de la neutralit√© carbone.
https://championnatdefrancedeseconomiesdenergie.org/
MISSION
Rendant compte au directeur d‚ÄôA4MT et en √©troite collaboration avec le directeur technique A4MT, vous √™tes Data Engineer, vous serez responsable de la conception, du d√©veloppement et de la maintenance des bases de donn√©es, et des outils de reporting. Vous travaillerez en √©troite collaboration avec l'√©quipe de d√©veloppement (prestataire externe) et vous participez √† la structuration d‚Äôune √©quipe IT interne pour cr√©er des solutions innovantes r√©pondant aux besoins de l'entreprise.
Votre mission s'articule autours des 3 axes ci-dessous:
1/ Pilotage et et d√©veloppement
d√©velopper et d√©ployer des reporting robustes et √©volutifs.
le planning de d√©veloppement et le budget allou√©.
avec les √©quipes d‚Äôanimation et le back office technique du programme et avec les prestataires externes pour comprendre les exigences et les sp√©cifications du projet.
√† la conception de l'architecture des bases de donn√©es et √† la prise de d√©cisions techniques.
la qualit√© des donn√©es en effectuant des contr√¥les qualit√©.
les performances des applications pour garantir une exp√©rience utilisateur fluide.
la maintenance et les mises √† jour r√©guli√®res des applications existantes.
√† l'aff√ªt des tendances et des technologies √©mergentes.
Vous serez responsable du process, de la ma√Ætrise d‚Äôouvrage li√©e √† la Data et garant(e) de la qualit√© de service.
2/ Implication des √©quipes et de la sous-traitance
Vous serez impliqu√© dans une √©quipe informatique naissante et dans une √©quipe projet avec les diff√©rentes fonctions m√©tiers. Vous devrez faire le suivi de votre implication avec le responsable de programme et le directeur technique d‚Äô A4MT :
3/ Gestion de projet
Vous tiendrez le tableau de bord des outils : budgets, engagements, planning, r√©sultats, d√©veloppements.
PROFIL
Vous avez une exp√©rience significative d‚Äôau moins 3 ann√©es dans l‚Äô√©cosyst√®me de big data, des serveurs et bases de donn√©es dans des contextes de projets, d‚Äôexploitation de migration.
COMPETENCES
Bac +5 dipl√¥m√©(e) d‚Äôune grande √©cole d‚Äôing√©nieur ou √©quivalent, vous √™tes :
+5 dipl√¥m√© (e) d‚Äôune √©cole d‚Äôing√©nieurs ou √©quivalent, en Data science, Informatique, g√©nie logiciel ou domaine connexe.
professionnelle d√©montr√©e de 3 ans ou plus en tant que Data Engineer
des langages structur√©s (JavaScript, Scala, Python‚Ä¶),
avec les bases de donn√©es relationnelles (MySQL, PostgreSQL) et non relationnelles (MongoDB, Firebase).
au moins un outil de reporting (Power BI, Tableau ‚Ä¶)
des services de d√©ploiement et d'h√©bergement cloud comme AWS, Azure ou Google Cloud Platform.
comp√©tences en d√©veloppement back-end avec des technologies comme Node.js, Python, Ruby on Rails, ou Java. et notamment en PHP sont recommand√©es
des langages de programmation front-end tels que HTML5, CSS3 et JavaScript (notamment frameworks: comme React, Angular ou Vue.js).
√† travailler en √©quipe, √† communiquer efficacement et √† r√©soudre les probl√®mes de mani√®re autonome.
des principes de s√©curit√© des applications web et des meilleures pratiques en mati√®re de d√©veloppement s√©curis√© ainsi que le respect du RGPD.
Date d‚Äôentr√©e et conditions
Le poste est √† pourvoir imm√©diatement; il est bas√© au 54, rue de Clichy, Paris (IX√®me). Niveau de r√©mun√©ration selon exp√©rience.
Contact
Merci d‚Äôadresser votre candidature compl√®te (CV, lettre de motivation, pr√©sentation du cursus en cours de conclusions et r√©f√©rences √©ventuelles) √† l‚Äôattention de M. Adrien Brunella sur le mail elisabeth.clement@a4mt.com
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go', 'JavaScript', 'HTML'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['MySQL', 'PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,(Senior) Data Engineer,Mirakl,France,https://fr.linkedin.com/jobs/view/senior-data-engineer-at-mirakl-3904076524?position=7&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=nk2bB5vqPzMQmCDY62Tvyg%3D%3D&trk=public_jobs_jserp-result_search-card,"Mirakl, leader et pionnier de l‚Äô√©conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'acc√©l√©rer de fa√ßon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avanc√©e, s√©curis√©e et √©volutive leur permettant de digitaliser leur activit√© et d'√©largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacit√©, offrir une exp√©rience d'achat personnalis√©e √† leurs clients, et augmenter leurs profits gr√¢ce au retail media. Bas√©e √† Paris et Boston, Mirakl est certifi√©e Great Place to Work.
A propos de Mirakl Labs
Nos √©quipes techniques et produits, nomm√©es Mirakl Labs, sont principalement r√©parties entre nos 2 hubs situ√©s √† Paris et √† Bordeaux. Elles collaborent au quotidien afin d'adresser les probl√©matiques de nos clients et utilisateurs en r√©pondant √† diff√©rents challenges li√©s aux nouvelles fonctionnalit√©s, √† la scalabilit√©, la s√©curit√© et l‚Äôergonomie‚Ä¶
Elles op√®rent en mode agile et s'organisent en Squads compos√©es d'un Squad Lead, de 5 d√©veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est sp√©cialis√©e sur un scope fonctionnel afin de concevoir et r√©aliser de nouvelles features, leurs √©volutions et des APIs (avec un d√©coupage en micro-services). Nos √©quipes Infrastructure, Architecture, S√©curit√©, Documentation, Product Design, Data et Support op√®rent en transverse en apportant leur expertise et de la coh√©rence sur l‚Äôensemble des produits.
Toutes les √©quipes sont responsables de leur p√©rim√®tre et chacun des collaborateurs apporte son exp√©rience et ses id√©es. Innovation, feedback et implication dans les prises de d√©cision sont au c≈ìur de notre philosophie.
Et pour favoriser ce partage avec d‚Äôautres passionn√©s, nous sommes sponsors, speakers, et h√¥tes de diff√©rents √©v√©nements, meetups, et associations de la sc√®ne Tech en France. Au cours des derni√®res ann√©es, nous avons particip√© √† des √©v√©nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.
A propos du job
La solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commer√ßants √† travers le monde. Cette solution g√®re et produit de gros volumes de donn√©es qui pr√©sentent des challenges extr√™mement int√©ressants pour les sp√©cialistes de la donn√©e (produits, commandes, clients, niveaux de stock, prix, messages, appels API, donn√©es de navigation, s√©ries temporelles, donn√©es g√©olocalis√©es etc.).
En tant que (Senior) Data Engineer au sein de l‚Äô√©quipe Data Mirakl, vos principales missions seront de :
contribuer √† l'enrichissement de la Data Platform (ETL)
am√©liorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inf√©rence real time etc.)
Int√©gr√©(e) dans une √©quipe de sp√©cialistes de la donn√©e (data engineers, machine learning engineers, data scientists, data analysts), vous √™tes un des acteurs cl√©s pour garantir la place de Mirakl comme solution dominante sur son march√©.
Notre stack et nos outils
Apache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, Ansible
Au quotidien, vous allez :
Participer √† la d√©finition et √† l‚Äôimpl√©mentation d‚Äôune architecture performante, robuste, scalable et aux co√ªts ma√Ætris√©s pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (√©valuation des feature stores, refactoring de DAG Airflow)
Accompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practices
Optimiser et am√©liorer la CI/CD de l‚Äô√©quipe en collaboration avec l‚Äô√©quipe SRE
Assurer la mont√©e en comp√©tence des membres de l‚Äô√©quipe sur les sujets de MLOps et Data Engineering
R√©fl√©chir √† la meilleure fa√ßon d'int√©grer les donn√©es Google Analytics dans la data platform
Partager ses connaissances et pr√©senter les travaux devant toutes les √©quipes Labs
Ce qu‚Äôon peut vous apporter :
Des projets data driven, divers et vari√©s (traitements massifs d‚Äôimages, de textes, time series etc.) pour des produits diff√©rents de Mirakl
Une culture orient√©e sur la veille technologique
Des projets qui ont un vrai impact business devant √™tre d√©ploy√©s sur des centaines de clients dans un contexte multilingue
Quelques exemples de sujets en cours :
Enrichissement des donn√©es produit √† partir des images et des descriptions
Mod√©ration automatique des produits
Mapping automatique des donn√©es produit
Identification des produits √† fort potentiels
D√©tection de comportements frauduleux
Sentiment analysis sur les messages √©chang√©s entre clients et vendeurs et dans les √©valuations
D√©termination de prix optimaux
Monitoring de la qualit√© de service des vendeurs
Des applications d‚Äôinf√©rence en synchrone de nos mod√®les de ML
Vous aimerez ce job si :
Vous √™tes passionn√©(e) par la data et les technologies modernes permettant d'en tirer partie
Vous vous int√©ressez √† la data science et avez des connaissances g√©n√©rales sur les algorithmes de Machine Learning
Vous avez un background en d√©veloppement et avez √©volu√© dans un environnement Data
Vous avez a minima 4 ans d‚Äôexp√©rience en environnement Machine Learning et/ou Data
Vous avez mis en production avec succ√®s des applications Big Data faisant appel √† du Machine Learning, du NLP, du traitement d‚Äôimages dans des projets d'envergure, √† fort volume de donn√©es
Votre ma√Ætrisez Python, √™tes un pro des frameworks data de la fondation Apache et √™tes √† l'aise dans un environnement AWS
Vous ma√Ætrisez au moins un outil d‚Äôorchestration (Airflow, Data Pipeline ou tout autre outil similaire)
Vous pr√©sentez vos travaux de mani√®re simple et accessible
Vous fa√Ætes preuve d'un bon relationnel et vous aimez mentorer des collaborateurs
Vous parlez couramment anglais et fran√ßais
Les plus pour le poste :
Vous avez une exp√©rience significative dans le domaine du e-commerce
Vous avez d√©j√† mis en place un Data Lake, Data Warehouse ou une Data Platform
Vous avez d√©ploy√© des applicatifs en environnement Kubernetes
Vous avez mis en place des pipelines d'ingestion de donn√©es avec une approche CDC √† l'aide de Debezium ou autre
Vous ma√Ætrisez Java/Scala
Mirakl est engag√©e en faveur de la diversit√©, de l‚Äô√©galit√© des chances et de l‚Äôinclusion. Nous c√©l√©brons nos diff√©rences car nous sommes convaincus que les qualit√©s visibles et invisibles de chaque Mirakl Worker sont une source de force et d‚Äôinnovation. Dans le cadre de cet engagement, nous √©tudions toutes les candidatures sans distinction de : genre, ethnicit√©, religion, orientation sexuelle, handicap, √¢ge ou toute autre caract√©ristique prot√©g√©e par la loi.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Machine Learning', 'CI/CD'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data Engineer Senior,AXA en France,"Hauts-de-Seine, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-senior-at-axa-en-france-3884386043?position=8&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=3U%2F2pMNXXaCLmgpNUaVdcg%3D%3D&trk=public_jobs_jserp-result_search-card,"Environnement
En tant que
Senior Data Engineer F/H
, vous allez contribuer directement aux projets des directions m√©tier (ex : fraude sant√©, multi√©quipements, pricing IARD, optimisation du lead management, fragilit√© auto, ‚Ä¶) d‚ÄôAXA France et √† la construction du socle technique Big Data.
Vous allez int√©grer une √©quipe d'une dizaine de personne compos√©e de Data Engineer et des Tech Lead travaillant en mode Feature Team au sein des tribus m√©tier de la Direction Transformation Digital Tech et DATA (DT2).
La Direction Transformation Digital Tech et DATA d'AXA France en quelques mots :
- Une organisation agile en feature teams : tribus, guildes, squads
- Des projets sur des applications innovantes √† fort trafic (web, mobile‚Ä¶)
- Des m√©thodologies craft (TDD, BDD, clean code, code review‚Ä¶) et DevOps
- Une communaut√© de partage de bonnes pratiques (BBL, dojo, meetup, conf‚Ä¶)
Votre r√¥le et vos missions
Vous aurez pour missions principales de d√©velopper les projets Big Data demand√©s par le m√©tier, et notamment :
Passer de la donn√©e brute √† de la donn√©e exploitable, expos√©e sous forme de tables requ√™tables dans le datalake
Consolider ces donn√©es au fur et √† mesure de leur alimentation r√©currente dans le data lake
Les exploiter pour atteindre la finalit√© business (exposition de business view, r√©int√©gration des r√©sultats dans le SI, service de scoring, ‚Ä¶)
De travailler √† la cr√©ation du socle technique Big Data et industrialiser le cycle de d√©veloppement de l'√©quipe
De mettre en place et de garantir le respect dans la dur√©e d'un processus qualit√© sur l'ensemble du cycle de DEV (documents, tests unitaires / int√©gration / fonctionnels, commentaires, versionning, etc.)
Votre profil
Vous justifiez de plusieurs exp√©riences significatives (+ de 5 ans) sur du
d√©veloppement big data, en particulier sur du PySpark.
Comp√©tences techniques :
Connaissances avanc√©es en d√©veloppement en
PySpark
(Spark avec le langage Python)
Maitrise de l'environnement
Microsoft Azure
Connaissances avanc√©es d'outils de BI comme
PowerBI
Comp√©tences transverses :
Capacit√© √† interagir avec des parties prenantes diverses : Business analyst, Architectes, M√©tier
Exp√©rience en mode de delivery Agile (Scrum, Kanban, etc...)
Driver et accompagner des Data Engineer junior sur les aspects technique
Et Id√©alement :
Des Connaissances sur Azure DevOps, Azure Pipeline, GIT, JIRA
Maitrise des Traitements Big Data en mode Streaming
Maitrise des Bases de donn√©es relationnelles et NoSQL
Une exp√©rience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory
Qui sommes nous ?
AXA est un des leaders de l‚Äôassurance et de la gestion d‚Äôactifs dans le monde.
Nous aidons nos 108 millions de clients √† traverser les petites et grandes difficult√©s de la vie.
Chaque jour, nous agissons ensemble pour inventer la meilleure mani√®re de les prot√©ger et voulons donner √† chacun les moyens de vivre une vie meilleure.
Un challenge qui donne le sourire et envie de se lever le matin !
Chez AXA, nous sommes persuad√©s que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs. C‚Äôest pour cette raison que nous menons une politique RH engag√©e qui favorise la diversit√©, qui pr√©serve l‚Äô√©quilibre vie priv√©e-vie professionnelle et acc√©l√®re le d√©veloppement des comp√©tences et des carri√®res.
Ainsi, en rejoignant AXA France vous travaillerez dans une entreprise responsable, offrant une v√©ritable culture d‚Äôexpertise, acc√©l√©rant le d√©veloppement des comp√©tences de chacun et proposant une r√©mun√©ration attractive.
Pourquoi nous rejoindre ?
Vous √™tes porteur d‚Äôid√©es et d‚Äôinitiatives innovantes ? Vous proposez des solutions et √™tes au service du client ? Faites partie de notre grande famille en rejoignant
Un leader mondial offrant des opportunit√©s de carri√®res int√©ressantes
Une entreprise qui donne une place de choix √† l‚Äôinnovation, √† l‚Äôinitiative et aux actions solidaires (notamment via l‚Äôassociation AXA Atout C≈ìur)
Un environnement inclusif √† tous les niveaux (mixit√©, handicap, initiatives pour favoriser l‚Äôinsertion des jeunes, orientation sexuelle, etc.)
Un acc√®s √† de multiples avantages (cong√©s, temps partiel, t√©l√©travail, etc.)
Un cadre stimulant, qui permet de rencontrer des collaborateurs performants et d‚Äôenrichir ses comp√©tences
Victime ou t√©moin, en cas de discrimination, vous pouvez adresser vos signalements et/ou alertes discrimination √† alerte.discrimination.harcelement@axa.fr
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['JIRA', 'Teams'], 'Other': ['DevOps', 'Big Data'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': ['Junior', 'Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Data Engineer (Snowflake),MindPal,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-snowflake-at-mindpal-3910994899?position=9&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=9jrBl%2BUf0qJsGQTz6OU5UQ%3D%3D&trk=public_jobs_jserp-result_search-card,"We are looking for experienced
Data Engineers
with knowledge of
Snowflake
platform.
Responsibilities
Creating and managing data in the Snowflake environment
Designing and implementing ETL (Extract, Transform, Load) solutions for transferring data between various sources and platforms
Optimizing the performance of Snowflake databases, including designing and implementing data structures and using indexes appropriately
Automating data processing workflows using tools such as Airflow or other workflow management tools
Deploying and configuring tools to monitor and report on the performance of the Snowflake system
Requirements
Minimum 1 year of experience as a Data Engineer
Ability to use Snowflake
Very good knowledge of SQL and programming in Python
Ability to work with databases, including the Snowflake platform
Knowledge of ETL tools and data integration
Ability to work in a team and good communication skills
Fluent English in speaking and writing
We Offer
B2B contract type
Full-time job
Remote and flexible working hours
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer,ASTRELYA,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-at-astrelya-3910760230?position=10&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=yV6o8FO4VtUJdgoHfgWavQ%3D%3D&trk=public_jobs_jserp-result_search-card,"ASTRELYA est un groupe de conseil et d‚Äôexpertise IT fond√© en 2017, pr√©sent en France (Paris et r√©gions) et en Suisse (Gen√®ve). Aujourd'hui plus de 280 collaborateurs accompagnent nos clients dans l‚Äôacc√©l√©ration et la transformation de leurs organisations.
Dans le cadre de notre d√©veloppement, nous recherchons un
Data Engineeer F/H
.
Vos r√¥les et responsabilit√©s :
D√©veloppements Java Spark
Optimisation et gestion des √©volutions de l&#39;architecture pour int√©grer des calculs sur des volum√©tries de plus en plus importantes
Support technique aupr√®s des √©quipes de d√©veloppement et du responsable applicatif
Conception des solutions applicatives coh√©rentes avec l&#39;ensemble du SI et avec les normes et standards
D√©velopper et garantir les pratiques de d√©veloppement et de documentation associ√©s (DevOps
L‚Äôenvironnement technique dans lequel vous √©voluerez :
Java, Scala, Spark, √©cosyst√®me Hadoop, environnement DevOps
Les comp√©tences recherch√©es :
Formation : √âcole d‚Äôing√©nieur ou √©quivalent Bac+5
Exp√©riences : Minimum 5 ans d‚Äôexp√©rience
Langues : Anglais technique
Excellent relationnel, force de proposition, autonome
Pourquoi rejoindre ASTRELYA ?
Une gestion de carri√®re personnalis√©e et un management de proximit√©
Une politique active de formations / certifications (technique, m√©tier, leadership)
Une offre vari√©e de missions d‚Äôexpertise
Un engagement RSE fort : Ecovadis Gold, Signataire de la charte pour la diversit√©, du Pacte des Nations Unies et mise en place du M√©c√©nat de comp√©tences
Un programme de cooptation attractif
Afterworks, conf√©rences techniques et activit√©s sportives r√©guliers
Cette annonce vous correspond ? Postulez !
üöÄ
Tous nos postes sont ouverts aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps'], 'FrSoftSkills': ['Leadership', 'Organisation'], 'EnSoftSkils': ['Leadership']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Data Engineer  H/F,Groupe INGENA,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-groupe-ingena-3883689479?position=1&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=PTJFmVLol0NZPIc8rRt%2BRw%3D%3D&trk=public_jobs_jserp-result_search-card,"Le groupe INGENA promeut la transition num√©rique en √©tant acteur d‚Äôun monde souhaitable.
Votre mission :
Concevoir, d√©velopper et tester des algorithmes de collecte et de traitement de gros volumes de donn√©es sous Scala, Python ou Java
Automatiser et optimiser les flux de donn√©es et leurs visualisations en dashboards
Industrialiser les traitements, la qualit√© et l‚Äôint√©grit√© des donn√©es
Participer √† la Mod√©lisation et √† la Gouvernance des donn√©es (process, normalisation, r√©f√©rentiel,‚Ä¶)
Contribuer √† la scalabilit√©, la s√©curit√©, la stabilit√© et la disponibilit√© des donn√©es de la plateforme
Analyser les donn√©es pour r√©pondre aux questions m√©tiers et participer √† l‚Äô√©volution de l‚Äôarchitecture Big Data
Concevoir, D√©velopper et Industrialiser des mod√®les de Machine Learning, Deep Learning, en collaboration avec les Data Scientists
Appliquer une d√©marche CI/CD (Git, Jira, Jenkins)
Les comp√©tences techniques n√©cessaires sont :
Exp√©rience de 5 ans minimum en d√©veloppements Scala, Python ou Java
Exp√©rience de 2 ans minimum sur SPARK et sur le traitement des flux en streaming
Expertise sur Hadoop (Hive, HBase, HDFS) sous distributions MapR ou Hortonworks
Exp√©rience souhait√©e sur ELK, Terraform, NoSQL,‚Ä¶
Fort background en Mod√©lisation de donn√©es ou ETL
Ma√Ætrise des briques analytiques des clouds AWS, GCP ou Azure
Sensibilisation √† la d√©marche CI/CD tools (Git, Jenkins)
La connaissance de Docker, Kubernetes et Ansible est un plus
Mise en ≈ìuvre des m√©thodes Agile (Scrum, Kanban,‚Ä¶)
Anglais souhait√©
Groupe INGENA
:
Le Groupe INGENA est sp√©cialis√© en Conseil M√©tier et en Int√©gration pour les march√©s de l‚Äôassurance, de la banque et de la Finance. INGENA intervient notamment sur les projets associ√©s √† la Data, aux Risques et √† la Distribution.
Le groupe comprend √©galement la soci√©t√© DRiMS sp√©cialis√©e en Finance de March√©.
Nos valeurs : Engagement, Int√©grit√© et Bienveillance.
La mise en pratique du monde souhaitable, c‚Äôest pour nous une entreprise √©co-responsable, √©thique, inclusive, sociale, soucieuse du bien-√™tre, de l‚Äô√©volution et de l‚Äô√©panouissement de ses √©quipes. Ce sont aussi des offres pour un monde durable comme la ma√Ætrise des risques ou l‚ÄôESG.
Dans un esprit convivial et engag√©, nous faisons en sorte que chacun puisse √™tre acteur de l‚ÄôINGENA souhaitable.
Bureau √† Paris 9√®me (M√©tro Le Peletier). Clients √† Paris ou tr√®s proche banlieue.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': ['JIRA'], 'Other': ['Big Data', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,DATA ENGINEER-LYON H/F,Lincoln France,"Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-lyon-h-f-at-lincoln-france-3851734549?position=2&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=VeypythEIv8Md9nnB3RwPA%3D%3D&trk=public_jobs_jserp-result_search-card,"Poste CDI : Data Engineer (Scala, Spark, GCP, etc.) -H/F - Lyon
Lincoln Pure Player Data
üí°: R√©inventant l'analyse
depuis 30 ans
. Experts en Modern BI, Big Data et Science des donn√©es üìä. Nous transformons vos donn√©es en solutions pour les grands comptes, des secteurs bancaire, retail, t√©l√©coms, industriel, sant√©, et plus encore üíº.
Description de poste
üéØ
Missions
:
Concevoir et d√©velopper des pipelines de donn√©es robustes et √©volutifs.
Int√©grer et transformer des donn√©es provenant de diff√©rentes sources.
D√©velopper et mettre en ≈ìuvre des algorithmes de traitement de donn√©es avanc√©s.
Collaborer √©troitement avec les √©quipes clients pour comprendre leurs besoins et fournir des solutions adapt√©es.
Assurer la qualit√© et la fiabilit√© des solutions d√©velopp√©es.
üîç
Pr√©requis
:
Ma√Ætrise des langages de programmation (
Python, Scala, Spark, etc
.).
Connaissance approfondie des bases de donn√©es et des technologies
Big Data (Hadoop, Spark, Kafka, Talend,...) et Cloud (AWS, GCP, Azure,...)
.
Exp√©rience avec
MySQL, PostgreSQL, MongoDB.
Solides comp√©tences en conception et en optimisation de pipelines de donn√©es.
Exp√©rience de travail en
m√©thode Agile
pour la gestion de projet et le d√©veloppement de solutions.
Capacit√© √† travailler de mani√®re autonome et en √©quipe.
Excellentes comp√©tences en communication et en r√©solution de probl√®mes.
üåü
Avantages :
Environnement collaboratif et innovant
Formations certifiantes et accompagnement individualis√©
T√©l√©travail et horaires flexibles
R√©mun√©ration comp√©titive avec avantages sociaux attrayants
Possibilit√© de mobilit√© √† Lille, Paris ou Aix-en-Provence
‚ú®
Processus de recrutement
: 2 entretiens (RH et technique)
Si vous √™tes passionn√© par les d√©fis de la Data et que vous souhaitez rejoindre une √©quipe dynamique et innovante,
postulez d√®s maintenant et contribuez √† red√©finir l'avenir de l'analyse de donn√©es chez Lincoln! üòâ
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['MySQL', 'PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Communication', 'R√©solution de probl√®mes'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '30', '30', '30']}"
LinkedIn,D√©veloppeur Big Data H/F,Inetum,"St.-Ouen, √éle-de-France, France",https://fr.linkedin.com/jobs/view/d%C3%A9veloppeur-big-data-h-f-at-inetum-3843965989?position=3&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=cF9s3MXmDqgW8F6HUp9rFw%3D%3D&trk=public_jobs_jserp-result_search-card,"D√©tail de l'offre
Informations g√©n√©rales
Entit√© de rattachement
Inetum est un leader europ√©en des services num√©riques. Pour les entreprises, les acteurs publics et la soci√©t√© dans son ensemble, les 28 000 consultants et sp√©cialistes du groupe visent chaque jour l'impact digital des solutions qui contribuent √† la performance, √† l'innovation et au bien commun.
Pr√©sent dans 19 pays au plus pr√®s des territoires, et avec ses grands partenaires √©diteurs de logiciels, Inetum r√©pond aux enjeux de la transformation digitale avec proximit√© et flexibilit√©.
Port√© par son ambition de croissance et d'industrialisation, Inetum a g√©n√©r√© en 2023 un chiffre d'affaires de 2,5 milliards d'‚Ç¨.
Pour r√©pondre √† un march√© en croissance continue depuis plus de 30ans, Inetum a fait le choix d√©lib√©r√© de se recentrer sur 4 m√©tiers afin de gagner en puissance et proposer des solutions sur mesure, adapt√©es aux besoins sp√©cifiques de ses clients le conseil (Inetum Consulting), la gestion des infrastructures et applications √† fa√ßon (Inetum Technologies), l'impl√©mentation de progiciels (Inetum Solutions) et sa propre activit√© d'√©diteur de logiciels (Inetum Software). Inetum a conclu des partenariats strat√©giques avec 4 grands √©diteurs mondiaux - Salesforce, ServiceNow, Microsoft et SAP et poursuit une strat√©gie d'acquisitions d√©di√©e afin d'entrer dans le top 5 europ√©en sur ces technologies et proposer la meilleure expertise √† ses clients.
Tous nos postes sont ouverts aux personnes en situation de handicap.
Description du poste
M√©tier
Applications Delivery - Software Development
Intitul√© du poste
D√©veloppeur Big Data H/F
Contrat
CDI
Description De La Mission
Le p√¥le
BFA
de la branche Application Services du groupe
INETUM
, recherche plusieurs d√©veloppeurs
Big Data
afin d'intervenir aupr√®s de clients grands comptes au sein
des march√©s bancaires et de l'assurance.
Directement int√©gr√©(e) chez l'un de nos clients sur des sujets strat√©giques et aux enjeux forts, vous serez amen√©(e) √†
Participer √† l'analyse d√©taill√©e √† partir des besoins des utilisateurs et de l'analyse fonctionnelle
Concevoir l'application et les tests √† partir de l'analyse d√©taill√©e
D√©rouler les tests et corriger les anomalies
Travailler sur la mise en place d‚Äôinfrastructures Big Data
R√©aliser les flux de donn√©es
Valider leur fonctionnement en s√©curit√© et performance
Assurer la p√©rennit√© de leurs √©volutions
Participer quotidiennement aux r√©unions d‚Äô√©quipe (daily meeting) afin de contribuer √† l‚Äô√©valuation de l‚Äôeffort de travail n√©cessaire
Profil
Issue d'une formation d'ing√©nieur / Bac+5 en Informatique
Dot√© d'une exp√©rience d‚Äôau moins 2 ans sur ce type poste
Ma√Ætrise des technologies Hadoop, Spark, Hive, Impala, ETL (Talend, Informatica, ‚Ä¶), Java, Scala, Python, SQL, les bases de donn√©es SQL (oracle, ‚Ä¶) et NoSQL (Cassandra, ‚Ä¶)
Des notions de Machine Learning et d‚ÄôIA sont recommand√©es pour bien appr√©hender les besoins de nos Data Scientists.
Exp√©rience au sein d'un environnement agile (Scrum) indispensable
Anglais obligatoire
Localisation du poste
Localisation du poste
France, Ile-de-France
Ville
145, Boulevard Victor Hugo 93400 Saint-Ouen
Crit√®res candidat
Niveau d'exp√©rience min. requis
Plus de 2 ans
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning'], 'FrSoftSkills': ['Flexibilit√©'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '30', '30', '30']}"
LinkedIn,Data Engineer - D√©veloppeur - 38 - 42K‚Ç¨ Nantes H/F,L2C / Sp√©cialiste du recrutement IT,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-d%C3%A9veloppeur-38-42k%E2%82%AC-nantes-h-f-at-l2c-sp%C3%A9cialiste-du-recrutement-it-3913996457?position=4&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=qmrHjOejaWqg6MEzmYhDuQ%3D%3D&trk=public_jobs_jserp-result_search-card,"L2C est un cabinet sp√©cialis√© dans le recrutement de profils informatiques, tech' et data en CDI pour des clients finaux.
CLIENT
Pr√©curseur, innovant et visionnaire, notre client a d√©velopp√© une plateforme bas√©e sur l'IA pr√©dictive, qui permet aux entreprises de prendre les meilleures d√©cisions.
R√©f√©rence reconnue et leader dans le domaine de la Business Intelligence, notre client d√©veloppe des solutions d'intelligence artificielle commerciale BtoB pointues, compl√®tes, avec un haut niveau de qualit√© : aide √† la prospection, gestion des appels d'offres, pr√©diction financi√®re
Solidement √©tabli, en croissance continue, notre client se r√©invente constamment afin de rester √† la pointe et de prendre soin de ses collaborateurs.
Depuis plus de 20 ans, notre client a conquis pr√®s de 15 000 clients. (Paypal, Dassault, KPMG)
C'est une soci√©t√© saine, bijou de la tech, pr√©curseur en termes de stack technique et fa√ßon de fonctionner, avec un bon √©tat d'esprit, offrant des conditions de travail agr√©ables.
Nous recherchons un candidat polyvalent, √† la crois√©e entre le traitement de donn√©es et le d√©veloppement. (Proche Nantes)
Poste √† pourvoir en interne en CDI. (t√©l√©travail 3 jours/semaine)
Missions
Vous participerez √† l'am√©lioration des outils r√©f√©rentiels Big Data, en √©troite collaboration avec les √©quipes de d√©veloppeurs (10 personnes) et les data scientists (6 personnes)
Vous d√©velopperez des solutions de captation et d'int√©gration des donn√©es issues de l'Open Data et des partenaires, crawls, scraping, imports de fichiers
Vous mod√©liserez des bases de donn√©es
Vous orchestrerez des flux de donn√©es entre les applicatifs, r√©f√©rentiels, bases de donn√©es (SQL/NoSQL) avec des outils ETL.
Vous valoriserez les donn√©es avec des traitements compl√©mentaires (g√©ocodage, oc√©risation)
Vous d√©velopperez des APIs pour des usages internes et pour les clients
Vous assurerez la supervision et l'exploitation des outils (surveillance des performances et garantie de la disponibilit√©.
Vous assurerez la qualit√© des donn√©es (nettoyage, standardisation, valorisation pour garantir la fiabilit√©)
Vous r√©digerez la documentation technique et accompagnerez les utilisateurs
Les plus
Soci√©t√© pr√©curseur, innovante et visionnaire, qui prend soin de ses collaborateurs
R√©f√©rence reconnue et leader dans le domaine de la Business Intelligence (IA pr√©dictive, sujets tech modernes et riches)
Groupe solide en forte croissance
Soci√©t√© solidement implant√©e en France et √† l'international depuis une vingtaine d'ann√©es
T√©l√©travail partiel
Environnement de travail sain et agr√©able
Compl√©mentaire sant√©/Pr√©voyance, comit√© d'entreprise, prime vacances, tickets restaurant
Vous disposez d'un bon bagage technique sur Python.
Vous avez l'habitude de vous auto-former sur les outils et langages et vous savez maintenir une veille active sur les outils de traitement des donn√©es.
Comp√©tences / Connaissances
Data-Management, Audit de qualit√© des donn√©es et usage des ETL
Syst√®mes Linux, gestion et administration des containers (Docker, Kubernetes)
D√©veloppement / Scripts : Python ++ (Avec Spark), JavaScript, C#
Bases De Donn√©es
SQL Server ou autres SGBD Relationnels
MongoDB
Elasticsearch
Bases de donn√©es orient√©es Graph (Neo4J)
Connaissances CI/CD, Git
Connaissance g√©n√©rale des technologies et framework big data usuels.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'C#', 'R', 'Go', 'JavaScript'], 'DataBase': ['SQL', 'NoSQL', 'Neo4j', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': ['Linux'], 'DBMS': ['SQL Server'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['Big Data', 'CI/CD'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '20', '20', '20']}"
LinkedIn,Data Engineer (H/F),Harry Hope.,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-harry-hope-3920545043?position=5&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=kGbVGmURBYVn0rXlEKV%2BSg%3D%3D&trk=public_jobs_jserp-result_search-card,"Harry Hope, cabinet de recrutement accompagne candidats et entreprises dans leurs recherches des meilleures opportunit√©s en France et √† l'international. Afin de mieux r√©pondre √† vos enjeux, tous nos consultants sont sp√©cialis√©s par secteur d'activit√© et zone g√©ographique.
Notre client, soci√©t√© en pleine croissance, sp√©cialis√© dans le domaine de la Big Data, recherche des Consultants Data Engineer ! Participez √† cette aventure et rejoignez une formidable √©quipe.
Vos missions principales seront diversifi√©es, comprenant notamment :
Participation aux processus d'avant-vente : Vous contribuerez √† l'√©laboration des propositions techniques, mettant en avant votre expertise pour r√©pondre aux besoins des clients.
Qualification technique des prestataires : Vous participerez activement √† l'√©valuation et √† la s√©lection des prestataires, garantissant un partenariat de qualit√©.
Direction et coordination des projets : Vous dirigerez et coordonnerez la conception et la mise en oeuvre des projets, assurant leur r√©ussite technique.
Documentation technique : Vous √©laborerez, au besoin, des dossiers d'architecture, d'installation et d'exploitation, assurant une tra√ßabilit√© et une compr√©hension optimale des solutions mises en place.
Participation active aux d√©veloppements : Vous apporterez votre expertise en contribuant directement aux d√©veloppements dans le cadre des projets.
De mani√®re plus √©tendue, vous aurez l'opportunit√© de :
Enrichir les bonnes pratiques : Vous contribuerez √† l'√©volution et √† l'am√©lioration des bonnes pratiques d'architecture et de d√©veloppement dans le domaine du Big Data.
Veille technologique : Vous r√©aliserez une veille constante sur les avanc√©es technologiques du secteur, assurant ainsi la pertinence des solutions propos√©es.
Formation technique : Vous √©laborerez des supports de formation technique pour nos clients et/ou nos consultants juniors, partageant ainsi votre savoir-faire.
Animation du p√¥le technique : Vous participerez activement √† l'animation du p√¥le technique favorisant un environnement collaboratif et innovant.
Vous √™tes d√©tenteur d'un dipl√¥me d'ing√©nieur (√©cole ou universit√©), et vous avez 5 ans d'exp√©rience en tant que Data Engineer.
En tant que Consultant Data Engineer, nous recherchons des professionnels poss√©dant des comp√©tences solides et des convictions dans les domaines suivants :
Architectures Big Data : Kappa, Lambda, R√©active, SMACK, etc.
Solutions technologiques : Hadoop, SGBD NoSQL, Kafka, Spark, etc.
Outils de d√©veloppement : Vous √™tes √† l'aise avec des outils tels que Hive, Pig, Python, Scala, etc.
Environnements d'exploitation et de supervision : Vous avez une exp√©rience pratique avec des outils tels qu'Ambari, Oozie, Zookeeper, etc. 20681288-55584
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Junior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Data Engineer,Mobiskill | WEFY Group,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-mobiskill-wefy-group-3907391938?position=6&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=d9sK3EdR8JW0CN1NTR9hag%3D%3D&trk=public_jobs_jserp-result_search-card,"La soci√©t√© ?
Cette startup a √©t√© cr√©√©e en 2018 et vise √† aider la prise de d√©cision de ses clients qui sont principalement dans le secteur du retail ou de l'alimentaire.
Ils permettent d'enrichir la donn√©e afin d'am√©liorer la strat√©gie de vente et marketing d'une entreprise gr√¢ce √† leur plateforme Saas bas√©e sur des algorithmes d'IA.
Ils ont besoin de renforcer leur √©quipe en Data Engineering pour g√©rer au mieux leur volum√©trie.
Les missions ?
- Editer le cahier des charges des donn√©es √† collecter aupr√®s de nos partenaires distributeurs
- Prendre en main la gestion de la donn√©e dans le cloud de la soci√©t√© pour optimiser les co√ªts et l‚Äôefficacit√© des analyses effectu√©es par l‚Äô√©quipe Analytics
- Anticiper les √©volutions et participer aux choix structurants de la soci√©t√© li√©s √† la gestion de la data
Le profil recherch√© ?
- Avoir 2/3 ans d'exp√©rience en Data Engineering (hors stage et alternance)
- Avoir pu travaill√© en Python comme langage de programmation
Avoir travaill√© au moins deux ans et si possible sur des sujets d'optimisation avec Spark !
- La ma√Ætrise des outils tels Airflow, Kafka et Snowflake seraient un plus appr√©ci√©
- Ma√Ætriser un des cloud providers et si possible avoir une exp√©rience sur Azure
Pourquoi les rejoindre ?
- Une soci√©t√© stable financi√®rement (fonds propres uniquement)
- Une startup en pleine croissance
- Une r√©mun√©ration en fonction de votre s√©niorit√©
- Volum√©trie de donn√©es incroyable, il y a de quoi s'amuser !
- Faire parti de l'unique retail-tech qui a un impact √©cologique positif (fin des prospectus, √©viter le g√¢chis alimentaire)
H√¢te de vous en dire plus rapidement !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer,MindPal,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-at-mindpal-3896997013?position=7&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=GrAS148%2BSqUlVtQ2ePplOg%3D%3D&trk=public_jobs_jserp-result_search-card,"We are looking for
Data Engineer!
Responsibilities
Designing, creating, and maintaining data processing systems
Analyzing and optimizing data processing workflows
Collaborating with the team to ensure data quality and efficiency
Testing and implementing new solutions
Requirements
At least 2 years of experience in designing and creating data processing systems
Proficiency in tools and programming languages related to data engineering (e.g. Hadoop, Spark, Scala, Python)
Excellent knowledge of databases and SQL language
Ability to work in a team and communicate effectively with other departments
Communicative English skills
Experience with AWS/AWS Glue is a plus
We Offer
B2B contract
Full-time job
Remote work and flexible hours
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer Alternant(e),Wakam,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-alternant-e-at-wakam-3918901392?position=8&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=xnrf2vRnerqq3Y11vT3uZQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Who are we?
Wakam is a B2B2C insurance company that creates white-label insurance solutions via its Play&Plug¬Æ technology platform for more than 150 distribution partners. We provide most of our insurance products through API, and hosts white label insurance solutions via our Play&Plug technology platform.
With a footprint spanning 32 countries and revenue of more than ‚Ç¨900 million in 2023, mostly generated outside France, Wakam is the European leader in digital and embedded insurance.
Strongly committed to social responsibility,
Wakam is a mission-driven company
dedicated to ""enabling transparent and impactful insurance"".
‚úé
Missions
Wakam assure la conception de produits d'assurances sur-mesure qui sont ensuite commercialis√©s par des partenaires distributeurs (courtiers, insurtech, retailers) sur un mod√®le B2B2C en marque blanche. Pour accompagner la forte croissance de l'entreprise, Wakam est √† la recherche d'un(e) alternant(e) pour rejoindre notre Office Data.
Rattach√©(e) √† l'√©quipe Data Platform (DPF), vous contribuerez activement √† l'√©laboration de la nouvelle plateforme en y d√©veloppant de nouveaux cas d'usages techniques et business.
Vos principales missions sont les suivantes :
Construire des pipelines ETL/ELT et reverse ETL sur les donn√©es des partenaires Wakam;
Comprendre l'architecture existante, incluant le portail d'ingestion des donn√©es, le framework de self-service et l'infrastructure technique;
R√©aliser des transformations de donn√©es √† l'aide du framework DBT en SQL;
Contribuer au d√©veloppement des produits de la Data Platform en utilisant Python et partager les connaissances acquises avec la communaut√© techniques de Wakam;
Collecter des donn√©es aux formats vari√©s provenant des diff√©rentes sources;
Participer activement au d√©veloppement de la data platform sur Snowflake;
Aider et assister les utilisateurs m√©tier dans l'utilisation des outils fournis par l'√©quipe DPF;
Documenter les diff√©rentes √©tapes de transformation et d'historisation des donn√©es;
‚úØ
Profil recherch√©
Vous suivez actuellement des √©tudes dans l'un de ces domaines : √©cole d'ing√©nieurs, master en informatique, data science, data engineering;
Vous avez de fortes capacit√©s d'analyse et de r√©flexion et savez √©galement √™tre dans l'action et orient√©.e r√©sultats ;
Vous √™tes curieux, autonome et agile;
Vous devez avoir de fortes capacit√©s d'analyse et de r√©flexion, mais √©galement √™tre dans l'action et orient√©.e r√©sultats;
Excellente ma√Ætrise du fran√ßais et de l'anglais, √† l'oral comme √† l'√©crit;
Bonne connaissance de Python, SQL, entrep√¥ts de donn√©es, syst√®mes distribu√©s, Cloud;
Process de recrutement
To help you get a complete picture of our hiring process and Wakam's work culture, please visit our dedicated page: Interviews at Wakam
√âchange avec Jade, Talent Acquisition
√âchange avec Mariana Gherghina (Senior Data Engineer) et Simon Pichon (Engineering Manager)
=> Welcome @Wakam
Positive energy, agility, and team spirit are essential to support Wakam in its hyper-growth!
You have the Wakam mindset? Join us!
More about us
Our culture?
Free to impact
. A culture where everything is possible, where all ideas are taken into consideration, where everyone has an impact on the transformation of insurance! Hungry for freedom? Thirsty for autonomy? If you are adventurous and like challenges, then the Wakam adventure might be made for you!
Discover on our website who we really are with the 11 cultural markers that so well describe us!
What we are looking for ?
Mindset compatibility with our 'Free to Impact' culture:
Think big
Biased for action
Curious and eager to learn
Can say no and find solutions
Aims for the moon (but please don't stick on the moon)
And above all: have fun working together ü§úü§õ !
Good to know !
Wakam is not based on a hierarchy but on a methodology where everyone finds their role and knows their objectives.
With a flat hierarchical system and a highly collaborative operating model, Wakam is an extremely agile and transparent company.
Every last Friday of the month, it's Free.day @Wakam, a day without meetings to take a step aside and dedicate ourselves to skills sponsorship or other activities (because we are curious, I remind you).
Full-remote is a reality at Wakam (there is even one Wakamee who works from his sailing boat ‚õµ) with our Wakam From Anywhere (WFA) program.
Last but not least : we are nice and we have fun! (you'll find out by yourself üòâ)
At Wakam, we are committed to fostering an inclusive environment where diversity is celebrated. If you require any reasonable adjustments during the recruitment process, please feel free to reach out to your recruiter.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Remote', 'Full', 'Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer Cloud (H/F),Beelix,"Mougins, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-cloud-h-f-at-beelix-3909193730?position=9&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=%2Bx0Epim5PeLAZ9pvSZREUQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ?
Depuis 2016, nous accompagnons nos clients sur des probl√©matiques de Product Management, Data et Design Thinking. Beelix contribue √† fa√ßonner le monde de demain en participant aux grandes avanc√©es des secteurs suivants:
üöóAutomobile
‚ö°Energie
üì°M√©dias & T√©l√©coms
üëóLuxe & Retail
üí∂ Banque, Finance & Assurance
‚úàÔ∏èD√©fense
Aujourd‚Äôhui, Beelix compte plus de 200 collaborateurs motiv√©s et dynamiques. Lab√©lis√©e Great Place To work en 2023, Beelix est aussi une entreprise engag√©e o√π il fait bon vivre.
Dans le cadre de notre d√©veloppement, nous recherchons un Data Engineer Cloud (H/F) en r√©gion PACA.
Quelles missions au quotidien ?
Concevoir, d√©velopper et d√©ployer des pipelines de donn√©es fiables et √©volutifs sur GCP.
Collaborer avec les √©quipes m√©tier pour comprendre les besoins en donn√©es et fournir des solutions adapt√©es.
Optimiser les performances et la disponibilit√© des solutions de donn√©es sur GCP.
Mettre en ≈ìuvre des pratiques de s√©curit√© des donn√©es et assurer la conformit√© aux r√©glementations.
Travailler en √©troite collaboration avec les √©quipes de d√©veloppement dans un environnement agile pour fournir des solutions dans des d√©lais serr√©s.
Expertise souhait√©e
Exp√©rience significative dans le d√©veloppement et la gestion de pipelines de donn√©es sur GCP ou autre plateforme cloud.
Ma√Ætrise des outils GCP tels que BigQuery, Dataflow, Pub/Sub, et Cloud Storage.
Solide exp√©rience en Python, Java ou Scala.
Compr√©hension des principes de l'ing√©nierie des donn√©es, du traitement des donn√©es en continu et des entrep√¥ts de donn√©es.
Capacit√© √† travailler de mani√®re autonome et en √©quipe, avec d'excellentes comp√©tences en communication.
A propos de vous ?
Dipl√¥m√© d'une √©cole d'ing√©nieurs ou √©quivalent
Au moins 3 ans d'exp√©rience en tant que Data Engineer
Exp√©rience en mode de Delivery Agile (Scrum, Kanban, etc.‚Ä¶)
Vous avez un bon niveau d‚Äôanglais tant √† l‚Äô√©crit qu‚Äô√† l‚Äôoral
Pourquoi nous rejoindre ?
Un suivi et un accompagnement au quotidien
Un organisme de formation certifi√© Qualiopi, un abonnement linkedin learning pour chaque salari√© et des partenariats avec des sp√©cialistes pour d‚Äôautres expertises
De nombreux √©v√©nements : Afterworks, Communaut√©s m√©tiers, Happy talks‚Ä¶
une Exp√©rience personnalis√©e bas√©e sur vos besoins gr√¢ce au Pr√©dictive Index
Notre package ¬´ unBeelievable ¬ª : 100% du titre de transport, Tickets restaurants, CSE, Prime de participation...
Nombreux √©v√®nements (afterworks, sport, etc) et des communaut√©s m√©tiers dynamiques
Le processus de recrutement ?
√âchange t√©l√©phonique (15 min)
Entretien 1 RH pour apprendre √† vous conna√Ætre
Entretien 2 avec votre futur N+1 pour appr√©hender la relation manag√©riale
Entretien 3 avec un Responsable commercial pour avoir la vision strat√©gique
Localisation : Mougins, format hybride
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': ['Hybride'], 'TypeContract': [], 'Salary': ['100'], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer & Analyst - Paris - F/H/X - CDI,Partoo,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-analyst-paris-f-h-x-cdi-at-partoo-3892387658?position=10&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=1AWLZFifjjDn5cL6tE%2Bgvw%3D%3D&trk=public_jobs_jserp-result_search-card,"Partoo, who are we? üëÄ
Partoo est une scale-up saas B2B qui a √† c≈ìur d‚Äôaider les commerces locaux, grandes entreprises ou PME √† se rapprocher de leurs clients. Pour cela, ils ont d√©velopp√© une plateforme tout-en-un et diff√©rentes solutions qui s‚Äôarticulent autour de 3 propositions de valeur : Get found, Get chosen & Get clients.
√Ä travers ces 3 propositions, ils ont d√©velopp√© plusieurs produits qui s‚Äôadaptent aux √©volutions du parcours d‚Äôachat des clients :
üîé Get found
Presence: Synchroniser les informations des magasins sur les principales plateformes (Google, Facebook, Waze, etc.), annuaires et GPS
Store Locator: Aider les clients √† trouver le magasin qui leur convient gr√¢ce √† des donn√©es locales actualis√©es et des filtres d√©di√©s sur les sites web des enseignes
R√©seaux sociaux: G√©rer les publications sur Facebook, Google, Instagram, etc
üéØ Get chosen
Review: Centraliser, r√©pondre et analyser les avis clients re√ßus sur Google et Facebook
Booster: Obtenir des avis positifs suppl√©mentaires sur Google par le biais de SMS et de QR codes
ü§ó Get clients
Messages: Centraliser et r√©pondre √† tous les messages de chat re√ßus via Google Business Messages, Messenger et bient√¥t aussi via Instagram, whatsapp, etc. (templates messages, conversations starter, appels manqu√©s...)
Quelques chiffres üóùÔ∏è
> Un label Happy at Work et l'une des meilleures notes Glassdoor de l'√©cosyst√®me avec 4.6/5 pour plus de 260 avis‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è Ô∏èÔ∏èÔ∏èÔ∏èÔ∏èÔ∏è
> 450+ employ√©s heureux, 37 nationalit√©s diff√©rentes, des bureaux √† Paris et Barcelone üöÄ
> Ils g√®rent 300 000 points de vente et travaillent de mani√®re transversale avec +1000 cha√Ænes (Carrefour, Generali, Toyota, D√©cathlon, Leroy Merlin etc.) et +6000 pme dans environ 150 pays
Notre m√©mo 2024: le mot du CEO (https://www.partoo.co/fr/blog/memo-2024/)
IMPACT üí•
Partoo compte aujourd‚Äôhui pas moins de 400 collaborateurs, qui ≈ìuvrent au quotidien √† maintenir une croissance saine, en phase avec les enjeux et challenges √©conomiques du moment.
Une des composantes clefs pour y parvenir r√©side en notre capacit√© √† d√©velopper et maintenir un haut niveau d‚Äôefficacit√© op√©rationnelle. Dans cette logique, am√©liorer notre capacit√© √† exploiter et utiliser la donn√©e pr√©sente dans nos syst√®mes est indispensable. Si nous avons d√©j√† une √©quipe Data en place, celle-ci est aujourd‚Äôhui mobilis√©e presque exclusivement sur les th√©matiques data relatives au fonctionnement de notre application ainsi qu‚Äô√† la construction d‚Äô√©l√©ments de visibilit√© pour nos clients.
Nous souhaitons donc recruter un Data Engineer & Analyst dont l‚Äôobjectif principal sera de permettre aux √©quipes Op√©rations et client-facing de visibiliser et tirer le meilleur parti d‚Äôune donn√©e aujourd‚Äôhui difficile d‚Äôacc√®s.
Manager : Adel Adman (cc. Cl√©ment Bouillaud, en charge de la team Operations)
TEAM üíô
Meetings r√©current avec les membres de Partoo :
Membre √† part enti√®re de l‚Äô√©quipe Data (elle-m√™me int√©gr√©e dans l‚Äô√©quipe Produit), tu seras n√©anmoins en contact r√©gulier avec les √©quipes Op√©rations, qui seront tes principales interlocutrices.
En d‚Äôautres termes, tu seras le pilier central entre les √©quipes Ops et Data.
Dans un premier temps, tu auras un meeting hebdomadaire avec Adel (Lead Data) et avec Cl√©ment (COO), le temps de cadrer tes premi√®res priorit√©s et de trouver la bonne r√©currence de rencontre avec les √©quipes Op√©rations.
MISSIONS üî•
Ton principal objectif consiste √† faire en sorte que chaque personne, des √©quipes Op√©rations comme des √©quipes client-facing, ait acc√®s √† la donn√©e dont elle a besoin, au moment o√π elle en a besoin, sur le support le plus ad√©quat. Pour y parvenir, plusieurs missions seront tiennes :
Architecture
:
Cr√©er des architectures de donn√©es robustes et √©volutives pour collecter, stocker et analyser de grandes quantit√©s de donn√©es provenant de diverses sources (Salesforce, Intercom, Chargebee, back office de Partoo, etc.)
Analyser et am√©liorer continuellement le mod√®le de donn√©es Salesforce (SF), en accompagnant l'√©quipe Ops dans le monitoring des anomalies et l'optimisation des performances
Int√©grations et flux
:
D√©velopper et optimiser des pipelines de donn√©es, assurant l'int√©gration fluide des donn√©es dans notre Data Warehouse depuis diff√©rentes sources, et inversement
Transformation & analyse
:
Concevoir et ex√©cuter des requ√™tes SQL complexes pour l'analyse de donn√©es, permettant de soutenir les d√©cisions business
Identifier et construire des KPI cruciaux, fournissant des insights pr√©cieux aux √©quipes business
Visualisation
:
Fournir aux √©quipes Ops et client-facing des outils de visualisation de donn√©es (Looker Studio, embedding, etc.), cl√©s dans l'optimisation de notre gestion de client√®le.
Formation
:
Former les √©quipes Op√©rations sur l‚Äôexploitation des tables de notre Datawarehouse ainsi que sur l‚Äôusage de Looker Studio et propager les principales best practices associ√©es. Tout √ßa, en collaboration au quotidien avec les √©quipes Ops !
DESIRED PROFILE üéØ
Comp√©tences recherch√©es :
Une tr√®s bonne connaissance du langage SQL, notamment PostgreSQL et BigQuery.
Ma√Ætrise du scripting Python et des notebooks pour l'analyse de donn√©es
D‚Äôexcellentes capacit√©s d'analyse pour comprendre les besoins business, identifier les anomalies dans les donn√©es et proposer des am√©liorations pertinentes
Une bonne aptitude √† manipuler et analyser de grands ensembles de donn√©es et en extraire des insights actionnables
Une tr√®s bonne ma√Ætrise d'au moins un outil de business intelligence tel que Looker Studio, PowerBI ou Tableau
Profils recherch√© :
Tu as plus de 3 ans d'exp√©rience en Data Engineering /Advanced Data Analysis
Tu ma√Ætrises les stacks de data les plus r√©centes (dbt, Airflow, Airbyte, etc.) et les meilleures pratiques en mati√®re de donn√©es (ETL, reverse-ETL, etc.)
Tu es orient√©(e) utilisateur et sais convertir les besoins commerciaux en solutions techniques
Tu sais communiquer avec les √©quipes et t'assurer que les meilleures pratiques sont adopt√©es
Tu es un team player !
Tu souhaites apprendre et grandir avec nous
RECRUITMENT PROCESS üõ†Ô∏è
A first video call with Marine, Talent Acquisition Specialist, 45 min
Interview with Adel, Lead Data Engineer, 1h
Case Study
Interview with Cl√©ment, Chief Operations Officer, 1h
√Ä comp√©tences √©gales, ce poste est ouvert aux travailleurs et travailleuses en situation de handicap ou assimil√©s au sens de l‚Äôarticle L5212-13 du Code du travail. Partoo s‚Äôengage en faveur de la diversit√©, l‚Äô√©galit√© professionnelle, l‚Äôemploi des travailleurs handicap√©s.
With equal skills, this position is open to disabled workers or those considered to be disabled within the meaning of Article L5212-13 of the French Labour Code. Partoo is committed to diversity, professional equality and the employment of disabled workers.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['PostgreSQL', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Senior Data & Cloud Engineer (H/F),fifty-five,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-cloud-engineer-h-f-at-fifty-five-3915044673?position=1&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=19LhPvryuXNgBpkjdc5ogw%3D%3D&trk=public_jobs_jserp-result_search-card,"Senior Data & Cloud Engineer
fifty-five est une data-company d'un genre nouveau qui aide les marques √† exploiter les donn√©es pour am√©liorer le marketing, les m√©dias et l'exp√©rience client gr√¢ce √† une combinaison de services de conseil et de technologie sp√©cialis√©s.
En tant que pilier data et marketing du Brandtech Group, nous offrons des services qui combinent le conseil en strat√©gie, les services de cloud, le conseil en m√©dia et l'exp√©rience client.
fifty-five, c'est plus de 400 experts du num√©rique. Des digital consultants, des sp√©cialistes du tracking et du m√©dia, des ing√©nieurs et des data scientists, travaillent tous en √©troite collaboration pour fournir des conseils marketing de haut niveau et une assistance technique aux marques, dans tout type d'industrie, partout dans le monde.
Partenaire des annonceurs de la collecte √† l'activation et l'exploitation des donn√©es, nous aidons les organisations √† devenir de v√©ritables entit√©s omnicanales ma√Ætrisant l'efficacit√© de leur √©cosyst√®me digital et ses synergies avec le monde physique.
Bas√© √† Paris, nous op√©rons sur 3 fuseaux horaires depuis nos 10 bureaux, situ√©s √† Paris, Londres, Gen√®ve, Milan, Shanghai, Hong Kong, Shenzhen, Taipei, Singapour et New York. fifty-five attache une importance particuli√®re au bien-√™tre de ses collaborateurs, ce qui lui a permis de figurer dans le classement Best Workplaces France en 2018.
Contexte :
L'√©quipe d'ing√©nierie d√©veloppe et met en ≈ìuvre les solutions techniques permettant la r√©alisation de pipelines de donn√©es et l'impl√©mentation de data platform pour nos clients : r√©cup√©ration de datas sur de multiples sources de donn√©es (APIs, files, etc.), data cleaning, data processing, automation et monitoring de l'ensemble. L'√©quipe s'appuie sur des technologies r√©centes (docker, kubernetes, terraform, notebooks, etc.) et met en place ses projets dans les diff√©rents clouds du march√© (GCP, Azure, AWS...).
Mission :
Nous sommes √† la recherche d'une personne capable de r√©aliser des projets techniques pour r√©pondre aux besoins de nos clients (par exemple: syst√®me de recommandations de produits, d√©tection d'anomalies, ranking). Les activit√©s vont du chiffrage et du sizing technique √† la mise en ≈ìuvre des architectures, en passant par la revue des sp√©cifications fonctionnelles et la production de code. Le Data & Cloud Engineer sera √©paul√© par un Lead dans ses missions. Il sera √©galement amen√© √† participer √† la R&D et √† accompagner les √©quipes transverses dans la mise en place d'outils de travail internes (librairies pour les data scientists, environnement Notebooks pour les data analysts et data scientists, d√©veloppement de frameworks sur diff√©rents cloud providers, etc.).
Nous souhaitons trouver la bonne personne pour faire √©voluer ou cr√©er de nouvelles solutions dans ce cadre. Les missions comprennent aussi bien du prototypage rapide pour des d√©monstrateurs, que de la production de code robuste qui tourne en production tous les jours.
Comp√©tences et exp√©riences :
4-5 ans d'exp√©rience en tant que Data Engineer
Ma√Ætrise de Python, SQL
Ma√Ætrise des environnements Cloud. Id√©alement certifi√© GCP, Azure ou AWS
Bonne connaissance de Docker/Kubernetes
Bonne connaissance d'au moins un data warehouse (BigQuery, Snowflake, etc)
Connaissance autour des Notebooks (Jupyter)
A l'aise avec des concepts li√©s aux APIs (OAuth, REST, etc.)
A l'aise avec les notions d'Infrastructure as Code (Terraform)
Au courant des pratiques GitOps et connaissances des concepts autour du CI/CD
La ma√Ætrise d'un orchestrateur, comme Apache Airflow, est un plus
Esprit d'√©quipe (collaborer aux tests unitaires, revue de code, partage de code, sprints)
Bon niveau en fran√ßais et en anglais
A d√©j√† travaill√© en mode projet avec des interlocuteurs vari√©s (consultant, data analyst, data scientist)
Une exp√©rience en marketing digital est un plus
Nous proposons :
un bureau au centre de Paris avec terrasse et jardin
un environnement multiculturel avec des collaborateurs aux nationalit√©s multiples (France, Royaume-Uni, Etats-Unis, Chine, Tunisie, Italie et plus)
des projets avec nos bureaux √† Londres, Hong Kong, New York, Shanghai, Gen√®ve, Shenzhen et Taipei
des TGIF et supers soir√©es
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Apache Airflow'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Data Engineer,NW,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-nw-3904072453?position=2&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=FFg227%2BWLr13f6Zrujr8iA%3D%3D&trk=public_jobs_jserp-result_search-card,"Type de contrat :
CDI
Localisation :
Paris, 7√®me (pr√©sentiel)
Date de d√©but :
d√®s que possible
Exp√©rience requise :
1 ou 2 ans d‚Äôexp√©rience
A propos de NW
NW vise √† rendre la transition √©nerg√©tique accessible √† tous. Depuis 2007, le groupe d√©ploie des solutions innovantes pour augmenter la part des √©nergies d√©carbon√©es dans le mix √©lectrique fran√ßais, soutenir la stabilit√© du r√©seau √©lectrique et contribuer au d√©veloppement de la mobilit√© √©lectrique.
Premi√®re licorne fran√ßaise de la transition √©nerg√©tique, NW est le leader en France du stockage d'√©lectricit√© avec sa solution JBox¬Æ et le pr√©curseur de la recharge haute puissance gr√¢ce √† ses bornes IECharge¬Æ. L'entreprise se d√©veloppe √©galement √† l'international, en particulier en Europe et aux Etats-Unis. En f√©vrier 2023, NW a rejoint la FrenchTech Next40.
Dans le cadre de notre forte croissance, nous recherchons un(e) Data Engineer pour rejoindre notre √©quipe tech. De formation Bac+5 Ing√©nieur ou similaire, vous souhaitez contribuer dans le domaine des √©nergies renouvelables, sur un poste √† fort impact et au sein d‚Äôune jeune √©quipe et engag√©e.
Vos principales missions
Mettre en place des outils de traitement et stockage de donn√©es
Benchmarking des solutions les plus adapt√©es aux besoins des √©quipes
Assurer la s√©curit√© de l‚Äôarchitecture de donn√©es
Participer √† la s√©lection de la stack technique
Actualisation et adaptation des solutions utilis√©es selon l‚Äô√©volution des technologies
Assurer la gestion des co√ªts li√©s aux besoins data avec les √©quipes internes
Support technique aux utilisateurs internes
Impl√©menter les processus de stockage et pr√©paration des donn√©es
Configurer la connexion aux APIs internes et externes
Formation des √©quipes internes sur les sujets data
Vos comp√©tences
Vous √™tes int√©ress√©(e) par les √©nergies renouvelables
Vous avez une r√©elle aisance relationnelle et une bonne capacit√© r√©dactionnelle
Vous avez la volont√© de rejoindre une entreprise en pleine croissance avec un projet de d√©veloppement ambitieux
Vous assurez la conversion des donn√©es
Vous ma√Ætrisez de l‚Äôautomatisation de la CI/CD
Vous parlez l‚Äôanglais couramment
Votre profil
Id√©alement, vous avez 1 ou 2 ans d‚Äôexp√©rience dans un poste similaire
Vous avez un Bac +5 Ing√©nieur ou similaire
Vous √™tes curieux(se), rigoureux(se), proactif(ve) et autonome
Tech stack
Python
Docker
Kubernetes
Apache Kafka
Apache Flink
Github Actions
Apache Iceberg
Pourquoi NW ?
D√©couvrir le secteur de la mobilit√© √©lectrique, du stockage d'√©nergie et du d√©veloppement de projet dans une entreprise
Rejoindre une √©quipe dynamique, positive, engag√©e
Participez activement aux d√©fis majeurs de la transition √©nerg√©tique et de la d√©carbonisation des √©nergies
Entreprise en pleine croissance, possibilit√© d‚Äôavoir un impact important dans la valorisation de l‚Äôentreprise
Processus de recrutement :
Entretien RH
Entretien manager
Test technique
Entretien fit √©quipe
NW Groupe est un employeur garantissant l'√©galit√© des chances. NW Groupe c√©l√®bre la diversit√© et s'engage √† fournir un environnement de respect mutuel o√π toutes les d√©cisions de recrutement sont bas√©es sur les qualifications, le m√©rite et les besoins de l'entreprise.
Organisation et m√©thodologies ‚úÖ
Nous travaillons en Squad sur le principe du roulement de projet avec pour but de participer activement √† la r√©flexion et au d√©veloppement de chacune des applications de l'entreprise.
Projets et d√©fis techniques üíª
Nos outils sont d√©velopp√©s en interne et permettent de d√©velopper, installer et superviser plusieurs centaines de sites de stockage d'√©nergie. Chaque jour, ces outils permettent d'optimiser la gestion de notre activit√© et d'acc√©l√©rer la transition √©nerg√©tique visant la d√©carbonisation des √©nergies.
Recherche et D√©veloppement üîç
Nous travaillons activement sur l‚Äôam√©lioration continue des concepts et des solutions existantes autour de la transition √©nerg√©tique. Nos √©quipes s'occupent non seulement de la conception et de la l'am√©lioration de ces syst√®mes mais aussi de l'exploration de futures opportunit√©s dans le secteur.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['Apache Kafka', 'Apache Flink'], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['CI/CD'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,"Data Engineer F/H - Syst√®me, r√©seaux, donn√©es (H/F)",UpMan Consulting,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-syst%C3%A8me-r%C3%A9seaux-donn%C3%A9es-h-f-at-upman-consulting-3901572843?position=3&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=5F%2FT5Lsts3uu%2FuZVqqv4gQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Cette offre d‚Äôemploi est fournie par P√¥le emploi
Description
Descriptif du poste: C est maintenant l occasion pour toi de rejoindre UpMan Consulting Notre ambition est de trouver les meilleurs profils Data Engineer pour intervenir chez nos clients grands comptes de la m√©tropole lilloise. On te propose une exp√©rience professionnelle en ad√©quation avec ce que tu souhaites r√©ellement. Tu d√©couvriras une ambiance de travail saine & bienveillante, tu participeras activement au d√©veloppement d une Happy StartUp, actuellement en forte croissance. O√π convivialit√© rime avec efficacit√© & o√π ta performance individuelle contribue √† notre r√©ussite globale. Tes missions / comp√©tences techniques Si tu l acceptes, ton r√¥le & tes missions seront les suivantes : * R√©aliser le processus d int√©gration de nouvelles donn√©es (r√©flexion sur la solution, mise en place d ETL, r√®gles de nettoyage, anonymisation ) * √ätre garant de l'acc√®s aux sources de donn√©es. * Ma√Ætrise de la donn√©e et √™tre le garant de sa qualit√© (r√©f√©rencement, normalisation et qualification) afin d'en faciliter l'exploitation par les √©quipes (Data Analysts et Data Scientists). * Ma√Ætrise de technologies Big Data et Cloud : Hadoop, Spark * Assurer la supervision et l'int√©gration de donn√©es structur√©es et non structur√©es venant de sources multiples, tout en veillant √† garder des donn√©es de qualit√©. * Assurer le suivi, la cartographie et la documentation des donn√©es int√©gr√©es * Afin de garantir une bonne ex√©cution de ta mission, nous recherchons les comp√©tences techniques suivantes : Langages de programmation : * SQL * Python / Pyspark * Java/Scala (plus rare, mais important) Diff√©rents types d ETL & orchestrateurs : * Airflow * Dagster * Prefect * SSIS/informatica * Talend Plateformes cloud : * GCP * Microsoft Azure * AWS Base de donn√©es relationnelles & NoSQL : * postgreSQL, MySQL,... * Redis, graphDB * Data warehouse/data transform : * Snowflake, Bigquery (tr√®s important) * DBT Qualit√© & comp√©tences n√©cessaires * Communiquant.e dans l √¢me * Avoir une bonne capacit√© de synth√®se & l esprit critique * Travail d √©quipe * Curiosit√© aigu√´ * Comprendre les objectifs & les besoins Nice to have * Anglais courant * Connaissance de la m√©thodologie DevOps * Notions en Data-science The office Pas de full remote (pour l instant) mais de l hybride dans la plupart des missions. En moyenne, 2 jours de t√©l√©travail par semaine. Cependant, les portes de nos bureaux √† Wambrechies sont toujours ouvertes pour accueillir nos collaborateurs pendant leurs journ√©es de t√©l√©travail & passer une bonne journ√©e tous ensemble ! Le salaire Junior : 30K √† 36K Ma√Ætrisant : 37K √† 43K Expert : 44K √† 50K & plus + notre package avantage Profil recherch√©: Ton Profil Tu es une personne passionn√©e & passionnante. Tu as envie d'√©voluer, de partager, de participer √† une mission collective & d√©couvrir LA nouvelle fa√ßon de collaborer avec une ESN made in Lille. Tu peux justifier d'une exp√©rience forte & significative en tant que Tech Lead Java, dans le d√©veloppement Java ! Pas besoin d'avoir trop ou pas assez de dipl√¥mes, chez nous, ce sont les comp√©tences qui priment ‚ÄØ! On se rencontre, on discute, on √©change sur tes envies professionnelles & on laisse la magie op√©rer. L'envie de grandir & de monter en comp√©tences est ton moteur au quotidien. Tu aimes les probl√©matiques complexes et les d√©fis technologiques. On dit de toi que tu es un.e agiliste dans l'√¢me, qui effectue une veille constante, √† l'aff√ªt de tout ce qui √©volue autour de toi... Ne r√©fl√©chis plus, saute le pas & d√©couvre UpMan Consulting, tu ne seras pas d√©√ßu. Tu balances ta d√©mission ?
PROFIL SOUHAIT√â
Exp√©rience
Exp√©rience exig√©e de 1 An(s)
Source: Pole emploi (https://www.pole-emploi.fr)
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['MySQL', 'PostgreSQL', 'Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Hybride', 'Remote', 'Full', 'Junior'], 'TypeContract': [], 'Salary': ['30K', '1'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer GCP (F/H),Apside,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-gcp-f-h-at-apside-2859485219?position=4&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=wv7OLTbzzRJCbMwFBnb29w%3D%3D&trk=public_jobs_jserp-result_search-card,"Envie de rejoindre une entreprise apprenante ? Engag√©e pour t‚Äôaccompagner dans ton √©volution professionnelle et dans tes projets personnels ?
Rejoins Apside Paris pour travailler sur nos projets de demain !
Le poste :
Tu seras amen√© √† participer √† la migration des donn√©es et le traitements Big Data depuis un cluster Hadoop interne vers l'infrastructure Google Cloud Platform.
Dans ce sens, tes missions seront les suivantes :
Participation aux chantiers de cadrage de la migration
Contribution √† la mise en place des environnements et outils de d√©ploiement automatis√©s
Accompagnement et formation des √©quipes √† l‚Äôoutil GCP
...
Environnement technique :
Jira Big data
Cloud GCP
Hadoop
Kubernetes
Spark, Kafka, Python
Toi ?
Tu as d√©j√† particip√© √† un projet de
migration Google Cloud Platform (GCP)
?
Tu es
rigoureux
,
bon communiquant
?
Tu souhaites participer √† un
projet d‚Äôenvergure associant cloud et Big Data
?
Alors ce poste de
Data Engineer GCP
est fait pour toi !
Et la suite ?
Tu rencontres d‚Äôabord l‚Äô√©quipe RH pour parler de tes attentes, ton projet, ton futur !
Puis les managers pour parler concret : missions, projets, parcours de carri√®re, et bien s√ªr salaire et avantages :)
Et tu discutes avec un de nos Tech Leads, pour √©valuer tes comp√©tences et te challenger.
Tu souhaites donner un nouvel √©lan √† ta carri√®re ? Rejoins la vie Apsidienne !
Pour en savoir plus √† www.apside.com
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': ['JIRA'], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['Salaire'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer Spark Scala - Services Financiers - Ile de France,Sopra Steria,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-spark-scala-services-financiers-ile-de-france-at-sopra-steria-3913390665?position=5&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=jSrg1Q0BPIqKrW7h8N2KDQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Company Description
Sopra Steria
, acteur majeur de la Tech en Europe, reconnu pour ses activit√©s de conseil, de services num√©riques et d‚Äô√©dition de logiciels, aide ses clients √† mener leur transformation digitale et √† obtenir des b√©n√©fices concrets et durables. Il apporte une r√©ponse globale aux enjeux de comp√©titivit√© des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d‚Äôactivit√© et des technologies innovantes √† une approche r√©solument collaborative.
Sopra Steria place l‚Äôhumain au centre de son action et s‚Äôengage aupr√®s de ses clients √† tirer le meilleur parti du digital pour construire un avenir positif.
Fort de 56 000 collaborateurs dans pr√®s de 30 pays, le Groupe a r√©alis√© un chiffre d‚Äôaffaires de 5,8 milliards d‚Äôeuros en 2023.
The world is how we shape it
Job Description
Votre futur environnement de travail :
Chez notre client, grande banque commerciale fran√ßaise, vous int√©grez nos squads pour intervenir sur des projets de grande envergure, des projets transformants et structurants de la banque de demain. Vous interviendrez sur la gestion d‚Äôapplications sur des domaines tels que : la conformit√©, la fraude, la lutte anti-blanchiment, les risques de cr√©dit, la tr√©sorerie, les paiements, les financements structur√©s ou encore le r√©glementaire bancaire.
Au sein de notre Data Factory, vous √™tes pleinement impliqu√©(e) dans toutes les phases de nos projets pour le compte de grands clients, contribuant ainsi √† leur succ√®s. Vous avez l'occasion de d√©velopper vos comp√©tences techniques et fonctionnelles de mani√®re approfondie, tout en travaillant sur des projets exigeants et passionnants pour le compte de grands clients du secteur bancaire.
Votre r√¥le et vos missions :
Vous avez pour r√¥le la mise en place de pipelines de donn√©es fiables, s√©curis√©s et √† l‚Äô√©chelle pour soutenir la mise √† disposition des donn√©es aux cas d‚Äôusage m√©tier qui en ont besoin.
Vos activit√©s principales sont les suivantes :
Vous travaillez avec le client pour √©valuer, concevoir, d√©ployer, am√©liorer et maintenir les pipelines de donn√©es;
Vous vous assurez que les pipelines de donn√©es cr√©√©s sont r√©silients, s√©curis√©s et accessibles;
Vous d√©finissez le mod√®le op√©rationnel pour monitorer et supporter les pipelines de donn√©es
Vous fournissez une expertise √† nos clients sur leurs donn√©es pour assurer leur optimisation et leur s√©curit√© par rapport √† leurs besoins;
Vous apportez un savoir en gestion de la qualit√© et la gouvernance de la donn√©e pour assurer le suivi de la conformit√© √† la gouvernance de la donn√©e
Vous faites de la veille technologique dans le domaine afin d‚Äôenrichir les roadmaps technologiques et fournir des solutions modernes √† nos clients.
Qualifications
Votre profil :
De formation Master 2 Ecole d'Ing√©nieurs ou Informatique, ou √©quivalent, vous justifiez d'une exp√©rience technique de 3 ans minimum et souhaitez √©voluer rapidement dans un contexte motivant. Vous avez ces comp√©tences requises :
Ma√Ætrise des technologies de bases de donn√©es Relationnelles et NoSQL
Ma√Ætrise d‚Äôau moins un outil d‚ÄôETL/ELT (Informatica, datastage, etc.)
Ma√Ætrise des technologies de traitement distribu√© de donn√©es (spark, scala, Hadoop)
Ma√Ætrise d‚Äôau moins un framework de streaming de donn√©es (Kafka, RabbitMQ, etc.)
Ma√Ætrise de chaines CI/CD et de des bonnes pratiques de DataOps
Ma√Ætrise de solution de Vitrtualisation de donn√©es (Denodo, Dremio, etc.)
M√©thodologie Agile Scrum
Anglais professionnel
Vous √™tes attir√©(e) par le monde du num√©rique, le Cloud (maitrise d'un environnement public ou priv√© est un plus) et des technologies innovantes.
Vous avez un bon esprit d'analyse, √™tes curieux(se) et passionn√©(e) et vous avez le sens du travail en √©quipe.
Additional Information
Ce que nous vous proposons :
Un accord t√©l√©travail pour t√©l√©travailler jusqu'√† 2 jours par semaine selon vos missions.
Un package avantages int√©ressants : une mutuelle, un CSE, des titres restaurants, un accord d'int√©ressement, des primes vacances et cooptation.
Un accompagnement individualis√© avec un mentor.
Des opportunit√©s de carri√®res multiples : plus de 50 m√©tiers, autant de passerelles √† imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy.
.La possibilit√© de s'engager aupr√®s de notre fondation ou de notre partenaire ¬´ Vendredi ¬ª.
L'opportunit√© de rejoindre le collectif Tech'Me UP (formations, conf√©rences, veille, et bien plus encore).
Employeur inclusif et engag√©, notre soci√©t√© ≈ìuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C‚Äôest pourquoi, attach√©s √† la mixit√© et √† la diversit√©, nous encourageons toutes les candidatures et tous les profils.
https://www.soprasteria.fr/nous-connaitre/nos-engagements
Show more
Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['50'], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,"Data Engineer (Python/Spark/Hadoop)-Aix-en-Provence F/H - Syst√®me, r√©seaux, donn√©es (H/F)",scient,"Aix-en-Provence, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-python-spark-hadoop-aix-en-provence-f-h-syst%C3%A8me-r%C3%A9seaux-donn%C3%A9es-h-f-at-scient-3904578388?position=6&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=J%2B0%2BLvS4df0oncADPyQXRg%3D%3D&trk=public_jobs_jserp-result_search-card,"Cette offre d‚Äôemploi est fournie par P√¥le emploi
Description
Descriptif du poste: Votre travail quotidien consistera √† : * Concevoir des mod√®les efficaces pour stocker et analyser des t√©raoctets de donn√©es. * Mettre en ≈ìuvre des flux d'acquisition et de transformation complexes * Construire des mod√®les de donn√©es intelligents pour servir nos √©quipes produits et nos √©quipes BI, Insights et data science tout en minimisant les co√ªts. * D√©velopper des outils pour aider nos data scientists √† industrialiser les projets d'apprentissage automatique. * Travailler sur la qualit√© et la fiabilit√© des donn√©es pour garantir que nous fournissons des mesures fiables √† l'ensemble de l'entreprise. * D√©velopper des outils pour aider nos scientifiques √† industrialiser les projets d'apprentissage automatique. * D√©velopper notre plateforme de science des donn√©es * Industrialiser les projets d'apprentissage automatique avec les scientifiques sp√©cialis√©s dans les donn√©es. Les enjeux * Data powerBI sur un data center -> doit √™tre migr√© dans 1 autre serveur * Travailler sur une infra hadoop / migration de MariaDB √† techno GPAS. * Aujourd'hui re√ßoit des flux de fichiers avec un ETL et met dans sa base MariaDB. L'environnement va √™tre remplac√© en plus du changement de serveur. L'ETL fait dans MariaDB va devoir √™tre recr√©√© dans GPAS Profil recherch√©: Votre profil : * Avec un minimum de 3 ans d'exp√©rience, vous avez une parfaite connaissance des Data Engineering, des technologies et vous ma√Ætrisez python (id√©alement avec plusieurs autres langages backend et vous connaissez bien les meilleures pratiques de d√©veloppement logiciel, telles que CI/CD, tests unitaires, QA et cr√©ation de mocks...). * Excellent esprit d'√©quipe et √† l'aise pour interagir avec les parties prenantes techniques et commerciales. * Habitu√© √† travailler dans un environnement agile et √† accepter les changements de priorit√©s. * Curieux, humble et faisant preuve d'un √©quilibre entre cr√©ativit√© et pragmatisme. * Grande volont√© d'apprendre et d'enseigner aux autres * Ma√Ætrise de l'anglais (√©crit et parl√©) Comp√©tences techniques : * Ma√Ætrise de Python, Scala, Spark et PostgreSQL * Maitrise Pyspark, Hive et Hadoop * Vous √™tes curieux, autonome, rigoureux et proactif, vous souhaitez rejoindre une √©quipe passionn√©e d'informatique, d'IA et d'innovations et que vous ma√Ætrisez les comp√©tences n√©cessaires.
PROFIL SOUHAIT√â
Exp√©rience
Exp√©rience exig√©e de 1 An(s)
Source: Pole emploi (https://www.pole-emploi.fr)
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['CI/CD'], 'FrSoftSkills': ['Cr√©ativit√©'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer,Pictarine,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-at-pictarine-3911913926?position=7&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=U7AF5ggHYB4XAUH2FvxmZQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Mission and challenges üéØ
Si tu es enthousiaste √† embarquer dans la nouvelle √©quipe data de Pictarine pour la faire rayonner avec tout ton savoir-faire, alors c‚Äôest l‚Äôaventure qu‚Äôil te faut! üèîÔ∏è
Avec plus de 1K tables, 2M de clients et 4M de commandes en 2022, les √©quipes de Pictarine ne sont jamais √† court d‚Äôid√©es pour explorer de nouveaux horizons. üöÄ
En tant que Data Engineer chez Pictarine tu vas pouvoir utiliser toutes tes comp√©tences SQL pour garantir la qualit√© de la data sur GCP, accompagner et challenger les besoins data.
Tu √©volueras au sein de l‚Äô√©quipe Engineering, compos√©e des p√¥les dev & data.
Ton r√¥le comprendra les aspects suivants üëáüèª
Tu es garant de la qualit√© de la data !
En simplifiant la structure de la data et r√©duisant le nombre de tables
En transformant les donn√©es pour les rendre facilement utilisables
En orchestrant le flux des donn√©es de mani√®re continue et automatique
Tu accompagnes et challenges les √©quipes de Pictarine !
En co-construisant des solutions data appropri√©es
En √©levant le niveau de jeu des m√©thodes data existantes
En faisant rayonner la data autour de bonnes pratiques et d‚Äôoutillages ad√©quates
Profil Recherch√©
About you üíé
Tu as au moins 5 ans d‚Äôexp√©rience sur un poste similaire
Tu ma√Ætrises le data warehouse BigQuery et son langage SQL
Tu es √† l'aise avec les services GCP
Tu as de bonnes connaissances dans la conception de mod√®les de donn√©es et les strat√©gies d'optimisation des requ√™tes SQL
Tu as des comp√©tences en DevOps pour le d√©ploiement et la gestion efficace des pipelines de donn√©es
Tu as une bonne ma√Ætrise de Python & Github
Tu es organis√©, rigoureux et portes une grande attention aux d√©tails
Tu es dot√© d‚Äôexcellentes qualit√©s relationnelles, de communication et de vulgarisation
Tu as une passion pour r√©soudre des probl√®mes business avec la programmation
Tu es curieux de tester des nouvelles technologies
Tu es un team player et toujours √† l'aff√ªt de nouvelles id√©es
Work @ Pictarine‚ú®
Un environnement de travail agile, collaboratif, international et multiculturel
Des perspectives d‚Äô√©volution rapides
Des locaux tout beaux √† Lab√®ge avec du mat√©riel dernier cri (mais aussi des snacks √† profusion et un frigo √† boissons toujours bien rempli)
Un apprentissage permanent : conf√©rence, meet-up, Pictarine Academy, cours d‚Äôanglais.
Des events tous les mois : massage, pilates, TGIF, team building .
Un environnement de travail flexible : horaires, politique de remote hybride.
Un package de r√©mun√©ration attractif : salaire comp√©titif, RTT, mutuelle & pr√©voyance 100% prise en charge, int√©ressement.
Des petits + : D√©veloppement de photos gratuit, subvention sport, 3 jours ‚Äúentraide familiale‚Äù, jours de cong√©s en plus avec l'anciennet√©... ü§´ on ne te d√©voile pas tout !
Recruitment process ‚öôÔ∏è
Tu souhaites nous rejoindre ? Viens rencontrer les gens avec qui tu vas bosser :
1er √©change pour apprendre √† se conna√Ætre avec Marie - Engineering Manager Data (15‚Äô)
Entretien Manager avec Marie (60-90‚Äô)
Test pratique afin de nous montrer tes talents üôÇ (3 heures)
Entretien final avec 2 membres du Codir (90‚Äô)
Welcome aboard !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Hybride', 'Remote'], 'TypeContract': [], 'Salary': ['100', '100'], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,D√©veloppeur Big Data - Spark,NEXTON,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/d%C3%A9veloppeur-big-data-spark-at-nexton-3911787310?position=8&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=gspnV%2B2uQbImXFxdlEEzMQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Mission (fiche m√©tier)
NEXTON recrute un
D√©veloppeur Big Data - Spark
, en CDI, √†
Lyon
!
Qui sommes-nous ?
NEXTON c‚Äôest avant tout une entreprise qui accompagne ses clients dans leur transformation digitale. Tous les jours, nous travaillons avec des grands comptes et des pures players (SNCF, Orange, BNP PARIBAS‚Ä¶).
Nous sommes experts du digital aussi bien sur de l‚Äôaccompagnement strat√©gique qu‚Äôop√©rationnel.
Fort du succ√®s, Nexton conna√Æt aujourd‚Äôhui un d√©veloppement significatif, autour de ses valeurs piliers : coh√©sion, confiance et performance.
Et pour toi ? Notre politique de d√©veloppement des comp√©tences dynamique saura te s√©duire avec un programme de suivi de carri√®re sur-mesure.
Le contexte :
Pour l'un de nos clients, dans le secteur de l'√©nergie, nous sommes √† la recherche d'un d√©veloppeur Big Data.
Les missions :
Apporter une expertise
Big Data
pour faciliter la manipulation des donn√©es.
D√©finir les solutions techniques permettant le traitement massif des donn√©es.
Mettre en place des
solutions de stockage de donn√©es
(SQL, NoSQL etc.)
Veiller la s√©curisation et la clart√© des pipelines de donn√©es pour faciliter
l'analyse
et la
transformation
.
Assurer la cr√©ation, la maintenance, l'optimisation et la s√©curit√© des bases de donn√©es.
Assurer le support aux √©quipes de
d√©veloppement
afin d'identifier et proposer des solutions performantes.
Profil (fiche m√©tier)
De formation sup√©rieure, tu justifies d'une exp√©rience d'au moins
4 ans
dans le domaine.
Tu maitrises
Spark
,
Python
et
SQL
.
Tu es
autonome
,
rigoureux
et
force de proposition
.
De plus, tu as acquis une
capacit√© d'analyse
et de
synth√®se
gr√¢ce √† tes diff√©rentes exp√©rience.
Tu maitrises √©galement les fondamentaux de
l'agilit√©
.
Enfin, ton
esprit d'√©quipe
te permet de communiquer et de travailler dans les meilleures conditions.
NEXTON c‚Äôest aussi et surtout de nombreux moments de rencontres tout au long de l‚Äôann√©e :
- Des communaut√©s : 2 Meet Up par mois pour partager et √©changer avec des experts
- De nombreux moments de rencontres professionnels et extra professionnels tout au long de l‚Äôann√©e
- Des moments privil√©gi√©s avec ton manager
Pr√™ts √† nous rejoindre ? Rencontrons-nous !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': ['Orange'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data Engineer Talend / Spark / Scala / MSBI,Sibylone,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-talend-spark-scala-msbi-at-sibylone-3918822674?position=9&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=GQ2byteWKyn3cPr%2FE6GnrA%3D%3D&trk=public_jobs_jserp-result_search-card,"SIBYLONE
, soci√©t√© de conseil sp√©cialis√©e dans les syst√®mes d‚Äôinformation de synth√®se et de pilotage, aide ses clients √† tirer toute la valeur de leur patrimoine de donn√©es, levier strat√©gique majeur de d√©veloppement et de rentabilit√©.
Notre ambition : rendre les diff√©rents acteurs de l‚Äôentreprise autonomes dans l‚Äôexploitation des donn√©es, lib√©rer les usages M√©tier, pour qu‚Äôils soient en mesure de relever les d√©fis de performance, de couverture de risque, de financement, de conqu√™te client, de RSE‚Ä¶ qui s‚Äôimposent √† eux.
Sp√©cialistes reconnus, nos consultants s‚Äôappuient pour cela sur une connaissance approfondie de l‚Äôactivit√© business de nos clients, en lien avec nos trois piliers que sont le M√©tier, la Data et le Projet.
SIBYLONE emploie 250 salari√©s et r√©alise un CA de 30m‚Ç¨ dans la prestation de services aupr√®s de grandes entreprises (8 grands comptes repr√©sentant 80% du CA). SIBYLONE est une filiale du Groupe Smart 4 Engineering cr√©√© en 2020. Le groupe s‚Äôest constitu√© en proc√©dant √† l‚Äôacquisition de 12 soci√©t√©s en France, en Italie, en Espagne et au Portugal dans le domaine de l‚Äôing√©nierie. Avec nos 3,000 ing√©nieurs / consultants hautement qualifi√©s, le Groupe offre ses services dans les domaines tr√®s porteurs du Digital, de la Data, de l‚ÄôIntelligence Artificielle, de la Cybers√©curit√©, du Cloud.
Nous recherchons pour l‚Äôun de nos clients du domaine bancaire :
Un.e Data Engineer
Le Data Engineer int√©grera une √©quipe projet Big Data dont l‚Äôobjectif premier est de conduire des projets ayant traits √† des probl√©matiques d‚Äôarchitecture et de conception.
Le Data Engineer sera en charge de la maintenance, du support et de l‚Äô√©volution d‚Äôun outil de pilotage financier d√©ploy√© au sein des directions centrales du groupe et de la facturation interne. Il participera notamment √† la conception, la construction, le d√©ploiement et le maintien en production d‚Äôarchitectures Big Data, ces derni√®res ayant pour objectif de permettre tant l‚Äô√©volution que l‚Äôoptimisation du syst√®me d‚Äôinformation d√©cisionnel existant.
Missions
Analyser, comprendre et cadrer une architecture permettant de r√©pondre aux besoins m√©tiers des clients
Concevoir et mettre en place des plateformes Data en tenant compte des contraintes tant techniques que fonctionnelles
Intervenir sur la conception et le d√©ploiement d‚Äôenvironnements
D√©veloppement de pipelines d‚Äôingestion et de pr√©paration
Gestion du stockage de donn√©es (syst√®mes de fichiers comme HDFS, bases SQL ou NoSQL)
Alimentation d‚Äôentrep√¥ts de donn√©es (Hive, Impala, Hbase, Snowflake, BigQuery, ‚Ä¶)
D√©velopper des applications d‚Äôexploration et de manipulation de donn√©es (SPARK / pySpark, Scala) afin d‚Äôalimenter les flux sortants, les reporting et d‚Äôexposer les donn√©es
Evoluer sur l‚Äôordonnancement des traitements de donn√©es (Oozie, Bash / Shell)
Assurer le maintien en conditions op√©rationnelles des plateformes produites
Etablir, formaliser, et promouvoir les best practices
Pourquoi pas vous ?
Profil recherch√© :
De formation sup√©rieure ing√©nieur en Informatique, vous justifiez d‚Äôune premi√®re exp√©rience r√©ussie en data engineering acquise dans un contexte projet au sein d‚Äôune start-up, d‚Äôun pure player, ou d‚Äôune ESN.
Vous disposez d‚Äôune bonne maitrise des langages propres aux environnements Big Data tels que :
Hadoop
Talend (Data Integration, Big Data)
Les solutions Cloud (Azure, AWS, GPC)
Spark, Scala, Python, Unix, SQL
Microsoft Power BI
Une connaissance de : Docker, ELK, Kubernetes, Cassandra, Kafka, ‚Ä¶ serait un plus, de m√™me que des fondamentaux DevOps (CI / CD).
Vous avez d√©j√† √©volu√© dans un contexte projet agile ou scrum et faites preuve de flexibilit√©, d‚Äôadaptabilit√© et savez √™tre force de proposition.
Au-del√† de vos comp√©tences techniques, vous √™tes curieux, autonome, organis√©, dot√© d‚Äôun bon sens relationnel et d‚Äôun esprit de synth√®se.
Vous vous reconnaissez dans la description du poste ?
Vous souhaitez travailler dans un environnement stimulant et dynamique ?
Vous souhaitez rejoindre une soci√©t√© ambitieuse ?
Vous souhaitez comprendre l‚Äôorigine de Sibylone ?
Venez-nous rencontrer :
La Team Talent Acquisition sera ravie d'√©changer avec vous !
Ce poste est ouvert aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Bash'], 'DataBase': ['SQL', 'NoSQL', 'Cassandra', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud', 'CI / CD'], 'FrSoftSkills': ['Adaptabilit√©', 'Flexibilit√©'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer H/F,Amiltone,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-amiltone-3846492584?position=10&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=nJmMAJWbmBew3htigNQ6mA%3D%3D&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ?
Nous sommes passionn√©s par les nouvelles technologies, et vous ?
Rejoindre Amiltone, c‚Äôest int√©grer des √©quipes dynamiques et soud√©es dans le cadre de projets novateurs et ambitieux. Nous relevons les challenges techniques de nos clients et les accompagnons dans leur transformation digitale.
Pourquoi choisir Amiltone‚ÄØ?
Amiltone, plus qu‚Äôune entreprise, un √©tat d‚Äôesprit !
Notre objectif ? Votre √©panouissement professionnel !
Nous Avons √† C≈ìur De
Vous accompagner au mieux au travers d‚Äôun suivi personnalis√©
Vous faire monter en comp√©tences en vous proposant des formations tout au long de votre carri√®re
Comprendre vos besoins et respecter nos engagements
Vous proposer des missions de qualit√© avec des technologies innovantes
Cultiver votre potentiel gr√¢ce √† notre programme de d√©veloppement personnel Addvise
Votre bien-√™tre passe aussi par des activit√©s extraprofessionnelles, c‚Äôest pourquoi nous vous proposons des s√©ances sportives anim√©es par nos coachs, soir√©es pour se retrouver et animations (√† l'agence ou en visio), Gaming nights‚Ä¶
Les Missions D'un Amiltonien
En tant que Data Engineer
(H/F)
, vous serez en charge des missions suivantes :
‚Äì Concevoir et d√©velopper les futures fonctionnalit√©s de la plateforme Big Data sous Google Cloud Platform.
‚Äì Concevoir les flux d'alimentation et les tables (structure de donn√©e).
‚Äì Automatiser et industrialiser les flux.
‚Äì Assurer le run applicatif, le cas √©ch√©ant.
La Stack Technique
Ma√Ætrise des langages suivants : SQL, Talend, BigQuery
Connaissances de Google (GCP)
Notion de programmation fonctionnelle
Le Profil D‚Äôun Amiltonien
Dipl√¥m√© Bac+4/5 (Ecole d'ing√©nieur/Master), vous disposez de 2 ann√©es d'exp√©rience dans le d√©veloppement de data.
Toujours sur le qui-vive des nouveaut√©s technologiques, vous √™tes force de proposition sur des technos, des outils ou des process qui permettent d'am√©liorer la qualit√© du code et la stabilit√© de nos applications.
Outre vos comp√©tences techniques, nous nous int√©ressons √©galement √† votre potentiel et votre motivation.
Nos postes sont ouverts aux personnes en situation de handicap.
Postuler
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
