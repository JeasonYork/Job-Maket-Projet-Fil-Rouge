title,company,location,link,description,skills,details
DATA ENGINEER (H/F),SFR,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-sfr-3879318123?position=2&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=02j4YeDzqfcHedAZ%2BJWgJw%3D%3D&trk=public_jobs_jserp-result_search-card,"En tant que Data Ing√©nieur exp√©riment√©, vous occuperez un r√¥le essentiel dans notre √©quipe Data Science.
Vous serez responsable de la conception, du d√©veloppement et de la maintenance des pipelines de donn√©es ainsi que de l'int√©gration de sources de donn√©es multiples.
Votre expertise sera cruciale pour garantir une gestion efficace des flux de donn√©es, ainsi que pour faciliter l'analyse et la visualisation des donn√©es en plus du support aux data scientists vos missions seront les suivantes :
Architecture projet des donn√©es
: Concevoir et d√©velopper des architectures projet de donn√©es robustes, √©volutives et performantes pour int√©grer et g√©rer de grandes quantit√©s de donn√©es provenant de sources multiples. Assurer la fiabilit√©, l'√©volutivit√© et la s√©curit√© des flux de donn√©es entrant d‚Äôun projet Data Science.
Int√©gration des donn√©es
: √âlaborer des pipelines de donn√©es efficaces pour l'extraction, la transformation et le chargement des donn√©es (via notre Framework ELT/ETL interne) provenant de diff√©rentes sources. Mettre en place des processus d'int√©gration automatis√©s et veiller √† la qualit√© des donn√©es.
Gestion des bases de donn√©es
: Concevoir et optimiser des bases de donn√©es pour r√©pondre aux besoins analytiques et de reporting. Assurer la performance, la disponibilit√© et la s√©curit√© des bases de donn√©es, ainsi que la gestion efficace des requ√™tes.
Collaboration interfonctionnelle
: Support des Data Scientists, vous travaillerez avec les √©quipes business pour comprendre leurs besoins et fournir des conseils et des recommandations bas√©s sur les donn√©es.
Optimisation des performances
: Surveiller et optimiser les performances des pipelines de donn√©es, des bases de donn√©es et des requ√™tes. Identifier les goulots d'√©tranglement et les points d'optimisation, et proposer des am√©liorations pour garantir des performances optimales.
S√©curit√© et conformit√©
: Veiller √† ce que les donn√©es soient trait√©es et stock√©es conform√©ment aux normes de s√©curit√© et de confidentialit√©. Mettre en place des m√©canismes de s√©curit√© pour prot√©ger les donn√©es sensibles et garantir la conformit√© aux r√©glementations en vigueur.
Votre profil :
Vous avez un
Dipl√¥me universitaire en informatique, en g√©nie logiciel, en science des donn√©es ou dans un domaine connexe et vous avez √† minima 5 ans d'exp√©rience en tant que Data Ing√©nieur.
Vous poss√©dez √©galement une solide ma√Ætrise des technologies et des outils suivants :
Hadoop, Spark, SQL, Kafka, GCP BigQuery,
De plus vous avez une bonne compr√©hension des architectures, des mod√®les et des concepts de base de donn√©s avec une exp√©rience avanc√©e dans la mise en ≈ìuvre de pipelines ETL et dans la gestion de bases de donn√©es.
Vos connaissances en mati√®re de s√©curit√© des donn√©es, de conformit√© aux r√©glementations ainsi que vos comp√©tences en programmation scripting et en d√©veloppement logiciel seront un plus.
Vos excellentes comp√©tences en communication seront des qualit√©s appr√©ci√©es et
un niveau d'anglais (appliqu√©e au domaine technique) est un plus.
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Engineer - Lille,Capgemini,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-lille-at-capgemini-3914228495?position=3&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=1bNEMjrDx4lwdAM9LaPuxQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Capgemini en quelques mots
Choisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations, o√π vous serez soutenu et inspir√© par une communaut√© d‚Äôexperts dans le monde entier, o√π vous pourrez r√©√©crire votre futur. Rejoignez-nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la valeur de la technologie pour les plus grandes organisations et participez √† la construction d‚Äôun monde plus durable et inclusif.
Vos missions
Vous maitrisez au minimum un langage de programmation appliqu√© √† l‚Äôanalyse de donn√©es
(Java, Python, Scala et les environnements Spark et / ou Hadoop).
Vous √™tes passionn√© par le Big Data et le Machine Learning et l‚Äôanalyse de donn√©es
Vous concevez et mettez en ≈ìuvre des strat√©gies s√©curis√©es d'acquisition et d'int√©gration de donn√©es
Vous configurez des r√©f√©rentiels de donn√©es √† la pointe de la technologie dans des environnements distribu√©s
Vous construisez des pipelines de donn√©es pour collecter, transformer et traiter des donn√©es en collaboration avec des scientifiques de donn√©es afin de r√©pondre aux exigences de la mod√©lisation de donn√©es d'analyse avanc√©e
Votre profil
Dipl√¥m√©(e) de Bac+5 en informatique
4 ans d‚Äôexp√©rience
(au sein d‚Äôune ESN ou chez un int√©grateur) en conseil client√®le
Une solide culture technologique
Un bon niveau d‚Äôanglais
3 raisons de nous rejoindre
Qualit√© de vie au travail :
accord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√©
professionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.
Apprentissage en continu :
certifications et formations en libre acc√®s, accompagnement sur mesure avec
votre carreer manager, parcours d‚Äôint√©gration sur 9 mois.
Avantages groupe & CSE :
plan actionnariat, activit√©s √† tarifs pr√©f√©rentiels, remboursement partiel
vacances, remboursement de votre abonnement sportif ou culturel
Nos engagements et priorit√©s
Le groupe Capgemini encourage une
culture inclusive dans un cadre multiculturel et handi-accueillant.
En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des
initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.
Capgemini
est un
leader mondial
, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de
55 ans d‚Äôexp√©rience,
nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le
cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning', 'Cloud'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Data Engineer (F/H),Thales,"V√©lizy-Villacoublay, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-thales-3908228180?position=4&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=p249HvSiTp4FSVBFlTAldQ%3D%3D&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?
Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr√©sents sur tous les continents. Le Groupe investit dans les innovations du num√©rique et de la ¬´ deep tech ¬ª ‚Äì big data, intelligence artificielle, connectivit√©, cybers√©curit√© et quantique ‚Äì pour construire un avenir de confiance, essentiel au d√©veloppement de nos soci√©t√©s, en pla√ßant l‚Äôhumain au c≈ìur des d√©cisions.
Thales propose des solutions, services et produits qui aident ses clients ‚Äì entreprises, organisations, Etats ‚Äì dans cinq grands march√©s vitaux pour le fonctionnement de nos soci√©t√©s : identit√© et s√©curit√© num√©riques, d√©fense, a√©ronautique, espace, et transport.
QUI ETES-VOUS ?
Dipl√¥m√© d‚Äôun Bac+5 en √©cole d‚Äôing√©nieur ou √©quivalent universitaire avec une sp√©cialisation en informatique, vous avez au moins 3 ans d'exp√©rience dans les technologies Big Data.
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
En tant que Data Engineer, vous jouerez un r√¥le cl√© dans la conception, le d√©veloppement et la maintenance de notre infrastructure de donn√©es, ainsi que dans la transformation et la gestion des flux de donn√©es.
VOS MISSIONS :
‚Ä¢ Concevoir, d√©velopper et d√©ployer des solutions Big Data en utilisant les technologies Hadoop.
‚Ä¢ Mettre en place des pipelines de donn√©es performants pour l'ingestion, le traitement et le stockage des donn√©es massives.
‚Ä¢ Collaborer √©troitement avec les √©quipes m√©tier pour comprendre leurs besoins en mati√®re d'analyse de donn√©es et proposer des solutions adapt√©es.
‚Ä¢ Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn√©es.
‚Ä¢ Assurer la qualit√© et la fiabilit√© des donn√©es trait√©es, en mettant en place des processus de validation et de nettoyage.
‚Ä¢ Identifier et r√©soudre les probl√®mes li√©s √† l'infrastructure Big Data et proposer des am√©liorations.
‚Ä¢ Travailler en √©troite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents √† partir des donn√©es.
Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Solutions Engineer (Data & AI),LVMH,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-solutions-engineer-data-ai-at-lvmh-3900392289?position=5&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=eaNM3PFCRsmq1V%2BoOCrajg%3D%3D&trk=public_jobs_jserp-result_search-card,"LVMH is the #1 Luxury group and is currently accelerating rapidly on digitalisation. It is bringing technology and innovation in the core of the established 75+ Maisons by inventing unique and powerful products and services.
We are looking for talented solution engineers (Software, Cloud, Data and AI) to join our team and be part of this tech revolution of bringing the Group and its Maisons to the next level.
If you believe Data and AI can enhance the retail industry, from the day-to-day operational tasks to the long term customer experience,
If you think that the Cloud technologies (we love Google Cloud) is a revolution for Data and AI products,
If you like building tech solutions having direct impacts on billion-dollar-valued businesses,
If you have good communication skills and like sharing your knowledge,
Apply now, and join us!
The mission
The Solution Engineer is providing advices and technical assets to the Maisons having Data & AI projects.
Our team (Group Data team) is building a technical framework for all the Maisons to implement easily and quickly Data and AI use cases. Your mission will be to support the Maisons to convert their use case needs to concrete and production ready technical solutions using our framework and tools.
You will cover a portfolio of Maisons, in direct contact with their business analysts, data scientists and IT teams. You will be their dedicated referent on the Data & AI technical topics (Data platform, AI/ML softwares, data transport and transformations, data quality).
Main responsibilities
You will be responsible of providing support and advices to a portfolio of Maisons on Data & AI tech topics (Cloud, Data stacks, Data transformations, Data transfers, ML ops).
You will keep a recurrent discussion with the Maisons to accelerate their projects and immediately provide our support when it's needed.
You will follow-up the engaged productions in the Maisons and report them to the global group data strategy committees.
Applying the quality and security standards. Making them evolve if necessary.
Producing realistic, understandable and documented solutions following the group guidelines.
Sharing and learning from the team by communicating difficulties and successes, taking and bringing honest feedbacks and improving the identified pain points.
Taking responsibility as member of the team on the product performances (delivery and long term usage)
Required expertise and knowledge
Ability to build technical solutions answering concrete usage (User Stories) and communicate them to the team.
Dimension and evaluate complexity for technical solution productions.
Extensive knowledge and experience with good learning and sharing abilities.
Evaluate quickly risks and opportunities about technical choices.
Solid oral, written, presentation and interpersonal communication and relationship skills.
Problem-solving skills on Data and AI, coding and software development
Tech lover
Feedback taker and giver
Team player
Key benefits to join our team
Attractive packages
Offices in the 8th arrondissement near the Champs Elys√©es
Flexibility on the working hours
Remote work possible (~40%)
7 weeks of holidays (cong√©s pay√©s + RTT)
LVMH brands exclusive private sales
Great employee committee and health insurance (CE, mutuelle)
Last generation MacBooks
Part of a young, motivated and tech savvy team. Get prepared for the Thursday drinks and the tech meet-ups!
You‚Äôre eligible if
You have a strong experience (3+ years) in cloud data architecting or consultancy.
You graduated from an engineering (or equivalent) with a master‚Äôs degree. Computer Science knowledge is mandatory.
Experience on data stacks and/or Google Cloud (built in components) is a huge plus.
French and English both written and oral (Maisons are all over the world)
You‚Äôre thrilled to support the #1 luxury group to get even better.
Hiring Process
Call with our HR partner dedicated to the Tech Team
Technical interview with the Solution Engineering Manager
Technical test
Interview with the Head of Engineering
Still here? Apply now!!
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['ML', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication', 'Flexibility']}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': ['40'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer ‚Äì Grenoble,Capgemini,"Grenoble, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-grenoble-at-capgemini-3905836212?position=6&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=RnAhVxcz3cUG9tZh23ItbQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Choisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations. Avec le soutien et l'inspiration d'une communaut√© d‚Äôexperts dans le monde entier, vous pourrez r√©√©crire votre futur. Rejoignez-nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la valeur de la technologie pour les plus grandes organisations et participer √† la construction d‚Äôun monde plus durable et inclusif.
Vos missions :
En tant que Data Engineer au sein d'une √©quipe multidisciplinaire, vos responsabilit√©s principales seront les suivantes :
Intervenir sur les diff√©rentes phases d'un projet dans un environnement Cloud et Agile.
Contribuer √† la gestion de la qualit√© des donn√©es et extraction et analyse de celle-ci, ainsi qu‚Äô√† la pr√©sentation des donn√©es dans leur forme raffin√©e.
Proposer des nouvelles lectures de donn√©es via un travail de fouille sur les gisements d‚Äôinformation, notamment client.
Adopter une posture de consultant : proposer de nouvelles solutions et accompagner le client dans ses choix.
Votre profil :
Titulaire d'un Bac+5 en √©cole d‚Äôing√©nieur ou en universit√©.
Connaissances approfondies des ETL (Talend, Informatica ou SSIS), du traitement de donn√©es (Spark, Python, Scala) ainsi que des bases de donn√©es (Oracle, SQL Server, Postgres).
Facult√© pour se montrer curieux, autonome et proactif dans la r√©alisation de ses t√¢ches.
Capacit√© √† faire preuve de rigueur et √† travailler en √©quipe.
Bon niveau d‚Äôanglais (B2 minimum).
3 raisons de nous rejoindre :
Qualit√© de vie au travail
: accord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√© professionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.
Apprentissage en continu
: certifications et formations en libre acc√®s, accompagnement sur mesure avec votre career manager, parcours d‚Äôint√©gration sur 9 mois.
Avantages groupe & CSE
: plan actionnariat, tarif pr√©f√©rentiels, remboursement partiel vacances, remboursement de votre abonnement sportif ou culturel.
Nos engagements et priorit√©s
:
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.
√Ä propos de Capgemini :
Capgemini est un leader mondial, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d‚Äôexp√©rience, nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Oracle', 'SQL Server'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '55', '55', '55']}"
Data Engineer H/F,Thales,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-thales-3903089036?position=7&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=w99zOK4aMb4C6eulo3aUbA%3D%3D&trk=public_jobs_jserp-result_search-card,"üì¢ Nous recherchons un(e) Data Engineer, bas√©(e) √† Lyon
üëâQuelques mots sur les activit√©s num√©riques de Thales Lyon :
Les activit√©s num√©riques repr√©sentent une entit√© rattach√©e au groupe Thales, sp√©cialis√©e dans l‚ÄôIT et pr√©sente au national.
L‚Äôagence de Lyon adresse divers sujets d‚Äôexpertise : ing√©nierie logiciels, cybers√©curit√©, infog√©rance des infrastructures et transformation digitale.
üéØ
Votre r√¥le et missions
En nous rejoignant, vous int√©grerez le centre de comp√©tences
Augmented data
,
sp√©cialis√© dans la conception, le d√©veloppement et l‚Äô√©volution d‚Äôapplications data centr√©es. Vous y boosterez votre carri√®re en travaillant sur des technologies telles que
Spark, Elasticsearch, Kube ...
le plus souvent dans un environnement
Agile
.
Dans le cadre des projets que nous op√©rons aujourd‚Äôhui :
- Vous contribuerez √† la conception, au maintien, √† la scalabilit√© des plateformes d‚Äôanalyse de donn√©es au travers de votre expertise sur les sujets data (base de donn√©es, gestion de flux, ETL ‚Ä¶)
- Vous contribuerez √† la conception et √† la mise en production des pipelines d‚Äôanalyses et de transformations de donn√©es en veillant √† leur bonne adaptation aux besoins m√©tiers et aux contraintes techniques du client
- Vous pourrez intervenir sur des sujets de visualisations, dans le but de notamment accompagn√©es nos clients sur la conception de Dashboard m√©tier intelligent ‚Ä¶
- Vous serez √©galement amen√©es √† √©changer directement avec des DevOps/Datascientist pour la mise en place, l‚Äôint√©gration des pipelines et l‚Äô√©laboration des algorithmes de traitements de donn√©es.
- A l‚Äô√©chelle du d√©partement, Vous serez un acteur majeur du d√©veloppement de notre activit√© et du lancement de nouveaux projets de valorisation de donn√©es.
üôã‚Äç‚ôÄÔ∏è üôã‚Äç‚ôÇÔ∏è
Votre profil
De formation Bac +5 en informatique (√©cole d‚Äôing√©nieur, Master ou √©quivalent), vous justifiez d‚Äôune premi√®re exp√©rience r√©ussie sur un projet data ? Vous souhaitez participer √† la conception et intervenir sur des solutions de r√©cup√©ration et d‚Äôexploitation de donn√©es m√©tiers dans des contextes critiques et hautement s√©curis√©s ?
Autonome, dynamique, organis√©(e) et proactif(ve), vous souhaitez √©voluer au sein d‚Äô√©quipes passionn√©es par l‚Äôexploration et l‚Äôint√©gration des technologies nouvelles au service des m√©tiers de nos clients ?
Vous avez des comp√©tences qui couvrent les domaines suivants :
Mise en place et gestion de base de donn√©es (SQL, Elasticsearch, Clickhouse ...)
Langages de programmations (Java, Python)
Gestion de flux (Kafka, flink, logstash ‚Ä¶)
Environnements big Data (Spark/hadoop )
Principes et outils de type ETL
Vous √™tes de plus int√©ress√©(e):
Par les environnements containeris√©s (docker, kubernetes, helm ...)
Les concepts DevOps (Ansible, CI/CD...)
Les sujets de Datavisualisation (Vega, Kibana, python librairies...)
Vous aimez travailler en √©quipe ? Vous √™tes reconnu(e) pour vos qualit√©s relationnelles et vos capacit√©s de vulgarisation ?
Alors notre poste d‚ÄôIng√©nieur(e) Data(H/F) est fait pour vous !
üôå
Votre carri√®re chez Thales
Diff√©rentes opportunit√©s vous permettront de d√©couvrir d'autres domaines ou sites. Vous pourrez √©voluer et d√©velopper vos comp√©tences dans diff√©rents domaines.
Explorez un espace attentif au d√©veloppement personnel.
D√©veloppez vos talents dans un autre domaine du groupe Thales, en d√©couvrant de nouveaux produits, de nouveaux clients, un nouveau pays ou en vous orientant vers une solution plus complexe.
Choisissez entre une expertise technique ou un parcours de leadership.
Vous travaillerez dans une entreprise r√©solument humaine avec des valeurs fortes comme la s√©curit√© au travail, l‚Äô√©galit√© Homme/Femme et l‚Äô√©quilibre vie personnelle/professionnelle (Accord T√©l√©travail).
Rattach√©(e) √† la Convention m√©tallurgie, vous b√©n√©ficierez aussi de ses multiples avantages (‚Ä¶)
Vous souhaitez en savoir plus ?
N‚Äôh√©sitez pas √† contacter notre √©quipe de recrutement ou nos √©quipes directement.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'CI/CD'], 'FrSoftSkills': ['Leadership'], 'EnSoftSkils': ['Leadership']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer - Nantes,Capgemini,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-nantes-at-capgemini-3803998213?position=8&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=qE%2Ffs1Bymeu3P2TnbkpBiA%3D%3D&trk=public_jobs_jserp-result_search-card,"Capgemini
Choisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations, o√π vous serez soutenu et inspir√© par une communaut√© d‚Äôexperts dans le monde entier, o√π vous pourrez r√©√©crire votre futur. Rejoignez-nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la valeur de la technologie pour les plus grandes organisations et participez √† la construction d‚Äôun monde plus durable et inclusif.
Vos missions :
Int√©gr√©(e) au sein d'une √©quipe projets intervenant pour des clients dans des secteurs d'activit√©s vari√©es, vous serez notamment en charge des missions suivantes :
Concevoir et mettre en oeuvre des strat√©gies s√©curis√©es d'acquisition et d'int√©gration de donn√©es,
Configurer des r√©f√©rentiels de donn√©es √† la pointe de la technologie dans des environnements distribu√©s, majoritairement dans le cloud (Google Cloud Platform, Azure Databricks, AWS) et/ou en environnement Hadoop (distribution MapR, Cloudera, Hortonworks),
Construire des pipelines de donn√©es pour collecter, transformer et traiter des donn√©es en collaboration avec des scientifiques de donn√©es afin de r√©pondre aux exigences de la mod√©lisation de donn√©es d'analyse avanc√©e.
Votre profil :
Dipl√¥me d‚Äôing√©nieur ou √©quivalent universitaire
Minimum 3 ans d'exp√©rience
Anglais courant
Ma√Ætrise des langages Java, Scala ou Python et expertise sur les framework Spark et/ou Hadoop.
Expertise sur les services Cloud Data Platform suivants : Azure Data Lake, Azure synapse, Azure Data Factory, Azure Data Explorer, GCP, AWS, Snowflake, Databricks‚Ä¶
3 raisons de nous rejoindre :
Qualit√© de vie au travail : accord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√©
professionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.
Apprentissage en continu : certifications et formations en libre acc√®s, accompagnement sur mesure avec votre carreer manager, parcours d‚Äôint√©gration sur 9 mois.
Avantages groupe & CSE : plan actionnariat, activit√©s √† tarifs pr√©f√©rentiels, remboursement partiel
vacances, remboursement de votre abonnement sportif ou culturel.
Nos engagements et priorit√©s :
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.
Capgemini
Capgemini est un leader mondial, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d‚Äôexp√©rience, nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer (H/F),Technology & Strategy,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-technology-strategy-3881556102?position=9&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=MKZjIJGEG0En6bgmZVJg5g%3D%3D&trk=public_jobs_jserp-result_search-card,"D√©couvrez Novencia
:
Expert en Data et Intelligence Artificielle, nous aidons nos clients √† exploiter et √† valoriser leurs donn√©es sous toutes ses formes en les accompagnant sur des projets de Data Analyse, Data Gourvernance, Data Architecture, Data Science, et Data Engineering‚Ä¶
Vous avez une solide exp√©rience de minimum 2 ans dans l'ing√©nierie des donn√©es et vous √™tes √† la recherche de nouveaux d√©fis ? Bouclez votre ceinture, la suite est pour vous !
Type de contrat : CDI
Lieu : Lyon
En qualit√© de Data Engineer (H/F), votre r√¥le sera :
Concevoir et proposer les solutions de d√©veloppement r√©pondant aux besoins fonctionnels et techniques des projets big data.
Tu participes √† la conception de solutions permettant le traitement de volumes importants de pipelines donn√©es.
R√©aliser ces solutions par l‚Äô√©criture de code, en respectant les m√©thodes et proc√©dures qualit√©s d√©finies au sein du d√©partement Technique.
Mise √† disposition s√©curis√© et lisible de la data.
S‚Äôassurer de la conformit√© fonctionnelle et technique de ces r√©alisations en effectuant les tests automatis√©s n√©cessaire et la mise en place de monitoring (syst√®me et qualit√©).
Assurer la maintenance des applicatifs / plateforme data science
Assurer une veille technologique
Vous disposez des comp√©tences suivantes :
Maitrise des plateformes Cloud (AWS, GCP ou Azure), de Scala et de SQL.
Un.e touche √† tout : poss√©dant des comp√©tences en langage Python/Spark, de bonnes capacit√©s de mod√©lisation, une forte app√©tence pour le Big Data
Fin.e connaisseur.euse : Data Engineer convaincu, tr√®s peu de secrets pour les clusters et pour les calculs parall√®les
Explorateur.trice : d√©couvre de nouvelles technos gr√¢ce √† une veille r√©guli√®re
D√©brouillard.e : rel√®ve de nouveaux d√©fis
Notre objectif commun est de co-construire votre carri√®re en fonction de vos aspirations et de vos comp√©tences.
Contactez-moi en message priv√© ou par mail √† s.ziki@technologyandstrategy.com !
Let's make it possible #together
*Nos postes sont ouverts aux personnes b√©n√©ficiant d‚Äôune Reconnaissance de la Qualit√© de Travailleur Handicap√© (RQTH). T&S Groupe encourage la diversit√© et l‚Äô√©galit√© sur le lieu de travail. Tous les candidats qualifi√©s H/F/* sont pris en consid√©ration pour un emploi sur un m√™me pied d'√©galit√©.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Data Engineer,digiRocks recrute ‚úÖ,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-digirocks-recrute-%E2%9C%85-3903481080?position=10&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=M%2Bh%2FZxqWFn8O59EgZBx1GA%3D%3D&trk=public_jobs_jserp-result_search-card,"üòé Envie d'accompagner des organisations dans leurs strat√©gies, Fan de data?
Rejoins un jeune cabinet de conseil en strat√©gie sp√©cialis√© en data. Le cabinet a √©t√© cr√©√© il y a 4 ans pas des anciens de grands cabinets de conseil en strat√©gie qui ne se reconnaissaient plus dans ce qu'est devenu le ""consulting"". Cependant ils n'ont pas perdu espoir de pouvoir apporter du conseil √† haute valeur ajout√©e dans une ambiance friendly, fa√ßon start-up, sans sacrifier l'excellence.
Jean-Patrick recrute un(e) Consultant Data Engineer √† Paris en CDI
‚úÖ MISSION :
Vous serez responsable de la mise en ≈ìuvre de bout en bout de la pile de donn√©es, de la collecte au reporting, avec un accent sur l'infrastructure et les processus techniques. Vous travaillerez avec des Consultants en Strat√©gie & Data et les soutiendrez dans la r√©solution des d√©fis li√©s aux donn√©es de leurs clients. Vous contribuerez √† la d√©finition des strat√©gies de donn√©es, √† la mise en ≈ìuvre des syst√®mes de donn√©es et vous soutiendrez l'exploitation des donn√©es dans des projets transformationnels. En g√©n√©ral, vous serez responsable de comprendre intimement les probl√®mes, de concevoir une strat√©gie technique pour les adresser et de faciliter une ex√©cution technique de haute qualit√©.
‚úÖ R√âSULTATS ATTENDUS :
üöÄ R√©sultat 1: Unificateur de Donn√©es : Architecturer, assembler, assimiler, nettoyer et conformer de grands ensembles de donn√©es complexes pour livrer des insights commerciaux et alimenter les exp√©riences de produits de donn√©es.
üöÄ R√©sultat 2: Agent de S√©curit√© des Donn√©es : Concevoir et construire une infrastructure de donn√©es fiable et √©volutive avec les techniques de confidentialit√© et de s√©curit√© de pointe pour prot√©ger les donn√©es.
üöÄ R√©sultat 3: DataOps : Poss√©der la pile de donn√©es de bout en bout, y compris la collecte d'√©v√©nements, la gouvernance des donn√©es, les int√©grations de donn√©es et la mod√©lisation.
üöÄ R√©sultat 4: Gardien des Donn√©es : Assurer la coh√©rence et la qualit√© de l'environnement technique et de la structure des donn√©es √† travers des m√©triques, de la documentation, des processus, des tests de donn√©es et de la formation.
Requirements
‚úÖ PROFIL RECHERCH√â :
Dipl√¥m√© d'une Grande Ecole de Commerce ou d'ing√©nieur, avec une premi√®re exp√©rience r√©ussie comme Data Engineer, id√©alement dans un contexte similaire au Conseil,
Connaissance des services de Data Warehouses Cloud. Exp√©rience avec Google BigQuery, Snowflake, AWS Redshift/Athena, Looker, Azure SQL DWH, ou Azure Databricks est tr√®s souhaitable.
Connaissance des architectures de donn√©es relationnelles et de grandes donn√©es, de l'entreposage de donn√©es, de l'int√©gration de donn√©es, de la mod√©lisation de donn√©es, de l'optimisation de donn√©es et des techniques d'analyse de donn√©es.
Exp√©rience dans la construction de pipelines de donn√©es de bout en bout en utilisant des plateformes de donn√©es sur site ou bas√©es sur le cloud.
Exp√©rience pratique dans la livraison de solutions comprenant des bases de donn√©es, SQL avanc√© et d√©veloppement logiciel dans des langues telles que Python.
Int√©ress√© et connaissant les technologies Big Data et les technologies de l'√©cosyst√®me Apache telles que Beam, Spark, Kafka, Airflow, bases de donn√©es, int√©gration, gestion des donn√©es de r√©f√©rence, assurance qualit√©, manipulation de donn√©es et technologies de gouvernance des donn√©es.
Exp√©rience avec les plateformes cloud publiques et l'infrastructure cloud qui est essentielle.
Expos√© aux outils ETL/ELT et de gouvernance.
Int√©ress√© par les technologies et principes IA et ML.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Big Data Engineer - Spark & Python - F/H,Orange Business,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-spark-python-f-h-at-orange-business-3916552415?position=11&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=dierIvCJx0KVOvKwp%2FTLFA%3D%3D&trk=public_jobs_jserp-result_search-card,"Et si Business & Decision et Orange Business conjuguaient leurs forces pour devenir l‚Äôun des leaders europ√©ens de la Data transformation ?
Nous l‚Äôavons fait ! Notre alchimie nous positionne comme un
acteur unique
intervenant sur toutes les √©tapes du
voyage de la donn√©e.
Depuis 30 ans, Business & Decision, entit√© de Digital Services s'est impos√©e comme un partenaire strat√©gique pour la transformation Data de nombreux clients, dans des secteurs tr√®s vari√©s. Digital Services est aujourd‚Äôhui l‚Äô
ESN d‚ÄôOrange Business
alliant les expertises historiques Cloud et Digital d‚ÄôOrange ainsi que le c≈ìur de m√©tier Data/IA de Business & Decision. Son but est d‚Äôaccompagner les entreprises et les acteurs publics dans leur transformation gr√¢ce aux 4000 experts pr√©sents dans plusieurs grandes villes fran√ßaises comme Montpellier, Niort, Lyon, Bordeaux, Lille et Toulouse ‚Ä¶
Description du poste
Orange Business, recherche pour son site de Lille, son futur Ing√©nieur Big Data pour rejoindre sa team Data.
Votre quotidien ?
En int√©grant Orange Business, vous pouvez participer √† une grande diversit√© d‚Äôactivit√©s dans la Data. En voici un aper√ßu :
Au d√©marrage du projet :
Recueillir et analyser les besoins du client
R√©diger les sp√©cifications fonctionnelles et techniques
Estimer les charges
Pendant la phase de r√©alisation :
Mod√©liser des datawarehouses et datamart
D√©velopper les proc√©dures d‚Äôalimentation (ETL)
D√©veloppement SPARK
en batch et streaming
D√©velopper les visualisations de donn√©es (DataViz)
R√©aliser la recette et les tests
Suivre et mettre en production
En fonction de votre √©volution et de nos enjeux, vous pouvez aussi √©voluer sur des missions transverses (conseil, coaching, avant-vente, formation, audit, etc.). La prise d‚Äôinitiative est toujours la bienvenue !
Qualifications
Vous poss√©dez 5 ans d'exp√©rience ou plus dans la mise en ≈ìuvre de projets d√©cisionnels.
Vous avez de solides comp√©tences
Spark
(job, scripting, d√©ploiement) ainsi que sur
Python.
Avoir des connaissances Kafka sera un plus √©galement.
Envie d‚Äôapprendre de nouvelles technos ? Vous souhaitez partager vos comp√©tences et b√©n√©ficier des expertises de la Team Orange Business ?
Outre l‚Äôaspect technique, c‚Äôest une personnalit√© qui est recherch√©e !
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': ['Orange'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '30', '30', '30']}"
Data Engineer H/F,Chantelle,"Cachan, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-chantelle-3909775663?position=12&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=dYJ3VWvHoYOq3%2Bgog2FcIg%3D%3D&trk=public_jobs_jserp-result_search-card,"La Direction des Syst√®mes d'Information et du Digital du groupe Chantelle recherche son/sa futur.e Data Engineer H/F, pour le lancement du grand chantier de r√©novation de l'architecture Data : la bascule de l'int√©gralit√© de son Data Warehouse vers Google Big Query.
Nous souhaitons recruter un Data Engineer H/F confirm√©.e, charg√©.e de contribuer √† la d√©finition de la feuille de route de la Chantelle Data Plaform. En tant que Data Engineer vous travaillerez au sein de l'√©quipe Data Int√©gration en charge de la Chantelle Data Platform.
Vos Missions :
- Mettre en ≈ìuvre une infrastructure autour de Google Cloud Platform permettant de collecter (airbyte, API, ...) , transformer (dataform, Bigquery ...), exposer (dataviz, API, applications, ...) et historiser les donn√©es g√©n√©r√©es par l'entreprise.
- Travailler en √©troite proximit√© avec les responsables des diff√©rents domaines fonctionnels (R√©f√©rentiels, Supply Chain, Manufacturing, B2B, Retail & e-commerce, Finance, ...), avec notre √©quipe de Data Analysts ainsi qu'avec l'√©quipe technique en charge des infrastructures transverses
- √ätre force de proposition sur tous les sujets d'architecture et de mod√©lisation (choix de mise en place de pipeline temps r√©els ou au contraire de flux de donn√©es en mode batch, ou bien encore stockage sur Big Query / Big Table en fonction des cas d'usage).
- D√©finir les √©l√©ments structurants, en justifiant vos choix, et les mettre en ≈ìuvre.
- Rationaliser et moderniser notre architecture d'int√©gration inter-applicative; se projeter sur la cr√©ation d'un mod√®le de donn√©es de type Datamesh.
- Faire la refonte de la BI de nombreux use cases tels que le pilotage de nos stocks, personnalisation de nos sites e-commerce en temps r√©el en fonction de nos profils client, etc‚Ä¶
Stack technique : Google Cloud Platform, BigQuery, DataForm, DataFlow, PubSub, Airbyte, Github ...
Bonne ma√Ætrise des langages Python et SQL
Pourquoi travailler chez Chantelle ?
Une flexibilit√© dans votre lieu de travail, selon la politique de t√©l√©travail de l'entreprise.
11 jours de RTT/an ainsi qu'un 13√®me mois.
Une culture d'entreprise familiale bas√©e sur des valeurs de respect, de cr√©ativit√©, de durabilit√© et de transparence
Une aventure dans laquelle vous pourrez vous √©panouir, apprendre et entreprendre, avec une grande vari√©t√© de missions et beaucoup d'autonomie
Des √©quipes ressources humaines et des managers √† votre √©coute pour vous accompagner dans votre parcours professionnel
Des r√©ductions sur nos produits et des ventes au personnel
Des avantages dans votre qualit√© de vie au travail : une conciergerie compl√®te proposant un large panel de services, des activit√©s en interne, un CSE.
Vous souhaitez rejoindre un Groupe familial, innovant, engag√© et leader dans son secteur en France comme √† l'international et vous souhaitez apporter votre expertise et authenticit√© pour guider votre √©quipe vers le succ√®s : postulez et rejoignez le Groupe Chantelle !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery', 'Big Query'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Cr√©ativit√©', 'Flexibilit√©'], 'EnSoftSkils': []}","{'JobDetail': ['Confirm√©'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer - Mod√©lisation SQL - F/H,Orange Business,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-mod%C3%A9lisation-sql-f-h-at-orange-business-3916551577?position=13&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=7BVihBcm8eV8DMPwgcInOw%3D%3D&trk=public_jobs_jserp-result_search-card,"Et si Business & Decision et Orange Business conjuguaient leurs forces pour devenir l‚Äôun des leaders europ√©ens de la Data transformation ?
Nous l‚Äôavons fait ! Notre alchimie nous positionne comme un acteur unique intervenant sur toutes les √©tapes du voyage de la donn√©e.
Depuis 30 ans, Business & Decision, entit√© de Digital Services s'est impos√©e comme un partenaire strat√©gique pour la transformation Data de nombreux clients, dans des secteurs tr√®s vari√©s. Digital Services est aujourd‚Äôhui l‚ÄôESN d‚ÄôOrange Business alliant les expertises historiques Cloud et Digital d‚ÄôOrange ainsi que le c≈ìur de m√©tier Data/IA de Business & Decision. Son but est d‚Äôaccompagner les entreprises et les acteurs publics dans leur transformation gr√¢ce aux 4000 experts pr√©sents dans plusieurs grandes villes fran√ßaises comme Montpellier, Niort, Lyon, Bordeaux, Lille et Toulouse ‚Ä¶
Description du poste
Orange Business, recherche pour son site de Lille, son futur Data Engineer pour rejoindre sa team Data.
Votre quotidien ?
En int√©grant Orange Business, vous pouvez participer √† une grande diversit√© d‚Äôactivit√©s dans la Data. En voici un aper√ßu :
Au d√©marrage du projet :
Recueillir et analyser les besoins du client
R√©diger les sp√©cifications fonctionnelles et techniques
Estimer les charges
Pendant la phase de r√©alisation :
Mod√©liser des datawarehouses et datamart (int√©gration de flux et consolidation des donn√©es)
D√©velopper les proc√©dures d‚Äôalimentation (ETL)
D√©velopper en SQL / PLSQL / Shell
Garantir la qualit√© des donn√©es et leur disponibilit√©
R√©aliser la recette et les tests
Suivre et mettre en production
En fonction de votre √©volution et de nos enjeux, vous pouvez aussi √©voluer sur des missions transverses (conseil, coaching, avant-vente, formation, audit, etc.). La prise d‚Äôinitiative est toujours la bienvenue !
Qualifications
Vous poss√©dez 5 ans d'exp√©rience ou plus dans la mise en ≈ìuvre de projets d√©cisionnels et en mod√©lisation.
Vous avez de s
olides comp√©tences en d√©veloppement SQL
(job, scripting, d√©ploiement) ainsi que sur Python.
Envie d‚Äôapprendre de nouvelles technos ? Vous souhaitez partager vos comp√©tences et b√©n√©ficier des expertises de la Team Orange Business ?
Outre l‚Äôaspect technique, c‚Äôest une personnalit√© qui est recherch√©e !
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Orange'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '30', '30', '30']}"
Data Engineer ‚Äì SQL & GCP - F/H,Orange Business,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-sql-gcp-f-h-at-orange-business-3916557264?position=14&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=jq%2FJhC7d%2Fp5ECg%2Fs%2FlXO0g%3D%3D&trk=public_jobs_jserp-result_search-card,"Et si Business & Decision et Orange Business conjuguaient leurs forces pour devenir l‚Äôun des leaders europ√©ens de la Data transformation ?
Nous l‚Äôavons fait ! Notre alchimie nous positionne comme un acteur unique intervenant sur toutes les √©tapes du voyage de la donn√©e.
Depuis 30 ans, Business & Decision, entit√© de Digital Services s'est impos√©e comme un partenaire strat√©gique pour la transformation Data de nombreux clients, dans des secteurs tr√®s vari√©s. Digital Services est aujourd‚Äôhui l‚ÄôESN d‚ÄôOrange Business alliant les expertises historiques Cloud et Digital d‚ÄôOrange ainsi que le c≈ìur de m√©tier Data/IA de Business & Decision. Son but est d‚Äôaccompagner les entreprises et les acteurs publics dans leur transformation gr√¢ce aux 4000 experts pr√©sents dans plusieurs grandes villes fran√ßaises comme Montpellier, Niort, Lyon, Bordeaux, Lille et Toulouse ‚Ä¶
Description du poste
Orange Business, recherche pour son site de Lille, son futur Data Engineer pour rejoindre sa team Data.
Votre quotidien ?
En int√©grant Orange Business, vous pouvez participer √† une grande diversit√© d‚Äôactivit√©s dans la Data. En voici un aper√ßu :
Au d√©marrage du projet :
Recueillir et analyser les besoins du client
R√©diger les sp√©cifications fonctionnelles et techniques
Estimre les charges
Pendant la phase de r√©alisation :
Mod√©liser des datawarehouses et datamart (int√©gration de flux et consolidation des donn√©es)
D√©velopper les proc√©dures d‚Äôalimentation (ETL)
D√©velopper en SQL
/ PLSQL / Shell
Garantir la qualit√© des donn√©es et leur disponibilit√©
Concevoir et d√©velopper des solutions frontend BI √† des fins analytics & dashboarding
R√©aliser la recette et les tests
Suivre et mettre en production
En fonction de votre √©volution et de nos enjeux, vous pouvez aussi √©voluer sur des missions transverses (conseil, coaching, avant-vente, formation, audit, etc.). La prise d‚Äôinitiative est toujours la bienvenue !
Qualifications
Vous poss√©dez 3 ans d'exp√©rience ou plus dans la mise en ≈ìuvre de projets d√©cisionnels et ing√©nierie ou analyse data.
Vous avez de
solides comp√©tences en d√©veloppement SQL
(job, scripting, d√©ploiement), vous avez l‚Äôhabitude de travailler dans un
environnement Google Cloud Plateform
ainsi qu‚Äôavec
Power BI
.
Envie d‚Äôapprendre de nouvelles technos ? Vous souhaitez partager vos comp√©tences et b√©n√©ficier des expertises de la Team Orange Business ?
Outre l‚Äôaspect technique, c‚Äôest une personnalit√© qui est recherch√©e !
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Orange'], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '30', '30', '30']}"
Data Engineer,eXalt Value,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-exalt-value-3897767649?position=15&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=i%2Fl3myI%2Bj%2FSf1j4kvKCgug%3D%3D&trk=public_jobs_jserp-result_search-card,"eXalt
est un cabinet de conseil IT
Pure player Data
& IA bas√© √† Paris.
Notre offre s‚Äôarticule autour de 4 piliers r√©unis au sein d‚Äôune m√™me communaut√© pour un accompagnement √† 360¬∞ alliant une expertise technique et m√©thodologique √† une approche conseil m√©tier:
Data Gouvernance & Project
Data Engineering & Big Data
Data Performance & Analytics
Data Science & IA
Filiale du groupe eXalt, cr√©√© en 2018,
regroupant plus de
950 collaborateurs en France
(Paris, Lyon, Bordeaux, Lille, Nantes, Marseille)
et √† l‚Äôinternational
(Colombie, Etats-Unis, Espagne, Belgique),
eXalt Value
apporte une
expertise approfondie
dans le domaine de la Data & IA et conseille les entreprises dans le d√©ploiement de leurs strat√©gies data-driven.
B√©n√©ficiant du support du groupe eXalt
(1er dans la cat√©gorie Conseil & Audit au classement des Champions de la Croissance 2024), eXalt Value
est en pleine croissance et regroupe aujourd‚Äôhui une communaut√© d‚Äôexpertise de plus de 60 collaborateurs en r√©gion parisienne.
Nos consultants interviennent sur d
es projets d‚Äôenvergure
dans divers secteurs d‚Äôactivit√©,
Banque & Assurance, M√©dias, Transports, Retail, Tourisme, etc.
Nous recherchons un
Data Engineer Confirm√© H/F (minimum 4 ans d'exp√©rience dans la fonction)
pour rejoindre notre communaut√© sur le
pilier Data Engineering & Big Data.
Vos missions:
Concevoir et d√©velopper des pipelines et des flux de donn√©es.
Int√©grer et transformer des donn√©es provenant de diff√©rentes sources.
D√©velopper et mettre en ≈ìuvre des algorithmes de traitement de donn√©es avanc√©s.
Collaborer √©troitement avec les √©quipes clients pour comprendre leurs besoins et fournir des solutions adapt√©es.
Assurer la qualit√© et la fiabilit√© des solutions d√©velopp√©es.
Conseiller les √©quipes clients sur les solutions √† mettre en place.
Les Pr√©requis :
Titulaire d'un Bac+5, Ecole d'Ing√©nieur
Ma√Ætrise d'un ou plusieurs langages de programmation (
Python, Scala, Spark, etc
.).
Exp√©rience approfondie des technologies
Big Data (Hadoop, Spark, Kafka, Talend, etc.)
Exp√©rience av√©r√©e
en
environnement Cloud (AWS, GCP, ou Azure)
.
Solides comp√©tences en conception et en optimisation de pipelines de donn√©es.
Exp√©rience de travail en
m√©thode Agile
Capacit√© √† travailler de mani√®re autonome et en √©quipe.
Excellentes comp√©tences en communication et en r√©solution de probl√®mes.
Ma√Ætrise de l‚Äôanglais (oral & √©crit dans un contexte international professionnel).
Votre environnement eXalt√©:
Un environnement de travail Collaboratif
favorisant les initiatives et projets transverses √† la Practice Data & IA (Lab IA, Data Hub, etc.).
Un collectif de consultants passionn√©s,
s‚Äôint√©ressant aux tendances innovantes du secteur.
Une Practice de proximit√©,
privil√©giant la mont√©e en comp√©tence de ses collaborateurs (formations, coachings, mentorats, etc.)
Un suivi individualis√© et de proximit√©
par un.e Data Sales Manager r√©f√©rent du compte client, un.e Charg√©.e RH et un.e Practice Manager
Une √©quipe ouverte et dynamique,
qui privil√©gie les moments de partage et de convivialit√© (s√©minaires, eXaltemps, meet-up, d√©jeuners d‚Äô√©quipe, etc.)
Notre processus de recrutement :
Un entretien RH avec Estelle,
√† la suite duquel vous saurez tout (ou presque) d‚ÄôeXalt Value,
Un entretien technique avec un Manager assorti d‚Äôun test technique,
lors duquel vous aurez l‚Äôoccasion de d√©montrer vos talents mais aussi d‚Äôapprendre avant m√™me de dire oui,
Un entretien final avec la Directrice Associ√©e ou le Directeur Op√©rationnel,
pour finir de vous convaincre de nous rejoindre üòä
Nous avons h√¢te de recevoir vos CV, et de faire votre connaissance!
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Communication', 'R√©solution de probl√®mes'], 'EnSoftSkils': ['Communication', 'Initiative']}","{'JobDetail': ['Confirm√©'], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Data Engineer,EarthDaily Agro,"Balma, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-at-earthdaily-agro-3883708013?position=16&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=i4cRUHDtp5y1qiyFUBzepw%3D%3D&trk=public_jobs_jserp-result_search-card,"About Us
EarthDaily Agro provides space age data and analytics to the organizations and people who feed the planet!
With 35 years of industry experience, EarthDaily Agro provides customers with the data, analysis and knowledge they need to make more efficient and effective decisions. B2B services range from global risk management and monitoring of agricultural commodities to the marketing of inputs and precision agriculture consulting, using the latest research in agronomy, information technologies and remote sensing.
EarthDaily Agro also develops highly customized business solutions for agricultural lenders, insurers, input suppliers and food companies, with easy-to-use analytics, that help reduce the daily risks of agriculture.
EarthDaily Agro is headquartered in Minneapolis, MN, USA, with offices in France, Brazil, Australia and Switzerland and is a division of EarthDaily Analytics Corp.
EarthDaily Analytics Corp., a vertically-integrated data processing and analytics company, is launching a new constellation of earth observation satellites. The EarthDaily satellite constellation will significantly enhance geospatial analytics capabilities in agriculture, forestry, environment, financial services, and intelligence, among many other verticals.
Main Job Tasks And Responsibilities
As a EarthDailyAgro Data Engineer, your primary responsibility will be to design, develop, and manage data pipelines and infrastructure specialized for geospatial and remote sensing applications. You will work closely with data scientists, geospatial analysts, remote sensing experts, software engineers, and DevOps teams to ensure the successful deployment and scaling of data pipeline to feed geospatial data machine learning models. Your role will be crucial in optimizing the geospatial machine learning ecosystem and ensuring the seamless integration of AI-driven geospatial solutions into real-world applications.
Your Responsibilities Include
Cloud-based data pipeline Conceptualization, Development and Scaling: Build up pipeline to ingest large volumes of geospatial data, pre-process them and meet data scientists‚Äô requirements, in terms of accessibility, speed, format, quality.
Automation and CI/CD: Industrialization of pipeline deployment, orchestration, workflows, and versioning.
Cost & Speed Optimization: Collaborate with infrastructure team to develop, optimize, and fine-tune pipeline.
Cloud and Containerization: Experience with cloud platforms (e.g., AWS, Azure, GCP) and containerization tools.
Infrastructure Management: Utilize containerization technologies and cloud-based services to set up and manage infrastructure, enabling seamless deployment and scalability.
Monitoring and Anomaly Detection: Implement monitoring systems to track pipeline performance and identify anomalies.
Version Control and Data Version Control: Proficient with version control systems like Git and DVC.
Security and Compliance: Ensure the security and privacy of geospatial data, adhering to relevant data protection regulations and industry best practices.
Collaboration and Communication: Collaborate with interdisciplinary teams to integrate data pipeline into existing applications or develop new geospatial products.
Issue Resolution and Troubleshooting: Identify and resolve promptly technical issues related to geospatial data processing, performance, or infrastructure.
Education, Knowledge And Abilities
Requirements
Education: Master's degree in Computer Science, specialisation in Geomatics and/or Remote sensing would be a plus.
Experience: 3+ years experiences with data pipeline processes and deployment is a must-have. Proven hands-on experience in setting up pipelines and data processes with opensource tools (e.g., MLFlow, Argo, Kubeflow) is desirable.
Programming Skills: Proficiency in Python and with data manipulation frameworks (e.g., dataframe, numpy, pandas, xarray, rasterio) and librairies (e.g., Dask).
Problem-Solving Skills: Autonomous, and strong analytical and problem-solving abilities to address complex geospatial data and analysis challenges.
Communication Skills: Excellent communication and interpersonal skills to collaborate effectively with cross-functional teams and stakeholders.
French mandatory (job based in France). Fluent in English (oral and written):‚ÄØmeetings with internal are mostly in‚ÄØEnglish.
Preferred Additional Skills
Experience with Earth Observation (EO) data analysis and processing.
Experience with geospatial data formats (e.g., GeoTIFF, Shapefile, NetCDF).
Spatial Analysis Techniques: Understanding of spatial analysis techniques and algorithms commonly used in geospatial data manipulation.
Remote Sensing Integration: Knowledge of remote sensing data sources (e.g., STAC catalog, satellite imagery, LiDAR, SAR) integration into data pipelines for accurate and up-to-date geospatial analysis.
CONDITIONS
Full time job based in Balma, near Toulouse, France.
Fixed + Bonuses
TR / ""Family"" insurance / CSE
Powered by JazzHR
WrfSXQ5YJg
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'ML', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration', 'Organization', 'Interpersonal Skills']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (F/H),Aubay,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-aubay-3573871076?position=17&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=5udQna6j91DvsfDszC3TCA%3D%3D&trk=public_jobs_jserp-result_search-card,"Passionn√© par la Data, tu souhaites rejoindre une communaut√© d‚Äôexperts dans le domaine afin de d√©velopper tes comp√©tences en Data Engineering. Aubay renforce ses √©quipes Data et recherche des Data Engineers pour int√©grer des dispositifs de projets pointus et vari√©s.
Ton quotidien en tant que Data Engineer chez Aubay, :
D√©finition de la strat√©gie de stockage et mise en ≈ìuvre des technologie appropri√©es (base de donn√©es SQL, NoSQL, stockage distribu√©,‚Ä¶)
Ingestion des donn√©es (structur√©es, semi-structur√©es ou non-structur√©es) selon diff√©rentes fr√©quences : batch, micro-batch ou temps r√©el
Conception et mise en ≈ìuvre de pipelines de donn√©es afin de fournir des donn√©es pr√™tes √† l‚Äôemploi aux consommateurs : uniformisation, mise en qualit√©, enrichissement, calcul d‚Äôindicateurs,‚Ä¶
Conception et d√©veloppement d‚ÄôAPI pour exposer les donn√©es aupr√®s d‚Äôapplications tierces
Appui aux Data Scientists pour industrialiser et optimiser les algorithmes de Machine Learning
Pr√©paration et animation d‚Äôateliers de travail avec des interlocuteurs vari√©s : recueil/approfondissement des besoins m√©tiers, avancement/restitution des travaux, transfert de comp√©tences,‚Ä¶
Ton profil :
Tu dispose d‚Äôune formation niveau BAC+5 (Master 2 ou √©cole d‚Äôing√©nieur) sp√©cialis√©e en informatique
Tu as d√©j√† une premi√®re exp√©rience significative (a minima 2 ans) en Data Engineering sur des technologies Big Data
Les technologies telles que Hadoop, Spark ou Kafka sont tes technologies de pr√©dilection
La programmation n‚Äôa plus de secret pour toi et tu maitrise parfaitement un ou plusieurs langages de programmation suivants : Java, Scala et Python
Tu ma√Ætrises les tenants et aboutissants de la philosophie DevOps et des outils orient√©s CI/CD
Tu es soucieux de la qualit√© et de la performance de tes d√©veloppements et tu t'int√©resse √† l‚Äôinnovation frugale
Tu es un expert technique dans ton domaine sans pour autant oublier l‚Äôimportance d‚Äôune communication orale et √©crite de qualit√© et adapt√©e √† chacun de tes interlocuteurs
Tu travaille au quotidien en mode agile et tu en maitrise les fondements
Ce qui nous caract√©rise :
Des missions et projets dans le domaine du Data Engineering en nombre et dans des secteurs vari√©s (Banque, Assurance, Telecom, Industrie,‚Ä¶) qui permettent √† nos collaborateurs de monter en comp√©tences et de devenir des experts Data reconnus
De l‚Äôapprentissage en continu avec des formations et des certifications sur les technologies Data d‚Äôaujourd‚Äôhui et de demain
Des experts Data mobilisables pour accompagner et soutenir techniquement les collaborateurs sur leurs projets
Des communaut√©s de savoir-faire Data proposant de mani√®re r√©guli√®re aux collaborateurs d‚ÄôAubay du contenu et des √©v√®nements de partage (webinar, meetup/afterwork, BBL,‚Ä¶) sur les th√©matiques suivantes : Data Engineering, Data Viz, Data Science/IA, Data Platform & Architecture,‚Ä¶
Aubay encourage la diversit√© sous toutes ses formes et garantit l'√©galit√© des chances √† tous les candidats. Tous nos postes sont ouverts aux personnes en situation de handicap et nous proposons tous les am√©nagements n√©cessaires.
Ta carri√®re chez Aubay :
Tu auras la possibilit√© de d√©velopper et certifier tes comp√©tences sur les derni√®res technologies Data avec un focus fort sur les plateformes Data Cloud telles qu‚ÄôAzure Synapse Analytics, Google Cloud Platform, Snowflake et Databricks
Tu pourras rejoindre la BU d‚Äôexcellence Data et √©voluer au sein d‚Äôun environnement humain et professionnel de haut niveau. Tu profiteras d‚Äôun management sur-mesure pour t'accompagner dans ta trajectoire de carri√®re
Au sein de la BU d‚Äôexcellence, de multiples perspectives s‚Äôoffriront √† toi :
R√¥le de ¬´ Lead ¬ª : Vous pourrez gagner en responsabilit√© sur le plan technologique et devenir un r√©f√©rent aupr√®s de nos clients et des collaborateurs de la communaut√© Data Engineering
R√¥le de ¬´ Champion ¬ª : Vous repr√©senterez Aubay aupr√®s d‚Äôun ou plusieurs de nos partenaires √©diteurs strat√©giques et vous participerez activement √† l‚Äôanimation de la relation sur le plan technologique
R√¥le de ¬´ Head ¬ª : Vous pourrez prendre la responsabilit√© du savoir-faire Data Engineering et de ses offres et en assurer le d√©veloppement au sens large (d√©veloppement business, recrutement, management de collaborateurs, d√©finition de la strat√©gie et animation de la communaut√© au sein du groupe Aubay,‚Ä¶)
Besoin d‚Äôen savoir plus sur le processus de recrutement ?
Un √©change macro au niveau RH avec Doriane
Un entretien technique avec Marius ou Peter, deux de nos r√©f√©rents techniques
Un √©change manag√©rial avec le Directeur de la BU Modern BI & Data
A savoir que l‚Äôordre des √©tapes peut varier selon tes envies (ex : √©change manag√©rial avec l‚Äô√©change technique)
Aubay encourage la diversit√© sous toutes ses formes et garantit l'√©galit√© des chances √† tous les candidats. Tous nos postes sont ouverts aux personnes en situation de handicap et nous proposons tous les am√©nagements n√©cessaires.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure', 'Google Cloud Platform'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Data Engineer / D√©veloppeur Big Data # H/F,Air France,"Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-d%C3%A9veloppeur-big-data-%23-h-f-at-air-france-3900080172?position=18&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=U0cfa8nHfasz5xn9vr%2BUqw%3D%3D&trk=public_jobs_jserp-result_search-card,"Description du poste
Intitul√© du poste
Data Engineer / D√©veloppeur Big Data # H/F
M√©tier
Syst√®mes d'informations - D√©veloppement
Cat√©gorie socio-professionnelle
Cadre
Pr√©sentation du contexte
Vous avez peut-√™tre d√©j√† voyag√© avec nous, mais que connaissez-vous de nos m√©tiers et de la richesse des donn√©es qu‚Äôils g√©n√®rent au quotidien ? Comment le traitement et l‚Äôexploitation de ces donn√©es peut contribuer √† notre strat√©gie de Revenue Management, ou encore aux multiples op√©rations √† r√©aliser pour permettre √† un vol de partir √† l‚Äôheure ?
Air France-KLM fait r√™ver 104 millions de passagers par an, en les emmenant vers plus de 250 destinations, gr√¢ce √† une flotte de plus de 500 appareils. Le Groupe emploie 80 000 collaborateurs partout dans le monde :les opportunit√©s sont vastes pour mettre √† profit ses comp√©tences, apprendre et se d√©velopper !
Le d√©partement de d√©veloppement DATA, OR & AI d‚ÄôAir France, au sein de la direction des Syst√®mes d‚ÄôInformation, intervient dans toute la cha√Æne de captation et de traitement des donn√©es du groupe pour d√©livrer √† nos m√©tiers des solutions applicatives cl√©s en main.
Le d√©partement est √©galement en charge de l‚Äôensemble des outils techniques (ETL, DataLakes, DataWarehouses, Data visualisation) et du d√©veloppement des talents et comp√©tences de Data Engineering.
Notre mission ? Transformer la donn√©e brute en d√©cision intelligente, pour mieux optimiser les m√©tiers d‚ÄôAir France ‚Äì KLM !
Pour cela, nous avons chacun un r√¥le essentiel √† jouer, pourquoi le v√¥tre ne serait pas celui de Data Engineer et de d√©veloppeur Big Data ?
Description de la mission
Au sein de notre d√©partement, vous travaillerez main dans la main avec d‚Äôautres Data Engineers et d√©veloppeurs Big Data ainsi qu‚Äôavec des sp√©cialistes des m√©tiers.
Int√©gr√© au sein d‚Äôune product team agile passionn√©e et dynamique :
Vous participez √† l‚Äôanalyse des besoins m√©tiers du commercial, des op√©rations a√©riennes, de l‚Äôexploitation sol en a√©roport, de la maintenance a√©ronautique ou encore du Cargo.
Vous contribuez √† la d√©finition, au d√©veloppement, √† l‚Äôindustrialisation et √† la maintenance d‚Äôapplications Big Data ou en Business Intelligence
Vous pr√©sentez la restitution de vos travaux et accompagnez les utilisateurs d‚Äôun point de vue fonctionnel ou m√©thodologique
Vous serez en contact avec les directions m√©tier du groupe Air France KLM.
Nous attachons beaucoup d'importance au d√©veloppement des comp√©tences de nos collaborateurs ainsi qu‚Äô√† leur offrir des conditions de travail favorables √† l‚Äôautonomie et aux missions √† forte valeur ajout√©e. L'ouverture, le respect, la bienveillance et le partage sont des valeurs humaines port√©es par l'entreprise.
Profil recherch√©
Vous √™tes dipl√¥m√© de niveau Master ou Ing√©nieur dans les domaines informatiques, vous avez acquis une exp√©rience professionnelle dans le d√©veloppement d‚Äôapplications.
Vous disposez d‚Äôune exp√©rience du d√©veloppement indispensable en Backend / Java
Vous ma√Ætrisez les bases de donn√©es relationnelles et le langage SQL
En Compl√©ment, Vous Avez Une Connaissance Ou Une Exp√©rience Dans Tout Ou Partie Des Concepts Ou Outils Suivants
Environnement Big Data (Spark, Hadoop, Elasticsearch, Kafka, ...)
Base de donn√©es noSQL (MongoDB, HBase, REDIS) ou Data Warehouse Teradata
Outil de Datavisualisation (Spotfire, PowerBI, Qlik ou Kibana)
Solutions de Cloud (GCP) et hybride (GCP / AZURE)
(Ces comp√©tences compl√©mentaires ou manquantes pouvant aussi s'acqu√©rir √† travers un parcours de reskilling et de formations aux outils du data engineering dispens√© en interne).
Vous avez particip√© √† des projets organis√©s en Scrum ou Kanban, et avez peut-√™tre m√™me ≈ìuvr√© comme Scrum-Master, ce qui vous permettra de vous int√©grer ais√©ment au sein d‚Äôune Product Team. Votre esprit de synth√®se, votre force de conviction et votre ma√Ætrise de la communication facilitent les d√©cisions avec l‚Äôensemble des collaborateurs de l‚Äô√©quipe, √©ventuellement en langue anglaise, √† l‚Äô√©crit comme √† l‚Äôoral.
Vous √™tes autonome, rigoureux(se), responsable et curieux(se), vous aimez travailler en √©quipe. Vous poss√©dez de bonnes capacit√©s d'√©coute, d'analyse, de synth√®se et de communication.
Et bien s√ªr, vous √™tes passionn√©(e), enthousiaste et ing√©nieux(se)
Ce que nous vous offrons
De la cr√©ation de valeur pour l‚Äôensemble des m√©tiers d‚ÄôAir France KLM
Des challenges et probl√©matiques complexes √† r√©soudre
L‚Äôopportunit√© de d√©ployer des solutions Data industrielles √† l‚Äô√©chelle !
Une grande part de responsabilit√© dans une structure hi√©rarchique horizontale
Un important degr√© de libert√© pour apprendre et d√©velopper son expertise au sein de l‚Äô√©quipe
On vous attend le plus rapidement possible ! Et pour une dur√©e ind√©termin√©e ;)
Type de contrat
CDI
Temps partiel possible
Non
Type d'horaires
Administratif
Profil candidat
Niveau d'√©tudes min. requis
Bac + 5 et plus
Langue
Anglais (4 - Confirm√© / C1)
Localisation du poste
Localisation du poste
France, Provence-Alpes-C√¥te d'Azur, Alpes Maritimes (06)
Site
Valbonne
Show more
Show less","{'ProgLanguage': ['Java', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Hybride', 'Confirm√©'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Junior Data engineer,WA.Technology,"Crouseilles, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/junior-data-engineer-at-wa-technology-3908458326?position=19&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=EbGJHiVHkqLvwlLGyNZEhQ%3D%3D&trk=public_jobs_jserp-result_search-card,"WA.Technology
is a B2B supplier of iGaming solutions with rapidly growing clients and partnerships in emerging markets. We offer a state-of-the-art iGaming platform, turnkey solutions, and standalone products that empower operators to enter or expand into emerging markets quickly and easily.
The WA.Platform is a fully scalable and customisable solution, featuring over 75 game providers, 6,400+ games, and support for multiple currencies, along with access to over 80 payment methods. WA. Technology enables operators to build their own casino, sportsbook, lottery, fantasy, or poker business precisely as they envision it.
About The Role,
We are seeking a highly skilled and motivated
Data Engineer
to design, implement, and maintain efficient and scalable data pipelines on the Google Cloud Platform (GCP). In this role, you will be responsible for managing data from MariaDB and Kafka sources, ensuring seamless integration into BigQuery, our primary data destination. Collaboration with cross-functional teams is crucial to understanding and meeting diverse data needs.
In this role, you will need to:
Design, implement, and maintain robust data pipelines on Google Cloud Platform.
Integrate MariaDB and Kafka as primary data sources for seamless data flow into BigQuery.
Collaborate across departments to address unique data requirements aligned with organizational goals.
Utilize Dataflow and Dataform for efficient data processing and transformation.
Ensure data integrity through rigorous validation and cleansing processes.
Optimize cloud-based infrastructure for speed and scalability.
Implement monitoring tools for proactive system performance tracking and issue resolution.
Provide ongoing support for data integrity and availability.
Maintain comprehensive documentation of data architecture, updating regularly.
Stay informed about the latest data technology trends.
Evaluate and recommend new technologies/methodologies to enhance processing and analysis capabilities.
What are the key experience and personal attribute requirements?
Bachelor's degree in Computer Science, Information Technology, or a related field.
2+ Hands-on experience relational database
Proven experience in developing data pipelines and ETL processes.
Strong SQL skills.
Knowledge of data modeling and database design.
Excellent collaboration and communication skills.
Strong problem-solving and troubleshooting abilities.
Ability to work independently and as part of a team.
Continuous learner, keeping up with emerging trends in data engineering.
What are some of the benefits of working at WA Technology?
100% remote opportunity
Flexible work environment
Attractive remuneration package
Opportunity to work with well-connected industry leaders.
A leadership approach that fosters innovation, creativity, and trust.
Opportunity to experience the buzz of highly driven and motivated work colleagues.
Experience a start-up feel in a fast-paced growth-driven environment.
Show more
Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': [], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['ML', 'Cloud'], 'FrSoftSkills': ['Communication', 'Leadership', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Leadership', 'Creativity', 'Collaboration', 'Organization']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': ['Package'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (H/F),iPepperGroup,"Valbonne, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ipeppergroup-3894091360?position=20&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=MXiVBVIb6BxwB0mgaE66rg%3D%3D&trk=public_jobs_jserp-result_search-card,"iPepper recrute pour l'un de ses clients une PME √©diteur de logiciel dans le domaine du voyage, un
Data Engineer (H/F)
passionn√©(e) et exp√©riment√©(e) pour rejoindre une √©quipe dynamique.
En tant qu'Ing√©nieur(e) Data, vous serez en charge d'extraire et de transformer des donn√©es, de construire et d'optimiser des pipelines de donn√©es, ainsi que de concevoir des visualisations de donn√©es intuitives et informatives.
Responsabilit√©s :
Concevoir, construire et maintenir des pipelines de donn√©es √©volutifs et efficaces pour transf√©rer des donn√©es entre des bases de donn√©es SQL et NoSQL.
D√©velopper et mettre en ≈ìuvre des processus ETL pour extraire, transformer et charger des donn√©es √† partir de diff√©rentes sources dans notre entrep√¥t de donn√©es.
Collaborer avec des √©quipes pluridisciplinaires pour comprendre les besoins en donn√©es et garantir la fourniture r√©ussie de solutions de donn√©es.
Optimiser et ajuster les pipelines de donn√©es existants pour la performance et la fiabilit√©.
Concevoir et d√©velopper des visualisations de donn√©es et des tableaux de bord pour fournir des insights exploitables aux parties prenantes.
Surveiller et r√©soudre les probl√®mes de pipelines de donn√©es, en veillant √† la qualit√© et √† l'int√©grit√© des donn√©es.
Profil recherch√© :
Dipl√¥me universitaire en informatique, en ing√©nierie ou dans un domaine connexe.
Exp√©rience av√©r√©e en tant que Data Engineer ou dans un r√¥le similaire, avec un accent particulier sur la construction de pipelines de donn√©es et de processus ETL.
Compr√©hension solide des bases de donn√©es
SQL
et
NoSQL
, y compris la mod√©lisation des donn√©es et la conception de sch√©mas.
Ma√Ætrise des langages de programmation tels que
Python, Java ou Scala.
Exp√©rience avec des outils de visualisation de donn√©es tels que
Tableau, Power BI.
Solides comp√©tences en analyse et en r√©solution de probl√®mes, avec la capacit√© de traduire des donn√©es complexes en insights exploitables.
Excellentes comp√©tences en communication et en collaboration, avec la capacit√© de travailler efficacement dans un environnement d'√©quipe pluridisciplinaire.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication', 'R√©solution de probl√®mes', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer - Profils exp√©riment√©s H/F,LCL,"Villejuif, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-profils-exp%C3%A9riment%C3%A9s-h-f-at-lcl-3888403052?position=21&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=z4Vl6fiAzW4xQbNi93g%2B9A%3D%3D&trk=public_jobs_jserp-result_search-card,"üè¶ LCL, c‚Äôest LA banque urbaine du Groupe Cr√©dit Agricole - avec nous, accompagnez la transformation, le d√©veloppement et le maintien technologiques de nos outils avec une vision business et de satisfaction de nos 6 millions de clients.
En tant qu‚Äôacteur majeur de la banque de d√©tail, nous nous adaptons chaque jour aux nouveaux modes de consommation et les projets de nos de clients internes et externes tout en garantissant le besoin de s√©curit√© et de d√©veloppement technologique qu‚Äôimpliquent nos activit√©s.
üí°Organis√©es en mode Agile, les 8 squads de la tribu DATA (6 squads M√©tier et 2 squads transverses) ≈ìuvrent au quotidien pour r√©pondre √† un enjeu majeur pour la banque : la collecte, le stockage, la gestion et l‚Äôusage de la donn√©e. En interaction permanente avec les autres tribus IT et les m√©tiers, elles √©tudient et proposent les solutions et architectures √† d√©ployer pour r√©pondre au mieux aux strat√©gies de d√©veloppement et de pilotage de l‚Äôensemble des m√©tiers de la banque.
Rejoignez-nous si vous souhaitez participer aux r√©flexions et au d√©veloppement de la trajectoire technique et DataCentric du SI LCL et plus largement du Groupe CA. Vous c√¥toierez et serez au c≈ìur de l‚Äôimpl√©mentation de technologies vari√©es telles que les plateformes Teradata, les solutions d‚Äôarchitecture applicative des technologies BigData ou IA, des environnements analytiques ou encore des solutions de datavisualisation. Vous assurerez le traitement de donn√©es en temps r√©el ou en batch et exposerez les donn√©es sous diff√©rentes formes.
Que vous souhaitiez devenir expert sur les socles technologiques ou relever le challenge de la gestion de projets M√©tier, nous vous aiderons √† atteindre vos propres objectifs.
Vous rejoindrez une √©quipe pluridisciplinaire, clairement orient√©e vers le d√©veloppement de ses collaborateurs √† de nouvelles technologies !
üéØ En tant que Data Engineer :
¬∑ Vous aimez analyser les besoins avec les m√©tiers, challenger, identifier les sources de donn√©es dans les diff√©rents univers technologiques, industrialiser des algorithmes, concevoir et d√©velopper des Datalab ou des Datamart sur les plateformes ? Vous saurez relever les challenges propos√©s par les squads m√©tier !
¬∑ Vous pr√©f√©rez travailler √† l‚Äôarchitecture et au d√©ploiement de nouvelles plateformes, √† la lev√©e de la dette technologique ou encore r√©aliser de la veille au service de notre trajectoire ? La squad Socles Data est faite pour vous !
¬∑ Au-del√† des projets que vous g√©rerez, garant du bon fonctionnement de votre parc applicatif, vous attacherez une grande attention √† la mise en ≈ìuvre de solutions optimis√©es.
¬∑ La rigueur, la communication, l‚Äôesprit d‚Äô√©quipe mais aussi la curiosit√© et la cr√©ativit√© font partie de vos soft skills ! ils vous permettront de r√©pondre aux enjeux de s√©curit√©, de qualit√©, de transmission de la connaissance et contribueront √† l‚Äôatteinte des objectifs de l‚ÄôIT et plus largement de LCL, au service de ses clients.
üíª Voici les principales technologies utilis√©es au sein de la tribu, si certaines vous sont famili√®res, nous vous aiderons √† monter en comp√©tence sur d‚Äôautres !
Langages utilis√©s : SQL, Python, Scala
SGBD : Teradata et utilitaires (TPT, BTEQ, ‚Ä¶)
Streaming : Kafka
Search : ElasticSearch, SolR
Environnement : Unix
Solutions Big Data : Hadoop Cloudera, DataIku, HDFS, Hive, Impala,
Devops : GitLab, Jenkins, Nexus
Outils de visualisation : MS BI (SSIS, SSAS, SSRS) Qlik Sens, BO
Mod√©lisation : MEGA
Outils collaboratifs : GIT, Jira, Confluence, Teams
‚ö°Si les nouveaux enjeux bancaires vous int√©ressent, que vous souhaitez int√©grer une √©quipe Agile au service des m√©tiers dans laquelle vous serez force de proposition et que vous aimez travailler dans un environnement motivant et dynamique, rejoignez-nous, cette offre est faite pour vous !
üî• Les + de notre entreprise :
Acc√®s au Plan d‚Äô√©pargne Groupe, int√©ressement et participation aux b√©n√©fices de l‚Äôentreprise + abondement
Prix pr√©f√©rentiels bancaires et avantages CSE
Parcours √©volutif dans l‚Äôentreprise et/ou dans le Groupe CA.S.A
T√©l√©travail (jusqu'√† 2 jours de t√©l√©travail par semaine)
De multiples commodit√©s sur le campus (restaurants d'entreprise, salle de sport, cr√®che, centre m√©dical, m√©diath√®que...)
Forfait et avantages pratiques ¬´ mobilit√© durable ¬ª pour les velotafeurs
Des √©quipes aussi diversifi√©es que structur√©es dans une dynamique de transformation
LCL s‚Äôengage en faveur de la diversit√© et nous encourageons tout(e) candidat(e) ayant l‚Äôexp√©rience requise √† postuler √† nos offres. Tous nos postes sont ouverts aux personnes en situation de handicap.
Nous avons encore de nombreuses raisons √† vous pr√©senter pour vous convaincre de nous rejoindre mais pour cela, il faudra postuler ici !
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['JIRA', 'Confluence', 'Teams'], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Communication', 'Cr√©ativit√©'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,Ramify,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-at-ramify-3896146641?position=22&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=JnSrc62bk8WQOsZhoPlmmg%3D%3D&trk=public_jobs_jserp-result_search-card,"ABOUT
Ramify‚Äôs mission is to help people achieve financial freedom, no matter who they are and how much they have. We are revolutionizing the private wealth management industry by making smart and affordable financial products for everyone.
No more standardized solutions, hidden fees and complicated words, Ramify enables everyone to become a smart investor. The team combines elements of its research with technology to design customized investment portfolios composed of world-class financial products.
The team comprises around 15 talented individuals. Ramify is looking for talented people in all sectors, who want to have a huge impact, move fast and deliver.
JOB DESCRIPTION
The Quantitative Investment Solutions (QIS) Team is dedicated to designing innovative investment portfolio models and developing cutting-edge investment features within our product suite. Moreover, the QIS Team is at the forefront of driving AI-based solutions for Ramify. This involves conceptualizing and implementing transformative AI solutions tailored to meet the diverse needs of various teams within Ramify.
As a Data Engineer on our QIS Team, you will play a pivotal role in shaping the future of investment strategies through data-driven insights and AI-based solutions. Collaborating closely with our talented team of quantitative researchers, and investment experts, your responsibilities will encompass architecting and implementing robust data pipelines. These pipelines will facilitate the seamless integration of diverse data sources, empowering Ramify teams to make informed decision-making.
Key Responsibilities:
Design, build and launch data pipelines at scale to move data across Ramify platform with SQL technologies.
Design and implement processes and tools for data onboarding and quality, helping to deliver an industry best-practice solution for managing the data lifecycle.
Produce stand-alone tools that can be used by other teams to automate data quality and discover faults.
Build analytical tools that provide insight into business metrics across Ramify.
Architect and lead the implementation of AI based solutions within Ramify
PREFERRED EXPERIENCE
We're looking for people who:
Want to make a difference. We are a small team effectively reshaping how people look at the industry. We need people who 'get it' and want to play an integral part in helping us accomplish this mission and are persistent in getting the job done.
Skills we're looking for:
Master‚Äôs or upper-year undergraduate-level coursework in either Computer Science, Management Information Systems, Business Information Systems, Mathematics or Finance related field.
2+ years of professional experience in data engineering.
2+ years of experience with one or more coding languages such as Python (is a must), Java.
Experience with data modeling and ETL design, implementation and maintenance.
Demonstrable mastery of industry best practices in the data lifecycle, including data quality automation and tooling.
Excellent written and verbal communication skills with ability to communicate complex designs and solutions to non-technical and highly technical audiences alike.
Good attention to detail.
Strong analytics and strategic thinking skills
Nice-to-haves :
Understanding of ML/ Generative AI technologies and their applications.
Possess a passion, curiosity, and energy for finance + investing. You understand the ins and outs of the wealth management, trading, and more importantly - know how to explain these concepts simply
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['ML'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,Thales,"Ollioules, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-at-thales-3902424527?position=23&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=9D9Rc8Bs0%2FSs66SNI5xCGA%3D%3D&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?
Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr√©sents sur tous les continents. Le Groupe investit dans les innovations du num√©rique et de la ¬´ deep tech ¬ª ‚Äì big data, intelligence artificielle, connectivit√©, cybers√©curit√© et quantique ‚Äì pour construire un avenir de confiance, essentiel au d√©veloppement de nos soci√©t√©s, en pla√ßant l‚Äôhumain au c≈ìur des d√©cisions.
Thales propose des solutions, services et produits qui aident ses clients ‚Äì entreprises, organisations, Etats ‚Äì dans cinq grands march√©s vitaux pour le fonctionnement de nos soci√©t√©s : identit√© et s√©curit√© num√©riques, d√©fense, a√©ronautique, espace, et transport.
QUI ETES-VOUS ?
Dipl√¥m√© d‚Äôun Bac+5 en √©cole d‚Äôing√©nieur ou √©quivalent universitaire avec une sp√©cialisation en informatique, vous avez a
u moins 3 ans d'exp√©rience
dans les technologies Big Data.
Passionn√© par le
secteur de la D√©fense et du Naval.
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
En tant que
Data Engineer,
vous jouerez un r√¥le cl√© dans la conception, le d√©veloppement et la maintenance de notre infrastructure de donn√©es, ainsi que dans la transformation et la gestion des flux de donn√©es.
VOS MISSIONS :
‚Ä¢ Concevoir, d√©velopper et d√©ployer des solutions Big Data en utilisant les technologies
Hadoop, Spark, Scala
.
‚Ä¢ Mettre en place des pipelines de donn√©es performants pour l'ingestion, le traitement et le stockage des donn√©es massives.
‚Ä¢ Collaborer √©troitement avec les √©quipes m√©tier pour comprendre leurs besoins en mati√®re d'analyse de donn√©es et proposer des solutions adapt√©es.
‚Ä¢ Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn√©es.
‚Ä¢ Assurer la qualit√© et la fiabilit√© des donn√©es trait√©es, en mettant en place des processus de validation et de nettoyage.
‚Ä¢ Identifier et r√©soudre les probl√®mes li√©s √† l'infrastructure Big Data et proposer des am√©liorations.
Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.
Show more
Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer H/F,Inetum,"St.-Ouen, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-inetum-3843966639?position=24&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=Q%2Bk6aPwFl6DvxvKp76rWTA%3D%3D&trk=public_jobs_jserp-result_search-card,"D√©tail de l'offre
Informations g√©n√©rales
Entit√© de rattachement
Inetum est un leader europ√©en des services num√©riques. Pour les entreprises, les acteurs publics et la soci√©t√© dans son ensemble, les 28 000 consultants et sp√©cialistes du groupe visent chaque jour l'impact digital des solutions qui contribuent √† la performance, √† l'innovation et au bien commun.
Pr√©sent dans 19 pays au plus pr√®s des territoires, et avec ses grands partenaires √©diteurs de logiciels, Inetum r√©pond aux enjeux de la transformation digitale avec proximit√© et flexibilit√©.
Port√© par son ambition de croissance et d'industrialisation, Inetum a g√©n√©r√© en 2023 un chiffre d'affaires de 2,5 milliards d'‚Ç¨.
Pour r√©pondre √† un march√© en croissance continue depuis plus de 30ans, Inetum a fait le choix d√©lib√©r√© de se recentrer sur 4 m√©tiers afin de gagner en puissance et proposer des solutions sur mesure, adapt√©es aux besoins sp√©cifiques de ses clients le conseil (Inetum Consulting), la gestion des infrastructures et applications √† fa√ßon (Inetum Technologies), l'impl√©mentation de progiciels (Inetum Solutions) et sa propre activit√© d'√©diteur de logiciels (Inetum Software). Inetum a conclu des partenariats strat√©giques avec 4 grands √©diteurs mondiaux - Salesforce, ServiceNow, Microsoft et SAP et poursuit une strat√©gie d'acquisitions d√©di√©e afin d'entrer dans le top 5 europ√©en sur ces technologies et proposer la meilleure expertise √† ses clients.
Tous nos postes sont ouverts aux personnes en situation de handicap.
Description du poste
M√©tier
Applications Delivery - Software Development
Intitul√© du poste
Data Engineer H/F
Contrat
CDI
Description De La Mission
Le p√¥le BFA de la branche Application Services du groupe INETUM, recherche plusieurs Data Engineers afin d'intervenir aupr√®s de clients grands comptes au sein des march√©s bancaires et de l'assurance.
Au sein de l'√©quipe Data, en tant que Data Engineer, vous participez √† la r√©alisation de divers projets et vos missions sont
Apporter votre connaissance en Big Data permettant la manipulation des donn√©es
Concevoir les plateformes permettant de traiter des volumes de donn√©es importants
Mettre en place des bases de donn√©es
Pr√©parer le pipeline de donn√©es pour que les donn√©es d√©ploy√©es soient s√©curis√©es et claires afin d'√™tre analys√©es et transform√©es.
Profil
De formation ing√©nieure en informatique Bac + 5 informatique ou scientifique
Bonne communication orale et √©crite en fran√ßais et niveau d‚Äôanglais professionnel
Savoir- √™tre Bon esprit d'analyse et de synth√®se, sens de l'organisation et de la qualit√©, force de proposition, rigueur, travail en √©quipe, adaptabilit√©.
Si vous vous reconnaissez, n'h√©sitez pas √† postuler !
Localisation du poste
Localisation du poste
France
Ville
Saint-Ouen
Crit√®res candidat
Niveau d'√©tudes min. requis
Bac+5
Niveau d'exp√©rience min. requis
Plus de 2 ans
Comp√©tences
SQL
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Communication', 'Adaptabilit√©', 'Organisation', 'Flexibilit√©'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '30', '30', '30']}"
Data Engineer (F/H),Renault Digital,"Boulogne-Billancourt, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-renault-digital-3911202728?position=25&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=xQaI%2FKhtHEWrp1eIaFQ%2Bxg%3D%3D&trk=public_jobs_jserp-result_search-card,"Contexte :
Dans le cadre de son programme Industrie 4.0, Renault d√©veloppe depuis 2017 sa propre plateforme pour connecter et agr√©ger les donn√©es industrielles des 22 sites du Groupe et de plus de 2500 machines.
Fort de partenariats strat√©giques sign√©s avec Google Cloud (stack data full GCP), Renault Digital est √† la recherche d‚Äôun(e) Data Engineer au sein du P√¥le Architecture et Data pour mettre en place des cha√Ænes de traitement de donn√©es r√©pondant √† de nouveaux besoins m√©tiers.
Vous collaborerez au jour le jour avec les √©quipes m√©tiers ainsi qu‚Äôavec les autres fonctions du P√¥le Architecture & Data (Data Analysts et Scientists, architectes, ‚Ä¶), exploitant des t√©raoctets de donn√©es (√©v√©nements en mode streaming, traitements en batch et temps r√©els et les appels aux APIs) afin entre autres d‚Äôalimenter des mod√®les de machine learning (segmentation clients, d√©tection automatiquement des pannes des v√©hicules, ‚Ä¶).
Responsabilit√©s principales :
Vous participez aux phases de framing, MVP et release des produits, services et APIs orient√©s data ;
Vous argumentez les choix d‚Äôarchitecture des projets et de la plateforme datalake sur GCP ;
Vous contribuez √† la valeur m√©tier des produits orient√©s Data s‚Äôappuyant sur le Datalake, en mettant en place des cha√Ænes bout en bout de traitement de la data, de l‚Äôingestion √† l‚Äôexposition d‚ÄôAPIs et √† la visualisation des donn√©es et des solutions ML/DS ;
Vous √™tes garant de la qualit√© des donn√©es transform√©es dans le Datalake, du bon fonctionnement des cha√Ænes de traitement et de l‚Äôoptimisation de l‚Äôutilisation des ressources des ressources cloud ;
Vous proposez des standards d‚Äôarchitecture et de d√©veloppement ;
Vous √™tes force de proposition, innovant(e) et bienveillant(e).
Environement technique :
Spark, Scala, Python, Java, Airflow, SQL, Google Cloud Platform (BigQuery, Cloud Storage, PubSub, Beam, Dataflow, Cloud ML, TensorFlow, Kubernetes), Git, Docker, JSON, Bash, Spotfire
Profil recherch√© :
Vous avez minimum 5 ans d‚Äôexp√©rience en tant que Data Engineer ;
Vous disposez d‚Äôune exp√©rience en d√©veloppement Spark, Scala, Python et requ√™tage SQL sur des gros volumes de donn√©es ;
Vous avez une app√©tence pour la data : validation, transformation, analyse, valorisation ;
Vous poss√©dez une exp√©rience de d√©veloppement et orchestration de chaines ETL complexes via Airflow ou √©quivalent ;
Vous pratiquez la m√©thodologie agile (Agile Scrum et/ou Kanban) ;
Vous utilisez les services cloud (pr√©f√©rablement GCP) ;
Vous √™tes capable d‚Äô√©changer en anglais technique √©crit et oral.
Informations compl√©mentaires :
Votre poste sera bas√© √† Boulogne-Billancourt (France) en CDI (temps plein)
Vous b√©n√©ficiez de 2 √† 3 jours de t√©l√©travail par semaine
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go', 'Bash'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': ['TensorFlow'], 'DataSerialization': ['Json'], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Temps plein', 'Full'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Engineer BI - Nantes,Capgemini,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-bi-nantes-at-capgemini-3803963477?position=26&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=%2Fm%2B%2Bu0YrOQ7XM7%2FjP%2Fx0gg%3D%3D&trk=public_jobs_jserp-result_search-card,"Capgemini
Choisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations, o√π vous serez soutenu et inspir√© par une communaut√© d‚Äôexperts dans le monde entier, o√π vous pourrez r√©√©crire votre futur. Rejoignez-nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la valeur de la technologie pour les plus grandes organisations et participez √† la construction d‚Äôun monde plus durable et inclusif.
Vos missions :
Int√©gr√©(e) au sein d‚Äôune √©quipe projet BI, Big Data ou Data Gouvernance pour des clients intervenant dans des secteurs d'activit√©s divers, vous serez notamment en charge des missions suivantes :
Mener les analyses fonctionnelles destin√©es √† traduire les besoins du client,
Mener les travaux de conception et de mod√©lisation,
Diriger le d√©veloppement de la solution / des traitements d'alimentation du DataWareHouse,
Organiser et pr√©parer les travaux de recette utilisateurs,
Mettre en place les processus d'industrialisation et mener cette derni√®re.
Votre profil :
Dipl√¥me d‚Äôing√©nieur ou √©quivalent universitaire
Minimum 3 ans d'exp√©rience
Anglais courant
Comp√©tences en BI sur SAP BI (Hana, BW, BODS, BI 4), Microsoft BI (SQL Server, SSIS, SSAS, SSRS), Oracle (ODI, OBIEE), Teradata, Informatica (Powercenter), IBM (Datastage, Cognos, TM1), Talend, AB Initio
Ma√Ætrise d'un ou de plusieurs outils de Dataviz : Microsoft Power BI, Tableau, Qlikview
Connaissances en Big Data (Ecosyst√®me Hadoop (HIVE, PIG, Mahout‚Ä¶), Cloudera, Pivotal, Spark, HNX) ou en analytics (R, SAS, IBM SPSS)
3 raisons de nous rejoindre :
Qualit√© de vie au travail : accord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√©
professionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.
Apprentissage en continu : certifications et formations en libre acc√®s, accompagnement sur mesure avec votre carreer manager, parcours d‚Äôint√©gration sur 9 mois.
Avantages groupe & CSE : plan actionnariat, activit√©s √† tarifs pr√©f√©rentiels, remboursement partiel
vacances, remboursement de votre abonnement sportif ou culturel.
Nos engagements et priorit√©s :
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.
Capgemini
Capgemini est un leader mondial, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d‚Äôexp√©rience, nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les
plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Oracle', 'SQL Server'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer (H/F),Beelix,"Antibes, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-beelix-3838611420?position=27&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=ueaRofuONErN9s66mmUeUA%3D%3D&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ?
Depuis 2016, nous accompagnons nos clients sur des probl√©matiques de Product Management, Data et Design Thinking. Beelix contribue √† fa√ßonner le monde de demain en participant aux grandes avanc√©es des secteurs suivants :
üöóAutomobile
‚ö°Energie
üì°M√©dias & T√©l√©coms
üëóLuxe & Retail
üí∂ Banque, Finance & Assurance
‚úàÔ∏èD√©fense
Aujourd‚Äôhui, Beelix compte plus de 200 collaborateurs motiv√©s et dynamiques. Lab√©lis√©e Great Place To work en 2023, Beelix est aussi une entreprise engag√©e o√π il fait bon vivre.
Dans le cadre de notre d√©veloppement, nous recherchons un Data Engineer (H/F) pour l'un de nos clients.
Quelles missions au quotidien ?
√ätre le leader de la brique Datalakehouse
D√©velopper les scripts de transformations de donn√©es et les pipelines d‚Äôalimentation
Proposer des √©volutions architecturales ou de fonctionnalit√©s pour am√©liorer le socle technique
√ätre le back-up du leader technique sur la partie reporting (Power BI)
Orientation satisfaction client et r√©sultat final forte mais √©galement sensibilit√© au ¬´ comment ¬ª
Innovation et proposition de nouvelles pratiques pour am√©liorer l‚Äôenvironnement et les conditions de travail des √©quipes
A propos de vous ?
5 + ann√©es d'exp√©rience en tant que Data Engineer
Ma√Ætrise des technologies suivantes : Microsoft Azure, Microsoft Azure Synapse Analytics (Spark / Python / Pipeline / Serverless), fichiers parquet / delta, Microsoft Power BI, Microsoft SQL Server, langage SQL, Datawarehousing / Mod√©lisation de donn√©es
Analyses et export de donn√©es
Connaissance de l‚Äôensemble du processus depuis la collecte jusqu‚Äô√† la mise √† disposition des donn√©es en ayant comme point fort la maitrise de sa transformation et mise en forme
Vous avez un bon niveau d‚Äôanglais
Localisation : Biot et/ou Carros
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['SQL Server'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,Digital Waffle,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-digital-waffle-3913824888?position=28&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=IEl%2FhktPBzJjGw4t%2Fz%2BTrw%3D%3D&trk=public_jobs_jserp-result_search-card,"Digital Waffle is proud to have partnered with an innovative tech startup in Paris, who are looking for a talented Data Engineer to join their growing team!
They are made up of a powerhouse of experts, combining
data engineers, business process gurus, and Project managers
who leverage the most advanced solutions available; utilising process mining, automation tools, and smart execution systems.
Looking for an experienced Data Engineer (3-5 years)
What You'll Do:
This is a full-time,
hybrid role (Paris-based)
where you'll wear many hats: data exploration, system integration, data prep, data modeling, and implementing data solutions.
Experience:
Expertise in data engineering, data modeling, and ETL (Extract, Transform, Load) processes
Data warehousing and data analytics skills
Experience handling large, complex datasets
Proficiency in SQL and programming languages like Python or Java
Stellar problem-solving and analytical skills
Top-notch communication and collaboration abilities
Bachelor's or Master's in Computer Science, Information Systems, or a similar field (a plus for process mining or intelligent process automation experience)
If you are an experienced and driven Data Engineer, please apply here!
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': ['Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (H/F),Scalian,"Valbonne, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-scalian-3819563847?position=29&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=zbaJOj29uyfFAKD4DOxKZA%3D%3D&trk=public_jobs_jserp-result_search-card,"Ing√©nieur DATA / Data engineer (H/F)
Valbonne/Sophia-Antipolis
Type : CDI
Lieu : Locaux Scalian Sophia-Antipolis
T√©l√©travail : En fonction des possibilit√©s
Date de prise de poste : imm√©diatement ou en fonction de votre pr√©avis
Salaire : en fonction du profil - entre 40 et 48K Brut annuels (hors avantages Scalian)
Avantages Scalian : Accord d'entreprise t√©l√©travail, Tickets restaurants, Mutuelle groupe, accord am√©nagement temps de travail, compte √©pargne temps, accord de participation et int√©ressement groupe, programme cooptation et apports d'affaires, accompagnement parentalit√©, avantages CSE
Vous √™tes data engineer ou vous souhaitez le devenir !
Quel sera votre r√¥le ?
La port√©e de la mission comprend (sans toutefois s'y limiter) :
Science des donn√©es
Ing√©nierie des donn√©es
Analyse des donn√©es
G√©nie logiciel
Ce que cette exp√©rience va vous apporter
Vous √™tes autonome, vous avez le sens du service et de l‚Äôanalyse, vous √™tes impliqu√©, nous vous offrons une ouverture sur des projets complexes et une rapide √©volution de carri√®re. Vous rejoignez notre business unit √† Sophia Antipolis compos√©e d'environ 50 consultants, avec possibilit√© de t√©l√©travail en fonction des sujets.
Nous co-construisons votre trajectoire professionnelle et assurons votre mont√©e en comp√©tences.
Nous nous inscrivons ensemble dans la dur√©e, nous assurons votre mont√©e en comp√©tences et disposons d'une vari√©t√© de sujets passionnants.
Ce que nous recherchons chez vous
De formation sup√©rieure (Bac+5, √©cole ou universit√©), vous poss√©dez id√©alement une premi√®re exp√©rience r√©ussie dans ce domaine (d√©butants accept√©s), vous aimez le travail en √©quipe.
Comp√©tences requises
:
Etape d‚Äôanalyse : Comprendre l‚Äôarchitecture technique, les sources de donn√©es, les objectifs fonctionnels.
Etape de conception : Solution de conception avec un fort centrage sur les pipelines de donn√©es et les mod√®les ML et l‚Äôexposition des KPI via API
Mise en ≈ìuvre : Apr√®s les phases d‚Äôanalyse et de conception, proc√©der √† a mise en ≈ìuvre dans des technologies s√©lectionn√©es (Java,Scala,Python,Spark)
Cr√©er un code test√© et document√©
Techno : Linux, Shell, Hadoop, Scrum, Python, Spark, Scala
Pourquoi feriez-vous le grand saut ?
Parce que Scalian vous accompagne dans le d√©veloppement de votre carri√®re :
Programme d'onboarding complet sur 1 an avec votre manager et votre RH
Programme de formation (Scalian Academy, e-learning, webinaires et formations externes)
Communaut√©s techniques (Squads, Practices) afin de valoriser et d√©velopper votre expertise
√âv√©nements internes (Afterworks, Awards Dinner, Kick Off, Live Event du COMEX, Stand Up) et externes (participation √† des salons et forums sp√©cialis√©s dans nos domaines d‚Äôactivit√©s‚Ä¶)
Dispositif d‚Äôacc√©l√©ration d‚Äôacc√®s √† la mobilit√© interne et √† des √©changes internationaux type Erasmus
Parce que Scalian favorise la Qualit√© de Vie au Travail :
Certifications Great Place to Work¬Æ et Best Workplaces for Women¬Æ
Prime de cooptation, prime vacances, prise en charge par l‚Äôemployeur de 60% des titres-restaurant, Accord t√©l√©travail (jusqu‚Äô√† 2,5 jours par semaine indemnis√©s), RTT (dont une partie mon√©tisable), CSE (activit√©s ludiques, ch√®ques-cadeaux, ch√®ques vacances)
Berceaux en cr√®ches inter-entreprises
Don ou r√©ception de jours de cong√©s en cas de difficult√©s personnelles
Parce que Scalian d√©veloppe une politique RSE concr√®te et ambitieuse :
Mobilit√© durable (indemnit√© kilom√©trique v√©lo, leasing de v√©los √† assistance √©lectrique)
Actions environnementales (Fresque du Climat, Reforest'Action, Clean Up Day, m√©c√©nat ONF)
Postes ouverts aux personnes en situation de Handicap
Diverses politiques de diversit√©, d‚Äôinclusion et d‚Äôint√©gration mises en place
Scalian c‚Äôest aussi :
Une entreprise en tr√®s forte croissance qui, cr√©√©e en 1989, compte aujourd‚Äôhui plus de 5500 personnes
Des r√©f√©rences clients √† forte valeur ajout√©e aupr√®s de grands industriels fran√ßais (du CAC40) et internationaux
Un terrain de jeu o√π l‚Äôexpertise se conjugue avec audace, libert√© d‚Äôentreprendre et convivialit√©
Si vous aspirez √† un environnement de travail qui valorise autant votre bien-√™tre que votre d√©veloppement professionnel,
rejoignez-nous et exprimez pleinement votre talent !
Envie d'√©largir le cadre ?
Je suis Liza Djehel, Talent Acquisition Officer.
Si votre CV est retenu, je vous contacte pour un premier √©change t√©l√©phonique de 15 √† 20 minutes.
Nous d√©terminons ensemble si ce poste est en ad√©quation avec vos comp√©tences et surtout, avec vos attentes.
L'√©change est positif ? Nous convenons d'un entretien de 1h (en pr√©sentiel ou en visio) avec Lucas Daunar, Business Manager √† Sophia-Antipolis. Cet √©change permet de revenir en d√©tail sur vos comp√©tences, vos attentes, de vous pr√©senter le poste plus en d√©tail, et d'√©voquer d'autres opportunit√©s.
Nous pr√©voyons ensuite un rendez-vous technique de 1h (en pr√©sentiel ou en visio) avec un de nos responsable technique.
Enfin, nous vous pr√©sentons notre proposition d'embauche.
Notre processus de recrutement dure entre 15 et 30 jours
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['40'], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
Data Engineer H/F,Ippon Technologies,Greater Nantes Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ippon-technologies-3902436649?position=30&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=AsgLBKPObp783Z2tkccsfQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Envie de rejoindre la communaut√© DATA la plus dynamique de France ?
Notre sp√©cialit√© est de construire des data platform dans le Cloud public avec les meilleurs technos du moment : Snowflake, Databricks, Matillion, DBT.
Membre de la Practice Data, le/la futur(e) Data Engineer sera int√©gr√©(e) √† nos √©quipes de conseil et sera suivi(e) par un(e) mentor qui l‚Äôaidera √† monter en comp√©tences.
Votre champs d‚Äôexpertise :
Intervenir sur les data platforms de nos clients pour d√©velopper de nouveaux pipelines de donn√©es (ingestion, traitement, exposition).
Travailler en collaboration avec les m√©tiers et les data scientists pour leur fournir un support √† l‚Äôindustrialisation de leurs travaux (tests, int√©gration continue, scalabilit√© des mod√®les, craftsmanship etc‚Ä¶)
D√©ployer des infrastructures cloud full
infra-as-code
(Terraform, CloudFormation).
Participer aux √©v√®nements internes √† la communaut√© data (BBL, webinar, datap√©ro interne, meetup, blog, dojos) et externes (Salon du Big Data, GCP Summit, Spark Summit, AWS Summit, Devoxx, workshop partenaire, meetups).
Capitaliser sur les missions et les diff√©rents √©v√®nements de la communaut√© au travers d‚Äôarticles de blogs, REX, BBL interne.
Vos connaissances :
Un framework de calcul distribu√© tel que Spark, Storm, Flink.
Un ou plusieurs langages de programmation (Python, Scala, Java...)
Diff√©rents syst√®mes de stockage de donn√©es (SQL ou NoSQL) et bien s√ªr le langage SQL.
La connaissance de Snowflake est bienvenue ;-)
Un framework de streaming de donn√©es tel que Kafka ou Amazon Kinesis.
Une exp√©rience sur les technologies Cloud : AWS, GCP, Azure
Le delivery et les projets en production faisant partie de notre ADN, vous √™tes capable de livrer du code de qualit√© dans des environnements agiles.
De plus en plus de nos projets se font en remote avec des clients du monde entier, il devient n√©cessaire d‚Äô√™tre √† l‚Äôaise en Anglais.
Ippon technologies c‚Äôest aussi :
üëç B√©n√©ficier d'un suivi de proximit√© r√©alis√© par votre manager technique : points r√©guliers pour votre suivi en mission, votre formation et votre √©volution de carri√®re
‚úåÔ∏è Rejoindre une entreprise o√π les valeurs du sport sont nos leitmotiv : d√©passement de soi, travail en √©quipe, bienveillance.
üóíÔ∏è Apprendre via notre programme de formation BlackBelt : https://bit.ly/3ByqcIL
üòÅ Travailler en pair programming ou avec un.e mentor pour gravir les √©chelons !
üí™ Pouvoir participer √† une aventure humaine au sein de notre Fondation Ippon pour r√©duire la fracture num√©rique dans le monde !
ü§ù Participer √† nos ap√©ros et divers √©v√®nements internes pour consolider la coh√©sion d‚Äô√©quipe
Et apr√®s ?
Et oui alors ? Que se passe-t-il une fois que vous √™tes convaincu d‚Äôavoir lu l‚Äôoffre d‚Äôemploi qui vous correspond bien ?
Nous vous proposons de prendre contact et de nous rencontrer !
Les Next Steps :
1 call RH
1 √©change RH
1 √©change Technique
Si le match est bon des deux c√¥t√©s : Hadjim√© ! Vous vous lancerez sur le tatami Ippon !
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks', 'Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform', 'CloudFormation'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (H/F),ternair,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ternair-3915757963?position=31&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=DDZVC8nqVobqpHnmOgDD6g%3D%3D&trk=public_jobs_jserp-result_search-card,"üë®‚ÄçüöÄ MISSION : üë©‚ÄçüöÄ
En coh√©rence avec la strat√©gie d‚Äôentreprise et la roadmap data, vous aurez pour principales missions de :
En lien avec l‚Äô√©quipe DevOps, construire, maintenir et faire √©voluer la plateforme de donn√©es;
D√©finir et piloter la coh√©rence de la collecte, la gestion et l‚Äôalimentation des donn√©es internes et externes, en diff√©rents modes : batch, streaming, API (architecture micro-services);
Pr√©parer et mettre en qualit√© les donn√©es pour les rendre disponibles dans les diff√©rents environnements de travail (datalake, datawarehouse, datamart);
V√©rifier la qualit√© des donn√©es, de leur bonne et r√©guli√®re ex√©cution ainsi que de leur utilisation ad√©quate (gestion des co√ªts);
Travailler en √©troite collaboration avec les data analysts, scientists et data stewards et business de l‚Äôentreprise ;
En lien avec l‚ÄôIT et la s√©curit√©, veiller aux r√®gles d'int√©grit√© et de s√©curit√© des donn√©es;
Veille technologique.
üßÆ Les outils :
Plateforme data : Google Cloud Platform (Big Query, Airflow)
D√©veloppement : Github/GitLab, Docker, Terraform, Python
Analytiques : Qlik
Gestion de projet s: Jira, Confluence, Miro, Drive, Docs, Sheets, Slides
ü§© Profil recherch√© : ü§©
Exp√©rience d'au moins 4-5 ans (apr√®s √©tudes) en data ing√©nierie (flux, mod√©lisation, run)
A l‚Äôaise avec l‚Äôenvironnement Cloud et les infrastructures digitales
Communiquant, p√©dagogue et fortes capacit√©s relationnelles
Anglais (√† l‚Äô√©crit)
R√©mun√©ration : 42-60 k‚Ç¨ en package selon exp√©rience
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Big Query'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': ['JIRA', 'Confluence'], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['Package'], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Engineer,Shippeo,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-at-shippeo-3908268236?position=32&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=SDVf9YZXmr8b1pbHooAYoA%3D%3D&trk=public_jobs_jserp-result_search-card,"Founded in 2014, Shippeo is a French based SaaS company providing supply chain visibility. Shippeo has grown from 70 to 220 employees during the last two years and is continuing to rapidly scale after an additional $40M fundraising round in October 2022.
Shippeo is an exceptionally diverse company with colleagues from 27 different nationalities and speaking 29 languages. With offices throughout Europe, North America and recently Asia, Shippeo provides global coverage to all of our clients.
Our product is composed of a mission critical SaaS web platform (API everywhere), with high traffic inbound/outbound integrations.
Our mission is to anticipate problems and proactively alert end-customers so they can efficiently manage exceptions. We achieve this by collecting and matching millions of theoretical and real data from different stakeholders.
The Data Intelligence Tribe is responsible for leveraging Shippeo‚Äôs data from our large shipper and carrier base, to build data products that help our users (shippers and carriers alike) and ML models to provide predictive insights. This tribe‚Äôs typical responsibilities are to:
get accurately alerted in advance of any potential delays on their multimodal flows or anomalies so that they can proactively anticipate any resulting disruptions
extract the data they need, get direct access to it or analyze it directly on the platform to gain actionable insights that can help them increase their operational performance and the quality and compliance of their tracking
provide best-in-class data quality by implementing advanced cleansing & enhancement rules
As a Data Engineer at Shippeo, your objective is to ensure that data is available and exploitable by our Data Scientists and Analysts on our different data platforms. You will contribute to the construction and maintenance of Shippeo‚Äôs modern data stack that‚Äôs composed of different technology blocks:
Data Acquisition (Kafka, KafkaConnect, RabbitMQ),
Batch data transformation (Airflow, DBT),
Cloud Data Warehousing (Snowflake, BigQuery),
Stream/event data processing (Python, docker, Kubernetes) and all the underlying infrastructure that support these use cases.
Qualifications
Required:
You have a degree (MSc or equivalent) in Computer Science.
3+ years of experience as a Data Engineer.
Experience building, maintaining, testing and optimizing data pipelines and architectures
Programming skills in Python and experience with asynchronous event processing (asyncio).
Advanced working knowledge of SQL, experience working with relational databases and familiarity with a variety of databases.
Working knowledge of message queuing and stream processing.
Knowledge of Docker and Kubernetes.
Knowledge of a cloud platform (preferably GCP).
Experience working with workflow management systems such as Airflow.
Desired:
Experience with cloud based data warehouse solutions (BigQuery, Snowflake).
Experience with Kafka and KafkaConnect (Debezium).
Experience with Infrastructure as code (Terraform/Terragrunt).
Experience building and evolving CI/CD pipelines with Github Actions.
Monitoring and alerting on Grafana / Prometheus.
Experience working on Apache Nifi.
Informations suppl√©mentaires
We are looking for talents who share our values:
üöÄ Ambition
üíô Care
üéØ Deliver
ü§ù Collaboration
Find out more about our values in
Our Culture Book
If you identify with our values and enjoy working in a fast-paced and international environment, Shippeo is just the place for you!
We are committed to fostering diversity and inclusion within our workplace as we value the unique perspectives and experiences that individuals from all backgrounds bring to our team. We are dedicated to providing equal employment opportunities to all candidates, regardless of their background or abilities, and our commitment to inclusion is reflected in our policies, practices, and workplace culture.
We understand that candidates may have unique needs or questions related to disability inclusion. To facilitate this, you can reach our dedicated Disability Advisor at
inclusion@shippeo.com
with any inquiries or requests for accommodations during the application process.
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['ML', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data engineer - F / H,United Robotics Group,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-united-robotics-group-3891680780?position=33&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=BOP09wArK5oohNUn%2FG9McA%3D%3D&trk=public_jobs_jserp-result_search-card,"Bienvenue chez
Aldebaran
, leader europ√©en de la robotique
au sein du groupe
United Robotics Group
.
Nous concevons et industrialisons des robots innovants avec une vision soci√©tale ambitieuse pour fa√ßonner un monde plus humain. Depuis 2005, nous sommes √† l'avant-garde de l'interaction homme-robot avec des produits embl√©matiques tels que NAO et Pepper.
Notre dernier-n√©,
Plato
,
incarne notre engagement envers la technologie de pointe et la s√©curit√©,
fabriqu√© en France avec des composants europ√©ens.
Rejoignez nos √©quipes multiculturelles et dynamiques pour √™tre au c≈ìur de la r√©volution de la robotique.
Si vous √™tes passionn√©.e par la robotique et l'intelligence artificielle, et que vous souhaitez contribuer √† fa√ßonner l'avenir, nous vous offrons une exp√©rience enrichissante et stimulante.
En tant que membre de notre √©quipe, vous b√©n√©ficierez d'une culture d'entreprise ax√©e sur le sens de ce que nous faisons et valorisant la responsabilit√© sociale et environnementale.
Chez Aldebaran, nous valorisons l'innovation, la diversit√© et l'√©galit√© et encourageons chacun.e √† √™tre ouvert.e, authentique, courageux.se, responsable et engag√©.e.
Finalit√© du poste
Au sein de l'√©quipe Cloud-Online Services, le Data engineer int√©grera l'√©quipe Data, responsable du d√©veloppement des produits destin√©s √† la collecte, aux process et √† l'exploitation des donn√©es de nos robots.
Il aura pour r√¥le de d√©finir et d'impl√©menter des services data, sur une infrastructure Cloud AWS, supportant des services en ligne qui g√®rent les robots du groupe.
Missions principales
Le Data engineer aura pour responsabilit√©s de :
√©valuer les choix d'architecture et de solutions techniques lors de la mise en place de PoC,
concevoir et d√©velopper des services Data en respectant la sp√©cification fonctionnelle et la m√©thodologie agile,
agr√©ger et stocker de grandes quantit√©s de donn√©es,
mettre en place des solutions de data processing,
int√©grer/d√©velopper des outils de visualisation de donn√©es et analyser les KPI,
d√©velopper, tester, s√©lectionner et mettre en production des algorithmes qui permettent de r√©pondre aux besoins,
r√©aliser des analyses de donn√©es,
mettre en place des tests de charge et fonctionnels pour les solutions Data,
investiguer et corriger les bugs remont√©s par les utilisateurs,
contribuer √† la mise en place de l'infrastructure et outil de d√©ploiement (CI/CD)
Rejoignez-nous pour faire partie d'une aventure passionnante o√π Pepper, NAO, Plato et leurs futurs successeurs attendent votre contribution pour repousser les limites de la technologie robotique !
Requirements
Pour la bonne ex√©cution des missions confi√©es, vous t√©moignez d'au moins 6 ans d'exp√©rience en tant que d√©veloppeur sur des projets data en Cloud en Python et Spark et avec comme Cloud provider AWS.
Comp√©tences demand√©es :
Bonne compr√©hension des technologies d'infrastructure et de d√©ploiement,
Comp√©tences techniques sur les services AWS : IOT core , Glue, lambda, Kinesis, S3, RDS,
Bonne compr√©hension technique dans la mise en place et l'automatisation de tests de charge et fonctionnels,
Bonne maitrise d'outils BI ou de dashboarding (POWER BI, TABLEAU, QUICKSIGHT)
Bonne connaissance et une exp√©rience pratique de Scrum\Scrumban et des m√©thodes agiles,
Une certification AWS sera appr√©ci√©e,
Un niveau de fran√ßais et d'anglais courant est indispensable,
Des exp√©riences dans des environnements fortement internationaux sont un plus
Benefits
Nos principaux avantages :
Une culture du bien-√™tre en entreprise qui a fait ses preuves (budget c√©l√©bration et moments de convivialit√© par √©quipes et directions, restauration collective de qualit√©, environnement de travail agr√©able)
Un engagement fort en mati√®re de responsabilit√© sociale et environnementale (promotion de l'√©galit√© professionnelle, performance de notre plan diversit√© et inclusion, r√©f√©rent handicap, fresque du num√©rique)
Une culture du t√©l√©travail encadr√©e de mani√®re appropri√©e !
Tous nos postes sont ouverts aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '6', '6', '6']}"
Data Engineer H/F,Neosoft,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-neosoft-3877878521?position=34&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=5ibIRVZnYxMQyNtqkit%2BIw%3D%3D&trk=public_jobs_jserp-result_search-card,"Tous nos postes sont ouverts au t√©l√©travail
Groupe ind√©pendant de conseil en transformation digitale de pr√®s de 1800 collaborateurs, N√©osoft s‚Äôest construit, depuis 2005, sur un mod√®le qui place l‚Äôexcellence, le d√©passement de soi et la RSE au c≈ìur de sa strat√©gie.
En nous rejoignant, vous int√©grez des communaut√©s d‚Äôexperts et de talents qui vous permettent de d√©velopper vos comp√©tences et d‚Äôoffrir √† nos clients le meilleur accompagnement possible.
Notre savoir-faire s‚Äôarticule autour de nos 6 domaines d‚Äôexpertise :
Conseil & Agilit√©
Cybers√©curit√©
Data
DevOps
Infrastructures & Cloud
Software Engineering
Nous recherchons pour int√©grer notre
agence lilloise
un(e)
Data Engineer confirm√©(e)
.
Nous aimerions vous voir rayonner au sein de notre communaut√© DATA (+100 collaborateurs) anim√©e par Nicolas Huche, son practice leader et Thibaud Blanchard son Technical Officer. Vous aiderez les clients √† consolider un patrimoine Data responsable.
üéØ
Vos missions :
Apr√®s une p√©riode d‚Äôint√©gration, en tant que
Data Engineer
, voici √† quoi ressembleront vos activit√©s dans des contextes clients Retail ou Banque / Assurance / Finance :
Analyser et s'approprier les cas d'usages
Analyser et valoriser les donn√©es du patrimoine
Mettre en place des flux de transformation de donn√©es
R√©aliser les tests permettant de s'assurer la qualit√© du delivery
Continuer la mise au point de frameworks data
Cr√©er et d√©velopper des modules de d√©ploiement des solutions
Assurer l'industrialisation de moteurs bas√©s sur l'IA
Assurer le niveau de performance des pipelines
Impl√©menter les outils de monitoring du socles de donn√©es
üìù
Votre profil :
Nous vous imaginons avec au moins 4 ans d‚Äôexp√©riences sur des projets autour de la
Data
, une ma√Ætrise des
bases de donn√©es (SQL)
, des outils de transformation de la donn√©e
(Talend, BigQuery, Airflow)
, et un socle de comp√©tences solides autours des langages
Python, Spark, Scala, Hadoop, Java.
üëâ
Votre carri√®re chez N√©osoft
Depuis sa cr√©ation, N√©osoft place ses collaborateurs au c≈ìur de sa strat√©gie. Notre culture pourrait se r√©sumer en un mot : le collectif.
Nos communaut√©s d‚Äôexperts vous donnent la possibilit√© d‚Äôapprendre, mais aussi de transmettre et de partager vos savoirs pour faire progresser les autres.
Nous veillons √† ce que chacun b√©n√©ficie d‚Äôun accompagnement de proximit√© et d‚Äôun suivi de carri√®re personnalis√© aupr√®s de votre manager d√©di√© :
1 bilan d‚Äôactivit√© trimestriel pour suivre le d√©veloppement de vos comp√©tences
1 entretien d‚Äô√©valuation qui a lieu chaque ann√©e pour √©valuer votre performance et d√©terminer vos nouveaux objectifs
1 entretien annuel aupr√®s de votre RH dans le but de cartographier vos nouvelles comp√©tences pour √©changer sur vos projets professionnels et souhaits de formations
üëâ
Vos avantages
Formations et d√©veloppement de l‚Äôexpertise :
Vous disposez de temps allou√© et r√©mun√©r√© en contribuant au d√©veloppement de votre expertise technique et de celle du groupe (Participations √† des Tech days, animation d‚Äôune conf√©rence √† l‚Äôinterne ou √† l‚Äôexterne, r√©daction d‚Äôarticles, rencontres avec nos candidats en processus de recrutement‚Ä¶)
Un abonnement illimit√© LinkedIn Learning offert
Bien-√™tre au travail :
Un accord de t√©l√©travail flexible jusqu‚Äô√† 100% de t√©l√©travail et personnalisable
Un partenariat avec Gymlib qui favorise le sport en entreprise
Des initiatives locales (afterworks, d√©fis sportifs, team buildings, ‚Ä¶)
Et bien plus encore :
Parce que les meilleurs cooptent les meilleurs, une politique de cooptation attractive r√©mun√©r√©e d√®s l‚Äôarriv√©e du collaborateur
En plus de votre salaire : participation, compte √©pargne temps, actionnariat...
üëâ
Votre parcours candidat
Notre processus de recrutement se compose de deux √©tapes cl√©s :
Un entretien de recrutement RH avec un Talent Acquisition Sp√©cialiste pour dresser un bilan de votre parcours professionnel et identifier les trajectoires de carri√®re possibles au sein de notre groupe
Un entretien d‚Äô√©valuation technique pour r√©aliser un diagnostic de vos comp√©tences techniques et identifier les comp√©tences sur lesquels poursuivre votre √©volution
Vous aurez √©galement la possibilit√© de rencontrer pour compl√©ter votre processus un acteur de notre p√¥le Business ou un pair de votre m√©tier pour √©changer sur son exp√©rience collaborateur.
Nous avons h√¢te de vous rencontrer !
A bient√¥t,
L‚Äô√©quipe N√©osoft üñê
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'ML', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': ['Confirm√©'], 'TypeContract': [], 'Salary': ['Salaire'], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Data & Cloud Engineer (H/F),fifty-five,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-cloud-engineer-h-f-at-fifty-five-3910028674?position=35&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=goi29nNPD0xfl2sj7aYFrg%3D%3D&trk=public_jobs_jserp-result_search-card,"Data & Cloud Engineer
fifty-five est une data-company d'un genre nouveau qui aide les marques √† exploiter les donn√©es pour am√©liorer le marketing, les m√©dias et l'exp√©rience client gr√¢ce √† une combinaison de services de conseil et de technologie sp√©cialis√©s.
En tant que pilier data et marketing du Brandtech Group, nous offrons des services qui combinent le conseil en strat√©gie, les services de cloud, le conseil en m√©dia et l'exp√©rience client.
fifty-five, c'est plus de 400 experts du num√©rique. Des digital consultants, des sp√©cialistes du tracking et du m√©dia, des ing√©nieurs et des data scientists, travaillent tous en √©troite collaboration pour fournir des conseils marketing de haut niveau et une assistance technique aux marques, dans tout type d'industrie, partout dans le monde.
Partenaire des annonceurs de la collecte √† l'activation et l'exploitation des donn√©es, nous aidons les organisations √† devenir de v√©ritables entit√©s omnicanales ma√Ætrisant l'efficacit√© de leur √©cosyst√®me digital et ses synergies avec le monde physique.
Bas√© √† Paris, nous op√©rons sur 3 fuseaux horaires depuis nos 10 bureaux, situ√©s √† Paris, Londres, Gen√®ve, Milan, Shanghai, Hong Kong, Shenzhen, Taipei, Singapour et New York. fifty-five attache une importance particuli√®re au bien-√™tre de ses collaborateurs, ce qui lui a permis de figurer dans le classement Best Workplaces France en 2018.
Contexte :
L'√©quipe d'ing√©nierie d√©veloppe et met en ≈ìuvre les solutions techniques permettant la r√©alisation de pipelines de donn√©es et l'impl√©mentation de data platform pour nos clients : r√©cup√©ration de datas sur de multiples sources de donn√©es (APIs, files, etc.), data cleaning, data processing, automation et monitoring de l'ensemble. L'√©quipe s'appuie sur des technologies r√©centes (docker, kubernetes, terraform, notebooks, etc.) et met en place ses projets dans les diff√©rents clouds du march√© (GCP, Azure, AWS...).
Mission :
Nous sommes √† la recherche d'une personne capable de r√©aliser des projets techniques pour r√©pondre aux besoins de nos clients (par exemple: syst√®me de recommandations de produits, d√©tection d'anomalies, ranking). Les activit√©s vont du chiffrage et du sizing technique √† la mise en ≈ìuvre des architectures, en passant par la revue des sp√©cifications fonctionnelles et la production de code. Le Data & Cloud Engineer sera √©paul√© par un Lead dans ses missions. Il sera √©galement amen√© √† participer √† la R&D et √† accompagner les √©quipes transverses dans la mise en place d'outils de travail internes (librairies pour les data scientists, environnement Notebooks pour les data analysts et data scientists, d√©veloppement de frameworks sur diff√©rents cloud providers, etc.).
Nous souhaitons trouver la bonne personne pour faire √©voluer ou cr√©er de nouvelles solutions dans ce cadre. Les missions comprennent aussi bien du prototypage rapide pour des d√©monstrateurs, que de la production de code robuste qui tourne en production tous les jours.
Comp√©tences et exp√©riences :
2 ans d'exp√©rience en tant que Data Engineer
Ma√Ætrise de Python, SQL
Ma√Ætrise des environnements Cloud. Id√©alement certifi√© GCP, Azure ou AWS
Bonne connaissance de Docker/Kubernetes
Bonne connaissance d'au moins un data warehouse (BigQuery, Snowflake, etc)
Connaissance autour des Notebooks (Jupyter)
A l'aise avec des concepts li√©s aux APIs (OAuth, REST, etc.)
A l'aise avec les notions d'Infrastructure as Code (Terraform)
Au courant des pratiques GitOps et connaissances des concepts autour du CI/CD
La ma√Ætrise d'un orchestrateur, comme Apache Airflow, est un plus
Esprit d'√©quipe (collaborer aux tests unitaires, revue de code, partage de code, sprints)
Bon niveau en fran√ßais et en anglais
A d√©j√† travaill√© en mode projet avec des interlocuteurs vari√©s (consultant, data analyst, data scientist)
Une exp√©rience en marketing digital est un plus
Nous proposons :
un bureau au centre de Paris avec terrasse et jardin
un environnement multiculturel avec des collaborateurs aux nationalit√©s multiples (France, Royaume-Uni, Etats-Unis, Chine, Tunisie, Italie et plus)
des projets avec nos bureaux √† Londres, Hong Kong, New York, Shanghai, Gen√®ve, Shenzhen et Taipei
des TGIF et supers soir√©es
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Apache Airflow'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Data Engineer,AFD Technologies,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-afd-technologies-3899625641?position=36&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=0XV4X5qxaks0ljefO73%2FRA%3D%3D&trk=public_jobs_jserp-result_search-card,"AFD.TECH part of Accenture
est le sp√©cialiste du conseil en transformation digitale des grandes entreprises üöÄ.
A ce jour, le Groupe est compos√© de 2.000 talents r√©partis dans 3 pays (France, Belgique & Maroc) üåé pour un chiffre d‚Äôaffaires annuel de 125M‚Ç¨ !
Nos Talents d‚Äôabord üòé:
Les Talents d‚ÄôAFD.TECH part of Accenture sont au c≈ìur de la strat√©gie du Groupe et il est primordial pour nous que chaque collaborateur trouve du sens dans son travail.
Au-del√† de proposer une carri√®re ambitieuse et personnalis√©e √† nos Talents, nous avons √† c≈ìur de leur offrir un environnement de travail flexible (remote), inclusif et √©panouissant dans tous nos bureaux (Paris, Bruxelles, Rabat, Lyon, Strasbourg, Lille, Nantes, Toulouse, Marseille, Bordeaux et Rennes)üåç.
Avec 20% de croissance par an et plus de 20 ans d‚Äôexistence, AFD.TECH part of Accenture est devenu l‚Äôacteur incontournable du march√© des infrastructures informatiques, r√©seaux et t√©l√©coms.
Notre proposition de valeur ? Intervenir sur l‚Äôensemble du cycle de vie de projets complexes, pour des clients grands comptes, venant de secteurs tels que la banque, le ferroviaire, les m√©dias, t√©l√©coms, etc (comme la Soci√©t√© G√©n√©rale, Bouygues Telecom, Orange, Thales et bien d‚Äôautres encore !)üë©üèª‚Äçüíª.
Nous rejoindre est une formidable aventure humaine : nous vous proposons un poste un poste de
Data Engineer en CDI
, au sein de notre agence Lilloise.
Vos missions ‚úÖ:
En tant que Data Engineer pour l'un de nos clients grands comptes, votre r√¥le s‚Äôarticulera autour de diff√©rents axes :
Appr√©hender le contexte et les enjeux m√©tier du client.
Collaborer avec les √©quipes m√©tier pour comprendre les exigences en mati√®re de donn√©es.
D√©finir des architectures data.
Concevoir et mettre en place des pipelines de donn√©es.
Construire des flux de donn√©es complexes.
Vous travaillerez dans une mission √† forte valeur ajout√©e et de longue dur√©e (minimum 1 an et demi).
Votre profil‚úÖ:
Vous ma√Ætrisez le langage SQL, les ETL et les ELT.
Vous aimez automatiser, mettre en place vos data pipelines et ma√Ætriser les technologies: CI/CD, Terraform, Github, Python, Kafka.
Vous poss√©dez des comp√©tences en data visualisation : Business Objects, Qlikview, Qlik Sense, PowerBI ou Data Studio.
Vous connaissez Google Cloud Platform (GCS, BigQuery).
Vous √™tes dipl√¥m√©(e) d‚Äôune formation BAC + 5.
Vous avez une premi√®re exp√©rience significative dans la data engineering (
minimum 3 ans
).
Vous projetez votre carri√®re dans un cabinet de conseil exigent et successful, qui vous permettra de d√©velopper votre esprit entrepreneurial et de r√©pondre √† vos ambitions.
Ce que nous offrons chez AFD.TECH part of Accenture ü§ó:
Une politique de flexibilit√© dans votre organisation et un bon √©quilibre de vie üèÉ‚Äç‚ôÇÔ∏è.
Des avantages plus que comp√©titifs üí∞.
Un accompagnement et un suivi r√©gulier durant tout votre parcours chez AFD.TECH (Launchpad, Linkers, rookies, etc‚Ä¶).
Un √©tat d‚Äôesprit familial et de la proximit√© entre tous üë®‚Äçüë©‚Äçüëß‚Äçüë¶.
Des moments de convivialit√© toute l‚Äôann√©e üçæ (√©vent en √©quipe, s√©minaire annuel, sports collectifs etc.).
Un parcours d‚Äô√©volution sur mesure üîº.
A tr√®s bient√¥t chez AFD.TECH part of Accenture!
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Orange'], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': ['Organisation', 'Flexibilit√©'], 'EnSoftSkils': []}","{'JobDetail': ['Remote'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '20', '20', '20']}"
Data engineer H/F,Extia,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-extia-3599188121?position=37&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=RpAHVod1lg1ca3LwgraXfw%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous souhaitez rejoindre une entreprise qui place l‚Äôhumain au c≈ìur de ses pr√©occupations ? On vous attend chez
Extia
!
Soci√©t√© de conseil sp√©cialis√©e dans les m√©tiers de l‚ÄôIT, de l‚Äôing√©nierie et du digital, Extia privil√©gie depuis sa cr√©ation en 2007 une approche qui allie performance et bien-√™tre au travail. Une vision de l‚Äôentreprise partag√©e aujourd‚Äôhui par plus de 2 500 Extiens en France et √† l'international et r√©compens√©e par le label Great Place to Work¬Æ depuis 13 ans, notamment en
2024 o√π les Extiens se hissent √† la premi√®re place du palmar√®s Best Workplaces France
!
Chez Extia, c‚Äôest ¬´ D‚Äôabord qui, ensuite quoi ¬ª alors, allons-y !
D'abord qui
Vous √™tes habitu√© √† travailler aussi bien avec des m√©ta-donn√©es qu‚Äôavec des donn√©es non-structur√©es. A cet effet vous maitrisez un ou plusieurs des concepts comme l‚ÄôETL, le Data mining le Machine learning, les Big data ou encore la Th√©orie des graphes par exemple,
Vous maitrisez les bases de l‚Äôanalyse statistique,
Vous √™tes apte √† r√©diger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus,
Vous maitrisez Spark et Hadoop
Vous √™tes familiaris√© avec l‚Äôenvironnement Linux,
Une exp√©rience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps r√©el seront aussi de r√©els atouts.
Ensuite quoi
Vous aurez le r√¥le de support technique aux √©quipes d‚Äôanalyse : structurer les donn√©es, r√©aliser des analyses ¬´ statistiques ¬ª ou ¬´ techniques ¬ª sur les donn√©es, d√©velopper des outils d‚Äôanalyse‚Ä¶
Vous m√®nerez des √©tudes afin d‚Äô√©valuer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin d‚Äôidentifier les solutions les plus pertinentes.
Vous serez en charge de :
Participer √† la d√©finition des besoins et √† la r√©daction des User Stories,
Collaborer avec les Data Scientists au d√©veloppement des modules d‚Äôanalyse de donn√©e,
Concevoir et construire des architectures de donn√©es,
Int√©grer des sources de donn√©es,
Vous assurez que les donn√©es sont facilement accessibles et que leur exploitation fonctionne comme demand√©, m√™me dans des circonstances hautement √©volutives,
Ex√©cuter des processus ETL (extraire / transformer / charger) √† partir d'ensembles de donn√©es complexes et / ou volumineux
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning', 'Statistiques', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '13', '13', '13']}"
Ing√©nieur Data Spark (F/H),Thales,"V√©lizy-Villacoublay, √éle-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-spark-f-h-at-thales-3890949531?position=38&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=LyzjWq%2FfgvJpebjvBp057g%3D%3D&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?
Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr√©sents sur tous les continents. Le Groupe investit dans les innovations du num√©rique et de la ¬´ deep tech ¬ª ‚Äì big data, intelligence artificielle, connectivit√©, cybers√©curit√© et quantique ‚Äì pour construire un avenir de confiance, essentiel au d√©veloppement de nos soci√©t√©s, en pla√ßant l‚Äôhumain au c≈ìur des d√©cisions.
Thales propose des solutions, services et produits qui aident ses clients ‚Äì entreprises, organisations, Etats ‚Äì dans cinq grands march√©s vitaux pour le fonctionnement de nos soci√©t√©s : identit√© et s√©curit√© num√©riques, d√©fense, a√©ronautique, espace, et transport.
QUI ETES-VOUS ?
Dipl√¥m√© d‚Äôun Bac+5 en √©cole d‚Äôing√©nieur ou √©quivalent universitaire avec une sp√©cialisation en informatique, vous avez au moins 3 ans d'exp√©rience dans les technologies Big Data.
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
En tant que Data Engineer, vous jouerez un r√¥le cl√© dans la conception, le d√©veloppement et la maintenance de notre infrastructure de donn√©es, ainsi que dans la transformation et la gestion des flux de donn√©es.
VOS MISSIONS :
‚Ä¢ Concevoir, d√©velopper et d√©ployer des solutions Big Data en utilisant les technologies Spark.
‚Ä¢ Mettre en place des pipelines de donn√©es performants pour l'ingestion, le traitement et le stockage des donn√©es massives.
‚Ä¢ Collaborer √©troitement avec les √©quipes m√©tier pour comprendre leurs besoins en mati√®re d'analyse de donn√©es et proposer des solutions adapt√©es.
‚Ä¢ Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn√©es.
‚Ä¢ Assurer la qualit√© et la fiabilit√© des donn√©es trait√©es, en mettant en place des processus de validation et de nettoyage.
‚Ä¢ Identifier et r√©soudre les probl√®mes li√©s √† l'infrastructure Big Data et proposer des am√©liorations.
‚Ä¢ Travailler en √©troite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents √† partir des donn√©es.
Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Alternance - Data Engineer H/F,Herm√®s,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/alternance-data-engineer-h-f-at-herm%C3%A8s-3889716412?position=39&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=5VSk5nClTgZjL1xgLiAxew%3D%3D&trk=public_jobs_jserp-result_search-card,"El√©ments de contexte
Herm√®s Digital Ventes et Services recherche pour sa direction Data & Performance :
Un Alternant Data Engineer (H/F)
Contrat d'alternance de 12 mois
A partir de Septembre 2024
Bas√© √† Paris
Principales activit√©s
Vous √™tes rattach√© au Data manager.
Vous avez pour principale mission d‚Äôaccompagner l‚Äô√©quipe Data dans les t√¢ches quotidiennes :
Reporting et statistiques de ventes et trafic (notamment via l‚Äôoutil Google Analytics et Google BigQuery)
Analyse des leviers d‚Äôacquisition de traffic SEA/SEO/Referral
Cr√©ation de Dashboard via l‚Äôoutil Google Data Studio
Participation aux travaux de CRO (Conversion Rate Optimization) et d‚ÄôAB testing
Mise en place d‚Äô√©tude pr√©dictive sur les donn√©es des sites Ecommerce
Profil
Etudiant en √©cole d‚Äôing√©nieur poss√©dant une forte culture Internet et une sensibilit√© aux probl√©matiques digitales e-commerce, vous avez une premi√®re exp√©rience en entreprise
Profil technique ou ais√© avec la technique, une sp√©cialisation en digital est en plus
Organis√©, rigoureux, curieux, autonome, bonne expression √©crite et aisance relationnelle
Ma√Ætrise du Pack Office indispensable, ayant d√©j√† utilis√© Google Analytics
La connaissance d‚Äôoutils de BI / Datavisualisation serait appr√©ci√©e (Google Data Studio, Tableau Software, Bime ou QlikView/QlikSense, PowerBI), de Base de Donn√©es (SQL, MySQL, BigQuery)
Une app√©tence pour la Data, ses languages (Python, R) et ses technologies (Notebooks, mod√©lisation statistique, Machine learning) est fortement appr√©ci√©e.
Anglais courant souhait√©
Sensible aux produits hauts de gamme, vous souhaitez vous investir dans un stage riche et formateur
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'PowerBI'], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['MySQL', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Statistiques'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,Coders Connect,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-coders-connect-3870419202?position=40&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=va%2BZHBT8a5zkOnTMbPoLOQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Coders Connect and Sanofi are joining forces to bring an electrifying twist to the biopharmaceutical world!
Work with a rhythm that suits your style (2 days remote and 3 days onsite magic).
Language
: Proficiency in English is required for this role to ensure effective communication within our diverse, global team.
About Sanofi:
We're not just a company; we're a global movement, focused on human health and making a real difference. Our mission? To battle pain, ease suffering, and sprinkle a little bit of magic in the process by developing life-changing medicines and vaccines through breakthrough science and wizard-level technology.
Digital & Data: The Pulse of Our Mission
At the heart of our quest lies our digital and data powerhouse. Think of us as the digital healthcare platform of your dreams, where innovation meets speed, and technology shakes hands with medicine. With our scale, deep-rooted connections in health ecosystems worldwide, and a knack for pushing boundaries, we're here to revolutionise medicine, one digital solution at a time.
The Role: Data Engineering Virtuoso
As our Data Engineering Virtuoso, you're tasked with designing and orchestrating the data pipelines that power our ambitious data analytics initiatives. You'll ensure our data's integrity and accessibility, laying the groundwork for groundbreaking insights and innovations.
Requirements
Cloud Platforms: Proficient in AWS services, with Azure & GCP knowledge a plus. Your work involves leveraging cloud solutions for scalable data processing and storage.
Data Modeling & Query Performance: Expertise in crafting data models and optimizing SQL queries to enhance performance. Experience with Snowflake or similar data warehousing solutions is highly valued.
Integration Services: Skilled in utilizing Integration Services like IICS and Tibco, you facilitate seamless data flow and integration across various platforms.
Scripting & Development: Proficient in scripting languages such as Python and R, enabling you to automate tasks and manipulate data efficiently. Familiarity with GitHub for source code management underscores your commitment to collaborative development and version control.
Visualization & Reporting: Knowledgeable in creating insightful data visualizations using tools like PowerBI, Tableau, or similar, turning complex data into actionable insights.
Data Governance & Compliance: A keen understanding of data quality, security, and governance standards, especially in healthcare environments subject to regulations like GxP, SOX, and data privacy laws.
Real World Data & Standard Models: Experience with Real World Data (e.g., EHR, Claims) and familiarity with standard data models (e.g., OMOP, FHIR) enhance your ability to contribute to our healthcare objectives.
Pipeline Frameworks: Proficiency in using frameworks like Apache Airflow or Kedro for crafting efficient, reliable data pipelines that support our AI and ML initiatives.
The Reward:
A chance to play a crucial role in a collaboration that's redefining healthcare through digital transformation.
A seat at the round table of diversity and inclusion, where different backgrounds and experiences conjure the richness of our culture.
An endless horizon of professional growth, learning opportunities, and the chance to contribute to a future where better health is a global reality.
The Call to Adventure:
If you're ready to join a quest for better ‚Äì better treatments, better outcomes, and better science ‚Äì and believe in the magic of bringing diverse talents together to make miracles happen, we want you. Let's embark on this journey together and transform the future of healthcare.
Better is out there. Are you ready to find it with us?
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Apache Airflow'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Cloud'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration', 'Initiative']}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (H/F),Epsilon France,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-epsilon-france-3912808369?position=41&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=%2F%2F3ZhY4YKHf7xPyoxJs8AA%3D%3D&trk=public_jobs_jserp-result_search-card,"Cette offre d‚Äôemploi est fournie par P√¥le emploi
Description
Dans le cadre du d√©veloppement de notre p√¥le Data & IA (cadrage fonctionnel et technique, d√©finition de use-cases, strat√©gie des moyens, accompagnement du changement, mise en ≈ìuvre, maintenance et commercialisation de solutions), nous recherchons un(e) Data Engineer qui aura pour missions : - D√©livrer des projets Data Lake / Big Data (ingestion de sources, pipeline de traitements de donn√©es, mod√©lisation, tests, d√©ploiements) dans un contexte de plus en plus DevOps, - Comprendre les besoins des √©quipes digitales, principalement associ√©es aux projets Data Science et leurs technologies / outils (Jupyter, Zeppelin, R, Python, .), - √ätre capable de faire le lien avec les contraintes techniques (IT, s√©curit√©, acc√®s, outils) d'une DSI, - Assurer la veille technologique sur les composants d'une plateforme Datalake, Cloud - Maintenir les environnements techniques et partager ses connaissances (capitalisation, s√©minaires, formations, KM en ligne), - R√©diger des documents projets (design, r√©alisation, d√©ploiement, .), - G√©rer l'√©volution des solutions propos√©es, et possiblement en assurer la TMA. Qualifications Inscrit en Master 2 informatique ou dans un domaine technique connexe au titre des ann√©es universitaire 2022-2025, Admis dans le cursus d'un CFA (universit√© ou √©cole d'ing√©nieur), Capacit√© d'apprendre, de comprendre et de travailler avec des nouvelles technologies, m√©thodologies et des solutions √©mergentes dans l'environnement technologique d'ing√©nierie cloud/donn√©es, Excellentes comp√©tences en communication, organisation, avec une attitude proactive et positive, Passion pour les nouvelles technologies et engagement √† acqu√©rir de nouvelles comp√©tences. Informations suppl√©mentaires CHOISISSEZ. - Notre expertise reconnue dans le domaine du d√©cisionnel et du Big Data depuis 30 ans, un cadre m√©thodologique et une organisation des comp√©tences anim√©es constamment dans un souci de veille et de progression, - Nos projets innovants et nos missions de conseil en cours de r√©alisation ou r√©alis√©s autour des solutions BI, Big Data et DMP, - Notre diversit√© de projets et de clients (SNCF, Groupe BPCE, Fnac, La Banque Postale.), - Notre management de proximit√© et notre souci de d√©veloppement des comp√©tences. Localisation : Paris 11e (Bastille) Contrat : POEI avec l'ecole Simplon et le programme Skills Les + EPSILON France : - Acc√®s Restaurant d'Entreprise (Campus Bastille) - Travail Hybride gr√¢ce √† notre Accord T√©l√©travail qui autorise jusqu'√† 2 jours par semaine - Engag√© avec le Forfait Mobilit√© Durable - Dispositif d'Epargne Salariale (Accord d'int√©ressement et de participation)
PROFIL SOUHAIT√â
Exp√©rience
D√©butant accept√©
Savoir-√™tre professionnels
Faire preuve de rigueur et de pr√©cision
Faire preuve de r√©activit√©
√ätre √† l'√©coute, faire preuve d'empathie
Langue
Anglais
Source: Pole emploi (https://www.pole-emploi.fr)
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Communication', 'Empathie', 'Organisation'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Hybride'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '30', '30', '30']}"
Data Engineer,Airswift,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-airswift-3909165766?position=42&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=6otrrgAHMn%2B2bPRXEycTZg%3D%3D&trk=public_jobs_jserp-result_search-card,"Data Engineer
Location
: Paris (Hybrid)
Contract type
: 12 months +
Years of Experience
: 4+
Recruitment Partner:
Airswift
Key Words:
Project Management | Jira | Digiboard | Banking | Stakeholder Management | Architecture | Cloud | Payments/Credit |ServiceNow | PPM |
Responsibilities
Design, develop, and implement data pipelines to collect, process, and store structured and unstructured data from various sources.
Collaborate with data scientists, analysts, and other stakeholders to understand data requirements and translate them into technical solutions.
Optimize and tune data pipelines for performance, scalability, and reliability.
Ensure data quality and integrity throughout the data lifecycle, implementing data validation and monitoring processes.
Evaluate and implement new tools and technologies to enhance our data infrastructure and capabilities.
Requirements
:
Extensive experience in Python.
Strong experience with data processing frameworks and tools such as Apache Spark.
Experience with cloud platforms such as AWS, Azure, or Google Cloud Platform.
Solid understanding of data modelling, database design, and SQL
French and English speaking
Freelancing opportunity
The next step
We have an exceptional team in place, and we are pleased to be able to appoint a further person to our growing business. We are aware that you may not ‚Äòtick all the boxes‚Äô, but if you believe you can genuinely offer some valuable skills and experience to our business, please in the first instance contact our recruitment partner Airswift.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['JIRA'], 'Other': ['Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
"Data Engineer ‚Äì Antibes, France (H/F)",Astek,"Antibes, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-antibes-france-h-f-at-astek-3909192086?position=43&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=BxG7YTWicXtd5pO8ytQ3Sg%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Antibes - France
Publi√©e il y a 2 semaines
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Intervenir dans la conception, le d√©veloppement, les tests unitaires, la qualification, l‚Äôint√©gration continue et la mise en production d‚Äô√©volutions sur les projets du p√¥le produits scoring (un p√¥le visant √† d√©velopper des solutions permettant de g√©n√©rer des scores ou des segments d‚Äôinformation pertinents dans divers domaines, notamment : profiling TV, PUB, SAB, MMDM, Voscastview) chez l‚Äôun de nos partenaires sp√©cialis√© dans le secteur des t√©l√©coms.
Votre Mission, Si Vous L‚Äôacceptez :
En collaboration avec les autres membres de l‚Äô√©quipe, vous devrez prendre en charge le RUN des applications du p√¥le produit scoring.
Conception d‚Äôune solution se basant sur les d√©veloppements existants et les besoins m√©tiers remont√©s par le Product Owner.
R√©alisation et d√©veloppement de nouvelles fonctionnalit√©s sur les composants des applications du p√¥le produits scoring et environnement CGP.
Votre Future √âquipe :
Au sein d‚Äôun environnement riche et complexe, vous √©voluerez avec des experts passionn√©s √† la fois techniques et fonctionnels (Ing√©nieurs sp√©cialis√©s, chef de projet, scrum master, product owner, analystes ‚Ä¶).
Votre stack de jeu
D ans un environnement SAFE sous cloud GCP, Big Query, OnPrime, Grafana, Python et Ansible.
Vous ?
De formation Ing√©nieur, vous justifiez d‚Äôune premi√®re exp√©rience sur un poste de Data engineer. Vous poss√©dez des comp√©tences d‚Äôautonomie et d‚Äôadaptabilit√© et vous avez une capacit√© √† communiquer efficacement au sein d‚Äôune √©quipe.
Le Groupe Astek
Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.
Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de
ses 7800 collaborateurs
qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.
Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.
Tous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies, pr√©sent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.
Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de ses 7800 collaborateurs qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.
Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde et ayant r√©alis√© un chiffre d‚Äôaffaires hors
acquisitions de 600M‚Ç¨ en 2023.
Tous les d√©tails sur le Groupe sur le site
Nos Plus
Astek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo
Une politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversit√©
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì Data engineer ‚Äì Big Data
Caract√©ristiques de l'emploi
Cat√©gorie Ing√©nieur
Job Industry T√©l√©com / M√©dia
Postuler en ligne
Nom *
Pr√©nom *
Email *
Un email valide est requis.
T√©l√©phone *
Un num√©ro de t√©l√©phone valide est requis.
Joindre un CV *
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì Data engineer ‚Äì Big Data
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Big Query'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Adaptabilit√©', 'Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (H/F),Web Transition,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-web-transition-3909147172?position=44&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=4zF8cj0%2Bo0yeJlbJeYrhvA%3D%3D&trk=public_jobs_jserp-result_search-card,"Web Transition, c‚Äôest qui ?
Fond√©e en 2011,
Web transition
est une entreprise de services num√©riques op√©rant sur le march√© de l‚ÄôIT/Digital !
Constituant une part essentielle de
MoOngy Digital Lab
, Web Transition accompagne ses clients grands comptes sur leurs projets de Webmarketing, de Design, Gestion de projet et √©galement en Data !
Notre objectif : nous implanter comme un acteur principal sur le march√© de la Transformation Digitale en accompagnant et valorisant les comp√©tences de nos collaborateurs !
Nous sommes convaincus que le succ√®s de MoOngy Digital Lab r√©side dans la somme des potentiels de nos √©quipes ü§ù
Ton √©quipe : La tribu Data
Parce qu‚Äôil est indispensable que tu puisses partager tes connaissances mais aussi en acqu√©rir de nouvelles, tu feras partie de l‚Äôune de nos tribus : celle de la Data. De plus, cela te permettra d‚Äô√™tre acteur dans le d√©veloppement et la strat√©gie de Web Transition. Ce syst√®me de co-r√©flexion et co-construction est un fondement essentiel chez nous !
Dans cette aventure, tu :
T‚Äôassures
de la ma√Ætrise de la donn√©e et est garant de la qualit√© de son utilisation (r√©f√©rencement, normalisation, et qualification)
Travailles
√† la compr√©hension et l'int√©gration des donn√©es en provenance des diff√©rents formats
des interfaces de flux
√©galement √† la d√©finition de la politique de la donn√©e et √† la structuration de son cycle de vie dans le respect des r√©glementations en vigueur
la supervision et l'int√©gration des donn√©es de diverse nature qui proviennent de ces sources multiples et v√©rifie la qualit√© des donn√©es qui entrent dans le Data Lake
Garantis
l'acc√®s qualitatif aux sources de donn√©es
Facilites
l‚Äôacc√®s aux donn√©es pour tes coll√®gues (data scientists, data analysts‚Ä¶)
Assistes
les autres √©quipes dans l'acc√®s et la compr√©hension des donn√©es des socles.
Rejoins-nous si tu as :
Exp√©rience d‚Äôau-moins 4 ans dans la Data
App√©tence √† la qualit√© des donn√©es.
Connaissance famili√®re des Datawarehouses.
Maitrise de Python, Oracle SQL, GCP/Power BI
Aisance avec les indicateurs, tu as une bonne capacit√© d'analyse et de r√©daction.
Ton savoir-√™tre :
Ouvert d‚Äôesprit
Rigoureux
Autonome
Respectueux des diff√©rences de chacun
Curieux
Proactif
Agile
Par o√π on commence ?
Un premier entretien RH d‚Äô1h pour comprendre ton parcours et tes aspirations
Un second entretien de 45 minutes avec l‚Äôun de nos Business Manager afin de valider tes comp√©tences et qu‚Äôil se projette sur l‚Äôune des missions qu‚Äôil pourrait te proposer
Un troisi√®me entretien de quelques minutes avec notre responsable d‚Äôagence pour te proposer d‚Äôint√©grer notre superbe Team Web !
3 entretiens en peu de temps, si ton profil correspond tu int√®greras tr√®s vite nos √©quipes üòâ
Pr√™t pour embarquer dans notre grande aventure humaine ? Deviens notre futur Weber en postulant √† cette offre ! Voici les avantages qui t‚Äôattendent en tant que Weber :
ü§© Des coll√®gues incroyables
üèÜ Certifi√©e Great Place to Work
üéÆ Des bureaux sympas (o√π vous serez toujours les bienvenus)
üéâ Des teambuilding et √©vents tous les mois
üíª Des tributs m√©tiers pour √©changer entre Weber du m√™me m√©tier
Des missions chez le client qui sont accompagn√©es et coach√©es par ton manager
Un accompagnement dans ton plan de carri√®re et tes envies de re skilling
ü§ì Un catalogue de formations certifiantes ouvert √† tous les salari√©s
üçΩÔ∏è Une carte tickets restaurant MyEdenred
‚ù§Ô∏è Une mutuelle GrasSavoye
üöé Une prise en charge des frais de transport √† 100%
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Data engineer H/F,Akkodis,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-akkodis-3890779946?position=45&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=vC%2BhZztWd%2B8k1rfzefcAEw%3D%3D&trk=public_jobs_jserp-result_search-card,"La ligne de service Consulting & Solutions d‚ÄôAkkodis France renforce ses √©quipes en r√©gion Hauts-de-France et recrute un
Data engineer H/F
en
CDI
sur la
m√©tropole lilloise
:
Description de la mission :
Concevoir, mettre en oeuvre et maintenir des pipelines de donn√©es efficaces et √©volutifs dans un environnement cloud (comme AWS, Azure, Google Cloud Platform‚Ä¶)
Assurer la qualit√© des donn√©es et des mod√®les
D√©finir les bonnes pratiques de d√©veloppement en impl√©mentant des outils de CI/CD
Assurer une veille technologique sur les technologies Cloud
Capacit√© √† interagir avec des parties prenantes diverses : business analyst, architecte, m√©tier‚Ä¶
Veiller au bon fonctionnement des pipelines en production
Profil :
De formation
Bac +4/5 en informatique
ou issu d'une
√©cole d'ing√©nieur
, vous poss√©dez une exp√©rience de
3 ans
minimum en tant que data engineer ainsi que les comp√©tences suivantes :
Une bonne connaissance des √©cosyst√®mes li√©s √† la data (Kafka, ETL, base de donn√©es‚Ä¶)
Une premi√®re exp√©rience sur un cloud provider (AWS, Azure, GCP)
Une bonne maitrise de langages de programmation tels que SQL, Python, Scala
Akkodis accompagne ses clients dans la mondialisation de leurs projets, aussi un anglais courant est requis pour l‚Äôensemble de nos collaborateurs.
Processus de recrutement :
Une charg√©e de recrutement vous contacte pour √©changer sur votre projet professionnel
Vous √©changez ensuite avec un.e manager sur les aspects techniques, les projets
Chez Akkodis nous sommes convaincus que de l‚Äôintelligence collective na√Æt le succ√®s. Il n‚Äôexiste pas qu‚Äôun mod√®le, nous valorisons l‚Äôagilit√© et l‚Äôexcellence, l‚Äôaudace et la cr√©ativit√©.
Et si nous parlions ensemble de vos ambitions pour les prochaines ann√©es ?
Akkodis est une entreprise handi-engag√©e et inclusive. Tous nos postes sont ouverts aux handicaps et √† la diversit√©. Tous diff√©rents, tous comp√©tents !
Akkodis, est un acteur mondial de l‚Äôing√©nierie et de l‚ÄôIT et un leader dans la smart industrie. Nous accompagnons nos clients dans leurs projets de transformation digitale via 4 lignes de service : Consulting, Solutions, Talent et Academy. Akkodis est un partenaire technologique de confiance pour ses clients √† l‚Äô√©chelle internationale. Nous co-cr√©ons et nous imaginons des solutions de pointe pour r√©pondre aux d√©fis majeurs de notre soci√©t√©, qu'il s'agisse d'acc√©l√©rer la transition √©nerg√©tique et de d√©velopper la mobilit√© verte, ou encore de construire des approches centr√©es sur les utilisateurs.
Dot√©s d‚Äôune forte culture de l‚Äôinclusion et de la diversit√©, nos 50 000 experts en IT et en ing√©nierie, pr√©sents dans 30 pays, allient les meilleures comp√©tences technologiques √† une connaissance transverse de toutes les industries pour fa√ßonner un futur plus durable. Nous sommes passionn√©s par l‚Äôid√©e d‚Äôinventer ensemble un avenir meilleur.
Akkodis en France, ce sont pr√®s de 9.000 experts en IT et en ing√©nierie r√©partis sur l'ensemble du territoire, des collaborateurs partageant des valeurs fortes d'honn√™tet√©, de respect, d'√©quit√© et d'inclusion. Notre engagement : leur permettre au quotidien d'√™tre eux-m√™mes au travail, et acteurs de leur vie et de leur d√©veloppement au sein d'Akkodis.
*Akkodis est une marque commerciale sous laquelle les entit√©s AKKA et Modis op√®rent
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': ['Cr√©ativit√©'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer F/H,Mobilize Financial Services ‚Äì France,"Noisy-le-Grand, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-mobilize-financial-services-%E2%80%93-france-3869637982?position=46&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=QjY4WuD6jrMpRjEyvVP3dw%3D%3D&trk=public_jobs_jserp-result_search-card,"üöó En route vers Mobilize !
A l‚Äô√©coute de tous nos clients, nous cr√©ons des services financiers innovants pour construire une mobilit√© durable pour tous.
Rejoindre Mobilize Financial Services,
c‚Äôest d‚Äôabord choisir d‚Äôint√©grer un groupe international
, filiale de Renault Group, une banque de financement solide, partenaire des constructeurs Renault‚ÄìNissan‚ÄìMitsubishi. Nos 4 000 collaborateurs pr√©sents dans 35 pays, agissent ensemble au service de nos clients.
Nous proposons √† nos clients - particuliers comme professionnels - les financements et les services les plus adapt√©s pour les v√©hicules neufs et d'occasion.
Nous finan√ßons √©galement l'activit√© des r√©seaux de concessionnaires des marques de l'Alliance Renault-Nissan-Mitsubishi et nous veillons √† faciliter leur gestion au quotidien pour leur permettre de d√©velopper leurs ventes et assurer leur p√©rennit√© financi√®re.
Notre entreprise se ""MOBILIZE"" en faveur de la diversit√© culturelle, l'√©galit√© hommes-femmes et l'int√©gration de personnes en situation de Handicap. Nous favorisons un environnement de travail o√π les diff√©rences individuelles sont reconnues, appr√©ci√©es, respect√©es et valoris√©es, de fa√ßon √† mettre √† profit les talents et les forces de chacun.
üöòPrenez le volant ! Pas de routine, tous nos itin√©raires sont diff√©rents !
Au sein de la DSI
,
votre
futur m√©tier consistera √† :
Accompagner l‚Äô√©quipe dans la transformation du domaine d√©cisionnel construit sur une architecture type DWH et le porter sur la solution GCP (Google Cloud Platform) de Mobilize FS
Participer √† la construction du projet de transformation vers GCP
Participer aux projets d‚Äô√©volution de notre plateforme Suite Elastic (ELK - Kibana)
Piloter des projets en √©troite collaboration avec les directions m√©tier et en accord avec le TBA (Tableau de Bord des Actions).
Assurer la gestion du budget, du planning, de la tenue des jalons et du respect des engagements sur les projets en responsabilit√©
Assurer la qualit√© et le bon fonctionnement du chargement des donn√©es.
Assurer la mise √† disposition des donn√©es et des outils de reportings √† toutes les directions clientes dans le respect des contrats de service
V√©ritable tout-terrain, vous nous int√©ressez !
L‚Äôesprit d‚Äô√©quipe et le sens du service client pour atteindre ensemble les diff√©rents objectifs ambitieux et satisfaire les diff√©rentes parties avec un haut niveau de qualit√©.
Vous avez un bon relationnel, de l‚Äô√©coute et une excellente communication afin d‚Äôinteragir avec des interlocuteurs de diff√©rents niveaux (direction technique et m√©tier) et de travailler en transverse.
Le sens de l‚Äôanalyse et de bonnes capacit√©s d‚Äôanticipation pour d√©celer les probl√®mes avant la naissance de ces derniers.
Force de proposition : avec vous il n'y a pas de probl√®mes, que des solutions
Vous avez un niveau d‚Äôanglais vous permettant de lire et de comprendre de la documentation technique
üíªüñ± Environnement technique :
Maitrise des langages Python - SQL / NoSQL
Exp√©rience significative sur Python
Exp√©rience avec Git
Une exp√©rience avec les outils Nifi, Airflow et GCP (BigQuery / Cloud Function / Cloud Storage ‚Ä¶) serait un plus
Gestion de projet, maintenance, √©volution, support
App√©tence pour les sujets techniques et fonctionnels : outils de mod√©lisation, exploration de donn√©es, IA, machine learning
Pourquoi nous rejoindre ?
Votre Pack confort
est compos√© de nombreux avantages üòÄ :
Rejoindre Mobilize Financial Services c‚Äôest int√©grer un grand groupe international qui offre des opportunit√©s de carri√®re
.
Un environnement de travail moderne et convivial
: locaux agr√©ables, salle de sport, terrasse, restaurant d‚Äôentreprise, parking avec un CSE dynamique avec de nombreuses offres voyages, sport, famille,
Nous sommes mobilis√©s pour d√©velopper la qualit√© de vie au travail de nos collaborateurs en faisant √©voluer nos fa√ßons de travailler (m√©thodes, outils, organisation du travail‚Ä¶) et nous sommes fiers d‚Äô√™tre certifi√©s ‚≠ê
Great Place To Work ‚≠ê
Possibilit√© de t√©l√©travailler 2 jours par semaine
Nous proposons une
r√©mun√©ration selon profil + Participation + Int√©ressement
Locaux situ√©s au pied du RER A ‚Äì Noisy le Grand Mont d‚ÄôEst
‚ùó Mobilize Financial Services d√©m√©nage ‚ùó Les postes √† pourvoir en r√©gion parisienne seront bas√©s √† Boulogne Billancourt √† horizon 2026
Pour en savoir plus sur notre entreprise,
suivez-nous sur LinkedIn !
La route du recrutement ?
üìû Un rapide entretien t√©l√©phonique,
üõë
un premier √©change
avec Marie DE CARLI, Responsable du d√©partement DATA
‚Ü™ et un dernier virage avec Agathe GROSBOIS, Responsale des Ressources Humaines
L‚Äô√©quipe Mobilize FS a h√¢te de vous recevoir !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau'], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Cloud'], 'FrSoftSkills': ['Communication', 'Collaboration', 'Organisation'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (H/F),MP DATA,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-mp-data-3908719610?position=47&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=ow485J5mRO5KVr5k5FP7Jg%3D%3D&trk=public_jobs_jserp-result_search-card,"MP DATA est une soci√©t√© sp√©cialis√©e dans l‚Äôacquisition, le traitement, et la valorisation des donn√©es.
Depuis sa cr√©ation en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance et l‚Äôexploitation de leurs donn√©es.
Les collaborateurs, tous issus de grandes √©coles, incarnent au quotidien les valeurs d‚ÄôExcellence, de Partage et d‚ÄôEngagement.
Ils associent savoir-faire technique, m√©thodologie et passion et mettent leurs comp√©tences au service de missions et projets au sein de grands groupes fran√ßais.
MP DATA accompagne ses clients sur toute la chaine au travers de 3 p√¥les d‚Äôexpertise : Conseil et Strat√©gie, Infrastructure & CloudOPS, Data Science.
Chez MP DATA, les √©quipes commerciales cherchent des missions en fonction des envies des collaborateurs et non pas l‚Äôinverse. Les consultants sont accompagn√©s dans tous leurs projets, de la mobilit√© g√©ographique, au changement de secteur d‚Äôactivit√© en passant par le d√©veloppement de nouvelles comp√©tences.
Rejoindre MP DATA, c‚Äôest la garantie de travailler sur des sujets passionnants avec un cadre technique fort.
Descriptif du poste :
Nous recherchons un Data Engineer exp√©riment√© pour rejoindre notre √©quipe.
En tant que Data Engineer, vous serez responsable de la conception, du d√©veloppement et de la mise en ≈ìuvre de pipelines de traitement de donn√©es en temps r√©el √† grande √©chelle.
Vous travaillerez avec des technologies telles que Kafka, Flink, Kinesis et vous utiliserez les services du cloud AWS pour stocker et traiter les donn√©es.
Vos responsabilit√©s :
Utiliser Kafka pour le traitement de flux de donn√©es en temps r√©el √† grande √©chelle, en travaillant avec les producteurs, les consommateurs et les topics.
Mettre en ≈ìuvre des pipelines de traitement de donn√©es en streaming avec Flink, en appliquant des transformations complexes et en g√©rant les √©tats.
√âcrire du code efficace et maintenable en Java / Python pour manipuler et analyser les donn√©es en temps r√©el.
Utiliser Kubernetes pour d√©ployer et g√©rer des applications conteneuris√©es √† grande √©chelle, en assurant la r√©silience et l‚Äô√©volutivit√© des services.
Utiliser les services AWS tels que Amazon S3, AWS Lambda, Elastic Kubernetes Service (EKS), Elastic Container Service (ECS) et Elastic Compute Cloud (EC2) pour le stockage, le traitement et le calcul des donn√©es en temps r√©el.
Suivre les meilleures pratiques pour une utilisation efficace du cloud, en assurant la gestion des co√ªts, la s√©curit√© des donn√©es et la disponibilit√© des services.
Collaborer avec l‚Äô√©quipe de d√©veloppement logiciel et la gestion de projets pour assurer un flux de d√©veloppement fluide et une livraison efficace des fonctionnalit√©s.
Bon √† savoir :
CDI / ASAP / Toulouse
Profil recherch√©:
Nous recherchons un candidat dipl√¥m√© d'une grande √©cole d'Ing√©nieur avec une premi√®re exp√©rience.
Comp√©tences n√©cessaires :
Exp√©rience significative dans un environnement industriel en mode DevOps, avec des outils tels que CICD, gitlab, Jenkins, Sonar, Nexus, XLdeploy, Camunda, etc.
Ma√Ætrise des langages de programmation tels que Python, Java et expertise dans l‚Äô√©criture et l‚Äôoptimisation du code SQL
Ma√Ætrise du fran√ßais et bonne maitrise de l‚Äôanglais.
Capacit√© √† travailler en √©quipe et esprit d‚Äô√©quipe.
Le processus de recrutement se d√©roule en 3 entretiens :
Prise de contact
1er entretien : Pr√©sentation et projet du candidat + pr√©sentation MP DATA
2√®me entretien : Entretien de qualification technique
3√®me entretien : Rencontre avec les √©quipes dans les locaux MP DATA + Proposition de collaboration
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data engineer python,FINAXYS,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-python-at-finaxys-3887107285?position=48&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=vr485KzJPECM8NQIBq1TcQ%3D%3D&trk=public_jobs_jserp-result_search-card,"LE CONTEXTE
Leader en
IT
, dans les domaines Banque
,
Finance
et
Assurance
,
Finaxys
est un cabinet de
conseil
cr√©√© en 2008. Nous accompagnons au quotidien les plus grandes banques du pays sur leur
transformation digitale
(BNP Paribas, Soci√©t√© G√©n√©rale, Cr√©dit Agricole, Natixis, etc.)
Nos clients bancaires travaillent √©galement dans des contextes Big Data sur des applications centrales rattach√©es aux Datalakes.
LES MISSIONS
D√©veloppement et traitements sur des applications Big Data (Python)
√ätre force de proposition sur les choix techniques les plus pertinents
Maintenir la qualit√© des solutions, mesure de cette qualit√©, alerte sur les non-conformit√©s et validation des solutions d√©finitives.
Analyser des risques li√©s aux solutions envisag√©es et proposition des actions de rem√©diation.
Apporter des solutions IT r√©pondant au mieux aux besoins du business port√© par la/le Product Owner (M√©tiers/Fonctions) en cherchant toujours la maximisation de la valeur g√©n√©r√©e
Accompagner les √©quipes dans les migrations Cloud
ENVIRONNEMENT TECHNIQUE
Python
Pandas
Scirpting Big Data
Culture DevOps (Jenkins, Maven, Ansible)
PROFIL
Comp√©tences Techniques et Fonctionnelles requises
Maitrise obligatoire de l‚Äôanglais
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data engineer,SEVETYS,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-sevetys-3905649273?position=49&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=s9WJPofDRfEwiXXMXYrTmg%3D%3D&trk=public_jobs_jserp-result_search-card,"Sevetys, premier groupe fran√ßais de cliniques v√©t√©rinaires, est pr√©sent dans toute la France avec plus de 150 √©tablissements. Cr√©√© en 2016, le groupe souhaite moderniser le m√©tier et mettre la qualit√© des soins et la satisfaction client au c≈ìur de son projet.
Le projet d‚Äôentreprise se caract√©rise par son hyper croissance et une culture de type start-up ax√©e sur le collectif, la coh√©sion, et l‚Äôengagement.
Fort de son succ√®s, Sevetys poursuit sa structuration et recrute un / une :
Data Engineer
‚ÄãLe
Data Engineer
travaille en √©troite collaboration avec une √©quipe Agile pluridisciplinaire pour construire des pipelines de donn√©es de haute qualit√© permettant de mettre en ≈ìuvre des solutions analytiques. Ces solutions g√©n√®reront des informations √† partir de nos donn√©es collect√©es, permettant de faire progresser les capacit√©s de prise de d√©cision du management de l‚Äôentreprise. Ce r√¥le n√©cessite une compr√©hension approfondie de l'architecture des donn√©es, de l'ing√©nierie des donn√©es, de l'analyse des donn√©es, du reporting. Le candidat id√©al est un ing√©nieur en donn√©es/logiciel ayant au moins une premi√®re exp√©rience dans la cr√©ation de produits de donn√©es soutenant des solutions analytiques.
Missions :
Con√ßoit, d√©veloppe, optimise et maintient une architecture de donn√©es et des pipelines qui respectent les objectifs de l'entreprise ;
R√©sout des probl√®mes de donn√©es afin de fournir des informations qui aident notre entreprise √† atteindre ses objectifs ;
Cr√©e des jeux de donn√©es pour les membres de l'√©quipe d'analyse afin d'am√©liorer leur productivit√© ;
Favorise une culture du partage, de la r√©utilisation, de la stabilit√© de la conception √† l'√©chelle et de l'efficacit√© op√©rationnelle des donn√©es et des solutions analytiques ;
Contribue √† l'√©valuation, la mise en ≈ìuvre et le d√©ploiement d'outils et de processus √©mergents pour l'ing√©nierie des donn√©es analytiques afin d'am√©liorer notre productivit√© en tant qu'√©quipe ;
√âlabore et met en ≈ìuvre des plans de communication/√©ducation sur les capacit√©s, les normes et les processus d'ing√©nierie des donn√©es analytiques ;
Travaille en partenariat avec des analystes business et des architectes de solutions pour d√©velopper des architectures techniques pour les projets et initiatives strat√©giques de l'entreprise.
Expertises techniques :
Exp√©rience du d√©veloppement de bases de donn√©es et d'une vari√©t√© de technologies de bases de donn√©es relationnelles ;
Exp√©rience des entrep√¥ts de donn√©es ;
Expertise en SQL et en analyse de donn√©es ; ma√Ætrise Python ;
Id√©alement certifi√© des technologies BI du Cloud Azure (Synapse, Azure Data Factory, PurView) ;
Connaissance de l'intelligence artificielle, des statistiques et/ou des math√©matiques appliqu√©es ;
Exp√©rience dans le d√©veloppement de solutions sur des services et infrastructures de cloud computing dans le domaine des donn√©es et de l'analyse ;
Exp√©rience du d√©ploiement de Power BI ;
Exp√©rience conceptuelle des donn√©es et de l'analyse, par exemple ETL, mod√©lisation dimensionnelle, outils de reporting, gouvernance des donn√©es, entreposage des donn√©es, donn√©es structur√©es et non structur√©es, qualit√© de donn√©es ;
Connaissance CI/CD et GitLab fortement appr√©ci√©.
Exp√©rience agile / Digitale / gouvernance :
Passionn√©(e) le d√©veloppement bas√© sur les donn√©es, la fiabilit√© et l'exp√©rimentation ;
Exp√©rience souhait√©e de travail au sein d'une √©quipe produit Agile collaborative ;
Connaissance de la gouvernance de la donn√©e.
Skills Individuels :
Motiv√©(e) et dot√©(e) de solides comp√©tences en mati√®re de r√©solution de probl√®mes et d'apprentissage ;
Flexibilit√© face aux changements d'orientation du travail au fur et √† mesure de l'√©volution du projet ;
Excellentes capacit√©s de communication, d'√©coute et de persuasion.
Attitude attendue :
Sens aigu des chiffres, curiosit√© intellectuelle et volont√© d'adapter sa position sur la base d'informations compl√©mentaires ;
Forte √©thique de travail ; capacit√© √† travailler √† un niveau abstrait et √† obtenir un consensus.
Informations suppl√©mentaires :
Poste √† pourvoir d√®s que possible ;
Remboursement des frais de transports + Mutuelle ;
Possibilit√© de t√©l√©travail jusqu'√† un jour par semaine.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': ['Statistiques'], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Statistiques', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication', 'R√©solution de probl√®mes', 'Collaboration', 'Flexibilit√©'], 'EnSoftSkils': ['Communication', 'Collaboration', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
DATA ENGINEER,Apside,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-at-apside-3909772916?position=50&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=j2LW3ztW%2Bq%2B5gYaNxbUPPQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Offre d'Emploi : DATA ENGINEER H/F chez Apside
Description du poste :
Nous sommes √† la recherche d'un Data Engineer passionn√© pour rejoindre notre √©quipe dynamique. Si vous avez une expertise dans le Big Data, la Data Science, l'analyse de donn√©es et l'architecture de donn√©es, cette opportunit√© est faite pour vous. Int√©grer notre communaut√© Data, c‚Äôest l‚Äôassurance de progresser, innover, partager, vous certifier et rendre service √† nos clients.
Vos missions :
D√©veloppement des jobs Spark pour la collecte et la transformation des donn√©es comptables disponibles dans les bucket S3.
Optimisation des jobs Spark.
D√©veloppement des batchs Java et √©criture des donn√©es au formats comptables.
√âcriture et ordonnancement des DAGs Airflow.
Support du d√©veloppement Spark Scala.
Maintenance applicative.
Production des √©v√©nements d√©di√©s √† la plateforme de donn√©es.
.
Votre r√¥le, vos comp√©tences :
Vous ma√Ætrisez au minimum un langage de programmation appliqu√© √† l‚Äôanalyse de donn√©es (SQL, Scala, Python, Java).
Vous √™tes passionn√© par le Big Data et le Machine Learning.
Vous concevez et mettez en ≈ìuvre des strat√©gies s√©curis√©es d'acquisition et d'int√©gration de donn√©es.
Vous configurez des r√©f√©rentiels de donn√©es √† la pointe de la technologie dans des environnements distribu√©s, majoritairement dans le cloud (Google Cloud Platform, Azure, AWS) et/ou en environnement Hadoop (distribution MapR, Cloudera, Hortonworks).
Environnement technique :
SQL
Python/Spark
Cloud AWS: AWS Glue, AWS Lambda (possibilit√© de vous former sur AWS)
Stockage objet (AWS S3)
Orchestration et scheduling de t√¢ches (Apache Airflow)
Bases analytiques et bases NoSQL (ElasticSearch, AWS Athena)
Votre profil :
Fort de 4 ann√©es d‚Äôexp√©rience en Data Engineer/ DATA ANALYST
Titulaire d‚Äôune formation sup√©rieure IT.
Capacit√© √† s‚Äôint√©grer dans un cadre technique client tout en √©tant √† m√™me de proposer des pistes d‚Äôam√©liorations pertinentes.
Autonome dans la gestion des projets.
Curieux et impliqu√©, vous √™tes bon communicant avec les clients et les acteurs de culture technique diff√©rente.
De bonnes raisons de rejoindre Apside ?
Un esprit start-up avec la stabilit√© d‚Äôun grand groupe, qui favorise l‚Äôagilit√©, le travail d‚Äô√©quipe et la proximit√©. Alors qu‚ÄôApside ne cesse d‚Äôagrandir sa famille d√©j√† forte de plus de 3000 consultants, nous sommes √† la recherche de nos nouveaux talents !
CDI + package salarial avantageux (Mutuelle offerte, RTT, Tickets Restaurant, Int√©ressement ...)
Participez et animez nos soir√©es techniques (Project Lab, Test Lab‚Ä¶),
Devenez speaker (Devoxx, DevFest, NCraft‚Ä¶),
Formez vous avec l‚ÄôAcademy By Apside (e-learning, formation, certification).
D√©veloppez votre r√©seau (Soir√©es trimestrielles, Afterwork, Soir√©es d‚Äôint√©gration‚Ä¶),
Int√©grez notre Communaut√©s d‚ÄôExperts et testez les derni√®res innovations techniques sur notre Bac √† Sable !
Apside s‚Äôengage en faveur de l‚Äôemploi des personnes en situation de handicap avec sa filiale Apsid‚ÄôEA : 1√®re entreprise adapt√©e totalement int√©gr√©e √† une ESN !
Pour aller plus loin avec APSIDE !
https://www.apside.com/fr/nos-offres-emploi/?_joboffer-agency=17833&_paged=2
Ce poste de DATA ENGINEER est fait pour vous !
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Apache Airflow'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['17833'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer Senior,AXA en France,"Hauts-de-Seine, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-senior-at-axa-en-france-3884386043?position=51&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=sDPS1GxZYKSqOr7DXdMrjQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Environnement
En tant que
Senior Data Engineer F/H
, vous allez contribuer directement aux projets des directions m√©tier (ex : fraude sant√©, multi√©quipements, pricing IARD, optimisation du lead management, fragilit√© auto, ‚Ä¶) d‚ÄôAXA France et √† la construction du socle technique Big Data.
Vous allez int√©grer une √©quipe d'une dizaine de personne compos√©e de Data Engineer et des Tech Lead travaillant en mode Feature Team au sein des tribus m√©tier de la Direction Transformation Digital Tech et DATA (DT2).
La Direction Transformation Digital Tech et DATA d'AXA France en quelques mots :
- Une organisation agile en feature teams : tribus, guildes, squads
- Des projets sur des applications innovantes √† fort trafic (web, mobile‚Ä¶)
- Des m√©thodologies craft (TDD, BDD, clean code, code review‚Ä¶) et DevOps
- Une communaut√© de partage de bonnes pratiques (BBL, dojo, meetup, conf‚Ä¶)
Votre r√¥le et vos missions
Vous aurez pour missions principales de d√©velopper les projets Big Data demand√©s par le m√©tier, et notamment :
Passer de la donn√©e brute √† de la donn√©e exploitable, expos√©e sous forme de tables requ√™tables dans le datalake
Consolider ces donn√©es au fur et √† mesure de leur alimentation r√©currente dans le data lake
Les exploiter pour atteindre la finalit√© business (exposition de business view, r√©int√©gration des r√©sultats dans le SI, service de scoring, ‚Ä¶)
De travailler √† la cr√©ation du socle technique Big Data et industrialiser le cycle de d√©veloppement de l'√©quipe
De mettre en place et de garantir le respect dans la dur√©e d'un processus qualit√© sur l'ensemble du cycle de DEV (documents, tests unitaires / int√©gration / fonctionnels, commentaires, versionning, etc.)
Votre profil
Vous justifiez de plusieurs exp√©riences significatives (+ de 5 ans) sur du
d√©veloppement big data, en particulier sur du PySpark.
Comp√©tences techniques :
Connaissances avanc√©es en d√©veloppement en
PySpark
(Spark avec le langage Python)
Maitrise de l'environnement
Microsoft Azure
Connaissances avanc√©es d'outils de BI comme
PowerBI
Comp√©tences transverses :
Capacit√© √† interagir avec des parties prenantes diverses : Business analyst, Architectes, M√©tier
Exp√©rience en mode de delivery Agile (Scrum, Kanban, etc...)
Driver et accompagner des Data Engineer junior sur les aspects technique
Et Id√©alement :
Des Connaissances sur Azure DevOps, Azure Pipeline, GIT, JIRA
Maitrise des Traitements Big Data en mode Streaming
Maitrise des Bases de donn√©es relationnelles et NoSQL
Une exp√©rience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory
Qui sommes nous ?
AXA est un des leaders de l‚Äôassurance et de la gestion d‚Äôactifs dans le monde.
Nous aidons nos 108 millions de clients √† traverser les petites et grandes difficult√©s de la vie.
Chaque jour, nous agissons ensemble pour inventer la meilleure mani√®re de les prot√©ger et voulons donner √† chacun les moyens de vivre une vie meilleure.
Un challenge qui donne le sourire et envie de se lever le matin !
Chez AXA, nous sommes persuad√©s que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs. C‚Äôest pour cette raison que nous menons une politique RH engag√©e qui favorise la diversit√©, qui pr√©serve l‚Äô√©quilibre vie priv√©e-vie professionnelle et acc√©l√®re le d√©veloppement des comp√©tences et des carri√®res.
Ainsi, en rejoignant AXA France vous travaillerez dans une entreprise responsable, offrant une v√©ritable culture d‚Äôexpertise, acc√©l√©rant le d√©veloppement des comp√©tences de chacun et proposant une r√©mun√©ration attractive.
Pourquoi nous rejoindre ?
Vous √™tes porteur d‚Äôid√©es et d‚Äôinitiatives innovantes ? Vous proposez des solutions et √™tes au service du client ? Faites partie de notre grande famille en rejoignant
Un leader mondial offrant des opportunit√©s de carri√®res int√©ressantes
Une entreprise qui donne une place de choix √† l‚Äôinnovation, √† l‚Äôinitiative et aux actions solidaires (notamment via l‚Äôassociation AXA Atout C≈ìur)
Un environnement inclusif √† tous les niveaux (mixit√©, handicap, initiatives pour favoriser l‚Äôinsertion des jeunes, orientation sexuelle, etc.)
Un acc√®s √† de multiples avantages (cong√©s, temps partiel, t√©l√©travail, etc.)
Un cadre stimulant, qui permet de rencontrer des collaborateurs performants et d‚Äôenrichir ses comp√©tences
Victime ou t√©moin, en cas de discrimination, vous pouvez adresser vos signalements et/ou alertes discrimination √† alerte.discrimination.harcelement@axa.fr
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['JIRA', 'Teams'], 'Other': ['DevOps', 'Big Data'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': ['Junior', 'Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Engineer,Beelix,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-beelix-3865239426?position=52&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=RbppPHyc%2Ba%2B6Xq1WS%2FNoKQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ?
Depuis 2016, nous accompagnons nos clients sur des probl√©matiques de Product Management, Data et Design Thinking. Beelix contribue √† fa√ßonner le monde de demain en participant aux grandes avanc√©es des secteurs suivants:
üöóAutomobile
‚ö°Energie
üì°M√©dias & T√©l√©coms
üëóLuxe & Retail
üí∂ Banque, Finance & Assurance
‚úàÔ∏èD√©fense
Aujourd‚Äôhui, Beelix compte plus de 200 collaborateurs motiv√©s et dynamiques. Lab√©lis√©e Great Place To work en 2023, Beelix est aussi une entreprise engag√©e o√π il fait bon vivre.
Dans le cadre de notre d√©veloppement, nous recherchons un Data Engineer en √éle-de-France.
Quelles missions au quotidien ?
Vous aurez pour missions principales de d√©velopper les projets Big Data demand√©s par le m√©tier, et notamment :
Passer de la donn√©e brute √† de la donn√©e exploitable, expos√©e sous forme de tables requ√™tables dans le Datalake
Consolider ces donn√©es au fur et √† mesure de leur alimentation r√©currente dans le Datalake
Les exploiter pour atteindre la finalit√© business (exposition de Business View, r√©int√©gration des r√©sultats dans le SI, service de scoring, ‚Ä¶)
De mettre en place et de garantir le respect dans la dur√©e d'un processus qualit√© sur l'ensemble du cycle de DEV (documents, tests unitaires / int√©gration / fonctionnels, commentaires, versionning, etc.)
Accompagner les Data Engineers sur son p√©rim√®tre pour garantir la qualit√© des livrables
Expertise souhait√©e
Expertise en SPARK et PySpark
Expertise sur Databricks
Une exp√©rience sur un cloud provider public comme Azure (id√©alement), AWS, ou GCP
Connaissances avanc√©es d'outils de BI comme PowerBI (id√©alement) ou Spotfire
Capacit√© √† interagir avec des parties prenantes diverses : Business analyst, Architectes, M√©tier
Etre expert dans les pratiques du Software Craftsmanship (Test Driven Development, Behavior Driven Development, Clean Code, Code Reviews, etc.)
Des Connaissances sur Azure DevOps, Azure Pipeline, GIT
Maitrise des Traitements Big Data en mode Streaming
Maitrise des Bases de donn√©es relationnelles et NoSQL
Une exp√©rience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory
A propos de vous ?
Dipl√¥m√© d'une √©cole d'ing√©nieurs ou √©quivalent
Au moins 3 ans d'exp√©rience en tant que Data Engineer
Exp√©rience en mode de Delivery Agile (Scrum, Kanban, etc.‚Ä¶)
Vous avez un bon niveau d‚Äôanglais tant √† l‚Äô√©crit qu‚Äô√† l‚Äôoral
Pourquoi nous rejoindre ?
Un suivi et un accompagnement au quotidien
Un organisme de formation certifi√© Qualiopi, un abonnement linkedin learning pour chaque salari√© et des partenariats avec des sp√©cialistes pour d‚Äôautres expertises
De nombreux √©v√©nements : Afterworks, Communaut√©s m√©tiers, Happy talks‚Ä¶
une Exp√©rience personnalis√©e bas√©e sur vos besoins gr√¢ce au Pr√©dictive Index
Notre package ¬´ unBeelievable ¬ª : 100% du titre de transport, Tickets restaurants, CSE, Prime de participation ...
Nombreux √©v√®nements (afterworks, sport, etc) et des communaut√©s m√©tiers dynamiques
Le processus de recrutement ?
√âchange t√©l√©phonique (15 min)
Entretien 1 RH pour apprendre √† vous conna√Ætre
Entretien 2 avec votre futur N+1 pour appr√©hender la relation manag√©riale
Entretien 3 avec un Responsable commercial pour avoir la vision strat√©gique
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['100'], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer,CGI,"Niort, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-at-cgi-3902057928?position=53&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=yvn5h2BSifUPF6%2FPZkJ7xg%3D%3D&trk=public_jobs_jserp-result_search-card,"Description de poste
Big Data, Data Science, Data analyse, Data architecture ... √áa n‚Äôa pas de secret pour vous ?
Que vous commenciez votre carri√®re professionnelle ou que vous soyez sp√©cialiste de l‚Äôune de ces disciplines, int√©grer notre communaut√© Data, c‚Äôest l‚Äôassurance de progresser, innover, partager, vous certifier et rendre service √† nos clients.
Si vous souhaitez int√©grer nos √©quipes √† Niort et accompagner les plus grands acteurs du secteur des Assurances, cette annonce est susceptible de vous int√©resser.
En tant que Data Engineer, vous serez responsable de la conception, du d√©veloppement, de la gestion et de l'int√©gration des syst√®mes bas√©s sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop. Ce r√¥le implique la mise en place d'architectures √©volutives et hautement disponibles pour r√©pondre aux besoins de traitement et de stockage de donn√©es de l'entreprise.
Fonctions et responsabilit√©s
Vos responsabilit√©s seront les suivantes:
-Maintenir et d√©velopper des solutions bas√©es sur les services AWS pour le stockage, le traitement et l'analyse de donn√©es
-Utiliser les services AWS appropri√©s tels que Amazon EC2, S3, RDS, Lambda, etc., pour r√©pondre aux exigences du projet.
-Cr√©er et maintenir les configurations Terraform pour la gestion de l'infrastructure en tant que code (IaC) sur AWS
-Participer √† la maintenance et √† la mise en place d'environnements OpenShift pour l'h√©bergement d'applications et de services
-G√©rer et administrer les clusters Kafka pour garantir la disponibilit√©, la performance et la s√©curit√© du syst√®me de messagerie
Participer √† l‚Äôassistance utilisateurs sur les briques de la plateforme Hadoop Cloudera Data
-Travailler avec les projets et les devOps pour assurer un traitement efficace des donn√©es
En rejoignant CGI, vous b√©n√©ficiez notamment d‚Äôune offre compl√®te de formations (techniques, m√©tiers, d√©veloppement personnel,‚Ä¶), de flexibilit√© gr√¢ce √† notre accord t√©l√©travail (jusqu‚Äô√† 3 jours de t√©l√©travail par semaine), d‚Äôune politique de cong√©s avantageuse (27 jours de cong√©s pay√©s, RTT, cong√©s anciennet√© et enfant malade,‚Ä¶) et d‚Äôun package d‚Äôavantages int√©ressant (r√©gime d‚Äôachats d‚Äôactions, participation, CSE,...).
Qualit√©s requises pour r√©ussir dans ce r√¥le
Ayant une premi√®re exp√©rience en tant que Data Engineer, vous avez une premi√®re exp√©rience relative aux points suivants:
-D√©veloppement et int√©gration sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop
-Connaissance avanc√©e de l'administration Kafka, y compris la configuration, la gestion et la r√©solution des probl√®mes
-Mise en ≈ìuvre de l'infrastructure en tant que code √† l'aide de Terraform
-Bonne compr√©hension des bonnes pratiques de s√©curit√© pour les syst√®mes cloud, les clusters Kafka et les plateformes Hadoop
CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, √† l‚Äô√©volution de carri√®res des hommes et des femmes et au bien-√™tre de nos salari√©s LGBT+. Dans un souci d‚Äôaccessibilit√© et de clart√©, le point m√©dian n‚Äôest pas utilis√© dans cette annonce. Tous les termes employ√©s se r√©f√®rent aussi bien au genre f√©minin que masculin.
Ensemble, en tant que propri√©taires, mettons notre savoir-faire √† l‚Äô≈ìuvre.
La vie chez CGI est ancr√©e dans l‚Äôactionnariat, le travail d‚Äô√©quipe, le respect et un sentiment d‚Äôappartenance. Chez nous, vous pourrez exploiter votre plein potentiel parce que‚Ä¶
Nous vous invitons √† devenir propri√©taire d√®s le jour 1 alors que nous travaillons ensemble √† faire de notre r√™ve une r√©alit√©. C‚Äôest pourquoi nous nous d√©signons comme associ√©s de CGI, plut√¥t que comme employ√©s. Nous tirons profit des retomb√©es de notre succ√®s collectif et contribuons activement √† l‚Äôorientation et √† la strat√©gie de notre entreprise.
Votre travail cr√©e de la valeur. Vous √©laborerez des solutions novatrices et d√©velopperez des relations durables avec vos coll√®gues et clients, tout en ayant acc√®s √† des capacit√©s mondiales pour concr√©tiser vos id√©es, saisir de nouvelles opportunit√©s, et b√©n√©ficier d‚Äôune expertise sectorielle et technologique de pointe.
Vous ferez √©voluer votre carri√®re en vous joignant √† une entreprise b√¢tie pour cro√Ætre et durer. Vous serez soutenus par des leaders qui ont votre sant√© et bien-√™tre √† c≈ìur et qui vous permettront de saisir des occasions afin de parfaire vos comp√©tences et √©largir les horizons.
Joignez-vous √† nous, l‚Äôune des plus importantes entreprises de conseil en technologie de l‚Äôinformation (TI) et en management au monde.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['OpenShift'], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Flexibilit√©'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['1'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,PROXIAD,Greater Nice Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-at-proxiad-3901014428?position=54&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=oOSHoRrWkL6odgpXOOrPXg%3D%3D&trk=public_jobs_jserp-result_search-card,"Contexte
En tant que Data Engineer, votre r√¥le consistera √† r√©aliser la conception, le d√©veloppement, les tests unitaires, la qualification, l'int√©gration continue et la mise en production d'√©volutions sur les projets du p√¥le produits scoring.
Ces projets Big Data GCP ont pour objet de d√©velopper des traitements de croisement de donn√©es, exploration data en mode agile (scrum et Safe), industriel (respect de normes), sur l'environnement Google Cloud Platform.
1 : Conception
Sp√©cification et conception d'une solution se basant sur les d√©veloppements existants.
Mettre en question les choix techniques dans le but de concevoir un logiciel r√©pondant au mieux √† la demande au moindre co√ªt et avec la qualit√© demand√©e.
Conception de l'expression de besoins, de la r√©ponse √† l'expression de besoins √† l'aide des besoins m√©tiers remont√©s par le Product Owner.
2 : R√©alisation
D√©veloppement de nouvelles fonctionnalit√©s sur les composants des applications du p√¥le produits scoring en environnement GCP (DataProc, GCS, BigQuery, Airflow...)
Tests des d√©veloppements r√©alis√©s
Revue de code des d√©veloppements des autres d√©veloppeurs
Mise en production via CICD des d√©veloppements
3 : Suivi du RUN applicatif
Prendre en charge avec les autres membres de l'√©quipe le RUN des applications du p√¥le produits scoring. Cela inclus les t√¢ches de rapport quotidien, la gestion des probl√®mes applicatifs, le soutien aux utilisateurs.
Comp√©tences attendues
Ma√Ætrise op√©rationnelle :
Confluence
Impl√©mentation de l‚Äôint√©gration continue (Utilisation de la chaine CI/CD existante )
Connaissance des principes DevOps
Jira
Anglais (lu, √©crit)
Ma√Ætrise avanc√©e :
Elaborer un cahier de recette
Big Query
Sp√©cifications technique et documentation
D√©veloppement :Python, SQL, Scala, Javascript, GitLab
Expertise
GCP : Exp√©rience significative en tant que Data Engineer Cloud. Mise en pratique des produits GCP et en particulier Dataproc, Big Query, composer, workflow, PubSub
D√©veloppement : Java
Compr√©hension g√©n√©rale des travaux BigData et du profiling
Informations compl√©mentaires :
T√©l√©travail 2 jours par semaines
R√©mun√©ration aux alentours des 45K‚Ç¨
Exp√©rience requise : 6 ans
Localisation : Mougins
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go', 'JavaScript'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery', 'Big Query'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['JIRA', 'Confluence'], 'Other': ['DevOps', 'Big Data', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '6', '6', '6']}"
CDI - DATA ENGINEER SPARK SCALA JUNIOR - H/F,ITNOVEM.,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/cdi-data-engineer-spark-scala-junior-h-f-at-itnovem-3899544280?position=55&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=AJXOr6PxIG7iPzlY%2F0%2FWWA%3D%3D&trk=public_jobs_jserp-result_search-card,"ITNOVEM, qui sommes-nous ?
Filiale technologique du groupe SNCF, int√©gr√©e √† la Direction du Digital et des Syst√®mes d‚Äôinformation, Itnovem
.
se positionne comme expert de l‚ÄôInternet Industriel. Porteuse de grands projets de la r√©volution digitale, notre soci√©t√© est en constante recherche de profils pour rejoindre la grande aventure de l‚ÄôInternet des objets, de la data science et de l‚Äôaccompagnement des projets digitaux.
Qu‚Äôil s‚Äôagisse de maintenance pr√©dictive, d‚Äôaide √† la d√©cision sur la maintenance des infrastructures, de gare 4.0, d‚Äôusine du futur, ou de s√©curisation des assets, nos √©quipes font valoir √† la fois une exp√©rience m√©tier et une expertise technique sans cesse renouvel√©e, dans le respect des valeurs du groupe :
Excellence
,
Innovation
,
Collectif
,
Agile
,
Engagement.
CONTEXTE
Au sein du p√¥le Factory Data & IA et dans le cadre de la mont√©e en charge des projets, nous sommes √† la recherche d'un¬∑e data engineer Scala/Spark junior.
Rattach√©¬∑e aux √©quipes Data Engineering et en collaboration avec les membres de l‚Äô√©quipe, son r√¥le sera de contribuer aux projets data sur stack Scala/Spark et √† l‚Äôam√©lioration de l‚Äôoutillage et des process internes.
Le recrutement intervient dans le cadre de la cr√©ation d‚Äôun plateau projet d√©di√© √† l‚Äôactivit√© TGV sur Nantes.
MISSIONS
Participer au d√©veloppement des projets data sur stack Scala/Spark
Etre acteur de la mise en place de bonnes pratiques de communication entre les plateaux nantais et parisiens
Avec l‚Äôappui de l‚Äô√©quipe, √™tre impliqu√©¬∑e dans la roadmap technologique (pratiques, outils) et de l‚Äôam√©lioration continue du p√©rim√®tre Scala/Spark
Contribuer proactivement √† la qualit√© et aux comp√©tences des √©quipes Data Science et Engineering : veille techno, capitalisation‚Ä¶
LE PROFIL RECHERCHE
Comp√©tences m√©tiers & outils :
Exp√©rience professionnelle (alternance, stage) ou acad√©mique sur le langage Scala et le d√©veloppement d‚Äôapplications Spark
Connaissances autour du SQL (principes, langage, mod√©lisation)
App√©tence sur les aspects fonctionnels et m√©tiers d‚Äôun projet
Notions de CI/CD (notre stack : Maven, Gitlab, Jenkins, Artifactory, Ansible)
Comp√©tences transverses :
Int√©r√™t prononc√© pour le software engineering
Aisance relationnelle
Proactivit√© et clart√© dans la communication
Rigueur et organisation
Force de proposition
Bonne communication √©crite et orale
Exp√©riences et formations
Titulaire d‚Äôun bac+5 sp√©cialis√© g√©nie logiciel / d√©veloppement ou exp√©rience √©quivalente.
Vous venez d‚Äôobtenir votre dipl√¥me ou occupez d√©j√† votre premier poste dans le domaine du d√©veloppement de pipelines Data.
Localisation
Poste bas√© √† Saint Denis, possiblement √† Lyon
T√©l√©travail jusqu‚Äô√† 3 jours par semaine.
D‚Äôautres raisons de rejoindre ITNOVEM !
üöÄ En tant que filiale SNCF, des opportunit√©s de carri√®res internes vous sont offertes.
üìö ITNOVEM croit en la formation continue de ses collaborateurs et leur donne l‚Äôopportunit√© de s‚Äôinscrire √† une formation par an minimum.
üöä Vos titres de transport sont pris en charge √† hauteur de 75%.
üçΩÔ∏è Via la carte titres-restaurant Swile, vous b√©n√©ficiez de 9,25 ‚Ç¨ par jour dont 60% pris en charge par ITNOVEM.
üíª Chez ITNOVEM, vous b√©n√©ficiez jusqu‚Äô√† 3 jours de t√©l√©travail par semaine.
üèñÔ∏è ITNOVEM vous permet de profiter de 28 cong√©s et de 16 RTT pour les cadres et 10 pour les non-cadres. Par ailleurs, 2 des 3 jours de cong√©s pour enfant malade sont r√©mun√©r√©s.
üë´ La mise en ≈ìuvre de l‚Äô√©galit√© professionnelle femmes/hommes est primordiale chez ITNOVEM. A chaque nouvelle embauche, l'entreprise s'engage √† proposer une r√©mun√©ration √©quivalente tant aux femmes qu'aux hommes.
‚ôªÔ∏è ITNOVEM incite tous les collaborateurs √† trier leurs d√©chets et les gobelets ont √©t√© bannis. Par ailleurs, chaque ann√©e, ITNOVEM participe √† ¬´ La grande collecte ¬ª, une initiative SNCF qui permet de collecter les PC devenus obsol√®tes en leur offrant une seconde vie
Show more
Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['CI/CD'], 'FrSoftSkills': ['Communication', 'Collaboration', 'Organisation'], 'EnSoftSkils': ['Communication', 'Collaboration', 'Initiative']}","{'JobDetail': ['Junior'], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
Junior Data Engineer (H/F/N),Ekimetrics,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/junior-data-engineer-h-f-n-at-ekimetrics-3903416527?position=56&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=hLcIMdf1paDtm%2BnDr8qtJg%3D%3D&trk=public_jobs_jserp-result_search-card,"Ekimetrics
est leader en data science et fournisseur de solutions AI. Depuis 2006, nous utilisons la data science au service de l‚Äôoptimisation de performance marketing, business, et de la transition vers une performance plus durable.
Si vous √™tes passionn√©.e de data, ou de technologie en g√©n√©ral, et que vous avez envie d‚Äô√™tre acteur.rice de votre avenir professionnel, votre place est s√ªrement chez Ekimetrics !
üìäEkimetrics, c‚Äôest:
‚Ä¢ 400 expert.e.s en data science
‚Ä¢ 1000 projets divers et vari√©s pour plus de 350 clients
‚Ä¢ 4 bureaux : Paris, Hong Kong, Londres et New York
‚Ä¢ 1 milliard de $ de profits g√©n√©r√©s pour nos clients depuis 2006
‚Ä¢ 7000 tonnes de CO2 √©vit√©es pour nos clients en 2022
üå±Chez Ekimetrics, nous avons l‚Äôambition d‚Äôaccompagner nos clients √† repenser leur business model, en r√©conciliant performance √©conomique, environnementale et sociale, gr√¢ce √† la data science.
C‚Äôest pourquoi nous avons en interne toutes les comp√©tences nous permettant de r√©pondre aux besoins de nos clients: Product Managers, Product Designers, Data Architects, Data Engineers, DevOps Engineers, Data Scientists.
Pourquoi recrutons-nous ?
En tant que Data Engineer, vous serez impliqu√© dans des projets stimulants avec des clients internationaux de premier plan dans des industries diverses, en construisant des solutions analytiques sur mesure pour r√©pondre aux enjeux de nos clients. Vous travaillerez en √©quipe, avec d'autres consultants Ekimetrics (data engineers, data scientists, software engineers) sur 1 ou 2 projets simultan√©ment. Vous b√©n√©ficierez de nos partenariats technologiques et d‚Äôune offre de formation pour vous accompagner dans votre mont√©e en comp√©tences.
Plus particuli√®rement vos responsabilit√©s seront de
:
‚Ä¢ Concevoir et d√©velopper des solutions permettant de collecter et pr√©parer la donn√©e ;
‚Ä¢ Impl√©menter et industrialiser des pipelines de donn√©es dans des environnements Cloud (Azure, GCP, AWS, Databricks, Snowflake) ;
‚Ä¢ D√©velopper des outils destin√©s √† faciliter l‚Äôex√©cution et le d√©ploiementdes pipelines de donn√©es (CICD, DevOps, MLOps) ;
‚Ä¢ Approfondir vos connaissances en GenAI, Machine Learning, MMO ;
‚Ä¢ Participer aux activit√©s de R&D. (Veille, formations, animation de Meetups, Hackathons, etc.)
Le profil et les comp√©tences recherch√©es
:
‚Ä¢ Bac+ 5 Ecole d'ing√©nieur ou √âquivalent ;
‚Ä¢ Premi√®re exp√©rience sur des sujets Big Data (Projet ou exp√©rience professionnelle) ;
‚Ä¢ Connaissances avanc√©es en base de donn√©es et en d√©veloppement (Python, SQL, Spark) ;
‚Ä¢ Exp√©rience dans un environnement Cloud ;
‚Ä¢ Connaissances avanc√©es en acquisition de donn√©es ;
‚Ä¢ App√©tence pour la Data Science.
ü§ù Pourquoi nous rejoindre ?
Rejoindre Ekimetrics, c‚Äôest int√©grer une entreprise dont les valeurs s‚Äôappliquent au quotidien :
‚Ä¢ Evoluer dans un environnement entrepreneurial et non traditionnel (
#curiosit√©)
‚Ä¢ √ätre capable de donner et recevoir du feedback pour s‚Äôam√©liorer en continu (
#excellence
)
‚Ä¢ Se former d√®s son arriv√©e et en continu gr√¢ce √† une exp√©rience apprenante unique, riche de nombreuses ressources (internes, externes, live et digital) alliant savoirs techniques, savoir-√™tre et savoir-faire (
#transmission
)
‚Ä¢ Faire partie d‚Äôune communaut√© accueillante et soud√©e(
#plaisir
)
‚Ä¢ Imaginer des solutions inattendues & sortir de sa zone de confort (
#cr√©ativit√©
)
En 2023, Ekimetrics a obtenu le statut d‚Äôentreprise √† mission qui t√©moigne de notre ambition forte en mati√®re de RSE. Notre raison d‚Äô√™tre: Faire de la data science et de l‚Äôintelligence artificielle l‚Äôacc√©l√©rateur de la transformation durable des organisations.
Nous sommes √©galement certifi√©s Great Place to Work¬© en France, au Royaume-Uni et aux Etats-Unis, et notre bureau de Hong Kong a re√ßu le prix Best Companies to Work for in Asia 2023¬©.
ü§© Vous aurez acc√®s √†‚Ä¶
‚Ä¢ Au catalogue de formation Eki.Academy qui contient des programmes qui vous feront monter en comp√©tences sur nos solutions et nos m√©tiers, des parcours apprenants sur notre plateforme digitale ainsi que des programmes d√©di√©s √† nos enjeux prioritaires, dont la sensibilisation aux sujets environnementaux avec la Climate School ;
‚Ä¢ Une vie sportive, artistique, musicale, ludique, caritative et engag√©e : de notre salle de sport privatis√©e √† nos expositions d‚Äôart, en passant par des jeux vid√©o et des concerts, ou encore les d√©fis RSE sur la plateforme Vendredi. Toutes ces initiatives sont port√©es par nos Eki.People ;
‚Ä¢ De nombreux √©v√®nements et s√©minaires pour rester proche de votre communaut√© ;
‚Ä¢ Des locaux modernes dans un quartier dynamique au c≈ìur de Paris (Grands boulevards) ;
‚Ä¢ Une politique de t√©l√©travail flexible.
üîÑNotre processus recrutement :
üî∏Un entretien RH avec un.e recruteur.se
üî∏Un test technique ou
peer-to-peer
interview selon profil
üî∏Une √©tude de cas avec un.e consultant.e
üî∏Un entretien final avec un.e Manager ou Partner
Nous serions ravi.e.s de vous donner de plus amples informations lors d‚Äôun entretien et attendons votre candidature avec impatience!
En tant qu‚Äôemployeur, Ekimetrics offre √† tous les m√™mes opportunit√©s d‚Äôacc√®s √† l‚Äôemploi sans distinction de genre, ethnicit√©, religion, orientation sexuelle, statut social, handicap et d‚Äô√¢ge. Ekimetrics veille √† d√©velopper un environnement de travail inclusif qui refl√®te la diversit√© dans ses √©quipes.
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': ['Cr√©ativit√©', 'Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer confirm√© (H/F),BforBank,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-h-f-at-bforbank-3918327555?position=57&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=LptYbqbw0Nw1VKBD9c1ANw%3D%3D&trk=public_jobs_jserp-result_search-card,"Sur le mod√®le d'une
""Tech company"",
BforBank place
l'humain et le digital
au c≈ìur de sa transformation. Notre mission,
offrir √† nos clients une exp√©rience bancaire incomparable
pour r√©pondre √† leurs besoins et usages mobile. üåü üì±
Rejoindre BforBank c‚Äôest
rejoindre une √©quipe engag√©e
dans un
grand projet de d√©veloppement strat√©gique en France et en Europe.
Nous sommes aujourd‚Äôhui 350 passionn√©(e)s et
recherchons nos talents pour construire la banque de demain
. üöÄ
Nous croyons en la force du collectif, chaque jour rassembl√©s autour de nos valeurs, de simplicit√©, d'optimisme et d‚Äôengagement, encourageant chacun √† oser, essayer et accepter d‚Äô√©chouer.
üéØ Au sein de la Direction Technologie, la Data Factory a pour objectifs de piloter, d√©finir, d√©ployer et op√©rer les meilleures solutions technologiques r√©pondant aux cas d‚Äôusage data et d‚Äôautomatisations de processus de la banque au travers de plateformes. √âgalement, la Data Factory contribue au d√©veloppement des produits, √† la cristallisation et √† la diffusion des pratiques au sein des Squads BforBank sur les usages data dans la banque.
Tu rejoindras une squad en charge de r√©soudre des probl√©matiques m√©tiers en cr√©ant des solutions applicatives utilisant les donn√©es, des data products, avec pour finalit√©s la prise de d√©cision via des moteurs de calcul ou des dashboards, la cr√©ation de flux r√©glementaires, la cr√©ation de data layer ou de reportings.
üöÄ Tes missions principales sont les suivantes :
¬∑ Participer aux analyses, √©tudes d‚Äôimpacts et cadrage techniques
¬∑ Concevoir des solutions en respectant les bonnes pratiques d‚Äôarchitecture data et d√©veloppement
¬∑ R√©aliser le d√©veloppement de nouveaux data products et assurer la maintenance √©volutive et corrective des data products existants
¬∑ R√©diger la documentation technique des data products
¬∑ Assurer un support aux testeurs
¬∑ Reporter de ton activit√© √† ta Squad et travailler dans une d√©marche d‚Äôefficacit√© collective
Concr√®tement tu seras amen√©(e) √† produire les livrables suivants :
¬∑ R√©aliser du code applicatif √† l‚Äô√©tat de l‚Äôart sur notre nouvelle Data Platform
¬∑ Cr√©er des data layer et des rapports sur notre outil de Data Visualisation
¬∑ R√©diger les documentations techniques li√©es √† ta solution, incluant le mod√®le de donn√©es, les proc√©dures, l‚Äôordonnancement
Ce que tu ma√Ætrises :
¬∑ Maitrise des services manag√©s de GCP (BigQuery, dataproc, dataflow, CloudSQL ‚Ä¶)
¬∑ Maitrise du langage Python, Pandas, Spark
¬∑ Maitrise de la mod√©lisation de base de donn√©es et du langage SQL
¬∑ Maitrise d‚Äôune chaine CI/CD (GitLab‚Ä¶)
¬∑ Bonne connaissance de Kafka
¬∑ Bonne connaissance d‚Äôun outil d‚Äôint√©gration de donn√©es type ETL (Informatica‚Ä¶)
¬∑ Connaissance de l‚Äôinfra as code (Terraform)
¬∑ Connaissance d‚Äôun outil de reporting (Looker, BO‚Ä¶)
ü§ù Ce poste est fait pour toi si :
¬∑ Tu es passionn√©(e) par la Data et leurs usages
¬∑ Tu es orient√© r√©solution de probl√®me, est curieux(se) et force de proposition
¬∑ Tu appr√©cies le travail en √©quipe
¬∑ Tu as un bon relationnel et est rigoureux(se)
¬∑ Tu as une bonne capacit√© d‚Äôanalyse et r√©dactionnelle
¬∑ Tu t‚Äôadaptes rapidement aux changements
üéì
Formation :
Tu es dipl√¥m√©(e) d‚Äôun master en √©cole de commerce, √©cole d‚Äôing√©nieur ou √©quivalent.
Chez BforBank nous recherchons avant tout des comp√©tences. Tu ne disposes pas du dipl√¥me requis mais as des exp√©riences √©quivalentes ? N'h√©site pas √† postuler !
üíº
Exp√©rience :
Exp√©rience confirm√©e de 3 ans en tant que Data Engineer.
En rejoignant BforBank tu trouveras‚Ä¶
¬∑ Un projet ambitieux de transformation digitale et culturelle √† l‚Äô√©chelon europ√©en, terrain d‚Äôinnovation et d‚Äôouverture d‚Äôesprit
¬∑ Une organisation apprenante, proposant un large choix de formations toute l‚Äôann√©e, et qui favorise l‚Äô√©change avec les autres marques du Groupe
¬∑ Une promo RSE multi-m√©tiers qui fait √©voluer en continu les actions de BforBank vers une banque plus responsable
¬∑ Une organisation du travail en mode Agile, impliquant un degr√© √©lev√© de collaboration et d'autonomie tout en travaillant avec un groupe de pairs diversifi√©s.
¬∑ Une Direction Technologie en pleine expansion, porteuse de nombreux d√©fis strat√©giques
Mais aussi‚Ä¶
De 2 jours √† 5 jours de t√©l√©travail modulables par semaine, dans la limite de 84 jours par an (frais de fonctionnement pris en charge)
25 jours de cong√©s + 16 jours de RTT
80% du co√ªt de la mutuelle d‚Äôentreprise pris en charge / couvert
Avantages collaborateurs Cr√©dit Agricole : taux et tarifs pr√©f√©rentiels
Des frais de transports rembours√©s √† 75%
Un restaurant d‚Äôentreprise
Des douches pour les sportifs et un tarif avantageux aupr√®s d‚Äôune salle de sport toute proche
üìç Le poste est bas√© √† La D√©fense, dans des locaux flambant neufs !
BforBank s'engage √† garantir l'√©galit√© des chances aux candidats car nous sommes convaincus de la richesse apport√©e par la diversit√© et l'inclusion dans nos √©quipes.
Rencontrons-nous !
Le processus de recrutement se d√©roule en 4 √©tapes :
üßëüèº‚Äçüíª
Call de 30 minutes avec notre √©quipe Talent Acquisition
Echange avec le Data Factory Manager et notre √©quipe Talent Acquisition (pr√©sentiel)
Echange avec une personne de l‚Äô√©quipe avec qui tu seras amen√© √† travailler (visio)
Echange avec le CTO (visio ou pr√©sentiel)
Notre processus de recrutement dure en moyenne 3 semaines et l‚Äô√©quipe Talent Acquisition se tiendra √† ta disposition pour te donner un maximum de visibilit√© sur l‚Äôavanc√©e du process.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Confirm√©'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
(Senior) Data Engineer,Mirakl,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-at-mirakl-3904071960?position=58&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=bdr9XDUp3RnH9V7yglXQrg%3D%3D&trk=public_jobs_jserp-result_search-card,"Mirakl, leader et pionnier de l‚Äô√©conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'acc√©l√©rer de fa√ßon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avanc√©e, s√©curis√©e et √©volutive leur permettant de digitaliser leur activit√© et d'√©largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacit√©, offrir une exp√©rience d'achat personnalis√©e √† leurs clients, et augmenter leurs profits gr√¢ce au retail media. Bas√©e √† Paris et Boston, Mirakl est certifi√©e Great Place to Work.
A propos de Mirakl Labs
Nos √©quipes techniques et produits, nomm√©es Mirakl Labs, sont principalement r√©parties entre nos 2 hubs situ√©s √† Paris et √† Bordeaux. Elles collaborent au quotidien afin d'adresser les probl√©matiques de nos clients et utilisateurs en r√©pondant √† diff√©rents challenges li√©s aux nouvelles fonctionnalit√©s, √† la scalabilit√©, la s√©curit√© et l‚Äôergonomie‚Ä¶
Elles op√®rent en mode agile et s'organisent en Squads compos√©es d'un Squad Lead, de 5 d√©veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est sp√©cialis√©e sur un scope fonctionnel afin de concevoir et r√©aliser de nouvelles features, leurs √©volutions et des APIs (avec un d√©coupage en micro-services). Nos √©quipes Infrastructure, Architecture, S√©curit√©, Documentation, Product Design, Data et Support op√®rent en transverse en apportant leur expertise et de la coh√©rence sur l‚Äôensemble des produits.
Toutes les √©quipes sont responsables de leur p√©rim√®tre et chacun des collaborateurs apporte son exp√©rience et ses id√©es. Innovation, feedback et implication dans les prises de d√©cision sont au c≈ìur de notre philosophie.
Et pour favoriser ce partage avec d‚Äôautres passionn√©s, nous sommes sponsors, speakers, et h√¥tes de diff√©rents √©v√©nements, meetups, et associations de la sc√®ne Tech en France. Au cours des derni√®res ann√©es, nous avons particip√© √† des √©v√©nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.
A propos du job
La solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commer√ßants √† travers le monde. Cette solution g√®re et produit de gros volumes de donn√©es qui pr√©sentent des challenges extr√™mement int√©ressants pour les sp√©cialistes de la donn√©e (produits, commandes, clients, niveaux de stock, prix, messages, appels API, donn√©es de navigation, s√©ries temporelles, donn√©es g√©olocalis√©es etc.).
En tant que (Senior) Data Engineer au sein de l‚Äô√©quipe Data Mirakl, vos principales missions seront de :
contribuer √† l'enrichissement de la Data Platform (ETL)
am√©liorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inf√©rence real time etc.)
Int√©gr√©(e) dans une √©quipe de sp√©cialistes de la donn√©e (data engineers, machine learning engineers, data scientists, data analysts), vous √™tes un des acteurs cl√©s pour garantir la place de Mirakl comme solution dominante sur son march√©.
Notre stack et nos outils
Apache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, Ansible
Au quotidien, vous allez :
Participer √† la d√©finition et √† l‚Äôimpl√©mentation d‚Äôune architecture performante, robuste, scalable et aux co√ªts ma√Ætris√©s pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (√©valuation des feature stores, refactoring de DAG Airflow)
Accompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practices
Optimiser et am√©liorer la CI/CD de l‚Äô√©quipe en collaboration avec l‚Äô√©quipe SRE
Assurer la mont√©e en comp√©tence des membres de l‚Äô√©quipe sur les sujets de MLOps et Data Engineering
R√©fl√©chir √† la meilleure fa√ßon d'int√©grer les donn√©es Google Analytics dans la data platform
Partager ses connaissances et pr√©senter les travaux devant toutes les √©quipes Labs
Ce qu‚Äôon peut vous apporter :
Des projets data driven, divers et vari√©s (traitements massifs d‚Äôimages, de textes, time series etc.) pour des produits diff√©rents de Mirakl
Une culture orient√©e sur la veille technologique
Des projets qui ont un vrai impact business devant √™tre d√©ploy√©s sur des centaines de clients dans un contexte multilingue
Quelques exemples de sujets en cours :
Enrichissement des donn√©es produit √† partir des images et des descriptions
Mod√©ration automatique des produits
Mapping automatique des donn√©es produit
Identification des produits √† fort potentiels
D√©tection de comportements frauduleux
Sentiment analysis sur les messages √©chang√©s entre clients et vendeurs et dans les √©valuations
D√©termination de prix optimaux
Monitoring de la qualit√© de service des vendeurs
Des applications d‚Äôinf√©rence en synchrone de nos mod√®les de ML
Vous aimerez ce job si :
Vous √™tes passionn√©(e) par la data et les technologies modernes permettant d'en tirer partie
Vous vous int√©ressez √† la data science et avez des connaissances g√©n√©rales sur les algorithmes de Machine Learning
Vous avez un background en d√©veloppement et avez √©volu√© dans un environnement Data
Vous avez a minima 4 ans d‚Äôexp√©rience en environnement Machine Learning et/ou Data
Vous avez mis en production avec succ√®s des applications Big Data faisant appel √† du Machine Learning, du NLP, du traitement d‚Äôimages dans des projets d'envergure, √† fort volume de donn√©es
Votre ma√Ætrisez Python, √™tes un pro des frameworks data de la fondation Apache et √™tes √† l'aise dans un environnement AWS
Vous ma√Ætrisez au moins un outil d‚Äôorchestration (Airflow, Data Pipeline ou tout autre outil similaire)
Vous pr√©sentez vos travaux de mani√®re simple et accessible
Vous fa√Ætes preuve d'un bon relationnel et vous aimez mentorer des collaborateurs
Vous parlez couramment anglais et fran√ßais
Les plus pour le poste :
Vous avez une exp√©rience significative dans le domaine du e-commerce
Vous avez d√©j√† mis en place un Data Lake, Data Warehouse ou une Data Platform
Vous avez d√©ploy√© des applicatifs en environnement Kubernetes
Vous avez mis en place des pipelines d'ingestion de donn√©es avec une approche CDC √† l'aide de Debezium ou autre
Vous ma√Ætrisez Java/Scala
Mirakl est engag√©e en faveur de la diversit√©, de l‚Äô√©galit√© des chances et de l‚Äôinclusion. Nous c√©l√©brons nos diff√©rences car nous sommes convaincus que les qualit√©s visibles et invisibles de chaque Mirakl Worker sont une source de force et d‚Äôinnovation. Dans le cadre de cet engagement, nous √©tudions toutes les candidatures sans distinction de : genre, ethnicit√©, religion, orientation sexuelle, handicap, √¢ge ou toute autre caract√©ristique prot√©g√©e par la loi.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Machine Learning', 'CI/CD'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Data Engineer | Python - Azure | IA & Machine Learning  | Paris ou Remote Partiel,Octopus IT - Expert du recrutement tech,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-python-azure-ia-machine-learning-paris-ou-remote-partiel-at-octopus-it-expert-du-recrutement-tech-3664568765?position=59&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=lfoaC1fMJXcvWcFxm77Xmg%3D%3D&trk=public_jobs_jserp-result_search-card,"La soci√©t√©
Cr√©√©e il y a plus de 2 ans, cette startup est la premi√®re base de connaissance intelligente d√©di√©e aux services clients. Leur mission ? En finir avec la frustration lorsque l'on contact un Help Desk.
Pour cela, elle propose aux entreprises la possibilit√© de d√©livrer une exp√©rience client d'exception : rapide et de qualit√©. Gr√¢ce √† leur moteur de recherche intelligent, cette entreprise est capable de centraliser toute la connaissance interne de l'entreprise (proc√©dures, produits, modes op√©ratoires, etc.) et la diffuse intelligemment dans les outils de production des conseillers de service client.
R√©sultat :
Plus besoin de chercher l'information
Des r√©ponses instantan√©es et de meilleures qualit√©es
Une autonomie totale des collaborateurs
Apr√®s une croissance fulgurante, elle a su s√©duire √† la fois de nombreuses scale up (Luko, OpenClassrooms, Japhy...) et grands groupes (BNP Paribas, La Poste, Fnac Darty...).
Apr√®s le recrutement de leur Lead Data (r√©aliser ensemble) et suite √† l'annonce de leur lev√©e de 2,5M‚Ç¨ pour tripler la taille de ses √©quipes, le but est maintenant de s'imposer tr√®s vite comme la base de connaissance de r√©f√©rence en France et en Europe. Pour ce faire, nous recherchons un Data Engineer.
Le poste
En travaillant main dans la main avec le Lead Data, ta mission sera de d√©velopper et de maintenir des flux de donn√©es complexes et robustes. La donn√©e √©tant au coeur de l' entreprise, dans le produit comme dans la strat√©gie, tu seras amen√© √† travailler avec un panel d‚Äôinterlocuteurs tr√®s vari√©s :
Data Scientists sur des sujets comme le monitoring des mod√®les de production et l‚Äôenrichissement des donn√©es d‚Äôentrainement.
Product Team sur des sujets de performance et d‚Äôacheminement de donn√©es au service de fonctionnalit√©s produit telles que le dashboard d‚Äôanalytics √† destination de nos clients.
Customer Success / Strategy sur des sujets de pilotage comme le suivi de l‚Äôutilisation de notre plateforme ou la mise en place de KPIs de performance.
Tu travailleras sur les probl√©matiques suivantes :
Tu seras responsable de notre architecture de donn√©es et de son outillage, mais aussi de la mise en place de pipelines de donn√©es complexes et robustes.
Tu seras amen√© √† mettre en place des outils de monitoring et d‚Äôalerting pour suivre de pr√®s nos nombreuses pipelines de donn√©e.
Tu seras garant de la qualit√© de nos donn√©es en assurant l‚Äôapplication des guidelines de code et des tests automatis√©s pour chacune de nos pipelines.
Tu seras amen√© √† mettre en place des outils de reporting / insights √† destination d‚Äôinterlocuteurs vari√©s (Data Science, Product, Customer Success, Clients, etc.).
Tu cr√©eras et d√©velopperas des pipelines de donn√©es avec des outils de scheduling et d‚Äôorchestration.
La stack sur laquelle vous travaillerez :
Langage : Python, Javascript
Framework data : PyTorch, Transformers (Hugging Face), FastAPI
Database : PostgreSQL, MongoDB, ElasticSearch, Redis
Infrastructure : Azure, Docker, Kubernetes, Spark, RabbitMQ, Serverless, Terraform
Environnement / Test : PyTest, Gitlab (git + ci/cd)
BI : Metabase, Superset
Votre profil
Entre 1 et 3 ans d'exp√©rience en CDI
Tu as une exp√©rience significative sur des probl√©matiques de Data engineering
Tu es quelqu'un de pragmatique
Un tr√®s bon niveau en Python et une tr√®s bonne rigueur dans le code
Bonne pratique de dev : clean code, TDD, BDD
Une bonne culture Ops
Une logique cloud (Aws, GCP ou Azure)
Le salaire & avantages
50-7O K‚Ç¨ selon exp√©rience
RTT
Carte Swile & Mutuelle
2/3 jours de t√©l√©travail par semaine
Et plus encore‚Ä¶
Ce qu‚Äôon pr√©f√®re
√ätre impliqu√© √† fond dans une aventure avec de nombreux challenges techniques
Belles opportunit√©s d'√©volutions sur des postes d'Architecte, de Lead ou de Ml Ops
Beaucoup de workshops en interne et catalogue de formations √† votre guise
Une opportunit√© de travailler sur un produit unique qui a d√©j√† s√©duit de tr√®s beaux clients (BNP Paribas, Fnac Darty, Luko, OpenClassrooms)
La possibilit√© de travailler sur une stack tr√®s moderne, des probl√©matiques complexes aussi bien en traitement de donn√©es, qu'en DevOps
Un plan de BSPCE (actions de l'entreprise) tr√®s int√©ressant et motivant !
Une culture d'entreprise fond√©e sur l'apprentissage, l'autonomie, la bienveillance et l'exigence
Le fait de travailler au quotidien avec des fondateurs passionn√©s par leur domaine d'expertise
Ce poste a √©t√© soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d‚ÄôExperts en Recrutement Tech (CDI et clients finaux uniquement) ‚Äì Visitez nous pour plus d‚Äôopportunit√©s :
www.octopusit.fr
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go', 'JavaScript'], 'DataBase': ['SQL', ' MongoDB', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': ['PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'ML', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['50'], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Data Engineer (H/F) - Lille,Logic@l Conseils,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-lille-at-logic%40l-conseils-3811575649?position=60&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=7mvmlHBKdLio1X1VzQ1izQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Dans le cadre du d√©veloppement de nos activit√©s sur la m√©tropole Lilloise, nous recherchons un
consultant data engineer
(H/F) pour intervenir chez l'un de nos grands comptes clients.
Vos missions :
Recueillir
les besoins m√©tiers et des √©quipes data
Concevoir et mettre en place les
traitements de donn√©es
R√©aliser les
tests de validation
Assurer
l‚Äôalimentation du dataware
R√©aliser les
ordonnancements des traitements
Etre garant de la
mise en place
, du
suivi
et de l‚Äô
exploitation
des outils d√©ploy√©s
Assurer
une veille technologique
r√©guli√®re
Environnement technique :
D√©veloppement :
Python, Scala, R, Java,
Framework :
Spark,
Hadoop,
Outils Big data :
Yarn, Pig, Hive, Kafka, Splunk
Bases de donn√©es :
MongoDB, HBase, Cassandra
ETL :
Talend, Stambia
Plateforme :
Hortonworks, Cloudera, Map Reduce
,
AWS, GCP, Azure
Votre profil :
Vous disposez d‚Äôune exp√©rience
d‚Äôau moins 2 ans en tant que data engineer
ou dans le domaine de l‚Äôanalyse et du traitement de donn√©es.
V√©ritable
passionn√© de la data
, vous √™tes
force de proposition
sur les solutions techniques √† mettre en ≈ìuvre. Vous maitrisez l‚Äôanglais dans un contexte professionnel.
Comp√©tences requises :
Analyses qualitatives et quantitatives (Interm√©diaire)
Anglais (Interm√©diaire)
Architecture fonctionnelle SI (D√©butant)
D√©veloppement d'ouvrages, produits ou √©v√©nements (D√©butant)
Gestion des contr√¥les, tests et diagnostics (D√©butant)
Gestion des risques (Interm√©diaire)
Ma√Ætrise des logiciels (Interm√©diaire)
Mise en exploitation / Production et maintenance (D√©butant)
Nos valeurs
Nous avons d√©cid√© de renverser la pyramide du management pour placer nos collaborateurs en t√™te des priorit√©s de l‚Äôentreprise.
En effet, attach√© √† des valeurs fortes, telles que la proximit√©, la sinc√©rit√©, la fid√©lit√©, la confiance et le respect, nous sommes persuad√©s que la r√©ussite r√©side dans le bien-√™tre de nos collaborateurs.
Cela se traduit par un accompagnement de proximit√©, de la transparence sans langue de bois, des √©changes r√©guliers avec les managers r√©f√©rents, un accompagnement dans le d√©veloppement de carri√®re qui est construit et jalonn√© avec les formations et certifications n√©cessaires et les missions en ad√©quation, pour mener √† bien l‚Äô√©volution de carri√®re.
Pour vous convaincre de nous rejoindre, nos avantages salari√©s compl√©mentaires :
Environnement bienveillant et stimulant au sein de 3 p√¥les d‚Äôexpertises
Formations et Certifications √† la demande
Tickets restaurants : 13‚Ç¨ par ticket
Remboursement √† 100 % des abonnements de transports en commun
Mutuelle frais de sant√© avec de hautes garanties
Prise en charge √† 100% de l‚Äôassurance Pr√©voyance
Ch√®que Cadeau Culture 120 ‚Ç¨
Compte CSE avec une cagnotte de 390 ‚Ç¨
Compte CE : billetterie, voyages, culture, sorties, √† des tarifs pr√©f√©rentiels
Des √©v√®nements chaque mois : activit√©s associatives, sportives, afterwork, s√©minaire,
Partenariat Losc (participation aux match dans la loge VIP logical conseils ‚Äì (Une Vingtaine de match par an)
Possibilit√© de t√©l√©travail
En int√©grant Logic@l Conseils, vous participez √† une r√©elle aventure humaine, alors pour postuler, il suffit de cliquer ci-dessous !
Tous nos postes sont ouverts, √† comp√©tences √©gales, aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['Cassandra', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Data Engineer BI - Nantes,Capgemini,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-bi-nantes-at-capgemini-3803963477?position=1&pageNum=2&refId=5U0uFfx%2F5Nb5dx3Ih9znKA%3D%3D&trackingId=7SpGJA5uenzj7a4NzhHATw%3D%3D&trk=public_jobs_jserp-result_search-card,"Capgemini
Choisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations, o√π vous serez soutenu et inspir√© par une communaut√© d‚Äôexperts dans le monde entier, o√π vous pourrez r√©√©crire votre futur. Rejoignez-nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la valeur de la technologie pour les plus grandes organisations et participez √† la construction d‚Äôun monde plus durable et inclusif.
Vos missions :
Int√©gr√©(e) au sein d‚Äôune √©quipe projet BI, Big Data ou Data Gouvernance pour des clients intervenant dans des secteurs d'activit√©s divers, vous serez notamment en charge des missions suivantes :
Mener les analyses fonctionnelles destin√©es √† traduire les besoins du client,
Mener les travaux de conception et de mod√©lisation,
Diriger le d√©veloppement de la solution / des traitements d'alimentation du DataWareHouse,
Organiser et pr√©parer les travaux de recette utilisateurs,
Mettre en place les processus d'industrialisation et mener cette derni√®re.
Votre profil :
Dipl√¥me d‚Äôing√©nieur ou √©quivalent universitaire
Minimum 3 ans d'exp√©rience
Anglais courant
Comp√©tences en BI sur SAP BI (Hana, BW, BODS, BI 4), Microsoft BI (SQL Server, SSIS, SSAS, SSRS), Oracle (ODI, OBIEE), Teradata, Informatica (Powercenter), IBM (Datastage, Cognos, TM1), Talend, AB Initio
Ma√Ætrise d'un ou de plusieurs outils de Dataviz : Microsoft Power BI, Tableau, Qlikview
Connaissances en Big Data (Ecosyst√®me Hadoop (HIVE, PIG, Mahout‚Ä¶), Cloudera, Pivotal, Spark, HNX) ou en analytics (R, SAS, IBM SPSS)
3 raisons de nous rejoindre :
Qualit√© de vie au travail : accord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√©
professionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.
Apprentissage en continu : certifications et formations en libre acc√®s, accompagnement sur mesure avec votre carreer manager, parcours d‚Äôint√©gration sur 9 mois.
Avantages groupe & CSE : plan actionnariat, activit√©s √† tarifs pr√©f√©rentiels, remboursement partiel
vacances, remboursement de votre abonnement sportif ou culturel.
Nos engagements et priorit√©s :
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.
Capgemini
Capgemini est un leader mondial, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d‚Äôexp√©rience, nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les
plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Oracle', 'SQL Server'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer (H/F),Beelix,"Antibes, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-beelix-3838611420?position=2&pageNum=2&refId=5U0uFfx%2F5Nb5dx3Ih9znKA%3D%3D&trackingId=sfIXeaz3U1LEHTkwKKru%2BQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ?
Depuis 2016, nous accompagnons nos clients sur des probl√©matiques de Product Management, Data et Design Thinking. Beelix contribue √† fa√ßonner le monde de demain en participant aux grandes avanc√©es des secteurs suivants :
üöóAutomobile
‚ö°Energie
üì°M√©dias & T√©l√©coms
üëóLuxe & Retail
üí∂ Banque, Finance & Assurance
‚úàÔ∏èD√©fense
Aujourd‚Äôhui, Beelix compte plus de 200 collaborateurs motiv√©s et dynamiques. Lab√©lis√©e Great Place To work en 2023, Beelix est aussi une entreprise engag√©e o√π il fait bon vivre.
Dans le cadre de notre d√©veloppement, nous recherchons un Data Engineer (H/F) pour l'un de nos clients.
Quelles missions au quotidien ?
√ätre le leader de la brique Datalakehouse
D√©velopper les scripts de transformations de donn√©es et les pipelines d‚Äôalimentation
Proposer des √©volutions architecturales ou de fonctionnalit√©s pour am√©liorer le socle technique
√ätre le back-up du leader technique sur la partie reporting (Power BI)
Orientation satisfaction client et r√©sultat final forte mais √©galement sensibilit√© au ¬´ comment ¬ª
Innovation et proposition de nouvelles pratiques pour am√©liorer l‚Äôenvironnement et les conditions de travail des √©quipes
A propos de vous ?
5 + ann√©es d'exp√©rience en tant que Data Engineer
Ma√Ætrise des technologies suivantes : Microsoft Azure, Microsoft Azure Synapse Analytics (Spark / Python / Pipeline / Serverless), fichiers parquet / delta, Microsoft Power BI, Microsoft SQL Server, langage SQL, Datawarehousing / Mod√©lisation de donn√©es
Analyses et export de donn√©es
Connaissance de l‚Äôensemble du processus depuis la collecte jusqu‚Äô√† la mise √† disposition des donn√©es en ayant comme point fort la maitrise de sa transformation et mise en forme
Vous avez un bon niveau d‚Äôanglais
Localisation : Biot et/ou Carros
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['SQL Server'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,Digital Waffle,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-digital-waffle-3913824888?position=3&pageNum=2&refId=5U0uFfx%2F5Nb5dx3Ih9znKA%3D%3D&trackingId=fba8MFee7aoxkZLGja%2BWZg%3D%3D&trk=public_jobs_jserp-result_search-card,"Digital Waffle is proud to have partnered with an innovative tech startup in Paris, who are looking for a talented Data Engineer to join their growing team!
They are made up of a powerhouse of experts, combining
data engineers, business process gurus, and Project managers
who leverage the most advanced solutions available; utilising process mining, automation tools, and smart execution systems.
Looking for an experienced Data Engineer (3-5 years)
What You'll Do:
This is a full-time,
hybrid role (Paris-based)
where you'll wear many hats: data exploration, system integration, data prep, data modeling, and implementing data solutions.
Experience:
Expertise in data engineering, data modeling, and ETL (Extract, Transform, Load) processes
Data warehousing and data analytics skills
Experience handling large, complex datasets
Proficiency in SQL and programming languages like Python or Java
Stellar problem-solving and analytical skills
Top-notch communication and collaboration abilities
Bachelor's or Master's in Computer Science, Information Systems, or a similar field (a plus for process mining or intelligent process automation experience)
If you are an experienced and driven Data Engineer, please apply here!
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': ['Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (H/F),Scalian,"Valbonne, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-scalian-3819563847?position=4&pageNum=2&refId=5U0uFfx%2F5Nb5dx3Ih9znKA%3D%3D&trackingId=8DPeW3FeRfB3CDPMsZLmIw%3D%3D&trk=public_jobs_jserp-result_search-card,"Ing√©nieur DATA / Data engineer (H/F)
Valbonne/Sophia-Antipolis
Type : CDI
Lieu : Locaux Scalian Sophia-Antipolis
T√©l√©travail : En fonction des possibilit√©s
Date de prise de poste : imm√©diatement ou en fonction de votre pr√©avis
Salaire : en fonction du profil - entre 40 et 48K Brut annuels (hors avantages Scalian)
Avantages Scalian : Accord d'entreprise t√©l√©travail, Tickets restaurants, Mutuelle groupe, accord am√©nagement temps de travail, compte √©pargne temps, accord de participation et int√©ressement groupe, programme cooptation et apports d'affaires, accompagnement parentalit√©, avantages CSE
Vous √™tes data engineer ou vous souhaitez le devenir !
Quel sera votre r√¥le ?
La port√©e de la mission comprend (sans toutefois s'y limiter) :
Science des donn√©es
Ing√©nierie des donn√©es
Analyse des donn√©es
G√©nie logiciel
Ce que cette exp√©rience va vous apporter
Vous √™tes autonome, vous avez le sens du service et de l‚Äôanalyse, vous √™tes impliqu√©, nous vous offrons une ouverture sur des projets complexes et une rapide √©volution de carri√®re. Vous rejoignez notre business unit √† Sophia Antipolis compos√©e d'environ 50 consultants, avec possibilit√© de t√©l√©travail en fonction des sujets.
Nous co-construisons votre trajectoire professionnelle et assurons votre mont√©e en comp√©tences.
Nous nous inscrivons ensemble dans la dur√©e, nous assurons votre mont√©e en comp√©tences et disposons d'une vari√©t√© de sujets passionnants.
Ce que nous recherchons chez vous
De formation sup√©rieure (Bac+5, √©cole ou universit√©), vous poss√©dez id√©alement une premi√®re exp√©rience r√©ussie dans ce domaine (d√©butants accept√©s), vous aimez le travail en √©quipe.
Comp√©tences requises
:
Etape d‚Äôanalyse : Comprendre l‚Äôarchitecture technique, les sources de donn√©es, les objectifs fonctionnels.
Etape de conception : Solution de conception avec un fort centrage sur les pipelines de donn√©es et les mod√®les ML et l‚Äôexposition des KPI via API
Mise en ≈ìuvre : Apr√®s les phases d‚Äôanalyse et de conception, proc√©der √† a mise en ≈ìuvre dans des technologies s√©lectionn√©es (Java,Scala,Python,Spark)
Cr√©er un code test√© et document√©
Techno : Linux, Shell, Hadoop, Scrum, Python, Spark, Scala
Pourquoi feriez-vous le grand saut ?
Parce que Scalian vous accompagne dans le d√©veloppement de votre carri√®re :
Programme d'onboarding complet sur 1 an avec votre manager et votre RH
Programme de formation (Scalian Academy, e-learning, webinaires et formations externes)
Communaut√©s techniques (Squads, Practices) afin de valoriser et d√©velopper votre expertise
√âv√©nements internes (Afterworks, Awards Dinner, Kick Off, Live Event du COMEX, Stand Up) et externes (participation √† des salons et forums sp√©cialis√©s dans nos domaines d‚Äôactivit√©s‚Ä¶)
Dispositif d‚Äôacc√©l√©ration d‚Äôacc√®s √† la mobilit√© interne et √† des √©changes internationaux type Erasmus
Parce que Scalian favorise la Qualit√© de Vie au Travail :
Certifications Great Place to Work¬Æ et Best Workplaces for Women¬Æ
Prime de cooptation, prime vacances, prise en charge par l‚Äôemployeur de 60% des titres-restaurant, Accord t√©l√©travail (jusqu‚Äô√† 2,5 jours par semaine indemnis√©s), RTT (dont une partie mon√©tisable), CSE (activit√©s ludiques, ch√®ques-cadeaux, ch√®ques vacances)
Berceaux en cr√®ches inter-entreprises
Don ou r√©ception de jours de cong√©s en cas de difficult√©s personnelles
Parce que Scalian d√©veloppe une politique RSE concr√®te et ambitieuse :
Mobilit√© durable (indemnit√© kilom√©trique v√©lo, leasing de v√©los √† assistance √©lectrique)
Actions environnementales (Fresque du Climat, Reforest'Action, Clean Up Day, m√©c√©nat ONF)
Postes ouverts aux personnes en situation de Handicap
Diverses politiques de diversit√©, d‚Äôinclusion et d‚Äôint√©gration mises en place
Scalian c‚Äôest aussi :
Une entreprise en tr√®s forte croissance qui, cr√©√©e en 1989, compte aujourd‚Äôhui plus de 5500 personnes
Des r√©f√©rences clients √† forte valeur ajout√©e aupr√®s de grands industriels fran√ßais (du CAC40) et internationaux
Un terrain de jeu o√π l‚Äôexpertise se conjugue avec audace, libert√© d‚Äôentreprendre et convivialit√©
Si vous aspirez √† un environnement de travail qui valorise autant votre bien-√™tre que votre d√©veloppement professionnel,
rejoignez-nous et exprimez pleinement votre talent !
Envie d'√©largir le cadre ?
Je suis Liza Djehel, Talent Acquisition Officer.
Si votre CV est retenu, je vous contacte pour un premier √©change t√©l√©phonique de 15 √† 20 minutes.
Nous d√©terminons ensemble si ce poste est en ad√©quation avec vos comp√©tences et surtout, avec vos attentes.
L'√©change est positif ? Nous convenons d'un entretien de 1h (en pr√©sentiel ou en visio) avec Lucas Daunar, Business Manager √† Sophia-Antipolis. Cet √©change permet de revenir en d√©tail sur vos comp√©tences, vos attentes, de vous pr√©senter le poste plus en d√©tail, et d'√©voquer d'autres opportunit√©s.
Nous pr√©voyons ensuite un rendez-vous technique de 1h (en pr√©sentiel ou en visio) avec un de nos responsable technique.
Enfin, nous vous pr√©sentons notre proposition d'embauche.
Notre processus de recrutement dure entre 15 et 30 jours
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['40'], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
Data Engineer H/F,Ippon Technologies,Greater Nantes Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ippon-technologies-3902436649?position=5&pageNum=2&refId=5U0uFfx%2F5Nb5dx3Ih9znKA%3D%3D&trackingId=igIUAipWQogxha%2BnVVMT3g%3D%3D&trk=public_jobs_jserp-result_search-card,"Envie de rejoindre la communaut√© DATA la plus dynamique de France ?
Notre sp√©cialit√© est de construire des data platform dans le Cloud public avec les meilleurs technos du moment : Snowflake, Databricks, Matillion, DBT.
Membre de la Practice Data, le/la futur(e) Data Engineer sera int√©gr√©(e) √† nos √©quipes de conseil et sera suivi(e) par un(e) mentor qui l‚Äôaidera √† monter en comp√©tences.
Votre champs d‚Äôexpertise :
Intervenir sur les data platforms de nos clients pour d√©velopper de nouveaux pipelines de donn√©es (ingestion, traitement, exposition).
Travailler en collaboration avec les m√©tiers et les data scientists pour leur fournir un support √† l‚Äôindustrialisation de leurs travaux (tests, int√©gration continue, scalabilit√© des mod√®les, craftsmanship etc‚Ä¶)
D√©ployer des infrastructures cloud full
infra-as-code
(Terraform, CloudFormation).
Participer aux √©v√®nements internes √† la communaut√© data (BBL, webinar, datap√©ro interne, meetup, blog, dojos) et externes (Salon du Big Data, GCP Summit, Spark Summit, AWS Summit, Devoxx, workshop partenaire, meetups).
Capitaliser sur les missions et les diff√©rents √©v√®nements de la communaut√© au travers d‚Äôarticles de blogs, REX, BBL interne.
Vos connaissances :
Un framework de calcul distribu√© tel que Spark, Storm, Flink.
Un ou plusieurs langages de programmation (Python, Scala, Java...)
Diff√©rents syst√®mes de stockage de donn√©es (SQL ou NoSQL) et bien s√ªr le langage SQL.
La connaissance de Snowflake est bienvenue ;-)
Un framework de streaming de donn√©es tel que Kafka ou Amazon Kinesis.
Une exp√©rience sur les technologies Cloud : AWS, GCP, Azure
Le delivery et les projets en production faisant partie de notre ADN, vous √™tes capable de livrer du code de qualit√© dans des environnements agiles.
De plus en plus de nos projets se font en remote avec des clients du monde entier, il devient n√©cessaire d‚Äô√™tre √† l‚Äôaise en Anglais.
Ippon technologies c‚Äôest aussi :
üëç B√©n√©ficier d'un suivi de proximit√© r√©alis√© par votre manager technique : points r√©guliers pour votre suivi en mission, votre formation et votre √©volution de carri√®re
‚úåÔ∏è Rejoindre une entreprise o√π les valeurs du sport sont nos leitmotiv : d√©passement de soi, travail en √©quipe, bienveillance.
üóíÔ∏è Apprendre via notre programme de formation BlackBelt : https://bit.ly/3ByqcIL
üòÅ Travailler en pair programming ou avec un.e mentor pour gravir les √©chelons !
üí™ Pouvoir participer √† une aventure humaine au sein de notre Fondation Ippon pour r√©duire la fracture num√©rique dans le monde !
ü§ù Participer √† nos ap√©ros et divers √©v√®nements internes pour consolider la coh√©sion d‚Äô√©quipe
Et apr√®s ?
Et oui alors ? Que se passe-t-il une fois que vous √™tes convaincu d‚Äôavoir lu l‚Äôoffre d‚Äôemploi qui vous correspond bien ?
Nous vous proposons de prendre contact et de nous rencontrer !
Les Next Steps :
1 call RH
1 √©change RH
1 √©change Technique
Si le match est bon des deux c√¥t√©s : Hadjim√© ! Vous vous lancerez sur le tatami Ippon !
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks', 'Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform', 'CloudFormation'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (H/F),ternair,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ternair-3915757963?position=6&pageNum=2&refId=5U0uFfx%2F5Nb5dx3Ih9znKA%3D%3D&trackingId=A01wsYYAG%2FYIpqiFBcjvNA%3D%3D&trk=public_jobs_jserp-result_search-card,"üë®‚ÄçüöÄ MISSION : üë©‚ÄçüöÄ
En coh√©rence avec la strat√©gie d‚Äôentreprise et la roadmap data, vous aurez pour principales missions de :
En lien avec l‚Äô√©quipe DevOps, construire, maintenir et faire √©voluer la plateforme de donn√©es;
D√©finir et piloter la coh√©rence de la collecte, la gestion et l‚Äôalimentation des donn√©es internes et externes, en diff√©rents modes : batch, streaming, API (architecture micro-services);
Pr√©parer et mettre en qualit√© les donn√©es pour les rendre disponibles dans les diff√©rents environnements de travail (datalake, datawarehouse, datamart);
V√©rifier la qualit√© des donn√©es, de leur bonne et r√©guli√®re ex√©cution ainsi que de leur utilisation ad√©quate (gestion des co√ªts);
Travailler en √©troite collaboration avec les data analysts, scientists et data stewards et business de l‚Äôentreprise ;
En lien avec l‚ÄôIT et la s√©curit√©, veiller aux r√®gles d'int√©grit√© et de s√©curit√© des donn√©es;
Veille technologique.
üßÆ Les outils :
Plateforme data : Google Cloud Platform (Big Query, Airflow)
D√©veloppement : Github/GitLab, Docker, Terraform, Python
Analytiques : Qlik
Gestion de projet s: Jira, Confluence, Miro, Drive, Docs, Sheets, Slides
ü§© Profil recherch√© : ü§©
Exp√©rience d'au moins 4-5 ans (apr√®s √©tudes) en data ing√©nierie (flux, mod√©lisation, run)
A l‚Äôaise avec l‚Äôenvironnement Cloud et les infrastructures digitales
Communiquant, p√©dagogue et fortes capacit√©s relationnelles
Anglais (√† l‚Äô√©crit)
R√©mun√©ration : 42-60 k‚Ç¨ en package selon exp√©rience
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Big Query'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': ['JIRA', 'Confluence'], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['Package'], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Engineer,Shippeo,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-at-shippeo-3908268236?position=7&pageNum=2&refId=5U0uFfx%2F5Nb5dx3Ih9znKA%3D%3D&trackingId=Qkp3nd%2B7kuHYXRYFNEMI%2Bg%3D%3D&trk=public_jobs_jserp-result_search-card,"Founded in 2014, Shippeo is a French based SaaS company providing supply chain visibility. Shippeo has grown from 70 to 220 employees during the last two years and is continuing to rapidly scale after an additional $40M fundraising round in October 2022.
Shippeo is an exceptionally diverse company with colleagues from 27 different nationalities and speaking 29 languages. With offices throughout Europe, North America and recently Asia, Shippeo provides global coverage to all of our clients.
Our product is composed of a mission critical SaaS web platform (API everywhere), with high traffic inbound/outbound integrations.
Our mission is to anticipate problems and proactively alert end-customers so they can efficiently manage exceptions. We achieve this by collecting and matching millions of theoretical and real data from different stakeholders.
The Data Intelligence Tribe is responsible for leveraging Shippeo‚Äôs data from our large shipper and carrier base, to build data products that help our users (shippers and carriers alike) and ML models to provide predictive insights. This tribe‚Äôs typical responsibilities are to:
get accurately alerted in advance of any potential delays on their multimodal flows or anomalies so that they can proactively anticipate any resulting disruptions
extract the data they need, get direct access to it or analyze it directly on the platform to gain actionable insights that can help them increase their operational performance and the quality and compliance of their tracking
provide best-in-class data quality by implementing advanced cleansing & enhancement rules
As a Data Engineer at Shippeo, your objective is to ensure that data is available and exploitable by our Data Scientists and Analysts on our different data platforms. You will contribute to the construction and maintenance of Shippeo‚Äôs modern data stack that‚Äôs composed of different technology blocks:
Data Acquisition (Kafka, KafkaConnect, RabbitMQ),
Batch data transformation (Airflow, DBT),
Cloud Data Warehousing (Snowflake, BigQuery),
Stream/event data processing (Python, docker, Kubernetes) and all the underlying infrastructure that support these use cases.
Qualifications
Required:
You have a degree (MSc or equivalent) in Computer Science.
3+ years of experience as a Data Engineer.
Experience building, maintaining, testing and optimizing data pipelines and architectures
Programming skills in Python and experience with asynchronous event processing (asyncio).
Advanced working knowledge of SQL, experience working with relational databases and familiarity with a variety of databases.
Working knowledge of message queuing and stream processing.
Knowledge of Docker and Kubernetes.
Knowledge of a cloud platform (preferably GCP).
Experience working with workflow management systems such as Airflow.
Desired:
Experience with cloud based data warehouse solutions (BigQuery, Snowflake).
Experience with Kafka and KafkaConnect (Debezium).
Experience with Infrastructure as code (Terraform/Terragrunt).
Experience building and evolving CI/CD pipelines with Github Actions.
Monitoring and alerting on Grafana / Prometheus.
Experience working on Apache Nifi.
Informations suppl√©mentaires
We are looking for talents who share our values:
üöÄ Ambition
üíô Care
üéØ Deliver
ü§ù Collaboration
Find out more about our values in
Our Culture Book
If you identify with our values and enjoy working in a fast-paced and international environment, Shippeo is just the place for you!
We are committed to fostering diversity and inclusion within our workplace as we value the unique perspectives and experiences that individuals from all backgrounds bring to our team. We are dedicated to providing equal employment opportunities to all candidates, regardless of their background or abilities, and our commitment to inclusion is reflected in our policies, practices, and workplace culture.
We understand that candidates may have unique needs or questions related to disability inclusion. To facilitate this, you can reach our dedicated Disability Advisor at
inclusion@shippeo.com
with any inquiries or requests for accommodations during the application process.
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['ML', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data engineer - F / H,United Robotics Group,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-united-robotics-group-3891680780?position=8&pageNum=2&refId=5U0uFfx%2F5Nb5dx3Ih9znKA%3D%3D&trackingId=oVJtK1t11uimHlb7BlJr8w%3D%3D&trk=public_jobs_jserp-result_search-card,"Bienvenue chez
Aldebaran
, leader europ√©en de la robotique
au sein du groupe
United Robotics Group
.
Nous concevons et industrialisons des robots innovants avec une vision soci√©tale ambitieuse pour fa√ßonner un monde plus humain. Depuis 2005, nous sommes √† l'avant-garde de l'interaction homme-robot avec des produits embl√©matiques tels que NAO et Pepper.
Notre dernier-n√©,
Plato
,
incarne notre engagement envers la technologie de pointe et la s√©curit√©,
fabriqu√© en France avec des composants europ√©ens.
Rejoignez nos √©quipes multiculturelles et dynamiques pour √™tre au c≈ìur de la r√©volution de la robotique.
Si vous √™tes passionn√©.e par la robotique et l'intelligence artificielle, et que vous souhaitez contribuer √† fa√ßonner l'avenir, nous vous offrons une exp√©rience enrichissante et stimulante.
En tant que membre de notre √©quipe, vous b√©n√©ficierez d'une culture d'entreprise ax√©e sur le sens de ce que nous faisons et valorisant la responsabilit√© sociale et environnementale.
Chez Aldebaran, nous valorisons l'innovation, la diversit√© et l'√©galit√© et encourageons chacun.e √† √™tre ouvert.e, authentique, courageux.se, responsable et engag√©.e.
Finalit√© du poste
Au sein de l'√©quipe Cloud-Online Services, le Data engineer int√©grera l'√©quipe Data, responsable du d√©veloppement des produits destin√©s √† la collecte, aux process et √† l'exploitation des donn√©es de nos robots.
Il aura pour r√¥le de d√©finir et d'impl√©menter des services data, sur une infrastructure Cloud AWS, supportant des services en ligne qui g√®rent les robots du groupe.
Missions principales
Le Data engineer aura pour responsabilit√©s de :
√©valuer les choix d'architecture et de solutions techniques lors de la mise en place de PoC,
concevoir et d√©velopper des services Data en respectant la sp√©cification fonctionnelle et la m√©thodologie agile,
agr√©ger et stocker de grandes quantit√©s de donn√©es,
mettre en place des solutions de data processing,
int√©grer/d√©velopper des outils de visualisation de donn√©es et analyser les KPI,
d√©velopper, tester, s√©lectionner et mettre en production des algorithmes qui permettent de r√©pondre aux besoins,
r√©aliser des analyses de donn√©es,
mettre en place des tests de charge et fonctionnels pour les solutions Data,
investiguer et corriger les bugs remont√©s par les utilisateurs,
contribuer √† la mise en place de l'infrastructure et outil de d√©ploiement (CI/CD)
Rejoignez-nous pour faire partie d'une aventure passionnante o√π Pepper, NAO, Plato et leurs futurs successeurs attendent votre contribution pour repousser les limites de la technologie robotique !
Requirements
Pour la bonne ex√©cution des missions confi√©es, vous t√©moignez d'au moins 6 ans d'exp√©rience en tant que d√©veloppeur sur des projets data en Cloud en Python et Spark et avec comme Cloud provider AWS.
Comp√©tences demand√©es :
Bonne compr√©hension des technologies d'infrastructure et de d√©ploiement,
Comp√©tences techniques sur les services AWS : IOT core , Glue, lambda, Kinesis, S3, RDS,
Bonne compr√©hension technique dans la mise en place et l'automatisation de tests de charge et fonctionnels,
Bonne maitrise d'outils BI ou de dashboarding (POWER BI, TABLEAU, QUICKSIGHT)
Bonne connaissance et une exp√©rience pratique de Scrum\Scrumban et des m√©thodes agiles,
Une certification AWS sera appr√©ci√©e,
Un niveau de fran√ßais et d'anglais courant est indispensable,
Des exp√©riences dans des environnements fortement internationaux sont un plus
Benefits
Nos principaux avantages :
Une culture du bien-√™tre en entreprise qui a fait ses preuves (budget c√©l√©bration et moments de convivialit√© par √©quipes et directions, restauration collective de qualit√©, environnement de travail agr√©able)
Un engagement fort en mati√®re de responsabilit√© sociale et environnementale (promotion de l'√©galit√© professionnelle, performance de notre plan diversit√© et inclusion, r√©f√©rent handicap, fresque du num√©rique)
Une culture du t√©l√©travail encadr√©e de mani√®re appropri√©e !
Tous nos postes sont ouverts aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '6', '6', '6']}"
Data Engineer H/F,Neosoft,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-neosoft-3877878521?position=9&pageNum=2&refId=5U0uFfx%2F5Nb5dx3Ih9znKA%3D%3D&trackingId=E0uvNqbx3ExrbNpYFJTgWA%3D%3D&trk=public_jobs_jserp-result_search-card,"Tous nos postes sont ouverts au t√©l√©travail
Groupe ind√©pendant de conseil en transformation digitale de pr√®s de 1800 collaborateurs, N√©osoft s‚Äôest construit, depuis 2005, sur un mod√®le qui place l‚Äôexcellence, le d√©passement de soi et la RSE au c≈ìur de sa strat√©gie.
En nous rejoignant, vous int√©grez des communaut√©s d‚Äôexperts et de talents qui vous permettent de d√©velopper vos comp√©tences et d‚Äôoffrir √† nos clients le meilleur accompagnement possible.
Notre savoir-faire s‚Äôarticule autour de nos 6 domaines d‚Äôexpertise :
Conseil & Agilit√©
Cybers√©curit√©
Data
DevOps
Infrastructures & Cloud
Software Engineering
Nous recherchons pour int√©grer notre
agence lilloise
un(e)
Data Engineer confirm√©(e)
.
Nous aimerions vous voir rayonner au sein de notre communaut√© DATA (+100 collaborateurs) anim√©e par Nicolas Huche, son practice leader et Thibaud Blanchard son Technical Officer. Vous aiderez les clients √† consolider un patrimoine Data responsable.
üéØ
Vos missions :
Apr√®s une p√©riode d‚Äôint√©gration, en tant que
Data Engineer
, voici √† quoi ressembleront vos activit√©s dans des contextes clients Retail ou Banque / Assurance / Finance :
Analyser et s'approprier les cas d'usages
Analyser et valoriser les donn√©es du patrimoine
Mettre en place des flux de transformation de donn√©es
R√©aliser les tests permettant de s'assurer la qualit√© du delivery
Continuer la mise au point de frameworks data
Cr√©er et d√©velopper des modules de d√©ploiement des solutions
Assurer l'industrialisation de moteurs bas√©s sur l'IA
Assurer le niveau de performance des pipelines
Impl√©menter les outils de monitoring du socles de donn√©es
üìù
Votre profil :
Nous vous imaginons avec au moins 4 ans d‚Äôexp√©riences sur des projets autour de la
Data
, une ma√Ætrise des
bases de donn√©es (SQL)
, des outils de transformation de la donn√©e
(Talend, BigQuery, Airflow)
, et un socle de comp√©tences solides autours des langages
Python, Spark, Scala, Hadoop, Java.
üëâ
Votre carri√®re chez N√©osoft
Depuis sa cr√©ation, N√©osoft place ses collaborateurs au c≈ìur de sa strat√©gie. Notre culture pourrait se r√©sumer en un mot : le collectif.
Nos communaut√©s d‚Äôexperts vous donnent la possibilit√© d‚Äôapprendre, mais aussi de transmettre et de partager vos savoirs pour faire progresser les autres.
Nous veillons √† ce que chacun b√©n√©ficie d‚Äôun accompagnement de proximit√© et d‚Äôun suivi de carri√®re personnalis√© aupr√®s de votre manager d√©di√© :
1 bilan d‚Äôactivit√© trimestriel pour suivre le d√©veloppement de vos comp√©tences
1 entretien d‚Äô√©valuation qui a lieu chaque ann√©e pour √©valuer votre performance et d√©terminer vos nouveaux objectifs
1 entretien annuel aupr√®s de votre RH dans le but de cartographier vos nouvelles comp√©tences pour √©changer sur vos projets professionnels et souhaits de formations
üëâ
Vos avantages
Formations et d√©veloppement de l‚Äôexpertise :
Vous disposez de temps allou√© et r√©mun√©r√© en contribuant au d√©veloppement de votre expertise technique et de celle du groupe (Participations √† des Tech days, animation d‚Äôune conf√©rence √† l‚Äôinterne ou √† l‚Äôexterne, r√©daction d‚Äôarticles, rencontres avec nos candidats en processus de recrutement‚Ä¶)
Un abonnement illimit√© LinkedIn Learning offert
Bien-√™tre au travail :
Un accord de t√©l√©travail flexible jusqu‚Äô√† 100% de t√©l√©travail et personnalisable
Un partenariat avec Gymlib qui favorise le sport en entreprise
Des initiatives locales (afterworks, d√©fis sportifs, team buildings, ‚Ä¶)
Et bien plus encore :
Parce que les meilleurs cooptent les meilleurs, une politique de cooptation attractive r√©mun√©r√©e d√®s l‚Äôarriv√©e du collaborateur
En plus de votre salaire : participation, compte √©pargne temps, actionnariat...
üëâ
Votre parcours candidat
Notre processus de recrutement se compose de deux √©tapes cl√©s :
Un entretien de recrutement RH avec un Talent Acquisition Sp√©cialiste pour dresser un bilan de votre parcours professionnel et identifier les trajectoires de carri√®re possibles au sein de notre groupe
Un entretien d‚Äô√©valuation technique pour r√©aliser un diagnostic de vos comp√©tences techniques et identifier les comp√©tences sur lesquels poursuivre votre √©volution
Vous aurez √©galement la possibilit√© de rencontrer pour compl√©ter votre processus un acteur de notre p√¥le Business ou un pair de votre m√©tier pour √©changer sur son exp√©rience collaborateur.
Nous avons h√¢te de vous rencontrer !
A bient√¥t,
L‚Äô√©quipe N√©osoft üñê
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'ML', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': ['Confirm√©'], 'TypeContract': [], 'Salary': ['Salaire'], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Data & Cloud Engineer (H/F),fifty-five,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-cloud-engineer-h-f-at-fifty-five-3910028674?position=10&pageNum=2&refId=5U0uFfx%2F5Nb5dx3Ih9znKA%3D%3D&trackingId=o9htNm8KQ7fNkBtS4SPmyQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Data & Cloud Engineer
fifty-five est une data-company d'un genre nouveau qui aide les marques √† exploiter les donn√©es pour am√©liorer le marketing, les m√©dias et l'exp√©rience client gr√¢ce √† une combinaison de services de conseil et de technologie sp√©cialis√©s.
En tant que pilier data et marketing du Brandtech Group, nous offrons des services qui combinent le conseil en strat√©gie, les services de cloud, le conseil en m√©dia et l'exp√©rience client.
fifty-five, c'est plus de 400 experts du num√©rique. Des digital consultants, des sp√©cialistes du tracking et du m√©dia, des ing√©nieurs et des data scientists, travaillent tous en √©troite collaboration pour fournir des conseils marketing de haut niveau et une assistance technique aux marques, dans tout type d'industrie, partout dans le monde.
Partenaire des annonceurs de la collecte √† l'activation et l'exploitation des donn√©es, nous aidons les organisations √† devenir de v√©ritables entit√©s omnicanales ma√Ætrisant l'efficacit√© de leur √©cosyst√®me digital et ses synergies avec le monde physique.
Bas√© √† Paris, nous op√©rons sur 3 fuseaux horaires depuis nos 10 bureaux, situ√©s √† Paris, Londres, Gen√®ve, Milan, Shanghai, Hong Kong, Shenzhen, Taipei, Singapour et New York. fifty-five attache une importance particuli√®re au bien-√™tre de ses collaborateurs, ce qui lui a permis de figurer dans le classement Best Workplaces France en 2018.
Contexte :
L'√©quipe d'ing√©nierie d√©veloppe et met en ≈ìuvre les solutions techniques permettant la r√©alisation de pipelines de donn√©es et l'impl√©mentation de data platform pour nos clients : r√©cup√©ration de datas sur de multiples sources de donn√©es (APIs, files, etc.), data cleaning, data processing, automation et monitoring de l'ensemble. L'√©quipe s'appuie sur des technologies r√©centes (docker, kubernetes, terraform, notebooks, etc.) et met en place ses projets dans les diff√©rents clouds du march√© (GCP, Azure, AWS...).
Mission :
Nous sommes √† la recherche d'une personne capable de r√©aliser des projets techniques pour r√©pondre aux besoins de nos clients (par exemple: syst√®me de recommandations de produits, d√©tection d'anomalies, ranking). Les activit√©s vont du chiffrage et du sizing technique √† la mise en ≈ìuvre des architectures, en passant par la revue des sp√©cifications fonctionnelles et la production de code. Le Data & Cloud Engineer sera √©paul√© par un Lead dans ses missions. Il sera √©galement amen√© √† participer √† la R&D et √† accompagner les √©quipes transverses dans la mise en place d'outils de travail internes (librairies pour les data scientists, environnement Notebooks pour les data analysts et data scientists, d√©veloppement de frameworks sur diff√©rents cloud providers, etc.).
Nous souhaitons trouver la bonne personne pour faire √©voluer ou cr√©er de nouvelles solutions dans ce cadre. Les missions comprennent aussi bien du prototypage rapide pour des d√©monstrateurs, que de la production de code robuste qui tourne en production tous les jours.
Comp√©tences et exp√©riences :
2 ans d'exp√©rience en tant que Data Engineer
Ma√Ætrise de Python, SQL
Ma√Ætrise des environnements Cloud. Id√©alement certifi√© GCP, Azure ou AWS
Bonne connaissance de Docker/Kubernetes
Bonne connaissance d'au moins un data warehouse (BigQuery, Snowflake, etc)
Connaissance autour des Notebooks (Jupyter)
A l'aise avec des concepts li√©s aux APIs (OAuth, REST, etc.)
A l'aise avec les notions d'Infrastructure as Code (Terraform)
Au courant des pratiques GitOps et connaissances des concepts autour du CI/CD
La ma√Ætrise d'un orchestrateur, comme Apache Airflow, est un plus
Esprit d'√©quipe (collaborer aux tests unitaires, revue de code, partage de code, sprints)
Bon niveau en fran√ßais et en anglais
A d√©j√† travaill√© en mode projet avec des interlocuteurs vari√©s (consultant, data analyst, data scientist)
Une exp√©rience en marketing digital est un plus
Nous proposons :
un bureau au centre de Paris avec terrasse et jardin
un environnement multiculturel avec des collaborateurs aux nationalit√©s multiples (France, Royaume-Uni, Etats-Unis, Chine, Tunisie, Italie et plus)
des projets avec nos bureaux √† Londres, Hong Kong, New York, Shanghai, Gen√®ve, Shenzhen et Taipei
des TGIF et supers soir√©es
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Apache Airflow'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Data Engineer Senior,AXA en France,"Hauts-de-Seine, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-senior-at-axa-en-france-3884386043?position=1&pageNum=5&refId=T%2B%2BV0JbclKMpVoA2J23Itg%3D%3D&trackingId=bodYRty8CHMU9PuiSRGKTA%3D%3D&trk=public_jobs_jserp-result_search-card,"Environnement
En tant que
Senior Data Engineer F/H
, vous allez contribuer directement aux projets des directions m√©tier (ex : fraude sant√©, multi√©quipements, pricing IARD, optimisation du lead management, fragilit√© auto, ‚Ä¶) d‚ÄôAXA France et √† la construction du socle technique Big Data.
Vous allez int√©grer une √©quipe d'une dizaine de personne compos√©e de Data Engineer et des Tech Lead travaillant en mode Feature Team au sein des tribus m√©tier de la Direction Transformation Digital Tech et DATA (DT2).
La Direction Transformation Digital Tech et DATA d'AXA France en quelques mots :
- Une organisation agile en feature teams : tribus, guildes, squads
- Des projets sur des applications innovantes √† fort trafic (web, mobile‚Ä¶)
- Des m√©thodologies craft (TDD, BDD, clean code, code review‚Ä¶) et DevOps
- Une communaut√© de partage de bonnes pratiques (BBL, dojo, meetup, conf‚Ä¶)
Votre r√¥le et vos missions
Vous aurez pour missions principales de d√©velopper les projets Big Data demand√©s par le m√©tier, et notamment :
Passer de la donn√©e brute √† de la donn√©e exploitable, expos√©e sous forme de tables requ√™tables dans le datalake
Consolider ces donn√©es au fur et √† mesure de leur alimentation r√©currente dans le data lake
Les exploiter pour atteindre la finalit√© business (exposition de business view, r√©int√©gration des r√©sultats dans le SI, service de scoring, ‚Ä¶)
De travailler √† la cr√©ation du socle technique Big Data et industrialiser le cycle de d√©veloppement de l'√©quipe
De mettre en place et de garantir le respect dans la dur√©e d'un processus qualit√© sur l'ensemble du cycle de DEV (documents, tests unitaires / int√©gration / fonctionnels, commentaires, versionning, etc.)
Votre profil
Vous justifiez de plusieurs exp√©riences significatives (+ de 5 ans) sur du
d√©veloppement big data, en particulier sur du PySpark.
Comp√©tences techniques :
Connaissances avanc√©es en d√©veloppement en
PySpark
(Spark avec le langage Python)
Maitrise de l'environnement
Microsoft Azure
Connaissances avanc√©es d'outils de BI comme
PowerBI
Comp√©tences transverses :
Capacit√© √† interagir avec des parties prenantes diverses : Business analyst, Architectes, M√©tier
Exp√©rience en mode de delivery Agile (Scrum, Kanban, etc...)
Driver et accompagner des Data Engineer junior sur les aspects technique
Et Id√©alement :
Des Connaissances sur Azure DevOps, Azure Pipeline, GIT, JIRA
Maitrise des Traitements Big Data en mode Streaming
Maitrise des Bases de donn√©es relationnelles et NoSQL
Une exp√©rience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory
Qui sommes nous ?
AXA est un des leaders de l‚Äôassurance et de la gestion d‚Äôactifs dans le monde.
Nous aidons nos 108 millions de clients √† traverser les petites et grandes difficult√©s de la vie.
Chaque jour, nous agissons ensemble pour inventer la meilleure mani√®re de les prot√©ger et voulons donner √† chacun les moyens de vivre une vie meilleure.
Un challenge qui donne le sourire et envie de se lever le matin !
Chez AXA, nous sommes persuad√©s que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs. C‚Äôest pour cette raison que nous menons une politique RH engag√©e qui favorise la diversit√©, qui pr√©serve l‚Äô√©quilibre vie priv√©e-vie professionnelle et acc√©l√®re le d√©veloppement des comp√©tences et des carri√®res.
Ainsi, en rejoignant AXA France vous travaillerez dans une entreprise responsable, offrant une v√©ritable culture d‚Äôexpertise, acc√©l√©rant le d√©veloppement des comp√©tences de chacun et proposant une r√©mun√©ration attractive.
Pourquoi nous rejoindre ?
Vous √™tes porteur d‚Äôid√©es et d‚Äôinitiatives innovantes ? Vous proposez des solutions et √™tes au service du client ? Faites partie de notre grande famille en rejoignant
Un leader mondial offrant des opportunit√©s de carri√®res int√©ressantes
Une entreprise qui donne une place de choix √† l‚Äôinnovation, √† l‚Äôinitiative et aux actions solidaires (notamment via l‚Äôassociation AXA Atout C≈ìur)
Un environnement inclusif √† tous les niveaux (mixit√©, handicap, initiatives pour favoriser l‚Äôinsertion des jeunes, orientation sexuelle, etc.)
Un acc√®s √† de multiples avantages (cong√©s, temps partiel, t√©l√©travail, etc.)
Un cadre stimulant, qui permet de rencontrer des collaborateurs performants et d‚Äôenrichir ses comp√©tences
Victime ou t√©moin, en cas de discrimination, vous pouvez adresser vos signalements et/ou alertes discrimination √† alerte.discrimination.harcelement@axa.fr
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['JIRA', 'Teams'], 'Other': ['DevOps', 'Big Data'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': ['Junior', 'Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Engineer,Beelix,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-beelix-3865239426?position=2&pageNum=5&refId=T%2B%2BV0JbclKMpVoA2J23Itg%3D%3D&trackingId=At6zkzF%2BwCiC%2FjDzU74g7g%3D%3D&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ?
Depuis 2016, nous accompagnons nos clients sur des probl√©matiques de Product Management, Data et Design Thinking. Beelix contribue √† fa√ßonner le monde de demain en participant aux grandes avanc√©es des secteurs suivants:
üöóAutomobile
‚ö°Energie
üì°M√©dias & T√©l√©coms
üëóLuxe & Retail
üí∂ Banque, Finance & Assurance
‚úàÔ∏èD√©fense
Aujourd‚Äôhui, Beelix compte plus de 200 collaborateurs motiv√©s et dynamiques. Lab√©lis√©e Great Place To work en 2023, Beelix est aussi une entreprise engag√©e o√π il fait bon vivre.
Dans le cadre de notre d√©veloppement, nous recherchons un Data Engineer en √éle-de-France.
Quelles missions au quotidien ?
Vous aurez pour missions principales de d√©velopper les projets Big Data demand√©s par le m√©tier, et notamment :
Passer de la donn√©e brute √† de la donn√©e exploitable, expos√©e sous forme de tables requ√™tables dans le Datalake
Consolider ces donn√©es au fur et √† mesure de leur alimentation r√©currente dans le Datalake
Les exploiter pour atteindre la finalit√© business (exposition de Business View, r√©int√©gration des r√©sultats dans le SI, service de scoring, ‚Ä¶)
De mettre en place et de garantir le respect dans la dur√©e d'un processus qualit√© sur l'ensemble du cycle de DEV (documents, tests unitaires / int√©gration / fonctionnels, commentaires, versionning, etc.)
Accompagner les Data Engineers sur son p√©rim√®tre pour garantir la qualit√© des livrables
Expertise souhait√©e
Expertise en SPARK et PySpark
Expertise sur Databricks
Une exp√©rience sur un cloud provider public comme Azure (id√©alement), AWS, ou GCP
Connaissances avanc√©es d'outils de BI comme PowerBI (id√©alement) ou Spotfire
Capacit√© √† interagir avec des parties prenantes diverses : Business analyst, Architectes, M√©tier
Etre expert dans les pratiques du Software Craftsmanship (Test Driven Development, Behavior Driven Development, Clean Code, Code Reviews, etc.)
Des Connaissances sur Azure DevOps, Azure Pipeline, GIT
Maitrise des Traitements Big Data en mode Streaming
Maitrise des Bases de donn√©es relationnelles et NoSQL
Une exp√©rience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory
A propos de vous ?
Dipl√¥m√© d'une √©cole d'ing√©nieurs ou √©quivalent
Au moins 3 ans d'exp√©rience en tant que Data Engineer
Exp√©rience en mode de Delivery Agile (Scrum, Kanban, etc.‚Ä¶)
Vous avez un bon niveau d‚Äôanglais tant √† l‚Äô√©crit qu‚Äô√† l‚Äôoral
Pourquoi nous rejoindre ?
Un suivi et un accompagnement au quotidien
Un organisme de formation certifi√© Qualiopi, un abonnement linkedin learning pour chaque salari√© et des partenariats avec des sp√©cialistes pour d‚Äôautres expertises
De nombreux √©v√©nements : Afterworks, Communaut√©s m√©tiers, Happy talks‚Ä¶
une Exp√©rience personnalis√©e bas√©e sur vos besoins gr√¢ce au Pr√©dictive Index
Notre package ¬´ unBeelievable ¬ª : 100% du titre de transport, Tickets restaurants, CSE, Prime de participation ...
Nombreux √©v√®nements (afterworks, sport, etc) et des communaut√©s m√©tiers dynamiques
Le processus de recrutement ?
√âchange t√©l√©phonique (15 min)
Entretien 1 RH pour apprendre √† vous conna√Ætre
Entretien 2 avec votre futur N+1 pour appr√©hender la relation manag√©riale
Entretien 3 avec un Responsable commercial pour avoir la vision strat√©gique
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['100'], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer,CGI,"Niort, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-at-cgi-3902057928?position=3&pageNum=5&refId=T%2B%2BV0JbclKMpVoA2J23Itg%3D%3D&trackingId=IMZKLUIu9KltYvuQgJMBZg%3D%3D&trk=public_jobs_jserp-result_search-card,"Description de poste
Big Data, Data Science, Data analyse, Data architecture ... √áa n‚Äôa pas de secret pour vous ?
Que vous commenciez votre carri√®re professionnelle ou que vous soyez sp√©cialiste de l‚Äôune de ces disciplines, int√©grer notre communaut√© Data, c‚Äôest l‚Äôassurance de progresser, innover, partager, vous certifier et rendre service √† nos clients.
Si vous souhaitez int√©grer nos √©quipes √† Niort et accompagner les plus grands acteurs du secteur des Assurances, cette annonce est susceptible de vous int√©resser.
En tant que Data Engineer, vous serez responsable de la conception, du d√©veloppement, de la gestion et de l'int√©gration des syst√®mes bas√©s sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop. Ce r√¥le implique la mise en place d'architectures √©volutives et hautement disponibles pour r√©pondre aux besoins de traitement et de stockage de donn√©es de l'entreprise.
Fonctions et responsabilit√©s
Vos responsabilit√©s seront les suivantes:
-Maintenir et d√©velopper des solutions bas√©es sur les services AWS pour le stockage, le traitement et l'analyse de donn√©es
-Utiliser les services AWS appropri√©s tels que Amazon EC2, S3, RDS, Lambda, etc., pour r√©pondre aux exigences du projet.
-Cr√©er et maintenir les configurations Terraform pour la gestion de l'infrastructure en tant que code (IaC) sur AWS
-Participer √† la maintenance et √† la mise en place d'environnements OpenShift pour l'h√©bergement d'applications et de services
-G√©rer et administrer les clusters Kafka pour garantir la disponibilit√©, la performance et la s√©curit√© du syst√®me de messagerie
Participer √† l‚Äôassistance utilisateurs sur les briques de la plateforme Hadoop Cloudera Data
-Travailler avec les projets et les devOps pour assurer un traitement efficace des donn√©es
En rejoignant CGI, vous b√©n√©ficiez notamment d‚Äôune offre compl√®te de formations (techniques, m√©tiers, d√©veloppement personnel,‚Ä¶), de flexibilit√© gr√¢ce √† notre accord t√©l√©travail (jusqu‚Äô√† 3 jours de t√©l√©travail par semaine), d‚Äôune politique de cong√©s avantageuse (27 jours de cong√©s pay√©s, RTT, cong√©s anciennet√© et enfant malade,‚Ä¶) et d‚Äôun package d‚Äôavantages int√©ressant (r√©gime d‚Äôachats d‚Äôactions, participation, CSE,...).
Qualit√©s requises pour r√©ussir dans ce r√¥le
Ayant une premi√®re exp√©rience en tant que Data Engineer, vous avez une premi√®re exp√©rience relative aux points suivants:
-D√©veloppement et int√©gration sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop
-Connaissance avanc√©e de l'administration Kafka, y compris la configuration, la gestion et la r√©solution des probl√®mes
-Mise en ≈ìuvre de l'infrastructure en tant que code √† l'aide de Terraform
-Bonne compr√©hension des bonnes pratiques de s√©curit√© pour les syst√®mes cloud, les clusters Kafka et les plateformes Hadoop
CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, √† l‚Äô√©volution de carri√®res des hommes et des femmes et au bien-√™tre de nos salari√©s LGBT+. Dans un souci d‚Äôaccessibilit√© et de clart√©, le point m√©dian n‚Äôest pas utilis√© dans cette annonce. Tous les termes employ√©s se r√©f√®rent aussi bien au genre f√©minin que masculin.
Ensemble, en tant que propri√©taires, mettons notre savoir-faire √† l‚Äô≈ìuvre.
La vie chez CGI est ancr√©e dans l‚Äôactionnariat, le travail d‚Äô√©quipe, le respect et un sentiment d‚Äôappartenance. Chez nous, vous pourrez exploiter votre plein potentiel parce que‚Ä¶
Nous vous invitons √† devenir propri√©taire d√®s le jour 1 alors que nous travaillons ensemble √† faire de notre r√™ve une r√©alit√©. C‚Äôest pourquoi nous nous d√©signons comme associ√©s de CGI, plut√¥t que comme employ√©s. Nous tirons profit des retomb√©es de notre succ√®s collectif et contribuons activement √† l‚Äôorientation et √† la strat√©gie de notre entreprise.
Votre travail cr√©e de la valeur. Vous √©laborerez des solutions novatrices et d√©velopperez des relations durables avec vos coll√®gues et clients, tout en ayant acc√®s √† des capacit√©s mondiales pour concr√©tiser vos id√©es, saisir de nouvelles opportunit√©s, et b√©n√©ficier d‚Äôune expertise sectorielle et technologique de pointe.
Vous ferez √©voluer votre carri√®re en vous joignant √† une entreprise b√¢tie pour cro√Ætre et durer. Vous serez soutenus par des leaders qui ont votre sant√© et bien-√™tre √† c≈ìur et qui vous permettront de saisir des occasions afin de parfaire vos comp√©tences et √©largir les horizons.
Joignez-vous √† nous, l‚Äôune des plus importantes entreprises de conseil en technologie de l‚Äôinformation (TI) et en management au monde.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['OpenShift'], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Flexibilit√©'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['1'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,PROXIAD,Greater Nice Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-at-proxiad-3901014428?position=4&pageNum=5&refId=T%2B%2BV0JbclKMpVoA2J23Itg%3D%3D&trackingId=akF4kKw%2FOHmdQHXCvd6JKA%3D%3D&trk=public_jobs_jserp-result_search-card,"Contexte
En tant que Data Engineer, votre r√¥le consistera √† r√©aliser la conception, le d√©veloppement, les tests unitaires, la qualification, l'int√©gration continue et la mise en production d'√©volutions sur les projets du p√¥le produits scoring.
Ces projets Big Data GCP ont pour objet de d√©velopper des traitements de croisement de donn√©es, exploration data en mode agile (scrum et Safe), industriel (respect de normes), sur l'environnement Google Cloud Platform.
1 : Conception
Sp√©cification et conception d'une solution se basant sur les d√©veloppements existants.
Mettre en question les choix techniques dans le but de concevoir un logiciel r√©pondant au mieux √† la demande au moindre co√ªt et avec la qualit√© demand√©e.
Conception de l'expression de besoins, de la r√©ponse √† l'expression de besoins √† l'aide des besoins m√©tiers remont√©s par le Product Owner.
2 : R√©alisation
D√©veloppement de nouvelles fonctionnalit√©s sur les composants des applications du p√¥le produits scoring en environnement GCP (DataProc, GCS, BigQuery, Airflow...)
Tests des d√©veloppements r√©alis√©s
Revue de code des d√©veloppements des autres d√©veloppeurs
Mise en production via CICD des d√©veloppements
3 : Suivi du RUN applicatif
Prendre en charge avec les autres membres de l'√©quipe le RUN des applications du p√¥le produits scoring. Cela inclus les t√¢ches de rapport quotidien, la gestion des probl√®mes applicatifs, le soutien aux utilisateurs.
Comp√©tences attendues
Ma√Ætrise op√©rationnelle :
Confluence
Impl√©mentation de l‚Äôint√©gration continue (Utilisation de la chaine CI/CD existante )
Connaissance des principes DevOps
Jira
Anglais (lu, √©crit)
Ma√Ætrise avanc√©e :
Elaborer un cahier de recette
Big Query
Sp√©cifications technique et documentation
D√©veloppement :Python, SQL, Scala, Javascript, GitLab
Expertise
GCP : Exp√©rience significative en tant que Data Engineer Cloud. Mise en pratique des produits GCP et en particulier Dataproc, Big Query, composer, workflow, PubSub
D√©veloppement : Java
Compr√©hension g√©n√©rale des travaux BigData et du profiling
Informations compl√©mentaires :
T√©l√©travail 2 jours par semaines
R√©mun√©ration aux alentours des 45K‚Ç¨
Exp√©rience requise : 6 ans
Localisation : Mougins
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go', 'JavaScript'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery', 'Big Query'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['JIRA', 'Confluence'], 'Other': ['DevOps', 'Big Data', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '6', '6', '6']}"
CDI - DATA ENGINEER SPARK SCALA JUNIOR - H/F,ITNOVEM.,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/cdi-data-engineer-spark-scala-junior-h-f-at-itnovem-3899544280?position=5&pageNum=5&refId=T%2B%2BV0JbclKMpVoA2J23Itg%3D%3D&trackingId=Z77%2B2%2BZ%2F6%2B2HP48vuwZ0vg%3D%3D&trk=public_jobs_jserp-result_search-card,"ITNOVEM, qui sommes-nous ?
Filiale technologique du groupe SNCF, int√©gr√©e √† la Direction du Digital et des Syst√®mes d‚Äôinformation, Itnovem
.
se positionne comme expert de l‚ÄôInternet Industriel. Porteuse de grands projets de la r√©volution digitale, notre soci√©t√© est en constante recherche de profils pour rejoindre la grande aventure de l‚ÄôInternet des objets, de la data science et de l‚Äôaccompagnement des projets digitaux.
Qu‚Äôil s‚Äôagisse de maintenance pr√©dictive, d‚Äôaide √† la d√©cision sur la maintenance des infrastructures, de gare 4.0, d‚Äôusine du futur, ou de s√©curisation des assets, nos √©quipes font valoir √† la fois une exp√©rience m√©tier et une expertise technique sans cesse renouvel√©e, dans le respect des valeurs du groupe :
Excellence
,
Innovation
,
Collectif
,
Agile
,
Engagement.
CONTEXTE
Au sein du p√¥le Factory Data & IA et dans le cadre de la mont√©e en charge des projets, nous sommes √† la recherche d'un¬∑e data engineer Scala/Spark junior.
Rattach√©¬∑e aux √©quipes Data Engineering et en collaboration avec les membres de l‚Äô√©quipe, son r√¥le sera de contribuer aux projets data sur stack Scala/Spark et √† l‚Äôam√©lioration de l‚Äôoutillage et des process internes.
Le recrutement intervient dans le cadre de la cr√©ation d‚Äôun plateau projet d√©di√© √† l‚Äôactivit√© TGV sur Nantes.
MISSIONS
Participer au d√©veloppement des projets data sur stack Scala/Spark
Etre acteur de la mise en place de bonnes pratiques de communication entre les plateaux nantais et parisiens
Avec l‚Äôappui de l‚Äô√©quipe, √™tre impliqu√©¬∑e dans la roadmap technologique (pratiques, outils) et de l‚Äôam√©lioration continue du p√©rim√®tre Scala/Spark
Contribuer proactivement √† la qualit√© et aux comp√©tences des √©quipes Data Science et Engineering : veille techno, capitalisation‚Ä¶
LE PROFIL RECHERCHE
Comp√©tences m√©tiers & outils :
Exp√©rience professionnelle (alternance, stage) ou acad√©mique sur le langage Scala et le d√©veloppement d‚Äôapplications Spark
Connaissances autour du SQL (principes, langage, mod√©lisation)
App√©tence sur les aspects fonctionnels et m√©tiers d‚Äôun projet
Notions de CI/CD (notre stack : Maven, Gitlab, Jenkins, Artifactory, Ansible)
Comp√©tences transverses :
Int√©r√™t prononc√© pour le software engineering
Aisance relationnelle
Proactivit√© et clart√© dans la communication
Rigueur et organisation
Force de proposition
Bonne communication √©crite et orale
Exp√©riences et formations
Titulaire d‚Äôun bac+5 sp√©cialis√© g√©nie logiciel / d√©veloppement ou exp√©rience √©quivalente.
Vous venez d‚Äôobtenir votre dipl√¥me ou occupez d√©j√† votre premier poste dans le domaine du d√©veloppement de pipelines Data.
Localisation
Poste bas√© √† Saint Denis, possiblement √† Lyon
T√©l√©travail jusqu‚Äô√† 3 jours par semaine.
D‚Äôautres raisons de rejoindre ITNOVEM !
üöÄ En tant que filiale SNCF, des opportunit√©s de carri√®res internes vous sont offertes.
üìö ITNOVEM croit en la formation continue de ses collaborateurs et leur donne l‚Äôopportunit√© de s‚Äôinscrire √† une formation par an minimum.
üöä Vos titres de transport sont pris en charge √† hauteur de 75%.
üçΩÔ∏è Via la carte titres-restaurant Swile, vous b√©n√©ficiez de 9,25 ‚Ç¨ par jour dont 60% pris en charge par ITNOVEM.
üíª Chez ITNOVEM, vous b√©n√©ficiez jusqu‚Äô√† 3 jours de t√©l√©travail par semaine.
üèñÔ∏è ITNOVEM vous permet de profiter de 28 cong√©s et de 16 RTT pour les cadres et 10 pour les non-cadres. Par ailleurs, 2 des 3 jours de cong√©s pour enfant malade sont r√©mun√©r√©s.
üë´ La mise en ≈ìuvre de l‚Äô√©galit√© professionnelle femmes/hommes est primordiale chez ITNOVEM. A chaque nouvelle embauche, l'entreprise s'engage √† proposer une r√©mun√©ration √©quivalente tant aux femmes qu'aux hommes.
‚ôªÔ∏è ITNOVEM incite tous les collaborateurs √† trier leurs d√©chets et les gobelets ont √©t√© bannis. Par ailleurs, chaque ann√©e, ITNOVEM participe √† ¬´ La grande collecte ¬ª, une initiative SNCF qui permet de collecter les PC devenus obsol√®tes en leur offrant une seconde vie
Show more
Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['CI/CD'], 'FrSoftSkills': ['Communication', 'Collaboration', 'Organisation'], 'EnSoftSkils': ['Communication', 'Collaboration', 'Initiative']}","{'JobDetail': ['Junior'], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
Junior Data Engineer (H/F/N),Ekimetrics,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/junior-data-engineer-h-f-n-at-ekimetrics-3903416527?position=6&pageNum=5&refId=T%2B%2BV0JbclKMpVoA2J23Itg%3D%3D&trackingId=rKkK5yorfgP2vq5BIs0%2BJQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Ekimetrics
est leader en data science et fournisseur de solutions AI. Depuis 2006, nous utilisons la data science au service de l‚Äôoptimisation de performance marketing, business, et de la transition vers une performance plus durable.
Si vous √™tes passionn√©.e de data, ou de technologie en g√©n√©ral, et que vous avez envie d‚Äô√™tre acteur.rice de votre avenir professionnel, votre place est s√ªrement chez Ekimetrics !
üìäEkimetrics, c‚Äôest:
‚Ä¢ 400 expert.e.s en data science
‚Ä¢ 1000 projets divers et vari√©s pour plus de 350 clients
‚Ä¢ 4 bureaux : Paris, Hong Kong, Londres et New York
‚Ä¢ 1 milliard de $ de profits g√©n√©r√©s pour nos clients depuis 2006
‚Ä¢ 7000 tonnes de CO2 √©vit√©es pour nos clients en 2022
üå±Chez Ekimetrics, nous avons l‚Äôambition d‚Äôaccompagner nos clients √† repenser leur business model, en r√©conciliant performance √©conomique, environnementale et sociale, gr√¢ce √† la data science.
C‚Äôest pourquoi nous avons en interne toutes les comp√©tences nous permettant de r√©pondre aux besoins de nos clients: Product Managers, Product Designers, Data Architects, Data Engineers, DevOps Engineers, Data Scientists.
Pourquoi recrutons-nous ?
En tant que Data Engineer, vous serez impliqu√© dans des projets stimulants avec des clients internationaux de premier plan dans des industries diverses, en construisant des solutions analytiques sur mesure pour r√©pondre aux enjeux de nos clients. Vous travaillerez en √©quipe, avec d'autres consultants Ekimetrics (data engineers, data scientists, software engineers) sur 1 ou 2 projets simultan√©ment. Vous b√©n√©ficierez de nos partenariats technologiques et d‚Äôune offre de formation pour vous accompagner dans votre mont√©e en comp√©tences.
Plus particuli√®rement vos responsabilit√©s seront de
:
‚Ä¢ Concevoir et d√©velopper des solutions permettant de collecter et pr√©parer la donn√©e ;
‚Ä¢ Impl√©menter et industrialiser des pipelines de donn√©es dans des environnements Cloud (Azure, GCP, AWS, Databricks, Snowflake) ;
‚Ä¢ D√©velopper des outils destin√©s √† faciliter l‚Äôex√©cution et le d√©ploiementdes pipelines de donn√©es (CICD, DevOps, MLOps) ;
‚Ä¢ Approfondir vos connaissances en GenAI, Machine Learning, MMO ;
‚Ä¢ Participer aux activit√©s de R&D. (Veille, formations, animation de Meetups, Hackathons, etc.)
Le profil et les comp√©tences recherch√©es
:
‚Ä¢ Bac+ 5 Ecole d'ing√©nieur ou √âquivalent ;
‚Ä¢ Premi√®re exp√©rience sur des sujets Big Data (Projet ou exp√©rience professionnelle) ;
‚Ä¢ Connaissances avanc√©es en base de donn√©es et en d√©veloppement (Python, SQL, Spark) ;
‚Ä¢ Exp√©rience dans un environnement Cloud ;
‚Ä¢ Connaissances avanc√©es en acquisition de donn√©es ;
‚Ä¢ App√©tence pour la Data Science.
ü§ù Pourquoi nous rejoindre ?
Rejoindre Ekimetrics, c‚Äôest int√©grer une entreprise dont les valeurs s‚Äôappliquent au quotidien :
‚Ä¢ Evoluer dans un environnement entrepreneurial et non traditionnel (
#curiosit√©)
‚Ä¢ √ätre capable de donner et recevoir du feedback pour s‚Äôam√©liorer en continu (
#excellence
)
‚Ä¢ Se former d√®s son arriv√©e et en continu gr√¢ce √† une exp√©rience apprenante unique, riche de nombreuses ressources (internes, externes, live et digital) alliant savoirs techniques, savoir-√™tre et savoir-faire (
#transmission
)
‚Ä¢ Faire partie d‚Äôune communaut√© accueillante et soud√©e(
#plaisir
)
‚Ä¢ Imaginer des solutions inattendues & sortir de sa zone de confort (
#cr√©ativit√©
)
En 2023, Ekimetrics a obtenu le statut d‚Äôentreprise √† mission qui t√©moigne de notre ambition forte en mati√®re de RSE. Notre raison d‚Äô√™tre: Faire de la data science et de l‚Äôintelligence artificielle l‚Äôacc√©l√©rateur de la transformation durable des organisations.
Nous sommes √©galement certifi√©s Great Place to Work¬© en France, au Royaume-Uni et aux Etats-Unis, et notre bureau de Hong Kong a re√ßu le prix Best Companies to Work for in Asia 2023¬©.
ü§© Vous aurez acc√®s √†‚Ä¶
‚Ä¢ Au catalogue de formation Eki.Academy qui contient des programmes qui vous feront monter en comp√©tences sur nos solutions et nos m√©tiers, des parcours apprenants sur notre plateforme digitale ainsi que des programmes d√©di√©s √† nos enjeux prioritaires, dont la sensibilisation aux sujets environnementaux avec la Climate School ;
‚Ä¢ Une vie sportive, artistique, musicale, ludique, caritative et engag√©e : de notre salle de sport privatis√©e √† nos expositions d‚Äôart, en passant par des jeux vid√©o et des concerts, ou encore les d√©fis RSE sur la plateforme Vendredi. Toutes ces initiatives sont port√©es par nos Eki.People ;
‚Ä¢ De nombreux √©v√®nements et s√©minaires pour rester proche de votre communaut√© ;
‚Ä¢ Des locaux modernes dans un quartier dynamique au c≈ìur de Paris (Grands boulevards) ;
‚Ä¢ Une politique de t√©l√©travail flexible.
üîÑNotre processus recrutement :
üî∏Un entretien RH avec un.e recruteur.se
üî∏Un test technique ou
peer-to-peer
interview selon profil
üî∏Une √©tude de cas avec un.e consultant.e
üî∏Un entretien final avec un.e Manager ou Partner
Nous serions ravi.e.s de vous donner de plus amples informations lors d‚Äôun entretien et attendons votre candidature avec impatience!
En tant qu‚Äôemployeur, Ekimetrics offre √† tous les m√™mes opportunit√©s d‚Äôacc√®s √† l‚Äôemploi sans distinction de genre, ethnicit√©, religion, orientation sexuelle, statut social, handicap et d‚Äô√¢ge. Ekimetrics veille √† d√©velopper un environnement de travail inclusif qui refl√®te la diversit√© dans ses √©quipes.
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': ['Cr√©ativit√©', 'Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer confirm√© (H/F),BforBank,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-h-f-at-bforbank-3918327555?position=7&pageNum=5&refId=T%2B%2BV0JbclKMpVoA2J23Itg%3D%3D&trackingId=EDXCCYjnmeSErR6yzcCRGQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Sur le mod√®le d'une
""Tech company"",
BforBank place
l'humain et le digital
au c≈ìur de sa transformation. Notre mission,
offrir √† nos clients une exp√©rience bancaire incomparable
pour r√©pondre √† leurs besoins et usages mobile. üåü üì±
Rejoindre BforBank c‚Äôest
rejoindre une √©quipe engag√©e
dans un
grand projet de d√©veloppement strat√©gique en France et en Europe.
Nous sommes aujourd‚Äôhui 350 passionn√©(e)s et
recherchons nos talents pour construire la banque de demain
. üöÄ
Nous croyons en la force du collectif, chaque jour rassembl√©s autour de nos valeurs, de simplicit√©, d'optimisme et d‚Äôengagement, encourageant chacun √† oser, essayer et accepter d‚Äô√©chouer.
üéØ Au sein de la Direction Technologie, la Data Factory a pour objectifs de piloter, d√©finir, d√©ployer et op√©rer les meilleures solutions technologiques r√©pondant aux cas d‚Äôusage data et d‚Äôautomatisations de processus de la banque au travers de plateformes. √âgalement, la Data Factory contribue au d√©veloppement des produits, √† la cristallisation et √† la diffusion des pratiques au sein des Squads BforBank sur les usages data dans la banque.
Tu rejoindras une squad en charge de r√©soudre des probl√©matiques m√©tiers en cr√©ant des solutions applicatives utilisant les donn√©es, des data products, avec pour finalit√©s la prise de d√©cision via des moteurs de calcul ou des dashboards, la cr√©ation de flux r√©glementaires, la cr√©ation de data layer ou de reportings.
üöÄ Tes missions principales sont les suivantes :
¬∑ Participer aux analyses, √©tudes d‚Äôimpacts et cadrage techniques
¬∑ Concevoir des solutions en respectant les bonnes pratiques d‚Äôarchitecture data et d√©veloppement
¬∑ R√©aliser le d√©veloppement de nouveaux data products et assurer la maintenance √©volutive et corrective des data products existants
¬∑ R√©diger la documentation technique des data products
¬∑ Assurer un support aux testeurs
¬∑ Reporter de ton activit√© √† ta Squad et travailler dans une d√©marche d‚Äôefficacit√© collective
Concr√®tement tu seras amen√©(e) √† produire les livrables suivants :
¬∑ R√©aliser du code applicatif √† l‚Äô√©tat de l‚Äôart sur notre nouvelle Data Platform
¬∑ Cr√©er des data layer et des rapports sur notre outil de Data Visualisation
¬∑ R√©diger les documentations techniques li√©es √† ta solution, incluant le mod√®le de donn√©es, les proc√©dures, l‚Äôordonnancement
Ce que tu ma√Ætrises :
¬∑ Maitrise des services manag√©s de GCP (BigQuery, dataproc, dataflow, CloudSQL ‚Ä¶)
¬∑ Maitrise du langage Python, Pandas, Spark
¬∑ Maitrise de la mod√©lisation de base de donn√©es et du langage SQL
¬∑ Maitrise d‚Äôune chaine CI/CD (GitLab‚Ä¶)
¬∑ Bonne connaissance de Kafka
¬∑ Bonne connaissance d‚Äôun outil d‚Äôint√©gration de donn√©es type ETL (Informatica‚Ä¶)
¬∑ Connaissance de l‚Äôinfra as code (Terraform)
¬∑ Connaissance d‚Äôun outil de reporting (Looker, BO‚Ä¶)
ü§ù Ce poste est fait pour toi si :
¬∑ Tu es passionn√©(e) par la Data et leurs usages
¬∑ Tu es orient√© r√©solution de probl√®me, est curieux(se) et force de proposition
¬∑ Tu appr√©cies le travail en √©quipe
¬∑ Tu as un bon relationnel et est rigoureux(se)
¬∑ Tu as une bonne capacit√© d‚Äôanalyse et r√©dactionnelle
¬∑ Tu t‚Äôadaptes rapidement aux changements
üéì
Formation :
Tu es dipl√¥m√©(e) d‚Äôun master en √©cole de commerce, √©cole d‚Äôing√©nieur ou √©quivalent.
Chez BforBank nous recherchons avant tout des comp√©tences. Tu ne disposes pas du dipl√¥me requis mais as des exp√©riences √©quivalentes ? N'h√©site pas √† postuler !
üíº
Exp√©rience :
Exp√©rience confirm√©e de 3 ans en tant que Data Engineer.
En rejoignant BforBank tu trouveras‚Ä¶
¬∑ Un projet ambitieux de transformation digitale et culturelle √† l‚Äô√©chelon europ√©en, terrain d‚Äôinnovation et d‚Äôouverture d‚Äôesprit
¬∑ Une organisation apprenante, proposant un large choix de formations toute l‚Äôann√©e, et qui favorise l‚Äô√©change avec les autres marques du Groupe
¬∑ Une promo RSE multi-m√©tiers qui fait √©voluer en continu les actions de BforBank vers une banque plus responsable
¬∑ Une organisation du travail en mode Agile, impliquant un degr√© √©lev√© de collaboration et d'autonomie tout en travaillant avec un groupe de pairs diversifi√©s.
¬∑ Une Direction Technologie en pleine expansion, porteuse de nombreux d√©fis strat√©giques
Mais aussi‚Ä¶
De 2 jours √† 5 jours de t√©l√©travail modulables par semaine, dans la limite de 84 jours par an (frais de fonctionnement pris en charge)
25 jours de cong√©s + 16 jours de RTT
80% du co√ªt de la mutuelle d‚Äôentreprise pris en charge / couvert
Avantages collaborateurs Cr√©dit Agricole : taux et tarifs pr√©f√©rentiels
Des frais de transports rembours√©s √† 75%
Un restaurant d‚Äôentreprise
Des douches pour les sportifs et un tarif avantageux aupr√®s d‚Äôune salle de sport toute proche
üìç Le poste est bas√© √† La D√©fense, dans des locaux flambant neufs !
BforBank s'engage √† garantir l'√©galit√© des chances aux candidats car nous sommes convaincus de la richesse apport√©e par la diversit√© et l'inclusion dans nos √©quipes.
Rencontrons-nous !
Le processus de recrutement se d√©roule en 4 √©tapes :
üßëüèº‚Äçüíª
Call de 30 minutes avec notre √©quipe Talent Acquisition
Echange avec le Data Factory Manager et notre √©quipe Talent Acquisition (pr√©sentiel)
Echange avec une personne de l‚Äô√©quipe avec qui tu seras amen√© √† travailler (visio)
Echange avec le CTO (visio ou pr√©sentiel)
Notre processus de recrutement dure en moyenne 3 semaines et l‚Äô√©quipe Talent Acquisition se tiendra √† ta disposition pour te donner un maximum de visibilit√© sur l‚Äôavanc√©e du process.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Confirm√©'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
(Senior) Data Engineer,Mirakl,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-at-mirakl-3904071960?position=8&pageNum=5&refId=T%2B%2BV0JbclKMpVoA2J23Itg%3D%3D&trackingId=yt%2BOLeejTmunadfgqcN3%2FQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Mirakl, leader et pionnier de l‚Äô√©conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'acc√©l√©rer de fa√ßon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avanc√©e, s√©curis√©e et √©volutive leur permettant de digitaliser leur activit√© et d'√©largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacit√©, offrir une exp√©rience d'achat personnalis√©e √† leurs clients, et augmenter leurs profits gr√¢ce au retail media. Bas√©e √† Paris et Boston, Mirakl est certifi√©e Great Place to Work.
A propos de Mirakl Labs
Nos √©quipes techniques et produits, nomm√©es Mirakl Labs, sont principalement r√©parties entre nos 2 hubs situ√©s √† Paris et √† Bordeaux. Elles collaborent au quotidien afin d'adresser les probl√©matiques de nos clients et utilisateurs en r√©pondant √† diff√©rents challenges li√©s aux nouvelles fonctionnalit√©s, √† la scalabilit√©, la s√©curit√© et l‚Äôergonomie‚Ä¶
Elles op√®rent en mode agile et s'organisent en Squads compos√©es d'un Squad Lead, de 5 d√©veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est sp√©cialis√©e sur un scope fonctionnel afin de concevoir et r√©aliser de nouvelles features, leurs √©volutions et des APIs (avec un d√©coupage en micro-services). Nos √©quipes Infrastructure, Architecture, S√©curit√©, Documentation, Product Design, Data et Support op√®rent en transverse en apportant leur expertise et de la coh√©rence sur l‚Äôensemble des produits.
Toutes les √©quipes sont responsables de leur p√©rim√®tre et chacun des collaborateurs apporte son exp√©rience et ses id√©es. Innovation, feedback et implication dans les prises de d√©cision sont au c≈ìur de notre philosophie.
Et pour favoriser ce partage avec d‚Äôautres passionn√©s, nous sommes sponsors, speakers, et h√¥tes de diff√©rents √©v√©nements, meetups, et associations de la sc√®ne Tech en France. Au cours des derni√®res ann√©es, nous avons particip√© √† des √©v√©nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.
A propos du job
La solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commer√ßants √† travers le monde. Cette solution g√®re et produit de gros volumes de donn√©es qui pr√©sentent des challenges extr√™mement int√©ressants pour les sp√©cialistes de la donn√©e (produits, commandes, clients, niveaux de stock, prix, messages, appels API, donn√©es de navigation, s√©ries temporelles, donn√©es g√©olocalis√©es etc.).
En tant que (Senior) Data Engineer au sein de l‚Äô√©quipe Data Mirakl, vos principales missions seront de :
contribuer √† l'enrichissement de la Data Platform (ETL)
am√©liorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inf√©rence real time etc.)
Int√©gr√©(e) dans une √©quipe de sp√©cialistes de la donn√©e (data engineers, machine learning engineers, data scientists, data analysts), vous √™tes un des acteurs cl√©s pour garantir la place de Mirakl comme solution dominante sur son march√©.
Notre stack et nos outils
Apache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, Ansible
Au quotidien, vous allez :
Participer √† la d√©finition et √† l‚Äôimpl√©mentation d‚Äôune architecture performante, robuste, scalable et aux co√ªts ma√Ætris√©s pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (√©valuation des feature stores, refactoring de DAG Airflow)
Accompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practices
Optimiser et am√©liorer la CI/CD de l‚Äô√©quipe en collaboration avec l‚Äô√©quipe SRE
Assurer la mont√©e en comp√©tence des membres de l‚Äô√©quipe sur les sujets de MLOps et Data Engineering
R√©fl√©chir √† la meilleure fa√ßon d'int√©grer les donn√©es Google Analytics dans la data platform
Partager ses connaissances et pr√©senter les travaux devant toutes les √©quipes Labs
Ce qu‚Äôon peut vous apporter :
Des projets data driven, divers et vari√©s (traitements massifs d‚Äôimages, de textes, time series etc.) pour des produits diff√©rents de Mirakl
Une culture orient√©e sur la veille technologique
Des projets qui ont un vrai impact business devant √™tre d√©ploy√©s sur des centaines de clients dans un contexte multilingue
Quelques exemples de sujets en cours :
Enrichissement des donn√©es produit √† partir des images et des descriptions
Mod√©ration automatique des produits
Mapping automatique des donn√©es produit
Identification des produits √† fort potentiels
D√©tection de comportements frauduleux
Sentiment analysis sur les messages √©chang√©s entre clients et vendeurs et dans les √©valuations
D√©termination de prix optimaux
Monitoring de la qualit√© de service des vendeurs
Des applications d‚Äôinf√©rence en synchrone de nos mod√®les de ML
Vous aimerez ce job si :
Vous √™tes passionn√©(e) par la data et les technologies modernes permettant d'en tirer partie
Vous vous int√©ressez √† la data science et avez des connaissances g√©n√©rales sur les algorithmes de Machine Learning
Vous avez un background en d√©veloppement et avez √©volu√© dans un environnement Data
Vous avez a minima 4 ans d‚Äôexp√©rience en environnement Machine Learning et/ou Data
Vous avez mis en production avec succ√®s des applications Big Data faisant appel √† du Machine Learning, du NLP, du traitement d‚Äôimages dans des projets d'envergure, √† fort volume de donn√©es
Votre ma√Ætrisez Python, √™tes un pro des frameworks data de la fondation Apache et √™tes √† l'aise dans un environnement AWS
Vous ma√Ætrisez au moins un outil d‚Äôorchestration (Airflow, Data Pipeline ou tout autre outil similaire)
Vous pr√©sentez vos travaux de mani√®re simple et accessible
Vous fa√Ætes preuve d'un bon relationnel et vous aimez mentorer des collaborateurs
Vous parlez couramment anglais et fran√ßais
Les plus pour le poste :
Vous avez une exp√©rience significative dans le domaine du e-commerce
Vous avez d√©j√† mis en place un Data Lake, Data Warehouse ou une Data Platform
Vous avez d√©ploy√© des applicatifs en environnement Kubernetes
Vous avez mis en place des pipelines d'ingestion de donn√©es avec une approche CDC √† l'aide de Debezium ou autre
Vous ma√Ætrisez Java/Scala
Mirakl est engag√©e en faveur de la diversit√©, de l‚Äô√©galit√© des chances et de l‚Äôinclusion. Nous c√©l√©brons nos diff√©rences car nous sommes convaincus que les qualit√©s visibles et invisibles de chaque Mirakl Worker sont une source de force et d‚Äôinnovation. Dans le cadre de cet engagement, nous √©tudions toutes les candidatures sans distinction de : genre, ethnicit√©, religion, orientation sexuelle, handicap, √¢ge ou toute autre caract√©ristique prot√©g√©e par la loi.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Machine Learning', 'CI/CD'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Data Engineer | Python - Azure | IA & Machine Learning  | Paris ou Remote Partiel,Octopus IT - Expert du recrutement tech,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-python-azure-ia-machine-learning-paris-ou-remote-partiel-at-octopus-it-expert-du-recrutement-tech-3664568765?position=9&pageNum=5&refId=T%2B%2BV0JbclKMpVoA2J23Itg%3D%3D&trackingId=VOh7imz%2B%2FpNP0UBJ9b97qQ%3D%3D&trk=public_jobs_jserp-result_search-card,"La soci√©t√©
Cr√©√©e il y a plus de 2 ans, cette startup est la premi√®re base de connaissance intelligente d√©di√©e aux services clients. Leur mission ? En finir avec la frustration lorsque l'on contact un Help Desk.
Pour cela, elle propose aux entreprises la possibilit√© de d√©livrer une exp√©rience client d'exception : rapide et de qualit√©. Gr√¢ce √† leur moteur de recherche intelligent, cette entreprise est capable de centraliser toute la connaissance interne de l'entreprise (proc√©dures, produits, modes op√©ratoires, etc.) et la diffuse intelligemment dans les outils de production des conseillers de service client.
R√©sultat :
Plus besoin de chercher l'information
Des r√©ponses instantan√©es et de meilleures qualit√©es
Une autonomie totale des collaborateurs
Apr√®s une croissance fulgurante, elle a su s√©duire √† la fois de nombreuses scale up (Luko, OpenClassrooms, Japhy...) et grands groupes (BNP Paribas, La Poste, Fnac Darty...).
Apr√®s le recrutement de leur Lead Data (r√©aliser ensemble) et suite √† l'annonce de leur lev√©e de 2,5M‚Ç¨ pour tripler la taille de ses √©quipes, le but est maintenant de s'imposer tr√®s vite comme la base de connaissance de r√©f√©rence en France et en Europe. Pour ce faire, nous recherchons un Data Engineer.
Le poste
En travaillant main dans la main avec le Lead Data, ta mission sera de d√©velopper et de maintenir des flux de donn√©es complexes et robustes. La donn√©e √©tant au coeur de l' entreprise, dans le produit comme dans la strat√©gie, tu seras amen√© √† travailler avec un panel d‚Äôinterlocuteurs tr√®s vari√©s :
Data Scientists sur des sujets comme le monitoring des mod√®les de production et l‚Äôenrichissement des donn√©es d‚Äôentrainement.
Product Team sur des sujets de performance et d‚Äôacheminement de donn√©es au service de fonctionnalit√©s produit telles que le dashboard d‚Äôanalytics √† destination de nos clients.
Customer Success / Strategy sur des sujets de pilotage comme le suivi de l‚Äôutilisation de notre plateforme ou la mise en place de KPIs de performance.
Tu travailleras sur les probl√©matiques suivantes :
Tu seras responsable de notre architecture de donn√©es et de son outillage, mais aussi de la mise en place de pipelines de donn√©es complexes et robustes.
Tu seras amen√© √† mettre en place des outils de monitoring et d‚Äôalerting pour suivre de pr√®s nos nombreuses pipelines de donn√©e.
Tu seras garant de la qualit√© de nos donn√©es en assurant l‚Äôapplication des guidelines de code et des tests automatis√©s pour chacune de nos pipelines.
Tu seras amen√© √† mettre en place des outils de reporting / insights √† destination d‚Äôinterlocuteurs vari√©s (Data Science, Product, Customer Success, Clients, etc.).
Tu cr√©eras et d√©velopperas des pipelines de donn√©es avec des outils de scheduling et d‚Äôorchestration.
La stack sur laquelle vous travaillerez :
Langage : Python, Javascript
Framework data : PyTorch, Transformers (Hugging Face), FastAPI
Database : PostgreSQL, MongoDB, ElasticSearch, Redis
Infrastructure : Azure, Docker, Kubernetes, Spark, RabbitMQ, Serverless, Terraform
Environnement / Test : PyTest, Gitlab (git + ci/cd)
BI : Metabase, Superset
Votre profil
Entre 1 et 3 ans d'exp√©rience en CDI
Tu as une exp√©rience significative sur des probl√©matiques de Data engineering
Tu es quelqu'un de pragmatique
Un tr√®s bon niveau en Python et une tr√®s bonne rigueur dans le code
Bonne pratique de dev : clean code, TDD, BDD
Une bonne culture Ops
Une logique cloud (Aws, GCP ou Azure)
Le salaire & avantages
50-7O K‚Ç¨ selon exp√©rience
RTT
Carte Swile & Mutuelle
2/3 jours de t√©l√©travail par semaine
Et plus encore‚Ä¶
Ce qu‚Äôon pr√©f√®re
√ätre impliqu√© √† fond dans une aventure avec de nombreux challenges techniques
Belles opportunit√©s d'√©volutions sur des postes d'Architecte, de Lead ou de Ml Ops
Beaucoup de workshops en interne et catalogue de formations √† votre guise
Une opportunit√© de travailler sur un produit unique qui a d√©j√† s√©duit de tr√®s beaux clients (BNP Paribas, Fnac Darty, Luko, OpenClassrooms)
La possibilit√© de travailler sur une stack tr√®s moderne, des probl√©matiques complexes aussi bien en traitement de donn√©es, qu'en DevOps
Un plan de BSPCE (actions de l'entreprise) tr√®s int√©ressant et motivant !
Une culture d'entreprise fond√©e sur l'apprentissage, l'autonomie, la bienveillance et l'exigence
Le fait de travailler au quotidien avec des fondateurs passionn√©s par leur domaine d'expertise
Ce poste a √©t√© soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d‚ÄôExperts en Recrutement Tech (CDI et clients finaux uniquement) ‚Äì Visitez nous pour plus d‚Äôopportunit√©s :
www.octopusit.fr
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go', 'JavaScript'], 'DataBase': ['SQL', ' MongoDB', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': ['PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'ML', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['50'], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Data Engineer (H/F) - Lille,Logic@l Conseils,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-lille-at-logic%40l-conseils-3811575649?position=10&pageNum=5&refId=T%2B%2BV0JbclKMpVoA2J23Itg%3D%3D&trackingId=11TBdmq9Jr5Wm4NJ8JV1bg%3D%3D&trk=public_jobs_jserp-result_search-card,"Dans le cadre du d√©veloppement de nos activit√©s sur la m√©tropole Lilloise, nous recherchons un
consultant data engineer
(H/F) pour intervenir chez l'un de nos grands comptes clients.
Vos missions :
Recueillir
les besoins m√©tiers et des √©quipes data
Concevoir et mettre en place les
traitements de donn√©es
R√©aliser les
tests de validation
Assurer
l‚Äôalimentation du dataware
R√©aliser les
ordonnancements des traitements
Etre garant de la
mise en place
, du
suivi
et de l‚Äô
exploitation
des outils d√©ploy√©s
Assurer
une veille technologique
r√©guli√®re
Environnement technique :
D√©veloppement :
Python, Scala, R, Java,
Framework :
Spark,
Hadoop,
Outils Big data :
Yarn, Pig, Hive, Kafka, Splunk
Bases de donn√©es :
MongoDB, HBase, Cassandra
ETL :
Talend, Stambia
Plateforme :
Hortonworks, Cloudera, Map Reduce
,
AWS, GCP, Azure
Votre profil :
Vous disposez d‚Äôune exp√©rience
d‚Äôau moins 2 ans en tant que data engineer
ou dans le domaine de l‚Äôanalyse et du traitement de donn√©es.
V√©ritable
passionn√© de la data
, vous √™tes
force de proposition
sur les solutions techniques √† mettre en ≈ìuvre. Vous maitrisez l‚Äôanglais dans un contexte professionnel.
Comp√©tences requises :
Analyses qualitatives et quantitatives (Interm√©diaire)
Anglais (Interm√©diaire)
Architecture fonctionnelle SI (D√©butant)
D√©veloppement d'ouvrages, produits ou √©v√©nements (D√©butant)
Gestion des contr√¥les, tests et diagnostics (D√©butant)
Gestion des risques (Interm√©diaire)
Ma√Ætrise des logiciels (Interm√©diaire)
Mise en exploitation / Production et maintenance (D√©butant)
Nos valeurs
Nous avons d√©cid√© de renverser la pyramide du management pour placer nos collaborateurs en t√™te des priorit√©s de l‚Äôentreprise.
En effet, attach√© √† des valeurs fortes, telles que la proximit√©, la sinc√©rit√©, la fid√©lit√©, la confiance et le respect, nous sommes persuad√©s que la r√©ussite r√©side dans le bien-√™tre de nos collaborateurs.
Cela se traduit par un accompagnement de proximit√©, de la transparence sans langue de bois, des √©changes r√©guliers avec les managers r√©f√©rents, un accompagnement dans le d√©veloppement de carri√®re qui est construit et jalonn√© avec les formations et certifications n√©cessaires et les missions en ad√©quation, pour mener √† bien l‚Äô√©volution de carri√®re.
Pour vous convaincre de nous rejoindre, nos avantages salari√©s compl√©mentaires :
Environnement bienveillant et stimulant au sein de 3 p√¥les d‚Äôexpertises
Formations et Certifications √† la demande
Tickets restaurants : 13‚Ç¨ par ticket
Remboursement √† 100 % des abonnements de transports en commun
Mutuelle frais de sant√© avec de hautes garanties
Prise en charge √† 100% de l‚Äôassurance Pr√©voyance
Ch√®que Cadeau Culture 120 ‚Ç¨
Compte CSE avec une cagnotte de 390 ‚Ç¨
Compte CE : billetterie, voyages, culture, sorties, √† des tarifs pr√©f√©rentiels
Des √©v√®nements chaque mois : activit√©s associatives, sportives, afterwork, s√©minaire,
Partenariat Losc (participation aux match dans la loge VIP logical conseils ‚Äì (Une Vingtaine de match par an)
Possibilit√© de t√©l√©travail
En int√©grant Logic@l Conseils, vous participez √† une r√©elle aventure humaine, alors pour postuler, il suffit de cliquer ci-dessous !
Tous nos postes sont ouverts, √† comp√©tences √©gales, aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['Cassandra', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Data Engineer,Mobiskill | WEFY Group,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-mobiskill-wefy-group-3907393935?position=1&pageNum=7&refId=2YID7uch9sWjo1I7wCmyNQ%3D%3D&trackingId=gPwfRZiToccoAQLQfsQAHQ%3D%3D&trk=public_jobs_jserp-result_search-card,"La soci√©t√© :
Le produit repose sur la data, leur solution bas√©e sur de l‚Äôintelligence artificielle permet de personnaliser le monde de la promotion et de la fid√©lisation. Ils viennent d'√™tre rachet√©s et ont une forte ambition pour leur expansion internationale.
Les missions :
- Travailler avec les data scientists pour apporter des solutions
- Industrialiser les mod√®les
- Optimiser la performance du produit
- D√©velopper des outils big data pour scaler
- Mentorer des profils plus juniors
Stack :
- Scala
- Spark / Spark Streaming
- Kafka
- GCP
- Cassandra
- Docker
Profil recherch√© :
- Entre 3 et 5 ans d'exp√©rience dans le Data Engineering
- Exp√©rience en Scala/Spark
- Exp√©rience sur cloud (tr√®s id√©alement GCP)
- Pr√™t √† faire des missions polyvalentes
- Ouvert √† d'autres technos (ils ont pour objectif d'impl√©menter prochainement des outils en Python)
Pourquoi les rejoindre :
- Expansion internationale : USA, Br√©sil, Russie, Espagne‚Ä¶
- Une stack √† la pointe et un champs d‚Äôaction pour POCer de nouvelles technos si il y a un int√©r√™t business
- Un encadrement bienveillant : les 2 leads techniques sont deux excellents techs ET d‚Äôexcellents mentors avec qui √©changer sur comment faire avancer la soci√©t√© (tu serais le troisi√®me maillons de la chaine).
- Politique remote hybride
- Des bureaux dans Paris intra-Muros
- Une r√©mun√©ration pouvant d√©passer 70k (avec package)
- Une entreprise tr√®s tech, particuli√®rement orient√©e Data
H√¢te de vous en dire plus rapidement !
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Hybride', 'Remote', 'Junior'], 'TypeContract': [], 'Salary': ['Package'], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Engineer,ALFI : Financial Markets Consultancy Services,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-alfi-financial-markets-consultancy-services-3916552424?position=2&pageNum=7&refId=2YID7uch9sWjo1I7wCmyNQ%3D%3D&trackingId=xN%2Fs023Ps5wbxsXxbzaCfw%3D%3D&trk=public_jobs_jserp-result_search-card,"Le Data Engineer intervient au sein de l‚Äô√©quipe Engineering Open Big Data du D√©partement Guilde Data, qui regroupe l‚Äôensemble des expertises technologiques li√©es √† l‚Äôing√©nierie de la donn√©e, de l‚Äôautomatisation et √† l‚Äôexploitation des mod√®les de Machine Learning.
Votre r√¥le et vos missions :
Vous aurez pour missions principales de d√©velopper les projets Big Data demand√©s par le m√©tier, et notamment :
Passer de la donn√©e brute √† de la donn√©e exploitable, expos√©e sous forme de tables requ√™tables dans le Datalake
Consolider ces donn√©es au fur et √† mesure de leur alimentation r√©currente dans le Datalake
Les exploiter pour atteindre la finalit√© business (exposition de Business View, r√©int√©gration des r√©sultats dans le SI, service de scoring, ‚Ä¶)
De mettre en place et de garantir le respect dans la dur√©e d'un processus qualit√© sur l'ensemble du cycle de DEV (documents, tests unitaires / int√©gration / fonctionnels, commentaires, versionning, etc.)
Accompagner les Data Engineers sur son p√©rim√®tre pour garantier la qualit√© des livrables
Expertise souhait√©e
Comp√©tences techniques :
Expertise en SPARK et PySpark
Expertise sur Databricks
Une exp√©rience sur un cloud provider public comme Azure (id√©alement), AWS, ou GCP
Connaissances avanc√©es d'outils de BI comme PowerBI (id√©alement) ou Spotfire
Comp√©tences transverses :
Capacit√© √† interagir avec des parties prenantes diverses : Business analyst, Architectes, M√©tier
Exp√©rience en mode de Delivery Agile (Scrum, Kanban, etc.‚Ä¶)
Etre expert dans les pratiques du Software Craftsmanship (Test Driven Development, Behavior Driven Development, Clean Code, Code Reviews, etc.)
Et :
Des Connaissances sur Azure DevOps, Azure Pipeline, GIT
Maitrise des Traitements Big Data en mode Streaming
Maitrise des Bases de donn√©es relationnelles et NoSQL
Une exp√©rience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory
Conform√©ment √† la r√®glementation, et √† notre politique d‚Äô√©galit√© professionnelle, tous nos postes sont ouverts aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer H/F,Lincoln France,"Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-lincoln-france-3829857168?position=3&pageNum=7&refId=2YID7uch9sWjo1I7wCmyNQ%3D%3D&trackingId=JgE3YnfQ5DjhRTX3PNYJ6Q%3D%3D&trk=public_jobs_jserp-result_search-card,"DATA ENGINEER H/F
CDI
3 ans minimum
Chez Lincoln
, nous formons une communaut√© d'innovateurs passionn√©s qui red√©finissent l'analyse de donn√©es depuis
plus de 30 ans
. En tant que
Pure Player Data
, notre expertise est reconnue dans les domaines
de la Modern BI, du Big Data et de la Science des donn√©es
.
Notre mission ?
Transformer les donn√©es en solutions concr√®tes pour nos clients grands comptes dans divers secteurs tels que la banque, le retail, les t√©l√©coms, l'industrie, la sant√©, etc.
Description de poste
Nous recherchons un
Data Engineer H/F
pour accompagner nos clients dans leurs projets strat√©giques.
Vos missions :
Concevoir et d√©velopper des pipelines de donn√©es robustes et √©volutifs.
Int√©grer et transformer des donn√©es provenant de diff√©rentes sources.
D√©velopper et mettre en ≈ìuvre des algorithmes de traitement de donn√©es avanc√©s.
Collaborer √©troitement avec les √©quipes clients pour comprendre leurs besoins et fournir des solutions adapt√©es.
Assurer la qualit√© et la fiabilit√© des solutions d√©velopp√©es.
Pr√©requis :
Ma√Ætrise des langages de programmation (
Python, Scala, etc
.).
Connaissance approfondie des bases de donn√©es et des technologies
Cloud (GCP, AWS, Azure, Snowflake, etc.)
Exp√©rience avec
MySQL, PostgreSQL, MongoDB.
Maitrise ETL/ELT (Talend, Stambia, etc.)
Solides comp√©tences en conception et en optimisation de pipelines de donn√©es.
Exp√©rience de travail en
m√©thode Agile
pour la gestion de projet et le d√©veloppement de solutions.
Capacit√© √† travailler de mani√®re autonome et en √©quipe.
Excellentes comp√©tences en communication et en r√©solution de probl√®mes.
Les plus du poste :
Environnement Collaboratif
: projets innovants favorisant le partage des connaissances.
Accompagnement individualis√© et de proximit√©
: formations certifiantes, attribution d‚Äôun Career Manager pour vous orienter dans votre trajectoire professionnelle, opportunit√©s d‚Äô√©volution de carri√®re.
Flexibilit√© du Travail
: T√©l√©travail et horaires flexibles pour votre √©quilibre vie professionnelle-personnelle.
R√©mun√©ration Comp√©titive
: Salaire comp√©titif avec des avantages sociaux attrayants.
Mobilit√©
: Possibilit√© de mobilit√© √† Paris, Lyon ou Aix-en-Provence offrant des exp√©riences diversifi√©es au sein de Lincoln.
Notre processus de recrutement :
un entretien RH (1h) et entretien technique (1h)
Cette annonce n‚Äôest pas faite pour vous si :
Vous √™tes freelance et vous comptez le rester !
Toujours l√† ? Postulez et rejoignez nos
400 experts en Data
üòâ.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['MySQL', 'PostgreSQL', 'Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Communication', 'R√©solution de probl√®mes', 'Flexibilit√©'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['400'], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer & Analyst - Paris - F/H/X - CDI,Partoo,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-analyst-paris-f-h-x-cdi-at-partoo-3892387658?position=4&pageNum=7&refId=2YID7uch9sWjo1I7wCmyNQ%3D%3D&trackingId=2e4pIaI4dkTrxrF9KildUg%3D%3D&trk=public_jobs_jserp-result_search-card,"Partoo, who are we? üëÄ
Partoo est une scale-up saas B2B qui a √† c≈ìur d‚Äôaider les commerces locaux, grandes entreprises ou PME √† se rapprocher de leurs clients. Pour cela, ils ont d√©velopp√© une plateforme tout-en-un et diff√©rentes solutions qui s‚Äôarticulent autour de 3 propositions de valeur : Get found, Get chosen & Get clients.
√Ä travers ces 3 propositions, ils ont d√©velopp√© plusieurs produits qui s‚Äôadaptent aux √©volutions du parcours d‚Äôachat des clients :
üîé Get found
Presence: Synchroniser les informations des magasins sur les principales plateformes (Google, Facebook, Waze, etc.), annuaires et GPS
Store Locator: Aider les clients √† trouver le magasin qui leur convient gr√¢ce √† des donn√©es locales actualis√©es et des filtres d√©di√©s sur les sites web des enseignes
R√©seaux sociaux: G√©rer les publications sur Facebook, Google, Instagram, etc
üéØ Get chosen
Review: Centraliser, r√©pondre et analyser les avis clients re√ßus sur Google et Facebook
Booster: Obtenir des avis positifs suppl√©mentaires sur Google par le biais de SMS et de QR codes
ü§ó Get clients
Messages: Centraliser et r√©pondre √† tous les messages de chat re√ßus via Google Business Messages, Messenger et bient√¥t aussi via Instagram, whatsapp, etc. (templates messages, conversations starter, appels manqu√©s...)
Quelques chiffres üóùÔ∏è
> Un label Happy at Work et l'une des meilleures notes Glassdoor de l'√©cosyst√®me avec 4.6/5 pour plus de 260 avis‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è Ô∏èÔ∏èÔ∏èÔ∏èÔ∏èÔ∏è
> 450+ employ√©s heureux, 37 nationalit√©s diff√©rentes, des bureaux √† Paris et Barcelone üöÄ
> Ils g√®rent 300 000 points de vente et travaillent de mani√®re transversale avec +1000 cha√Ænes (Carrefour, Generali, Toyota, D√©cathlon, Leroy Merlin etc.) et +6000 pme dans environ 150 pays
Notre m√©mo 2024: le mot du CEO (https://www.partoo.co/fr/blog/memo-2024/)
IMPACT üí•
Partoo compte aujourd‚Äôhui pas moins de 400 collaborateurs, qui ≈ìuvrent au quotidien √† maintenir une croissance saine, en phase avec les enjeux et challenges √©conomiques du moment.
Une des composantes clefs pour y parvenir r√©side en notre capacit√© √† d√©velopper et maintenir un haut niveau d‚Äôefficacit√© op√©rationnelle. Dans cette logique, am√©liorer notre capacit√© √† exploiter et utiliser la donn√©e pr√©sente dans nos syst√®mes est indispensable. Si nous avons d√©j√† une √©quipe Data en place, celle-ci est aujourd‚Äôhui mobilis√©e presque exclusivement sur les th√©matiques data relatives au fonctionnement de notre application ainsi qu‚Äô√† la construction d‚Äô√©l√©ments de visibilit√© pour nos clients.
Nous souhaitons donc recruter un Data Engineer & Analyst dont l‚Äôobjectif principal sera de permettre aux √©quipes Op√©rations et client-facing de visibiliser et tirer le meilleur parti d‚Äôune donn√©e aujourd‚Äôhui difficile d‚Äôacc√®s.
Manager : Adel Adman (cc. Cl√©ment Bouillaud, en charge de la team Operations)
TEAM üíô
Meetings r√©current avec les membres de Partoo :
Membre √† part enti√®re de l‚Äô√©quipe Data (elle-m√™me int√©gr√©e dans l‚Äô√©quipe Produit), tu seras n√©anmoins en contact r√©gulier avec les √©quipes Op√©rations, qui seront tes principales interlocutrices.
En d‚Äôautres termes, tu seras le pilier central entre les √©quipes Ops et Data.
Dans un premier temps, tu auras un meeting hebdomadaire avec Adel (Lead Data) et avec Cl√©ment (COO), le temps de cadrer tes premi√®res priorit√©s et de trouver la bonne r√©currence de rencontre avec les √©quipes Op√©rations.
MISSIONS üî•
Ton principal objectif consiste √† faire en sorte que chaque personne, des √©quipes Op√©rations comme des √©quipes client-facing, ait acc√®s √† la donn√©e dont elle a besoin, au moment o√π elle en a besoin, sur le support le plus ad√©quat. Pour y parvenir, plusieurs missions seront tiennes :
Architecture
:
Cr√©er des architectures de donn√©es robustes et √©volutives pour collecter, stocker et analyser de grandes quantit√©s de donn√©es provenant de diverses sources (Salesforce, Intercom, Chargebee, back office de Partoo, etc.)
Analyser et am√©liorer continuellement le mod√®le de donn√©es Salesforce (SF), en accompagnant l'√©quipe Ops dans le monitoring des anomalies et l'optimisation des performances
Int√©grations et flux
:
D√©velopper et optimiser des pipelines de donn√©es, assurant l'int√©gration fluide des donn√©es dans notre Data Warehouse depuis diff√©rentes sources, et inversement
Transformation & analyse
:
Concevoir et ex√©cuter des requ√™tes SQL complexes pour l'analyse de donn√©es, permettant de soutenir les d√©cisions business
Identifier et construire des KPI cruciaux, fournissant des insights pr√©cieux aux √©quipes business
Visualisation
:
Fournir aux √©quipes Ops et client-facing des outils de visualisation de donn√©es (Looker Studio, embedding, etc.), cl√©s dans l'optimisation de notre gestion de client√®le.
Formation
:
Former les √©quipes Op√©rations sur l‚Äôexploitation des tables de notre Datawarehouse ainsi que sur l‚Äôusage de Looker Studio et propager les principales best practices associ√©es. Tout √ßa, en collaboration au quotidien avec les √©quipes Ops !
DESIRED PROFILE üéØ
Comp√©tences recherch√©es :
Une tr√®s bonne connaissance du langage SQL, notamment PostgreSQL et BigQuery.
Ma√Ætrise du scripting Python et des notebooks pour l'analyse de donn√©es
D‚Äôexcellentes capacit√©s d'analyse pour comprendre les besoins business, identifier les anomalies dans les donn√©es et proposer des am√©liorations pertinentes
Une bonne aptitude √† manipuler et analyser de grands ensembles de donn√©es et en extraire des insights actionnables
Une tr√®s bonne ma√Ætrise d'au moins un outil de business intelligence tel que Looker Studio, PowerBI ou Tableau
Profils recherch√© :
Tu as plus de 3 ans d'exp√©rience en Data Engineering /Advanced Data Analysis
Tu ma√Ætrises les stacks de data les plus r√©centes (dbt, Airflow, Airbyte, etc.) et les meilleures pratiques en mati√®re de donn√©es (ETL, reverse-ETL, etc.)
Tu es orient√©(e) utilisateur et sais convertir les besoins commerciaux en solutions techniques
Tu sais communiquer avec les √©quipes et t'assurer que les meilleures pratiques sont adopt√©es
Tu es un team player !
Tu souhaites apprendre et grandir avec nous
RECRUITMENT PROCESS üõ†Ô∏è
A first video call with Marine, Talent Acquisition Specialist, 45 min
Interview with Adel, Lead Data Engineer, 1h
Case Study
Interview with Cl√©ment, Chief Operations Officer, 1h
√Ä comp√©tences √©gales, ce poste est ouvert aux travailleurs et travailleuses en situation de handicap ou assimil√©s au sens de l‚Äôarticle L5212-13 du Code du travail. Partoo s‚Äôengage en faveur de la diversit√©, l‚Äô√©galit√© professionnelle, l‚Äôemploi des travailleurs handicap√©s.
With equal skills, this position is open to disabled workers or those considered to be disabled within the meaning of Article L5212-13 of the French Labour Code. Partoo is committed to diversity, professional equality and the employment of disabled workers.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['PostgreSQL', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer,RSight¬Æ,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-rsight%C2%AE-3856216625?position=5&pageNum=7&refId=2YID7uch9sWjo1I7wCmyNQ%3D%3D&trackingId=8Zpi5qSzXdHWTRv3cLq8Zg%3D%3D&trk=public_jobs_jserp-result_search-card,"Nous recherchons pour notre client, un
leader mondial des services et conseils en technologies
, un
ing√©nieur Databricks et Data Factory
qui rejoindra une √©quipe qui combine des comp√©tences m√©tiers avec une forte expertise data, analytique et d‚Äôintelligence artificielle pour mettre en ≈ìuvre des solutions qui visent √† am√©liorer la gestion et la valorisation des donn√©es.
Descriptif des missions:
Vous √™tes int√©ress√© √† travailler sur une solution ayant un impact direct sur les ambitions de notre client en mati√®re de data (datadriven, data d√©mocratisation) ? Alors devenez membre de l‚Äô√©quipe Corporate Data Lake de notre client ! Comme tout autre membre de l'√©quipe, vous :
Participer √† la d√©finition des composants informatiques supportant la fourniture de services
D√©velopper, tester, industrialiser et d√©ployer des composants en minimisant les impacts sur les utilisateurs (automatisation, 0 temps d'arr√™t,...)
Documenter la bonne utilisation des services
D√©ployer et supporter nos fonctionnalit√©s sur la plateforme
Apporter assistance et conseils aux utilisateurs m√©tiers
Op√©rer la solution en op√©ration courante (incluant le suivi de la qualit√© des services) et intervenir dans la r√©solution des incidents
Participer activement √† l'am√©lioration continue des activit√©s de l'√©quipe
Expliquer aux collaborateurs ce que le Corporate Data Lake peut faire pour eux
Configurer des espaces de travail pour eux
Fournir du coaching et de l'expertise lors de r√©unions en face √† face ou sur les canaux communautaires
Participer √† l'effort de support de la plateforme dans une approche ""vous la construisez, vous l'ex√©cutez""
Contribuer aux premi√®res phases de conception d√©finissant l'avenir du Corporate Data Lake
Comp√©tences:
1er exp√©rience Azure (PaaS et IaaS)
Connaissance de Databricks et Data Factory
Ma√Ætrise d'un ou plusieurs langages parmi : Python, Scala, Spark, PowerShell
Int√©gration et livraison continues (Jenkins, Azure Devops, GIT Lab CI, ‚Ä¶)
Pratique des fondamentaux du g√©nie logiciel (Gestion de Configuration, Tests,...)
Anglais : √† l'aise pour assister √† une r√©union et r√©diger de la documentation technique
Bonne capacit√© d'√©coute, orientation client/utilisateur
Expression orale et √©crite adapt√©e √† l'interlocuteur
Curiosit√© et adaptation aux changements technologiques
B√©n√©fices:
Un processus de recrutement court, un accompagnement personnalis√©, une √©volution qui s'adapte √† votre trajectoire de carri√®re.
En plus de votre quotidien li√© √† votre mission, vous pourrez entreprendre, √™tre form√©, passer des certifications.
Plan d'√©pargne pour la retraite collectif, mutuelle, tickets restaurant, des cong√©s d'anciennet√©, un catalogue CE, des accords d‚Äôentreprise relatifs au t√©l√©travail et √† la parentalit√© et autres avantages.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Stage - Data Engineer - ML (H/F),Withings,"Issy-les-Moulineaux, √éle-de-France, France",https://fr.linkedin.com/jobs/view/stage-data-engineer-ml-h-f-at-withings-3613476264?position=6&pageNum=7&refId=2YID7uch9sWjo1I7wCmyNQ%3D%3D&trackingId=DoyNgT9yj6tnq%2BmyCF3KHQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Chez Withings, nous d√©veloppons des appareils de sant√© connect√©e : nos balances connect√©es, montres hybrides, tensiom√®tres, moniteurs de sommeil et tous les dispositifs de notre gamme sont aujourd'hui utilis√©s par des millions d'utilisateurs. Notre objectif est de permettre la pr√©vention, le d√©pistage et l'accompagnement d'un certain nombre de maladies chroniques via des produits et des services innovants afin de r√©volutionner la mani√®re dont on prend soin de notre sant√©.
Au sein de l'√©quipe Machine Learning, nous d√©veloppons des algorithmes pour extraire des informations physiologiques et m√©dicales pour nos utilisateurs tels que le SPO2, la fr√©quence cardiaque, la d√©tection de diverses pathologies comme la fibrillation atriale, l'apn√©e du sommeil...
Int√©gr√©.e au sein de l'√©quipe Machine Learning, tu auras une ou plusieurs des responsabilit√©s suivantes :
D√©velopper un outil de monitoring de la dette technique, des mauvaises pratiques de code, des failles de s√©curit√© ;
Construire des dashboards de visualisation ;
Construire un syst√®me d'alerte pour notifier les contributeurs d'√©ventuels probl√®mes ;
D√©velopper des outils permettant de corriger les √©ventuels probl√®mes de fa√ßon automatis√©e ;
Requirements
√Ä la recherche d'un stage d'une dur√©e de 3 √† 6 mois ;
Pr√©paration d'un Master en √©cole d'ing√©nieur ou √©quivalent / ann√©e de c√©sure possible ;
Ma√Ætrise de Python ;
Ma√Ætrise de Debian ou de Ubuntu, de Shell et de l'environnement Linux ;
Premi√®re exp√©rience sur du d√©veloppement logiciel ;
Culture DevOps (omnipr√©sence du monitoring, automatisation des t√¢ches, ...)
Compr√©hension de la culture et des besoins des diff√©rents membres de l'√©quipe ;
Rigueur, autonomie, prise d'initiative, curiosit√©
Benefits
Rejoindre l'aventure Withings, c'est :
Int√©grer un des pionniers et leaders mondiaux de la sant√© connect√©e, plusieurs fois prim√© au Consumer Electronic Show
Contribuer √† des projets innovants et ambitieux pour la sant√© de demain dans un environnement agile et en constante √©volution
Int√©grer une entreprise internationale, membre de la FrenchTech 120, dont les √©quipes sont bas√©es √† Issy-les-Moulineaux, Boston, Hong-Kong et Shenzhen
Participer √† l'am√©lioration continue de nos produits et services en les b√™ta-testant avant leur sortie, notamment lors de nos nombreuses sessions sportives entre coll√®gues
Participer √† la Withings Med Academy en assistant √† des conf√©rences de professionnels de sant√© afin de renforcer ses connaissances dans le domaine m√©dical
Collaborer avec des coll√®gues passionn√©s et c√©l√©brer ensemble chacune de nos r√©ussites !
Toutes les candidatures re√ßues sont √©tudi√©es ind√©pendamment de l'origine ethnique, des croyances, de la religion, du genre, de l'orientation sexuelle ou de la sant√© des candidats. Withings aspire √† offrir et garantir l'√©galit√© des chances aux candidats et seules les personnes habilit√©es (RH et Management) auront acc√®s aux informations concernant votre candidature.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Machine Learning'], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': ['Hybride'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Stage - Data Engineer,Exotec,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/stage-data-engineer-at-exotec-3918170659?position=7&pageNum=7&refId=2YID7uch9sWjo1I7wCmyNQ%3D%3D&trackingId=WBU9RcALIUZp84dp5t1Vfw%3D%3D&trk=public_jobs_jserp-result_search-card,"Chez Exotec, nous mettons l'excellence technologique au service de la red√©finition des relations entre humains et robots. A travers le monde, nos solutions r√©volutionnent la fa√ßon dont nos clients d√©livrent leurs produits aux consommateurs finaux. Nous contribuons au succ√®s des plus grandes marques du commerce et de l'industrie, tout en am√©liorant les conditions de travail de leurs salari√©s.
Par l'alliance de l'intelligence artificielle et d'un hardware performant, nos robots sont d√©sormais d√©ploy√©s dans le monde entier et leur succ√®s a fait de nous la premi√®re licorne industrielle fran√ßaise.
Rejoindre Exotec, c'est l'opportunit√© de donner du sens √† vos comp√©tences. Grandissez avec plus de 800 ExoPeople dans le monde entier pour faire de vos id√©es des r√©alit√©s.
La r√©volution robotique port√©e par Exotec ne fait que commencer, vous en √™tes ?
Au sein du p√¥le Data, de la DSI d'Exotec, votre r√¥le sera de participer au d√©veloppement de l'environnement et de l'infrastructure Data d'Exotec.
Pour cela :
Vous participez √† la mise en ≈ìuvre des composants techniques de la plateforme de donn√©es d'Exotec
Vous travaillez sur la collecte dans la plateforme de donn√©es provenant de sources multiples : Salesforce, ERP, logiciels d√©velopp√©s en interne
Vous nettoyez, mettez en qualit√© et pr√©parez les donn√©es afin de les rendre disponibles pour les diff√©rents cas d'usage qui en ont besoin
Vous migrez des reportings existants vers la plateforme de donn√©es et mettez en ≈ìuvre de nouveaux cas d'usage pour r√©pondre aux besoins de l'entreprise
Vous travaillerez au sein de l'√©quipe data et en √©troite collaboration avec la software factory, ainsi qu'avec les utilisateurs des m√©tiers qui ont besoin de rendre intelligibles les donn√©es disponibles
Requirements
Vous √™tes √©tudiant(e) d'une √©cole d'Ing√©nieur g√©n√©raliste avec une sp√©cialisation programmation ou informatique
Vous recherchez un stage de fin d'√©tudes d'une dur√©e de 4 √† 6 mois
Vous avez id√©alement une premi√®re exp√©rience en Data Engineering et le d√©veloppement de pipeline de donn√©es
Vous maitrisez Python, l'ETL et SQL,
Curieux(se) et rigoureux(se), vous souhaitez rejoindre une √©quipe jeune et dynamique ainsi que vous investir dans des projets complexes et excitants
Vous avez un niveau d'anglais courant
Chez Exotec, nous garantissons l'√©galit√© des chances dans notre processus de recrutement. L'ensemble des candidatures re√ßues sont √©tudi√©es ind√©pendamment de l'√¢ge, du genre, de l'origine, de la religion, de la couleur de peau, de la nationalit√©, du sexe, du handicap, de l'orientation sexuelle ou de toute autre distinction prot√©g√©e par la loi. Nous mettons en place un environnement de travail inclusif et respectueux de toutes les diff√©rences. En rejoignant le Pacte Parit√©, Exotec s'engage pour un √©cosyst√®me French Tech plus paritaire.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,StackEase,"Marseille, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-at-stackease-3906618983?position=8&pageNum=7&refId=2YID7uch9sWjo1I7wCmyNQ%3D%3D&trackingId=dus3QZepxedeM%2FgZcg7KtA%3D%3D&trk=public_jobs_jserp-result_search-card,"Context :
It is challenging in many ways to develop a net zero electricity grid. Adding renewable energies means more need for storage and for grid balancing. Grid-scale batteries handle these issues but their operation is not quite simple.
A battery has access to many different revenue streams, each being specific. No revenue alone is enough to make it economically viable. All revenues stacked and optimized together ensure profitability in the long run and a fast deployment.
StackEase‚Äôs ambition is to develop optimization and trading algorithms that merge the battery revenue streams and ensure their sustainable development. The final tool will be an autopilot that makes the best decisions in real time, controls the battery accordingly and sends the corresponding orders to¬† the market.
About StackEase:
StackEase is a deeptech spinoff from the INRIA (French Institute for Research in Computer Science). It was created in August 2023 and secured its first fundings. Members are located in Marseille and Paris.
Our values are innovation, customer satisfaction, merit and sustainability. The company's purpose is to leverage Machine Learning and Mathematical Optimization to accelerate the energy transition.
Missions :
Define and develop the backend architecture of StackEase
Set up databases and data pipelines collecting battery and market data
Deploy and maintain optimisation algorithms and forecasts
Develop a robust and scalable SaaS platform for 24/7 battery management with high cyber standards
Participate in the UI/UX product definition
Skills Wishlist :
Scientific BS/MS/PhD with 2+ years of experience in software engineering
Experience with the common backend tools: Python, Git, Kubernetes, SQL/NoSQL ‚Ä¶ Knowledge of the AWS environment is a plus
Enthusiastic, rigorous, autonomous and willing to be involved in major technical decisions
Knowledge/Interest in the energy sector and ancillary services
Compensation :
45k‚Ç¨ - 60k‚Ç¨ salary range (incl. healthcare, unemployment rate, vacations, ‚Ä¶)
Flexible remote work policies
You do not need to meet 100% of the requirements to apply, we will study all applications: please send your resume to jobs@stackease.fr. References and a cover letter are also welcome but not mandatory.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': ['100'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer / Big Data,ALTEN,"Antibes, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-big-data-at-alten-3896177673?position=9&pageNum=7&refId=2YID7uch9sWjo1I7wCmyNQ%3D%3D&trackingId=9KPNQINsEC%2BkKrRJPbAmCQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Alten is one of the 3 main consulting societies in France. It is present in more than 30 countries in the word. Sophia-Antipolis is the first and largest technopole in Europe, located in the South of France between Nice and Cannes, near Antibes. It‚Äôs also called the European Silicon Valley.
Reporting to our consulting team, you will work in an IT environment as an IT Business Analyst, taking part in projects in an Agile environment.
Job Description
The mission consists in taking part toprojectsthat are collecting, processing, and converting raw data into information (Flat Data + KPIs) that can be interpreted by data/business analysts.
TheData accessibilityis the ultimate goal of this mission, by enabling the Digital data users to utilize data for their business decisions.
This role is more Pipeline-centric, for which you need in-depth knowledge of distributed systems and computer science.
The mission scope will encompass the design and delivery of some key components of the Digital Data platform(Spark environment, Scala language) including following activities:
Participate to specifications reviews, propose technical solutions and perform feasibility studies.
Acquire datasets that align with business needs.
Develop algorithms to transform data into useful, actionable information.
Develop, construct, test, and maintain optimal data pipeline architectures.
Create new data validation methods and data analysis tools.
Ensure compliance with data governance and security policies.
Identify ways to improve data reliability, efficiency, and quality.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Prepare data for predictive and prescriptive modeling.
Work with data and analytics experts to strive for greater functionality in our data systems; which requires a closed collaboration with the other trains.
Develop software according to Amadeus Standards, including documentation
Perform code reviews in line with Amadeus quality standards.
Conduct unit, package and performance tests of the software and ensure a level of quality in line with the Amadeus guidelines.
Participate in the validation / acceptance phase of the product cycle ensuring the fine-tuning necessary to finalize the product.
Produce software documentation necessary for the application and issue it to the requesting departments.
Support the end user in the Production phase by debugging existing software solutions in response to Problem Tracking Records (PTR) and Change Requests (CR) issued from Product Management or Product Definition.
As part of the team, the consultant will, as well, work as DevOps, releasing the software load to production, monitoring jobs and being involved in maintenance activities. Quality analyst activities are also handled by the Devs.
Our current data platform is a MapR architecture, and we are in the process to migrate the whole platform to the Azure cloud., which is one of the key focuses for the team in the upcoming months. This will trigger easier adoption of data and foster collaboration within Amadeus around data.
Qualifications
Technical skills:
Previous experience as a data engineer or in a similar role
Experience building or optimizing ‚Äúbig data‚Äù data pipelines, architectures and data sets.
Hands-on experience with Scala (>2 years or a strong experience with Java/C++ with a good knowledge level of Scala)
Experience with big data tool: Spark, Kafka, MapR , Hadoop
Understanding extract, transform, and load ETL systems
Knowledge of cloud services: MS Azure
Soft skills:
Agile Mindset: must be comfortable working with Agile values and artifacts
Fast learning: must be able to adapt quickly to the existing environment and new changes
Analytical thinking and problem-solving mindset: must be able to quickly identify, implement work-around to solve incidents and work on long term data solutions
Team spirit, knowledge sharing, Empathy: must be able to work in a team and to communicate clearly with the other team members and users
Pro-activity, Professionalism, Opennessand Innovative mindset
Various:
English: professional level
Knowledge of Scrum framework and Agile methodologies.
Knowledge of airline business is a plus
Additional Information
ALTEN places the career development of the Engineers at the heart of its model and allows you to quickly take on responsibilities and evolve in line with your professional objective. It's the promise of growing your skills on concrete subjects in a project team, with a permanent contract as an ALTEN consultant!
Do you recognize yourself in this description? Then send us your CV.
Our teams will be delighted to study your application and meet you!
Show more
Show less","{'ProgLanguage': ['Java', 'C++', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Empathy', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['2'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,ASTRELYA,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-at-astrelya-3910760230?position=10&pageNum=7&refId=2YID7uch9sWjo1I7wCmyNQ%3D%3D&trackingId=v8lA3BhOGBaAvAsiUoQ%2FXA%3D%3D&trk=public_jobs_jserp-result_search-card,"ASTRELYA est un groupe de conseil et d‚Äôexpertise IT fond√© en 2017, pr√©sent en France (Paris et r√©gions) et en Suisse (Gen√®ve). Aujourd'hui plus de 280 collaborateurs accompagnent nos clients dans l‚Äôacc√©l√©ration et la transformation de leurs organisations.
Dans le cadre de notre d√©veloppement, nous recherchons un
Data Engineeer F/H
.
Vos r√¥les et responsabilit√©s :
D√©veloppements Java Spark
Optimisation et gestion des √©volutions de l&#39;architecture pour int√©grer des calculs sur des volum√©tries de plus en plus importantes
Support technique aupr√®s des √©quipes de d√©veloppement et du responsable applicatif
Conception des solutions applicatives coh√©rentes avec l&#39;ensemble du SI et avec les normes et standards
D√©velopper et garantir les pratiques de d√©veloppement et de documentation associ√©s (DevOps
L‚Äôenvironnement technique dans lequel vous √©voluerez :
Java, Scala, Spark, √©cosyst√®me Hadoop, environnement DevOps
Les comp√©tences recherch√©es :
Formation : √âcole d‚Äôing√©nieur ou √©quivalent Bac+5
Exp√©riences : Minimum 5 ans d‚Äôexp√©rience
Langues : Anglais technique
Excellent relationnel, force de proposition, autonome
Pourquoi rejoindre ASTRELYA ?
Une gestion de carri√®re personnalis√©e et un management de proximit√©
Une politique active de formations / certifications (technique, m√©tier, leadership)
Une offre vari√©e de missions d‚Äôexpertise
Un engagement RSE fort : Ecovadis Gold, Signataire de la charte pour la diversit√©, du Pacte des Nations Unies et mise en place du M√©c√©nat de comp√©tences
Un programme de cooptation attractif
Afterworks, conf√©rences techniques et activit√©s sportives r√©guliers
Cette annonce vous correspond ? Postulez !
üöÄ
Tous nos postes sont ouverts aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps'], 'FrSoftSkills': ['Leadership', 'Organisation'], 'EnSoftSkils': ['Leadership']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Int√©grateur/Data Engineer,Apollo Plus,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/int%C3%A9grateur-data-engineer-at-apollo-plus-3915774077?position=1&pageNum=10&refId=YRlmHfDXD2q8y%2FLEi2ngtQ%3D%3D&trackingId=auvz94%2F%2BKdvLumd1UTOF%2FA%3D%3D&trk=public_jobs_jserp-result_search-card,"Nous, c'est Apollo Plus.
Notre ambition ? Devenir La solution SaaS bas√©e sur l‚ÄôIA, d'aide √† la d√©cision et de pr√©dictions de la demande dans les secteurs du tourisme, de l‚Äôh√¥tellerie et du retail.
Depuis notre lancement sur ce march√© en 2017, nous n'avons pas arr√™t√© de grandir et d'enrichir notre application pour accompagner nos clients dans leurs diff√©rents challenges et questionnements :
Est-il possible de pr√©dire l‚Äôintention et le comportement des visiteurs ?
Quelle segmentation des visiteurs construire √† partir de nombreuses sources ?
O√π et pour quelle offre g√©n√©rer de l‚Äôaffluence suppl√©mentaire ?
Quelle est l‚Äô√©lasticit√© prix et la disponibilit√© √† payer de nos clients ?
Comment enrichir nos donn√©es avec de l'open data pertinente ?
Comment pouvons-nous am√©liorer la connaissance de nos visiteurs ?
Comment mesurer les campagnes marketing et les plans de communication ?
Apollo Plus est pr√©sent sur les march√©s fran√ßais, allemand, espagnol, belge et am√©ricain.
Le p√©rim√®tre du poste concerne essentiellement le parcours et la transformation des donn√©es depuis leur stockage chez un client jusque dans nos bases de donn√©es.
Missions
Int√©grer de nouveaux clients : traduire les besoins m√©tier en pipelines de traitement de donn√©es, cod√©s en Python
Impl√©menter de nouveaux connecteurs pour r√©cup√©rer les donn√©es (solutions de billetterie, de paiement, de r√©servations, de gestion h√¥teli√®re, etc.)
Impl√©menter de nouvelles features d'analytiques (KPIs, granularit√© des chiffres, etc.)
Participer √† l'√©volution et au maintien de nos pipelines de traitement de donn√©es
Am√©liorer l'impl√©mentation, le test et le backtesting de nos algorithmes de ML
Am√©liorer la configurabilit√© (par ex. permettre aux √©quipes m√©tier de configurer directement les r√®gles de calcul)
Am√©liorer l'outillage (CI/CD, tests, monitoring)
Stack technique
React, GraphQL
Django, Graphene-Django, DRF
pandas, scikit-learn, SQLAlchemy
PostgreSQL, ClickHouse
prefect
Azure, Azure Devops (√©quivalent GitHub), Docker, Linux
Comp√©tences requises
Bonne connaissance du langage Python et du SQL
Exp√©rience avec la manipulation de dataframes (par ex. avec pandas, spark)
Ma√Ætrise pratique de git
Comp√©tences appr√©ci√©es
Familiarit√© avec l'algorithmique
Familiarit√© avec les bases des OS : process, thread, m√©moire, r√©seau...
Exp√©rience avec un cloud provider (Azure, AWS, ...)
Exp√©rience en infra (VM, SSH, containerisation, ...)
Exp√©rience avec un outil d'orchestration de workflow (Prefect, Airflow, ...)
Anglais professionnel
Processus de recrutement
Rencontre RH (Google Meet - 30 minutes maximum) pour √©changer sur votre parcours et vos aspirations ainsi que notre trajectoire et nos besoins
Tech interview (Google Meet - 30 minutes maximum) pour pr√©ciser l'ad√©quation comp√©tences/besoins
Case Study (√† distance ou en pr√©sentiel) suite √† l'√©change Tech
Debrief (en pr√©sentiel - peut-√™tre fait √† la suite du Case Study) avec le CTO et RH et remise d'offre
Informations compl√©mentaires
Type de contrat :
CDI
Date de d√©but :
20 mai 2024
Lieu :
Paris
Exp√©rience :
> 6 mois
T√©l√©travail ponctuel autoris√©
Salaire :
entre 36000‚Ç¨ et 45000‚Ç¨ / an
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': ['Spark'], 'MachingLearning': ['Scikit-Learn'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': ['Linux'], 'DBMS': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': [], 'Other': ['DevOps', 'ML', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['36000'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (F/H/X),Goaheadspace,"Pantin, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-x-at-goaheadspace-3915359112?position=2&pageNum=10&refId=YRlmHfDXD2q8y%2FLEi2ngtQ%3D%3D&trackingId=xUgTcqgGkUmSsyChPhHiIA%3D%3D&trk=public_jobs_jserp-result_search-card,"MFG Labs est une soci√©t√© de conseil et r√©alisation experte en data, qui aide les entreprises √† am√©liorer leurs prises de d√©cision, √† automatiser leurs processus et √† cr√©er de nouveaux services gr√¢ce √† la data science, au design et √† l'utilisation des derni√®res technologies.
MFG Labs intervient √† toutes les √©tapes de votre transformation data : de la cr√©ation d'une feuille de route de projets data, √† la d√©couverte d'insights, √† la mod√©lisation de probl√©matiques complexes, de la cr√©ation d'un mod√®le pr√©dictif √† l'impl√©mentation technique d'une solution data sur-mesure
MFG Labs accompagne ses clients de diff√©rentes mani√®res :
Strat√©gie
Solutions
Fondations
MFG Labs d√©ploie une approche holistique pluridisciplinaire, en m√™lant des data scientists, des designers, des data engineers et des consultants, afin d'apporter des solutions compl√®tes de bout en bout √† des probl√©matiques complexes.
Dans le cadre du d√©veloppement de l‚Äô√©quipe, nous recherchons un.e Data Engineer √†
Pantin (magasins g√©n√©raux).
Au sein de l‚Äô√©quipe Data Technology, vous aurez pour mission de travailler sur des probl√©matiques de collecte de la donn√©e sur tout type de support digital : web, mobile, application, voire IoT.
Votre r√¥le au sein de l‚Äô√©quipe :
Faire partie d‚Äôune √©quipe pluridisciplinaire avec des talents en Design de Service, Consulting et Data science.
D√©velopper des applications de production int√©grant diff√©rents outils : des Math√©matiques Appliqu√©s, Machine (Deep) Learning, Recherche Op√©rationnelle, Statistiques.
D√©velopper des pipelines de traitement de donn√©es avec l‚Äô√©quipe de Data Science pour : ing√©rer, transformer et d√©livrer des donn√©es et mod√®les √† nos applications.
D√©ployer des applications utilisant les derniers outils mis √† disposition par les diff√©rents Clouds publics.
√Ä propos de vous :
Vous √™tes titulaire d'un niveau Bac +4/Bac +5 d'une √©cole d'ing√©nieur
Vous avez au minimum deux ans d'exp√©rience hors stage ou alternance
Vous √™tes rigoureux¬∑se vis-√†-vis de vous-m√™me et des autres quant √† la qualit√© du code.
Vous avez quelques connaissances et comp√©tences solides en d√©veloppement et en en Data Ing√©nierie au sens large.
En
d√©veloppement
Python 3 et SQL
Framework de traitement de donn√©es (Spark ou √©quivalent)
Docker
GIT
En +
Framework permettant de d√©ployer des APIs (Flask ou √©quivalent)
CI/CD
La pratique d'au moins un cloud (AWS, GCP ou Azure) est appr√©ci√©e
En Data Ing√©nierie
Datawarehouse ou Datalake
Data Pipelines Batch et/ou Straming
En +
Outils de BI (Tableau, Power BI‚Ä¶)
Outils MLOps (Sagemaker, VertexAI, etc.)
Si vous vous reconnaissez dans cette annonce, n'h√©sitez pas √† postuler !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': [], 'Other': ['ML', 'Statistiques', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer H/F,Dalkia,"Angers, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-dalkia-3907349741?position=3&pageNum=10&refId=YRlmHfDXD2q8y%2FLEi2ngtQ%3D%3D&trackingId=5wEEPPCD7CRNwrkdwQtzoQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Descriptif du poste
Et si vous faisiez √©quipe avec nous ? Rejoindre Dalkia, c'est plus de sens et d'implication contre le r√©chauffement climatique ; plus de relations humaines, avec un m√©tier de service anim√© par l'esprit d'√©quipe ; plus de technicit√©, avec des projets ambitieux et innovants fond√©s sur nos expertises ; plus d'employabilit√©, avec des parcours diversifi√©s et individualis√©s. Rejoindre Dalkia, c'est rejoindre plus qu'une entreprise : un collectif de 20 000 collaborateurs engag√©s en faveur de la transition √©nerg√©tique.
Dalkia Froid Solutions, acteur majeur de la r√©frig√©ration, sp√©cialis√© dans les services √©nerg√©tiques pour les process industriels et tertiaires, recherche un(e) Data Engineer
(H/F)
. Rattach√© (e) au Responsable Data au sein de la Direction des Syst√®mes D'Informations, vous √™tes le garant du bon d√©roulement des d√©veloppements de flux de donn√©es et de leur pr√©paration pour leur analyse. Vous aurez l'opportunit√© de rejoindre une √©quipe en construction.
Candidater chez Dalkia Froid Solutions, c‚Äôest avoir l‚Äôenvie d‚Äôint√©grer un grand groupe √† l‚Äôesprit familial. L‚Äôhumain est au c≈ìur de nos m√©tiers, nous donnons la chance √† tous, afin de d√©couvrir nos talents de demain. Venez renforcer notre Direction des Syst√®mes d'Informations et contribuez √† l'optimisation √©nerg√©tique √† travers la data !
Vos Principales Missions
D√©finir l'architecture ETL et d√©velopper les jobs d'int√©gration de donn√©es pour notre environnement Big Data.
Assurer le monitoring quotidien des jobs et optimiser les performances de traitement.
Garantir la qualit√© et l'int√©grit√© des donn√©es en industrialisant leur nettoyage.
Adapter les DataMarts pour le reporting en collaboration avec les √©quipes m√©tiers : comprendre et analyser les besoins utilisateurs, et r√©diger les sp√©cifications fonctionnelles et techniques.
Vous serez √©galement ammen√© √† collaborer avec l'√©quipe Infrastructure pour d√©finir les besoins techniques et planifier les investissements. En lien avec votre √©quipe vous conduirez des projets vari√©s et participerez √† la mise en oeuvre de rapports BI et de mod√®les de machine learning.
Lieu :
Si√®ge Social - Angers / T√©l√©travail possible √† raison de 2 jours par semaine apr√®s p√©riode d'essaie
Votre profil
Dipl√¥m√© (e) d'un bac + 5 minimum sp√©cialis√© en Data Engineer ,vous avez de bonnes qualit√©s relationnelles afin d'accompagner le d√©ploiement des projets. Votre rigueur et votre logique sont incontestables. Vous aimez travailler en √©quipe pour accompagner l'entreprise vers l'excellence op√©rationnelle.
C√¥t√© Outils ? Vous maitrisez les langages SQL et Pyhton et vous avez d√©j√† pratiqu√© les outils DBT et GitLab. Une premi√®re exp√©rience avec un outil de BI/Datavisualisation est souhait√©e.
La connaissance des outils Qlik Sense ou Talend serait un plus!
Pr√™t(e) √† faire une diff√©rence avec nous ? Postulez d√®s maintenant !
Ensemble, nous contribuons collectivement √† la transition √©nerg√©tique. C'est pourquoi chez Dalkia Froid Solutions, nous sommes convaincus que chacun peut participer √† relever ce d√©fi. De ce fait, chaque candidature recevra la m√™me attention.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Analytics Engineer,Vestiaire Collective,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/analytics-engineer-at-vestiaire-collective-3875996826?position=4&pageNum=10&refId=YRlmHfDXD2q8y%2FLEi2ngtQ%3D%3D&trackingId=8vuJPLbUeY03j4erAEmiMw%3D%3D&trk=public_jobs_jserp-result_search-card,"Vestiaire Collective is the leading global online marketplace for desirable pre-loved fashion. Our mission is to transform the fashion industry for a more sustainable future by empowering our community to promote the circular fashion movement. Vestiaire was founded in 2009 and is headquartered in Paris with offices in London, Berlin, New York, Singapore, Ho Chi Minh and Hong Kong and warehouses in Tourcoing (France), Crawley (UK), Hong Kong and New York.
We currently have a diverse global team of 700 employees representing more than 50 nationalities. Our values are Activism, Transparency, Dedication and Greatness and Collective. We are proud to be a BCorp.
About The Role
This role is central to our data strategy and requires a balance of technical expertise and business acumen. As a Junior Analytics Engineer, you will be at the heart of our data-driven initiatives, working closely with cross-functional teams to transform raw data into a single source of truth data mart. Your work will directly influence key decisions in finance, payment systems and business performance.
What You'll Do
Design, implement, and maintain efficient and reliable data pipelines using a modern data stack: Airflow, Snowflake, DBT
Develop advanced data models to support complex analytics, including financial reconciliations, cost effectiveness and profitability models. Collaborate with finance, payments and tech teams to understand their data requirements and translate these into sophisticated technical solutions
Ensure scalability and performance of our data infrastructure to handle large-scale, multi-faceted data sets from diverse sources
Implement and maintain data quality checks and monitoring systems for accuracy and consistency
Innovate and integrate new technologies and methodologies to enhance data capabilities across finance domains
Assist the finance team in building key dashboards in Tableau to enable data driven decision making
Who You Are
Required Qualifications:
Bachelor‚Äôs/Master‚Äôs in Computer Science, Engineering, Statistics, or related field
At least one previous experience in analytics engineering, with strong skills in ETL and data modeling, an awareness of data warehousing and dataOps practices
Proficient in SQL and programming languages like Python or R
Experience with cloud data technologies and big data tools
Desirable Skills:
Apache Airflow: an understanding of workflow management
Git: Solid knowledge in version control and CI/CD integration
Cloud Service: AWS, Snowflake or similar cloud experience
Data Visualization Tools: Proficiency in tools like Tableau, Looker, Snowsight
Previous experience in DBT for data modeling
What we offer
üéÅ
A meaningful job with an impact on the way people consume fashion and promote sustainability
Flexible work possibilities
The opportunity to do career-defining work in a fast-growing French-born scale up
The possibility to work as part of a globally diverse team with more than 50 nationalities
Two days to help Project - reinforcing your activist journey and volunteer for an association
Significant investment in your learning and growth
Competitive Compensation And Benefits Package
As full member of our entrepreneurial project, you will be eligible to free shares
Vestiaire Collective is an equal opportunities employer
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Apache Airflow'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau'], 'Statistics': ['Statistics'], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['Big Data', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': ['Full', 'Junior'], 'TypeContract': [], 'Salary': ['Package'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (F/H) - Alternance,Vertbaudet,"Tourcoing, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-alternance-at-vertbaudet-3853542017?position=5&pageNum=10&refId=YRlmHfDXD2q8y%2FLEi2ngtQ%3D%3D&trackingId=BlTZ4D5w5ZRpcFiIPssV8A%3D%3D&trk=public_jobs_jserp-result_search-card,"A PROPOS DE NOUS !
Vertbaudet est le pure-player leader europ√©en du monde de l'enfant, au travers de 10 sites web adapt√©s aux besoins de chaque march√© (France, Allemagne, Suisse, Royaume-Uni, Belgique, Pays-Bas, Espagne, Portugal, Autriche et .com pour le reste du monde). En France, Vertbaudet est √©galement pr√©sent dans 72 magasins.
Vertbaudet s‚Äôappuie sur une communaut√© de plus de 3 millions de parents, clients actifs de nos sites qui b√©n√©ficient d‚Äôune exp√©rience d‚Äôachat personnalis√©e.
Vertbaudet d√©veloppe √† la fois une offre exclusive au travers de sa marque propre et propose √©galement des marques leaders ou innovantes.
Par son expertise et sa cr√©ativit√©, Vertbaudet r√©pond √† tous les besoins des parents pour leurs enfants de 0 √† 12 ans en Mode, Chaussures, Maison, Pu√©riculture et Jouets.
Cr√©√© en 1963, Vertbaudet emploie plus de 1000 personnes en France et a g√©n√©r√© un chiffre d‚Äôaffaires sup√©rieur √† 330 millions ‚Ç¨ HT en 2023.
Poste:
Rattach√©(e) √† notre Direction Informatique, tu rejoins le d√©partement Intelligence Clients et plus particuli√®rement ¬´ la team ¬ª de Florent, notre Responsable Data DSI. Notre mission est d‚Äôoptimiser la valeur de nos clients par la bonne connaissance de leurs profils et de leur activit√©
Tu int√©greras une √©quipe de Data Engineers pour apprendre √† leur c√¥t√© et participer √† nos projets : construction de flux de donn√©es, maintenance d‚Äôune plateforme Data moderne, d√©veloppements d‚Äôalgorithmes complexes, mise en place de r√®gles DataQuality ‚Ä¶
Tu manipuleras des outils et des m√©thodes vari√©s : Stambia, SQL, CI/CD, Snowflake, Airflow, Cloud Azure ‚Ä¶
Tu seras accompagn√©(e) par un Data Engineer Senior qui saura te faire grandir et te permettre de d√©livrer de la valeur pour notre √©quipe et l‚Äôentreprise.
Pour cela, tu dois avoir l‚Äôenvie d‚Äôapprendre de nouveaux langages et de nouveaux outils, de perfectionner ta connaissance du SQL, de la rigueur. Tu auras l‚Äôoccasion de d√©couvrir des domaines m√©tiers diff√©rents : Marketing, Produit, Finance, Logistique.
Profil:
Vraiment sympathique toutes ces missions, non ? Alors, si tu es en formation type Bac+5 ing√©nieur ou √©quivalent universitaire avec une sp√©cialisation en data/statistique (ex : ENSAI, Polytech, Master Siad, ISN, Econom√©trie...), tu es peut-√™tre la personne qu'il nous faut !
Le SQL n‚Äôa plus de secret pour toi ?
Tu es capable d‚Äôextraire de la donn√©e et de la manipuler ais√©ment ?
Ton anglais
is good enough
pour collaborer avec nos filiales internationales ?
Tu n‚Äôas pas peur de param√©trer un cluster Azure ?
Envoie-nous vite ta candidature !
Plus que tes exp√©riences professionnelles, nous nous attacherons √† ta passion, ta compr√©hension de la marque, ton envie de t'immerger dans notre univers. Concr√®tement, nous recherchons un(e) v√©ritable passionn√©(e), quelqu'un qui n'a pas peur de s'investir dans ses missions, quelqu'un de fiable, de r√©actif, qui comprend les enjeux du business digital et qui poss√®de une sensibilit√© client.
Tu es disponible pour une alternance de 24 mois √† partir de Septembre 2024
Pour faciliter le traitement de ta candidature,
merci d'indiquer sur ton CV le rythme d'alternance que propose ton √©cole
Lieu : TOURCOING (59)
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': ['Cr√©ativit√©'], 'EnSoftSkils': []}","{'JobDetail': ['Senior'], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '12', '12', '12']}"
Data Engineer,Harnham,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-harnham-3901400227?position=6&pageNum=10&refId=YRlmHfDXD2q8y%2FLEi2ngtQ%3D%3D&trackingId=ziWhFh8xzvynvlEVy14t8w%3D%3D&trk=public_jobs_jserp-result_search-card,"DATA ENGINEER
LA DEFENSE (92)
56K EUR
Rejoignez une √©quipe en tant que Data Engineer au sein d‚Äôune start-up orient√©e Intelligence Artificiel, et aidez √† fa√ßonner l‚Äôavenir technologique. C‚Äôest votre chance de mettre en pratique vos comp√©tences techniques et de jouer un r√¥le dans le futur du domaine des donn√©es.
VOTRE MISSION :
Concevoir et d√©velopper des pipelines de donn√©es pour assurer la collecte, le traitement, et le stockage efficaces des donn√©es pour comprendre les besoins.
Collaboration avec les √©quipes m√©tiers
Elaborer des processus de validation des donn√©es et mettre en place des tests automatis√©s
Concevoir et impl√©menter des mod√®les de donn√©es
VOTRE PROFIL :
Au moins 6 mois de stage en tant que Data Engineer
Dipl√¥m√© d‚Äôun Master (2 ans minimum)
Maitrise d'un ou plusieurs Clouds Publics (AWS; GCP; Azure)
Maitrise d'outils classiques (Python, Spark, SQL)
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Big Data Engineer Databricks Senior - H/F - CDI,Talan,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-databricks-senior-h-f-cdi-at-talan-3909664424?position=7&pageNum=10&refId=YRlmHfDXD2q8y%2FLEi2ngtQ%3D%3D&trackingId=9Jk4wfhD6YOUymiIHt4IyA%3D%3D&trk=public_jobs_jserp-result_search-card,"Talan est un groupe international de conseil en transformation et en innovation par la technologie, cr√©√© en 2002.
Nos 5000 consultantes et consultants partagent √† travers le monde l‚Äôaudace d‚Äôinnover, le go√ªt de l‚Äôexcellence, et l‚Äôenvie de relever les d√©fis les plus complexes.
Nous accompagnons les entreprises dans des secteurs vari√©s‚ÄØ: √©nergie, industrie, transport, finance, luxe‚Ä¶ √† travers 3 grandes expertises‚ÄØ:
Le Conseil en Management et Innovation (320 Consultants en France)
La valorisation des donn√©es, leurs structurations, et leurs usages (Data et Technologies)
L‚Äôint√©gration de solutions logicielles (Cloud et Applications Services)
Nos valeurs‚ÄØ: engagement, respect, partage, esprit d‚Äô√©quipe et optimisme.
Talan est une entreprise responsable, reconnue par ses collaborateurs et attach√©e √† la diversit√©. Des am√©nagements peuvent √™tre propos√©s si vous √™tes en situation de handicap.
Retrouvez nos engagements RSEiciet nos actions en faveur de la diversit√©ici
Job Description
Nous sommes √† la recherche d‚Äôun Big Data Engineer Databricks S√©nior qui sera en charge de l‚Äôint√©gration des donn√©es: acquisition, pr√©paration, mod√©lisation et stockage, exposition, . Vous devrez faire preuve d‚Äôun √©tat d‚Äôesprit √† la fois innovant, m√©thodique, orient√© solution (et non probl√®me!), et communiquant.
Responsabilit√©s
Manager des Big Data Engineer et Cloud Engineer
Coacher techniquement les membres de l‚Äô√©quipe: solution et code review sur site, recommandation sur les formations √† suivre, certifications √† r√©aliser, ‚Ä¶
Analyse des besoins techniques m√©tiers, d√©finition de l‚Äôarchitecture solution et logiciel, r√©f√©rent technique, d√©veloppement et optimisation, code review, maintenir les pratiques Devops ‚ÄúYou build IT, You run IT‚Äù, support √† recette et mise en production, documentation, et parfois assumer le r√¥le de Scrum Master,‚Ä¶
Benchmark de solutions et conseil aupr√®s de notre client sur les solutions technologiques √† adopter, en lien avec leurs besoins
Partage de connaissances et formations interne
Qualifications
Issu(e) d‚Äôune formation sup√©rieure (√©cole d‚Äôing√©nieur, master,‚Ä¶)
Vous disposez d‚Äôau moins 4 ann√©es d‚Äôexp√©rience dans le domaine du Big Data (et particuli√®rement sur le framework Spark), et au moins 6 ann√©es d‚Äôexp√©rience dans le d√©veloppement logiciel
Vous ma√Ætrisez led√©veloppement logiciel (Scala, Python ‚Ä¶), et vous disposez de solides exp√©riences dans la mise en place de pipelines de donn√©es
Vous ma√Ætrisez leFramework Spark (id√©alement sur Databricks) etson optimisation
Exp√©rience sur une plateforme Cloud serait un plus et id√©alement AWS
Exp√©rience sur des flux temps r√©elserait un plus : Kafka + Spark Streaming
Vous ma√Ætrisez les bases de donn√©es SQL et le langage SQL
Vous avez de l'exp√©rience sur les m√©thodes de stockage: HDFS, S3,,‚Ä¶
Vous avez de bonnes connaissances en devOps : Jenkins, Gitlab, Maven, ‚Ä¶
La connaissance des concepts suivants serait un +: DataOps, DataVault, DataMesh..
Connaissance de l‚ÄôAgilit√©
Autonome
Organis√©(e)
Sens du partage
Bonne communication
Orientation produit et solution
Additional Information
AVANTAGES
:
Plan de formation pour accompagner votre carri√®re (formations √©diteurs, certifications) gr√¢ce √† nos partenariats nous accordant une position de partenaire privil√©gi√©, et management de proximit√© par des experts
Locaux modernes en centre-ville
Top 5 du Palmar√®s Great Place to Work
T√©l√©travail jusqu‚Äô√† 5 jours selon les missions, prime d‚Äô√©quipement de 100‚Ç¨
Mobilit√© en France et √† l‚Äô√©tranger
Top 1% des entreprises √©valu√©es par Ecovadis dans le domaine social, environnemental et √©thique
Tickets restaurant, prime vacances, 50% transport (abonnement transport public), mutuelle
Permanence handicap (consultant d√©di√© aux collaborateurs en situation de handicap et aux proches aidants)
Actionnariat salari√©
Prime de cooptations
RTT
PROCESS RECRUTEMENT
:
L‚Äô√©quipe recrutement s‚Äôengage √† vous proposer un processus de recrutement rapide et fluide
1 entretien RHpar Teams (45min)
1 test technique
1 entretien technique par Teams (1heure)
1 entretien op√©rationnel avec le responsable de domaine, au si√®ge (1heure)
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Alternance - Data Engineer H/F,METEOJOB by CleverConnect,"Villeneuve-d‚ÄôAscq, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/alternance-data-engineer-h-f-at-meteojob-by-cleverconnect-3891237691?position=8&pageNum=10&refId=YRlmHfDXD2q8y%2FLEi2ngtQ%3D%3D&trackingId=7%2FvZRxNxZ9KZ0pZ0CaSZ5A%3D%3D&trk=public_jobs_jserp-result_search-card,"Description Du Poste
Au sein du groupe Auchan, les √©quipes d'Auchan Retail International sont au service des diff√©rents pays dans lesquels Auchan est implant√©.
Experts des m√©tiers du Digital, de la Finance, du Juridique, des Ressources Humaines et de la gestion d'entreprise, leur mission est d'accompagner les entit√©s Auchan pays √† se construire, se structurer et se d√©velopper.
Nous recherchons aujourd'hui
un(e) alternant(e) Data Engineer
(H/F).
La mission sera de concevoir et d√©velopper les nouveaux flux de donn√©es (batch et temps r√©el) en √©troite collaboration avec l'√©quipe actuelle de Data Engineer, Data Scientist et les √©quipes m√©tiers.
Les Principales Missions Seront Les Suivantes
Analyser les besoins des m√©tiers et les traduire en sp√©cifications techniques (en contribuant √©galement √† l'√©laboration des contrats d'interface et √† la mod√©lisation physique)
D√©velopper des pipelines de donn√©es au sein de son p√©rim√®tre
Veiller √† la qualit√© et l'efficience des d√©veloppements de l'√©quipe
Contribuer √† la construction de la plateforme data et des services en remontant les besoins non couverts par le framework
Travailler en √©troite collaboration avec l'√©quipe actuelle de Data Engineers, Data Scientists et les √©quipes m√©tiers.
Tu √âvolueras Dans Un Environnement Technique Compos√© De
Google cloud platform (BigQuery, VertexAI)
SQL
Python
Description Du Profil
Votre profil :
√âtudiant(e) en √©cole d'Ing√©nieurs ou Master Informatique ou √©quivalent, vous recherchez une alternance et √™tes passionn√©(e) de la Data pour participer √† des projets d'envergures au sein d'une √©quipe Data dynamique.
Comp√©tences Techniques
A l'aise (ou ayant envie de le devenir) dans l'environnement cloud GCP et ses services associ√©s (Bigquery, GCS, Pubsub, Cloud function, Composer etc‚Ä¶)
Vos connaissances sur les langages SQL et Python et des grands principes de mod√®le seront vos alli√©s pour r√©pondre aux besoins de cette offre.
Savoir √ätre
R√©actif, avec le sens du service, vous justifiez de bonnes capacit√©s d'√©coute et d'un bon relationnel.
Curieux, autonome et proactif.
Parce qu'Auchan Retail est convaincu que la diversit√© fait la richesse d'une entreprise, nous √©tudions, √† comp√©tences √©gales, toutes les candidatures et adaptons le processus de recrutement et le poste √† tous les profils.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Senior Data Engineer,Foxintelligence,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-at-foxintelligence-3822491504?position=9&pageNum=10&refId=YRlmHfDXD2q8y%2FLEi2ngtQ%3D%3D&trackingId=qoKsI34biGUtx2FrnXb9Bg%3D%3D&trk=public_jobs_jserp-result_search-card,"Chez Foxintelligence, nous sommes des amoureux de la data. ü§ì
Notre mission est de rendre les consommateurs et les marques plus intelligents, gr√¢ce √† une donn√©e de march√© r√©volutionnaire issue de l'intelligence collective. Pour les consommateurs, Foxintelligence rend accessibles et utiles leurs donn√©es transactionnelles issues de leurs bo√Ætes mail ou comptes bancaires. En les anonymisant, nous cr√©ons des statistiques uniques qui permettent aux marques de rester en phase avec les produits qui se vendent le mieux et les attentes des consommateurs.
Nous publions une application grand public aim√©e par des millions de personnes (Cleanfox, 5m+ de t√©l√©chargements, 4.8/5 üíñ sur l'app store et le play store) et pr√©parons le lancement d'une app de bilan carbone √† l'exp√©rience radicalement nouvelle. Gr√¢ce √† notre plateforme data, elle va rendre possible une prise de conscience massive des enjeux du changement climatique üåç et des actions individuelles possibles pour le combattre. Nous pensons que l'information est une force de changement puissante, lorsqu'elle s'appuie sur la data.
Utilisant ces donn√©es personnelles totalement anonymis√©es, notre plateforme SaaS foxintelligence.io est devenue la r√©f√©rence de la market intelligence digitale en Europe avec des dizaines de grands groupes clients. Le point commun entre Deliveroo, Just Eat, Mano Mano, BackMarket ou The Boston Consulting Group ? Ils vont tr√®s vite (on ne s'ennuie pas avec eux !) et ils nous font tous confiance !
Soutenus par des investisseurs de premier plan (17m lev√©s aupr√®s de Daphni, Partech, GFC et eFounders) et r√©cemment int√©gr√© au groupe NielsenIQ nous sommes maintenant √† la conqu√™te de l'Europe et en phase d'hyper-croissance.
Si notre FoxHQ reste √† Paris, notre √©quipe de plus de 120 talents pluridisciplinaires (tech, data et business) travaille depuis partout en France et m√™me en dehors (ex. Turquie). Nous pensons que notre politique remote-first, notre culture forte (bienveillance, exigence, r√©silience et data-first) et notre innovation permanente en termes de modes de travail (ex. grille de salaire transparente, formation au changement climatique, transparence sur la strat√©gie) sont les cl√©s de notre r√©ussite collective.... et de ta r√©ussite avec nous !
Job Description
Nous recherchons un
Senior Data Engineer
pour rejoindre l'√©quipe charg√©e des applications et des services internes. Tu seras responsables du cycle de vie complet de tes projets, du design √† la mise en production. Les projets r√©cents accomplis par l'√©quipe comprennent une plateforme d'enrichissement des donn√©es de g√©olocalisation capable de g√©rer des centaines de millions de data points par jour ainsi qu'un API de machine learning bas√©e sur ChatGPT capable de cat√©goriser automatiquement nos donn√©es.
Tes responsabilit√©s
Design, d√©veloppement et maintenance de nos services internes d'enrichissement des donn√©es
Travailler en √©troite collaboration avec nos product managers, data analysts, et autre partie prenantes pour d√©finir les besoin techniques et les sp√©cifications
Coacher et guider nos profils junior
Diagnostiquer et r√©soudre les diff√©rents probl√®mes techniques qui peuvent survenir (pas d'astreinte)
Requirements
Comp√©tences n√©cessaires (ce qu'il te faut pour r√©ussir sur ce poste):
Hard Skills
Excellent niveau en SQL et tr√®s bonne connaissance du service BigQuery de GCP
Une bonne connaissance de Python est requise
Des connaissances sur Airflow sont fortement recommand√©es
De bonnes connaissances sur K8s plus g√©n√©ralement en gestion d'infrastructure
Soft Skills
Excellente communication
Capacit√© √† g√©rer plusieurs priorit√©s et √† s'adapter √† un environnement en constante √©volution
Exp√©rience
Avoir travaill√© avec BigQuery
Une solide exp√©rience en gestion de bases de donn√©es relationnelles
Ladies
Les √©tudes montrent que les femmes ont moins tendance √† postuler √† une offre d'emploi quand elles n'ont pas toutes les qualifications. Ladies, ne vous mettez pas de barri√®re et donnez-nous la chance de nous faire notre propre avis, nous serons toujours ravis d'√©changer avec vous ! Si notre raison d'√™tre vous parle, postulez !
Self-made data lovers
Les dipl√¥mes c'est bien, les skills c'est mieux et l'exp√©rience t'en donne. Aucun dipl√¥me n'est requis chez nous, ce sont les comp√©tences et l'√©nergie qui comptent !
Recruitment process
Round 0 : entretien (fit) avec notre Head of People
Round 1 : entretien avec un ou 2 manager(s) de l'√©quipe
Test technique / Etude de cas
Round 2: entretien avec notre CTO
Benefits
Avantages/ce que nous offrons :
Salaire et variable comp√©titifs
Remote friendly (+ budget am√©nagement de l'espace de travail @Home)
Bonus Cooptation
Bonne assurance sant√© (Alan - prise en charge √† 50%)
Titres restaurants (swile) : pris en charge √† 60% par Fox
Syst√®me de cr√®che subventionn√© par Fox
Culture forte et pratiques de management √† la pointe (strat√©gie et r√©sultats financiers transparents, feedback 360, grille de salaire innovante et transparente etc.)
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Statistiques'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': ['Remote', 'Junior', 'Senior'], 'TypeContract': [], 'Salary': ['0'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (Snowflake),MindPal,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-snowflake-at-mindpal-3896992742?position=10&pageNum=10&refId=YRlmHfDXD2q8y%2FLEi2ngtQ%3D%3D&trackingId=Cnl6cwGQ8OVBr%2BVZq52Q3w%3D%3D&trk=public_jobs_jserp-result_search-card,"We are looking for experienced
Data Engineers
with knowledge of
Snowflake
platform.
Responsibilities
Creating and managing data in the Snowflake environment
Designing and implementing ETL (Extract, Transform, Load) solutions for transferring data between various sources and platforms
Optimizing the performance of Snowflake databases, including designing and implementing data structures and using indexes appropriately
Automating data processing workflows using tools such as Airflow or other workflow management tools
Deploying and configuring tools to monitor and report on the performance of the Snowflake system
Requirements
Minimum 1 year of experience as a Data Engineer
Ability to use Snowflake
Very good knowledge of SQL and programming in Python
Ability to work with databases, including the Snowflake platform
Knowledge of ETL tools and data integration
Ability to work in a team and good communication skills
Fluent English in speaking and writing
We Offer
B2B contract type
Full-time job
Remote and flexible working hours
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer H/F,Meilleurtaux,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meilleurtaux-3912494325?position=1&pageNum=12&refId=RDfIAW6D%2Bq5WzkINrCwGag%3D%3D&trackingId=r4C2Hgw4OP5G7JgzOclkoA%3D%3D&trk=public_jobs_jserp-result_search-card,"Description De L'entreprise
Scale-up embl√©matique du paysage Tech fran√ßais et marque connue aupr√®s d‚Äôun large public, Meilleurtaux est la marketplace incontournable pour le cr√©dit, l‚Äôassurance et le placement. Chaque ann√©e, plus de 3 millions de Fran√ßais utilisent nos services.
Notre mission : offrir √† nos clients les meilleurs produits, au meilleur prix avec le meilleur conseil. Notre but : redonner le pouvoir √† nos clients et leur faire gagner du temps et de l‚Äôargent.
Nos sites web et applis mobiles recueillent plus de 100M de visites par an. Nous travaillons avec de nombreux partenaires banques, assurance et gestionnaires d‚Äôactifs.
Notre ADN d‚Äôinnovation et de remise en question permanente pour servir nos clients nous conduit √† lancer chaque semaine de nouveaux projets, pilot√©s par l‚Äôune de nos √©quipes produit.
Quelques Chiffres
üëâ pr√®s de 2000 collaborateurs au sein du groupe dont 1000 collaborateurs au sein de notre r√©seau de franchises.
üëâ + de 350 agences r√©parties sur l‚Äôensemble du territoire.
üëâ x2 CA en l‚Äôespace de 4 ans.
üëâ une satisfaction client √† 4,8/5 en 2022.
üëâ 100 M de visites sur les sites et applis du groupe.
Description Du Poste
Vous souhaitez rejoindre la fintech leader en cr√©dit et en assurance, en forte croissance, innovante, dynamique et d√©bordante de projets ? Ce qui suit va vous int√©resser !
Contexte de ce recrutement
üöÄ
Nous sommes engag√©s dans le d√©veloppement d‚Äôune
Customer Data Platform.
Cette Plateforme De Donn√©es Est Au C≈ìur De La Strat√©gie De Croissance De L‚Äôentreprise Va Nous Permettre De
Augmenter la Customer Lifetime Value (CLTV) de nos clients,
D'int√©grer dans tous nos produits des composants IA innovants,
R√©duire nos co√ªts d‚Äôacquisition,
Faciliter le pilotage du business √† travers une optimisation de nos outils de BI.
Vous vous √©panouirez dans notre environnement en √©volution rapide, o√π l'adaptabilit√© est essentielle. Au-del√† de la r√©solution de d√©fis techniques, nous souhaitons que vous contribuiez activement √† la construction de la culture d'ing√©nierie de Meilleurtaux, √† l'am√©lioration des pratiques et √† la promotion d'un environnement collaboratif et innovant.
Vos missions üìù
Cr√©er et maintenir une infrastructure de donn√©es de pointe en permettant aux utilisateurs finaux d'acc√©der √† de la donn√©e pr√©cise et de qualit√© ;
D√©velopper de nouveaux mod√®les de donn√©es et des pipelines.
Ils ont auront pour objectif de prendre en charge une grande vari√©t√© de cas d'utilisation (de l'analyse et du reporting √† l'apprentissage automatique et √† l'innovation de produits) ;
Explorer en permanence de nouvelles technologies de donn√©es ;
Tester les solutions les plus innovantes et prometteuses du march√© en vue de pouvoir am√©liorer nos capacit√©s en mati√®re de donn√©es ;
Recruter, encadrer et accompagner votre √©quipe de Data Engineers au quotidien ;
Partager et d√©fendre vos meilleures pratiques d'ing√©nierie de donn√©es au sein des principaux organes de d√©cision de l'entreprise.
Notre stack technique
üõ†
D√©veloppement : Python, React, java, Salesforce
CI-CD : Git, Docker
Infrastructure cloud : GCP et Azure
Bases de donn√©es : Google BigQuery et Databricks
BI : Qliqsense
Ce poste n√©cessite d'interagir avec de nombreuses √©quipes au sein de Meilleurtaux que ce soit sur le plan technique (√©quipes IT, Data Scientist et BI) et/ou fonctionnel (Product Managers).
Ceci n‚Äôest qu‚Äôun avant-go√ªt de la superbe aventure que vous vous appr√™tez √† rejoindre, le poste √©tant √©videmment amen√© √† √©voluer en fonction de vous et vos propositions.
Qualifications
Pourquoi √™tes-vous notre TOP candidat ? üßê
Avec une premi√®re exp√©rience r√©ussie de 2 √† 4 ans en tant que Data Engineer.
Vous savez cr√©er des architectures de donn√©es efficaces, √©volutives et robustes.
Vous concevez des syst√®mes adapt√©s au pr√©sent mais √©galement √† l'avenir et qui r√©sistent √† l'√©preuve du temps.
Bien entendu, il est important que vous ayez de tr√®s bonnes comp√©tences techniques que ce soit en Python ; SQL et les autres outils pouvant exister en ing√©nierie de donn√©es.
La Big Data n'a plus de secret pour vous. Spark & Hadoop sont vos plateformes de r√©f√©rence sur ce domaine.
Vous avez d√©j√† particip√© au d√©ploiement d'infrastructure en Big Data.
Id√©alement, vous fa√Ætes partie d'une communaut√© de professionnels de la Data vous permettant d'√™tre toujours au fait des derni√®res actualit√©s.
Le must : cette expertise a √©t√© acquise au sein de l'industrie Fintech / Assurtech ou secteur √©quivalent.
Les soft-skills attendus pour r√©ussir chez Meilleurtaux ?
Du leadership : vous savez embarquer vos interlocuteurs dans un projet structurant et √† forts enjeux pour l'entreprise.
De la curiosit√© et de l'apprentissage continu : dans un domaine en constante √©volution, nous recherchons une personne connect√©e aux nouvelles technologies et aux derni√®res innovations.
De l'adaptation : vous savez prendre en consid√©ration les contraintes de l'entreprise et √©valuer les risques techniques.
Comment se d√©roule le processus de recrutement chez nous ?
1 -
Premier √©change avec la Team RH pour apprendre √† mieux vous conna√Ætre.
2 -
Rencontre sur place avec votre futur manager, l'√©quipe √©ventuellement et un membre de l'√©quipe RH.
3 -
R√©alisation d'une √©tude de cas et restitution avec le manager (selon le poste).
4 -
Votre candidature a √©t√© retenue ? F√©licitations et bienvenue √† bord üéâ
Qu'attendez-vous pour participer √† la construction de cette √©quipe de Data Engineers et partager votre expertise au sein d'une √©quipe passionn√©e par les sujets de Data ?
Informations suppl√©mentaires
En Nous Rejoignant , Meilleurtaux Vous Offre üòç
Un package attractif comprenant primes individuelles et collectives (participation et int√©ressement).
La mutuelle ALAN avec des tarifs avantageux, une prise en charge rapide des remboursements et la pr√©voyance prise en charge √† 100% par Meilleurtaux.
Une carte SWILE avec 10‚Ç¨ de tickets restaurant par jour travaill√©.
Une prise en charge de votre transport de ""mobilit√© douce"" (trottinette, scooter, v√©lo...) dans le cadre du Forfait Mobilit√©s Durables.
L'acc√®s au CSE, sans condition d'anciennet√©.
2 jours de t√©l√©travail / semaine apr√®s votre p√©riode d'int√©gration et une prise en main de votre poste.
Pour Vous Proposer Un Environnement De Travail Stimulant Et Propice √† L'√©panouissement Et L'atteinte De Ses Objectifs, Meilleurtaux a Mis En Place üí•
Des moments de convivialit√© (afterwork, Lunch & Learn, point d'actualit√© Groupe, soir√©es d'entreprise, secret coffee...)
La possibilit√© de choisir votre mat√©riel de travail (ordinateur & t√©l√©phone)
Un dispositif d'acc√®s √† la formation √† travers l'attribution d'une licence Openclassrooms (formation au choix selon vos envies et besoins).
Nous n'attendons plus que vous !
Le manque de confiance peut parfois nous emp√™cher de postuler √† un emploi. Mais nous allons vous r√©v√©ler un secret : il n‚Äôexiste pas de candidat ¬´ parfait ¬ª. Donc, n‚Äôh√©sitez pas √† postuler si ce poste vous donne envie de vous d√©passer tous les jours.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Adaptabilit√©', 'Leadership'], 'EnSoftSkils': ['Leadership']}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['100'], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Consultant Data Engineer,WHIZE,"Neuilly-sur-Seine, √éle-de-France, France",https://fr.linkedin.com/jobs/view/consultant-data-engineer-at-whize-3907486262?position=2&pageNum=12&refId=RDfIAW6D%2Bq5WzkINrCwGag%3D%3D&trackingId=w6CYjt5HexGT1E7LfIFO3Q%3D%3D&trk=public_jobs_jserp-result_search-card,"Offre d‚Äôemploi pour un CDI : Consultant Data Engineer
WHIZE est sp√©cialis√©e dans le d√©veloppement de solutions sur mesure en architecture Serverless (Azure, Amazon WS, Google CP) et de solutions bas√©es sur l'√©cosyst√®me Microsoft 365 (SharePoint, Teams, Power Platform).
Vos missions :
Concevoir des solutions de traitement de volume tr√®s important de donn√©es.
D√©veloppement de flux de donn√©es et pr√©paration de leur analyse.
Pr√©paration des donn√©es pour l'analyse des donn√©es collect√©es.
Profil recherch√© :
2 ans minimum d‚Äôexp√©rience.
Ma√Ætrise du langage Python et Scala
Connaissance d'un ou plusieurs ETL du march√© (Talent , SSIS, Azure Data Factory, ...)
Forte expertise en SQL
√ätre √† l‚Äôaise avec un ou plusieurs outils Devops (Jenkins, git, GitHub, gitlab, docker, kubernetes, etc‚Ä¶)
Connaissances appr√©ci√©es :
Hadoop, Spark, Kafka
Connaissance des syst√®mes NoSQL : Elasticsearch, HBase, Cassandra, Redshift
Connaissance de l'offre data d'un des providers Cloud (GCP, Azure, AWS)
Qu‚Äôattendez vous pour nous rejoindre ?
Vous ferez partie d‚Äôune soci√©t√© √† taille humaine et qui b√©n√©ficie des avantages d'un grand groupe. Nous adressons une centaine de clients en direct dont la moiti√© sont des grands comptes.
Vous serez accompagn√©(e) et manag√©(e) par le CEO de WHIZE (THE WHIZE MAN).
Vous allez compl√©ter notre √©quipe dynamique et travailler avec nous dans une ambiance Start-up et conviviale.
Vous occuperez des postes int√©ressants et √©volutifs.
Vous b√©n√©ficierez des √©v√®nements internes organis√©s pour parler tech, business et projets.
Vous r√©aliserez des projets √† forte valeur ajout√©e.
üìç : Neuilly-Sur-Seine+ T√©l√©travail
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'Cassandra', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
"Big Data Engineer ‚Äì Paris, France (H/F)",Astek,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-%E2%80%93-paris-france-h-f-at-astek-3470775874?position=3&pageNum=12&refId=RDfIAW6D%2Bq5WzkINrCwGag%3D%3D&trackingId=6%2FLH5FlHsKFTsDTg3Z1MyA%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Paris - France
Publi√©e il y a 2 mois
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Nous rejoindre en tant que
Big Data Engineer (H/F),
afin d‚Äôaccompagner un op√©rateur t√©l√©coms, Leader en Europe dans la cr√©ation d‚Äôune infrastructure cloud (IAAS) performante, robuste et s√©curis√©e.
Un challenge portant sur des millions d‚Äôutilisateurs dans un environnement technique innovant, strat√©gique et o√π l‚Äôentraide et la bonne humeur priment !
Votre Mission, Si Vous L‚Äôacceptez :
Qualifier les donn√©es et les r√©sultats
Conception technique des solutions
D√©cliner les impacts de la strat√©gie et des innovations technologiques au sein des processus et outils de l‚Äôexploitant SI
Assurer l‚Äôaccompagnement et le d√©ploiement des √©volutions des processus et outils
Contribuer aux programmes de transformation DevOps, Cloud et catalogues des offres SI
D√©velopper des fonctions transverses et les ¬´ uses cases ¬ª
Accompagner la phase de mise en production
Votre Future √âquipe :
Vous int√©grerez une √©quipe √† la fois technique et fonctionnel, qui ≈ìuvre chaque jour pour d√©velopper et maintenir en conditions op√©rationnelles l‚Äôensemble des solutions IT !
L‚Äô√©quipe est en interaction avec des clients √† la fois internes et externes.
Votre stack de jeu
Syst√®me d‚Äôexploitation : Linux
Environnement Big data : Hadoop, Spark, Scala
Cloud computing : GCP ou AWS
Base de donn√©es : No SQL (Cassandra, Mongo DB)
Dataviz : Power BI ou Kibana
Des notions en d√©veloppement feront la diff√©rence !
Les Petits Plus Du Projet :
Vous √©voluerez au sein d‚Äôune √©quipe impliqu√©e et r√©active et interviendrez sur un projet polyvalent et √† forte valeur ajout√©e.
Vous ?
Dipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieur ou √©quivalent de niveau Bac+5.
Vous justifiez id√©alement d‚Äôune exp√©rience d‚Äôau moins 3 ans d‚Äôexp√©riences sur un poste similaire ?
Vous faite preuve de proactivit√© et d‚Äôesprit d‚Äô√©quipe, √™tes dot√©(e) d‚Äôun excellent sens de l‚Äôorganisation et vous aimez les challenges et la r√©solution de probl√®me ?
Alors ce poste est fait pour vous, n‚Äôh√©sitez plus et rejoignez l‚Äôaventure ASTEK !
Astek
Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.
Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de
ses 7800 collaborateurs
qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.
Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.
Tous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Notre projet commun vous plait ?
Postulez √† cette annonce, et soyez transparent !
Maud, notre Talent Acquisition Referent, vous contactera pour un premier √©change.
Puis vous rencontrerez Yoram, votre futur manager, avec lequel vous √©changerez autour d‚ÄôAstek, de votre parcours, de vos attentes et de votre future mission .
Enfin, vous rencontrerez Anthime, notre Directeur d‚Äôagence avec lequel vous pourrez valider votre int√©r√™t et ad√©quation pour le poste et finaliser les √©l√©ments contractuels.
Nos Plus
Astek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo
Une politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversit√©
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì developpement ‚Äì Scala ‚Äì Data
Caract√©ristiques de l'emploi
Cat√©gorie Ing√©nieur
Job Industry T√©l√©com / M√©dia
Postuler en ligne
Nom *
Pr√©nom *
Email *
Un email valide est requis.
T√©l√©phone *
Un num√©ro de t√©l√©phone valide est requis.
Joindre un CV *
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì developpement ‚Äì Scala ‚Äì Data
Show more
Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
"Big Data Engineer ‚Äì Lille, France (H/F)",Astek,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-%E2%80%93-lille-france-h-f-at-astek-3839097187?position=4&pageNum=12&refId=RDfIAW6D%2Bq5WzkINrCwGag%3D%3D&trackingId=NviWlQb3wBpX4sQPbEeH4w%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Lille - France
Publi√©e il y a 2 mois
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Nous rejoindre en tant que
Big Data Engineer (H/F),
afin d‚Äôaccompagner un op√©rateur t√©l√©coms, Leader en Europe dans la cr√©ation d‚Äôune infrastructure cloud (IAAS) performante, robuste et s√©curis√©e.
Un challenge portant sur des millions d‚Äôutilisateurs dans un environnement technique innovant, strat√©gique et o√π l‚Äôentraide et la bonne humeur priment !
Votre Mission, Si Vous L‚Äôacceptez :
Qualifier les donn√©es et les r√©sultats
Conception technique des solutions
D√©cliner les impacts de la strat√©gie et des innovations technologiques au sein des processus et outils de l‚Äôexploitant SI
Assurer l‚Äôaccompagnement et le d√©ploiement des √©volutions des processus et outils
Contribuer aux programmes de transformation DevOps, Cloud et catalogues des offres SI
D√©velopper des fonctions transverses et les ¬´ uses cases ¬ª
Accompagner la phase de mise en production
Votre Future √âquipe :
Vous int√©grerez une √©quipe √† la fois technique et fonctionnel, qui ≈ìuvre chaque jour pour d√©velopper et maintenir en conditions op√©rationnelles l‚Äôensemble des solutions IT !
L‚Äô√©quipe est en interaction avec des clients √† la fois internes et externes.
Votre stack de jeu
Syst√®me d‚Äôexploitation : Linux
Environnement Big data : Hadoop, Spark, Scala
Cloud computing : GCP ou AWS
Base de donn√©es : No SQL (Cassandra, Mongo DB)
Dataviz : Power BI ou Kibana
Des notions en d√©veloppement feront la diff√©rence !
Les Petits Plus Du Projet :
Vous √©voluerez au sein d‚Äôune √©quipe impliqu√©e et r√©active et interviendrez sur un projet polyvalent et √† forte valeur ajout√©e.
Vous ?
Dipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieur ou √©quivalent de niveau Bac+5.
Vous justifiez id√©alement d‚Äôune exp√©rience d‚Äôau moins 3 ans d‚Äôexp√©riences sur un poste similaire ?
Vous faite preuve de proactivit√© et d‚Äôesprit d‚Äô√©quipe, √™tes dot√©(e) d‚Äôun excellent sens de l‚Äôorganisation et vous aimez les challenges et la r√©solution de probl√®me ?
Alors ce poste est fait pour vous, n‚Äôh√©sitez plus et rejoignez l‚Äôaventure ASTEK !
Astek
Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.
Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de
ses 7800 collaborateurs
qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.
Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.
Tous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Notre projet commun vous plait ?
Postulez √† cette annonce, et soyez transparent !
Maud, notre Talent Acquisition Referent, vous contactera pour un premier √©change.
Puis vous rencontrerez Yoram, votre futur manager, avec lequel vous √©changerez autour d‚ÄôAstek, de votre parcours, de vos attentes et de votre future mission .
Enfin, vous rencontrerez Anthime, notre Directeur d‚Äôagence avec lequel vous pourrez valider votre int√©r√™t et ad√©quation pour le poste et finaliser les √©l√©ments contractuels.
Nos Plus
Astek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo
Une politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversit√©
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì developpement ‚Äì Scala ‚Äì Data
Caract√©ristiques de l'emploi
Cat√©gorie Ing√©nieur
Job Industry T√©l√©com / M√©dia
Postuler en ligne
Nom *
Pr√©nom *
Email *
Un email valide est requis.
T√©l√©phone *
Un num√©ro de t√©l√©phone valide est requis.
Joindre un CV *
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì developpement ‚Äì Scala ‚Äì Data
Show more
Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data engineer Palantir - H/F - Paris,Lojelis,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-palantir-h-f-paris-at-lojelis-3901067276?position=5&pageNum=12&refId=RDfIAW6D%2Bq5WzkINrCwGag%3D%3D&trackingId=EUheVK8VM82DLRjEgxHx8g%3D%3D&trk=public_jobs_jserp-result_search-card,"Pr√©sentation de la soci√©t√©
Lojelis
est n√© en 2005, d‚Äôun projet entrepreneurial de Sylvain Jourdy, toujours √† la t√™te du groupe. Historiquement int√©grateur de solutions ERP, lojelis a √©volu√© au fil des ann√©es dans un objectif d‚Äôaccompagnement des entreprises dans leurs probl√©matiques technologiques et m√©tiers.
Experts en
ERP, D√©veloppement, Business Intelligence, AMOA
et
PMO,
nous sommes 170 collaborateurs r√©partis sur 6 agences en France. Nous conseillons nos clients sur tous les secteurs d‚Äôactivit√©s et sans distinction de taille. Nos √©quipes les accompagnent tout au long de leurs projets, de la conception √† la mise en production et au support.
Nous vous proposons donc de rejoindre une entreprise qui mise sur la proximit√© avec ses collaborateurs et o√π la cr√©ativit√© et la prise d‚Äôinitiatives y sont fortement encourag√©es.
Description des missions
Dans le cadre de divers projets en r√©gion parisienne, nous recherchons un(e) Data Engineer maistrisant Palantir Foundry.
Le contexte ?
Nous aidons nos clients dans leur transformation digitale.
Votre r√¥le sera d'accompagner les utilisateurs m√©tiers dans l'expression, la formalisation, l'analyse et la mod√©lisation de leurs besoins SI, ainsi que dans le suivi des projets.
Vos missions ;
Construire, livrer et maintenir des produits de donn√©es.
Travailler avec les √©quipes produits afin de d√©velopper de nouvelles fonctionnalit√©s.
Etre responsable de la construction, de la livraison, de la maintenance et de la documentation d'artefacts de donn√©es.
Conseiller sur l'architecture des flux de donn√©es de bout en bout.
Profil recherch√©
Votre profil ?
Apr√®s 1 √† 2 ans en tant que Data Engineer ou Data Scientist, vous d√©sirez √©voluer au sein d'un grand groupe afin de continuer √† d√©velopper vos comp√©tences.
You speak and write English in a professional environment
Vous maitrisez les technologies Python et SQL.
Vous avez d√©j√† travaill√© sur l'outil Palantir Foundry.
Nous recherchons surtout une personne dot√©e d'un bon relationnel qui appr√©cie le travail en √©quipe et sait se montrer force de proposition.
Les petits +
Nous nous engageons √† √©viter toute discrimination et √† traiter tous nos candidats de mani√®re √©quitable. C‚Äôest pourquoi l‚Äôensemble de nos intervenants au processus de recrutement sont form√©s au recrutement et √† la non-discrimination peu importe sa nature selon la loi applicable.
Notre processus de recrutement ?
Etude du CV
Echange t√©l√©phonique pour faire connaissance
Un entretien RH pour parler plus en d√©tail de vos aspirations et de Lojelis
Un entretien m√©tier avec la manager du p√¥le AMOA
Prise de d√©cision et retour
Notre processus d‚Äôint√©gration ?
Informations transmises en amont de votre arriv√©e : documentations, planning de votre premier jour, ‚Ä¶
Parcours d‚Äôint√©gration : pr√©sentation de Lojelis, des locaux, des √©quipes, des projets, des outils et process, formations au besoin, ‚Ä¶
Exemples de ce qu'il vous attend chez Lojelis
Qualit√© de vie au travail et RSE
Des managers de p√¥le qui vous accompagnent au quotidien dans votre carri√®re
Carte titres restaurant Edenred : 8,80‚Ç¨ par jour pris √† 60% en charge par Lojelis
Mutuelle couvrant gratuitement les enfants
Remboursement de 75% de l‚Äôabonnement transports en commun
10 jours de compensation/an d√®s 6 mois d‚Äôanciennet√©
Prime vacances (convention Syntec)
Primes de cooptation
3 jours de t√©l√©travail possibles par semaine
Un CSE offrant diff√©rents avantages
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Cr√©ativit√©'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Data Engineer,HarfangLab,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-harfanglab-3849760187?position=6&pageNum=12&refId=RDfIAW6D%2Bq5WzkINrCwGag%3D%3D&trackingId=ee2YG0IB53MykNwqdA7klQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Who we are?
HarfangLab
is a
cybersecurity scale-up
, and we have developed an
Endpoint Detection and Response
(EDR) software to
detect and mitigate modern cyberattacks
on a company's workstations and servers. Our algorithms detect abnormal behaviors and generate security alerts or block program execution.
From 50 to 100 employees in 2023, HarfangLab is experiencing hypergrowth and has already achieved several significant milestones: winners of the Ministry of Defense's cyber challenge in 2019, recipients of the BPI's I-Nov competition in 2020, and software certified by ANSSI in 2021.
Our initial clients include CAC40 industrial companies and government entities. We completed our
first funding round of ‚Ç¨5 million in 2021 and our second funding round of ‚Ç¨25 millions in 2023
, which will enable us to strengthen our teams, and to expand internationally in Europe.
Our mission is to
protect businesses and government agencies from modern cybersecurity threats
(cybercrime, data theft, influence)
that endanger the economic health of companies and the security of the nation
.
What you will do with us?
You will work within the
Artificial Intelligence team
, consisting of 5 individuals, under the direct and daily supervision of the team lead.
This team designs, implements, and deploys supervised algorithms for detecting malicious behavior.
As a
Data Engineer
you will:
Gather requirements from stakeholders,
Manage data for the AI and CTI departments,
Design, develop, and maintain the existing data warehouse,
Implement a data lake if deemed appropriate,
Create data pipelines using ELT processes,
Design tools for data visualization.
About You
Hard Skills
Master‚Äôs degree in Computer Science, Engineering, or a related field,
Proven experience as a Data Engineer, 2 years minimum,
Proficient in Python,
SQL: Strong in SQL syntax and query optimization, NoSQL will be a big plus,
Competence in data warehousing and data lake architecture,
Proficiency in at least one ELT tool and strong understanding of related processes.
Soft Skills
Strong communication and teamwork skills,
Excellent problem-solving and attention to detail,
You enjoy learning and sharing your knowledge with others,
You demonstrate initiative - when an opportunity arises to improve existing processes, you seize it.
About Us
Our office and Team Life:
Offices located in the heart of Paris, near Bourse (75002),
High-quality equipment based on preferences and needs (PC, Mac, additional screens, etc.),
Thanks to our Office Manager, we regularly organize events such as seminars, happy hours, themed evenings, and more,
An onboarding process to welcome each new colleague with an explanation of the roles and a mentor to support you during your early days!""
A great team that always seeks to improve their skills
And more:
An attractive package: Base salary + profit sharing,
Flexible remote work options,
A mentor to guide you throughout your probationary period,
Health insurance: The best health insurance with Alan and Moka Care, a mental health at work app,
Meal vouchers: We use the Swile card and also have access to a discount platform through our works council,
7 to 11 additional days off (RTT) per year, in addition to the 25 days of paid vacation. GymLib subscription, covered 80% by HarfangLab,
Access to training and events of your choice and according to your professional needs.
The recruitment process
A 30-minutes call with our Talent Acquisition Manager,
A 30-minutes visio interview with the Hiring Manager,
A 1 hour on-site interview + 30 minutes with the team for a team fit assessment,
A psychometric test to assess your motivations and soft skills,
A final HR video appointment to review your soft skills and motivations.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['ML'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication', 'Teamwork', 'Initiative']}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': ['7', '7'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Senior Data Engineer (H/F),relevanC,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-h-f-at-relevanc-3845776902?position=7&pageNum=12&refId=RDfIAW6D%2Bq5WzkINrCwGag%3D%3D&trackingId=%2BIBvHbhwTiBQPpKpHBIS8g%3D%3D&trk=public_jobs_jserp-result_search-card,"relevanC est une filiale du Groupe Casino et a √©t√© fond√©e en 2017.
Nous avons des bureaux en France, au Br√©sil et en Colombie et op√©rons √† l'√©chelle mondiale.
Nos solutions de Retail Media permettent √† nos clients de g√©n√©rer de nouvelles sources de revenus publicitaires gr√¢ce √† des annonces pertinentes et personnalis√©es.
En tant que Data Engineer tu auras acc√®s aux donn√©es de nos clients internes (enseignes du groupe Casino) et externes √† traiter au sein de notre data warehouse. Tes missions seront les suivantes :
travailler en √©troite collaboration avec tous les autres membres de la squad
√©crire / relire du code en respectant les bonnes pratiques de d√©veloppement ainsi que les tests unitaires et participer
assurer la co-responsabilit√© du d√©roulement des d√©ploiements, des mises en production et du bon fonctionnement des applications avec les autres membres de la squad
r√©diger la documentation technique quand cela est n√©cessaire
mettre en ≈ìuvre les bonnes pratiques relatives au RGPD telles que d√©finies par le tech lead
Ce CDI bas√© √† Paris centre (1er arrondissement) d√©butera d√®s que possible.
Faire partie de relevanC, qu‚Äôest-ce que √ßa signifie ?
Travailler sur une stack technologique de pointe (Python, PySpark, Google BigQuery, Apache, Airflow‚Ä¶)
√ätre membre √† part enti√®re d‚Äôune √©quipe dynamique et passionn√©e aux profils tr√®s vari√©s (chefs de projets, d√©veloppeurs, designers, animations commerciales)
Travailler dans un environnement stimulant et relever des nouveaux d√©fis chaque jour
Rejoindre une entreprise en pleine expansion avec des opportunit√©s fortes de d√©veloppements et d‚Äôinnovation
Profil recherch√©
Dipl√¥m√©(e) d‚Äôune grande √©cole d‚Äôing√©nieur ou profil universitaire sp√©cialis√© en Data / Informatique / Math / Stats.
5 ans (et plus) d‚Äôexp√©rience en Data Engineering
App√©tence forte pour le marketing digital et le retail, force de proposition, business oriented et moteur d‚Äôinnovation
Une maitrise parfaites des bonnes pratiques de d√©veloppement
Solides comp√©tences en Python, Spark et SQL
Une exp√©rience sur Google Cloud Platform est un plus
Lien vers notre politique de traitement des donn√©es : https://relevanc.com/fr/politique-de-protection-des-donn%C3%A9es-recrutemen
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Chef', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data engineer senior - PAU,Capgemini,Greater Pau Area,https://fr.linkedin.com/jobs/view/data-engineer-senior-pau-at-capgemini-3905823820?position=8&pageNum=12&refId=RDfIAW6D%2Bq5WzkINrCwGag%3D%3D&trackingId=l8ZlSgutdgTLQMyhKsDHJQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Capgemini :
Choisir Capgemini, c‚Äôest choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations. Avec le soutien et l‚Äôinspiration d‚Äôune communaut√© d‚Äôexperts dans le monde entier, vous pourrez r√©√©crire votre future.
Rejoignez nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la valeur de la technologie pour les plus grandes organisations et participer √† la construction d‚Äôun monde plus durable et inclusif.
Vos missions :
Au sein d'une √©quipe pluridisciplinaire, vos missions seront de :
Concevoir, d√©velopper et mod√©liser des outils de traitement et visualisation de la donn√©es
: mettre en place des pipelines de collecte, stockage et transformation de la donn√©es dans un contexte DevOps ; mettre en place des outils de nettoyage de la donn√©es afin de la rendre accessible et exploitable aux Data analysts et Data scientists.
Industrialiser des solutions dans un contexte Cloud DevOps
.
Collaborer √† la strat√©gie projet et au d√©veloppement de l'offre port√©e par Capgemini
: se positionner comme expert dans votre domaine, apporter et concevoir des solutions innovantes garantissant √† nos clients comp√©titivit√© et respect des normes li√©es √† leur secteur d'activit√©.
Accompagner de jeunes d√©veloppeuses et d√©veloppeurs dans leur mont√©e en comp√©tence
: apporter conseils techniques et retours d'exp√©riences ; les faire b√©n√©ficier de vos savoirs et expertises ; les challenger en leurs proposant au quotidien un accompagnement qui leur permettra de sortir de leur zone de confort.
Participer √† la vie de l'√©quipe data de Pau
: proposer, organiser et assister aux √©v√©nements et ateliers.
Votre profil :
Dipl√¥me en informatique, Data, Big Data ou √©quivalent
Minimum 4 ann√©es d'exp√©rience sur un poste similaire en ESN, client final ou cabinet
Anglais courant
Maitrise du langage de programmation Python (notamment Pandas)
Maitrise des technologies Cloud (AWS, Azure ou GCP) et outils DevOps (Ansible, Kubernetes, Terraform‚Ä¶)
Maitrise des processus de mise en place de pipeline, gestion et traitement de la donn√©e.
Aptitude d√©montr√©e √† travailler de mani√®re autonome tout en collaborant efficacement au sein d‚Äôune √©quipe multidisciplinaire
Forte app√©tence pour le challenge et l'innovation.
3 raisons de nous rejoindre
:
Qualit√© de vie au travail
: accord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√© professionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.
Apprentissage en continu
: certifications et formations en libre acc√®s, accompagnement sur mesure avec votre career manager, parcours d‚Äôint√©gration sur 9 mois.
Avantages groupe & CSE
: plan actionnariat, activit√©s √† tarifs pr√©f√©rentiels, remboursement partiel vacances, remboursement de votre abonnement sportif ou culturel.
Nos engagements et priorit√©s :
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.
A propos de Capgemini :
Capgemini est un leader mondial, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d‚Äôexp√©rience, nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profil de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '55', '55', '55']}"
Data Engineer (F/H) - en alternance,Carrefour,"Massy, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-en-alternance-at-carrefour-3884390443?position=9&pageNum=12&refId=RDfIAW6D%2Bq5WzkINrCwGag%3D%3D&trackingId=j2jnbwpHUusdjaD5Xbcjaw%3D%3D&trk=public_jobs_jserp-result_search-card,"Le saviez-vous ?
Nous rejoindre, c‚Äôest rejoindre l‚Äôun des leaders mondiaux de la distribution qui met l'accent au quotidien sur la diversit√©, la RSE et le digital, pour satisfaire nos clients et nos collaborateurs. En tant que partenaire premium des Jeux Olympiques et Paralympiques de Paris 2024, nous partageons les valeurs du sport en permettant √† nos √©quipes de se d√©passer et encourageons une alimentation saine au juste prix pour tous.
Vous cherchez √† travailler dans une entreprise dynamique o√π votre travail rime avec impact social et environnemental ? Bienvenue chez nous !
Data Engineer (F/H) - en alternance
En tant qu' alternant, vous int√©grerez la plateforme supply chain o√π vous serez amen√© √† appuyer le p√¥le pr√©vision et optimisation particuli√®rement sur des sujets data et d‚Äôanalyse de donn√©es.
Au sein d'une √©quipe compos√©e de data scientists et de data engineers organis√©e en mode Scrum Agile, vous travaillerez pour am√©liorer au quotidien un outil de calcul de pr√©vision (pr√©vision de la demande des entrep√¥ts Carrefour). Vous participez √† l'√©volution fonctionnelle et technique de l'application.
üéØ Les missions
Dans ce cadre, vous serez amen√© √†
Explorer et analyser les donn√©es du datalake carrefour
Participer au cadrage des nouvelles fonctionnalit√©s
D√©velopper les √©volutions des traitements, des mod√®les statistiques et de machine learning de pr√©vision et des reporting
Tester les fonctionnalit√©s d√©velopp√©es
R√©pondre aux demandes utilisateurs
üë• Profil
Vous √™tes en √©cole d‚Äôing√©nieur, en master 2 ou √©quivalent avec une sp√©cialisation data science, data engineering, statistique, informatique.
Vous avez une exp√©rience en traitement et analyse de donn√©es.
Vous avez un esprit d‚Äôanalyse et la capacit√© de travailler en √©quipe et √† distance.
Vous √™tes autonome et rigoureux, fluide dans votre communication orale et √©crite et √† l'√©coute des besoins de vos interlocuteurs.
Vous √™tes reconnu pour vos capacit√©s d'anticipation, votre sens de l'initiative et votre r√©activit√©.
Vous avez une bonne connaissance des langages suivants
SQL
Python
Une connaissance de GCP et de Big query serait un plus.
Une connaissance m√™me th√©orique de la m√©thodologie agile serait un plus
Une connaissance de GIT serait un plus.
Encore plus de bonnes raisons de nous rejoindre
Int√©grer une √©quipe conviviale √† taille humaine au sein d‚Äòun grand groupe
12 % de remise sur achat
üìù Informations compl√©mentaires
Date de d√©but  09 septembre 2024
Dur√©e  1 an
Lieu  Lyon
D√©placements en magasin et en concurrence dans la r√©gion parisienne
Avantages 50 % du titre de transport pris en charge par Carrefour
Envie de rejoindre l‚Äôaventure ?
Chez Carrefour, nous avons √† c≈ìur de ne passer √† c√¥t√© d‚Äôaucun talent et sommes fiers de compter des √©quipes repr√©sentatives de la soci√©t√© dans son ensemble. Nous encourageons ainsi tous types de profils √† postuler √† cette offre et garantissons un processus de recrutement d√©nu√© de toutes formes de discriminations.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Big Query'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Statistiques'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer +3 years xp,OntraaK,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-%2B3-years-xp-at-ontraak-3909457589?position=10&pageNum=12&refId=RDfIAW6D%2Bq5WzkINrCwGag%3D%3D&trackingId=pm1pYKxQsqU4o%2FAja6BOYg%3D%3D&trk=public_jobs_jserp-result_search-card,"Company Description
OntraaK is a start-up focused on operational excellence powered by advanced technologies such as process mining, intelligent process automation, and execution management systems. Our goal is to enable deep knowledge of real processes, identify inefficiencies, and automate processes at scale. We work with a pragmatic and flexible approach, maximizing value for our customers during proof of value or organization-wide implementation projects. Our team consists of data engineers, business and process experts, and managers who are certified on the most advanced solutions in the market.
We are looking for
2 Experienced Data Engineers
. You have 3 to 5 years in data engineering positions. You are passionate about playing with big set of datas from multiple sources. You love to improve complex situations with data driven decisions, to work in an innovative environment, and at the end of the day to transform all this in high valuable insights ? You love challenges and are ready to take off by developing your skills with a dynamic team ?
Let‚Äôs have a chat !
As a Data Explorer by OntraaK, you will deliver highly valuable data-driven insights through your data expertise. Our passion for solving complex and challenging problems four our customers is what is moving us every day. Your role as a Data Explorer is key to deliver this value !
Role Description
This is a full-time data engineer role at OntraaK. As a data engineer, your day-to-day tasks will include data exploration, connecting source systems, data preparation, data modeling, and implementing data solutions. This is a hybrid role based in Paris, with the flexibility for some remote work.
Qualifications
Data Engineering, Data Modeling, and Extract Transform Load (ETL) skills
Data Warehousing and Data Analytics skills
Experience in working with large and complex datasets
Proficiency in SQL and programming languages such as Python or Java
Strong problem-solving and analytical skills
Excellent communication and collaboration abilities
Bachelor's or Master's degree in Computer Science, Information Systems, or a related field
Experience with process mining or intelligent process automation is a plus
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration', 'Organization', 'Flexibility']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Senior Data engineer (H/F),Believe,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-h-f-at-believe-3904676141?position=1&pageNum=15&refId=4Y4I0MAYAq8eeUJ%2FxaKDAA%3D%3D&trackingId=yWYK7VADP87Qgb%2BjxbIrEg%3D%3D&trk=public_jobs_jserp-result_search-card,"Description De L'entreprise
Believe est avant tout une passion pour la musique, la technologie et le marketing num√©rique, partag√©e par plus de 1720 talents dans plus de 50 pays. C'est un esprit visionnaire et entrepreneurial qui nous anime et fait de nous un leader mondial de la distribution num√©rique de musique.
Believe est une tribu d'experts qui rel√®ve avec succ√®s les d√©fis de la transformation de notre industrie musicale au quotidien. C‚Äôest une aventure, une aventure humaine, propice et stimulante pour nous tous.
Enfin, Believe est une histoire qui a d√©but√© en 2005 et que nous devons continuer √† raconter, maintenant et avec vous. Believe a pour mission de d√©velopper les labels et les artistes de mani√®re adapt√©e √† chaque stade de leur carri√®re ; dans tous les march√©s locaux dans le monde ; avec respect, expertise, √©quit√© et transparence.
www.believe.com
Ready to #setthetone with Believe?
Description Du Poste
Contexte
Vous int√©grez la Tribu Data Office de Believe et la squad Dataplateforme en tant que Data engineer.
La Dataplateforme s'appuie sur une stack AWS / Snowflake avec des pratiques √† l'√©tat de l'art en data engineering et data mod√©lisation, et des contraintes de fort volume et haute performance.
Au Sein De La Squad Organis√©e Selon La Pratique Scrum, En Charge Du Build Et Du Run De Son P√©rim√®tre, Vous Aurez Pour Responsabilit√© D'impl√©menter Les Flux De Donn√©es Depuis L'ingestion Des Nouvelles Sources Jusqu'√† Leur Pr√©paration Pour Exposition Au Travers Des Niveaux Bronze, Silver Et Gold (warehouse) Vous Maitrisez Ainsi
La conception et le d√©veloppement d'un pipeline d'ingestion sur AWS (Step function / python / S3) La transformation de donn√©es (Python, Spark Scala / Databricks, SQL) Les pratiques de test (TU Python, TU Spark Scala) La mod√©lisation Data en flocons Les pratiques de run (surveillance, monitoring, fix) La r√©daction de la documentation (Data galaxy / Confluence) Les enjeux de performances, de suivi des couts et de s√©curit√©
Qualifications
Pourquoi nous rejoindre ? Chez believe, notre leitmotiv est simple : ouverture d‚Äôesprit, passion et implication ! On appr√©ciera aussi votre agilit√©, votre sens de l‚Äôinnovation, votre excellent relationnel et votre enthousiasme !
Vous √™tes de niveau BAC+3 √† BAC+5 (√âcoles d'ing√©nieurs, BTS, DUT, DESS, Mast√®re).
Vous justifiez d‚Äôune exp√©rience significative (au moins 3 ans) dans les technologies de notre stack: AWS, Snowflake, python, spark scala, SQL.
L'esprit Craft est une √©vidence.
Vous √™tes convaincu de l‚Äôimportance de la donn√©e, et pensez qu‚Äôelle est √† mettre en regard des besoins m√©tiers. Bref, vous aimez la donn√©e et √™tes pragmatique.
Vous aimez vous tenir au courant des nouvelles √©volutions technologiques, et pratiquez une veille r√©guli√®re.
Votre niveau d‚Äôanglais est courant, √† l‚Äôoral comme √† l‚Äô√©crit.
Informations suppl√©mentaires
Set the tone with us
Chez Believe, nous avons deux c≈ìurs : nos collaborateurs et nos artistes.
Nous croyons en la force de nos collaborateurs, qui s'√©panouissent chaque jour en d√©veloppant leur potentiel... Notre objectif est d'offrir √† nos collaborateurs le meilleur environnement possible pour qu'ils puissent s'√©panouir.
Rock the job
Programme de formation et de coaching sur mesure
Une politique de t√©l√©travail
Un programme de bien-√™tre ""Pauses"" avec de nombreuses activit√©s et animations en interne
Acc√®s √† Eutelmed, la plateforme num√©rique de sant√© mentale et de bien-√™tre qui permet de parler √† un psychologue exp√©riment√©
Un restaurant d'entreprise sain et √©co-responsable
Une assurance sant√© individuelle ou familiale
Avantages CE
Un rooftop
Une salle de sport avec des cours gratuits
Sing in harmony
Des groupes d'ambassadeurs pour s'engager sur la r√©duction de l'empreinte carbone et environnementale de Believe et l‚Äô√©quit√© professionnelle Femme/Homme.
Mise en place du Forfait mobilit√© durable: remboursement jusqu‚Äô√† 600‚Ç¨ des frais de transport en commun/avec une faible empreinte carbone.
Cong√© 2nd parent de 5 jours calendaires r√©mun√©r√©s √† 100% (en plus du cong√© l√©gal paternit√© ou du cong√© d‚Äôadoption, nous ne l‚Äôattribuons pas au cong√© maternit√©)
Believe s‚Äôengage √† garantir l‚Äô√©galit√© des chances en mati√®re d‚Äôemploi, sans tenir compte de l‚Äôorigine, du sexe, des m≈ìurs, de l‚Äôorientation sexuelle, du genre, de l‚Äô√¢ge, de la situation de famille, de l‚Äô√©tat de grossesse, d‚Äôune pr√©tendue race, des opinions politiques, des activit√©s syndicales, des convictions religieuses, de l‚Äôapparence physique, du nom de famille, du lieu de r√©sidence, de l‚Äô√©tat de sant√©, ou en situation de handicap.
D√©couvrez nos nouveaux locaux : bit.ly/believeoffice
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Confluence'], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5', 'Bac+3'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
"Data Engineer F/H - Syst√®me, r√©seaux, donn√©es (H/F)",UpMan Consulting,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-syst%C3%A8me-r%C3%A9seaux-donn%C3%A9es-h-f-at-upman-consulting-3901572843?position=2&pageNum=15&refId=4Y4I0MAYAq8eeUJ%2FxaKDAA%3D%3D&trackingId=ZKfIreukuM7MAeHx18f0CA%3D%3D&trk=public_jobs_jserp-result_search-card,"Cette offre d‚Äôemploi est fournie par P√¥le emploi
Description
Descriptif du poste: C est maintenant l occasion pour toi de rejoindre UpMan Consulting Notre ambition est de trouver les meilleurs profils Data Engineer pour intervenir chez nos clients grands comptes de la m√©tropole lilloise. On te propose une exp√©rience professionnelle en ad√©quation avec ce que tu souhaites r√©ellement. Tu d√©couvriras une ambiance de travail saine & bienveillante, tu participeras activement au d√©veloppement d une Happy StartUp, actuellement en forte croissance. O√π convivialit√© rime avec efficacit√© & o√π ta performance individuelle contribue √† notre r√©ussite globale. Tes missions / comp√©tences techniques Si tu l acceptes, ton r√¥le & tes missions seront les suivantes : * R√©aliser le processus d int√©gration de nouvelles donn√©es (r√©flexion sur la solution, mise en place d ETL, r√®gles de nettoyage, anonymisation ) * √ätre garant de l'acc√®s aux sources de donn√©es. * Ma√Ætrise de la donn√©e et √™tre le garant de sa qualit√© (r√©f√©rencement, normalisation et qualification) afin d'en faciliter l'exploitation par les √©quipes (Data Analysts et Data Scientists). * Ma√Ætrise de technologies Big Data et Cloud : Hadoop, Spark * Assurer la supervision et l'int√©gration de donn√©es structur√©es et non structur√©es venant de sources multiples, tout en veillant √† garder des donn√©es de qualit√©. * Assurer le suivi, la cartographie et la documentation des donn√©es int√©gr√©es * Afin de garantir une bonne ex√©cution de ta mission, nous recherchons les comp√©tences techniques suivantes : Langages de programmation : * SQL * Python / Pyspark * Java/Scala (plus rare, mais important) Diff√©rents types d ETL & orchestrateurs : * Airflow * Dagster * Prefect * SSIS/informatica * Talend Plateformes cloud : * GCP * Microsoft Azure * AWS Base de donn√©es relationnelles & NoSQL : * postgreSQL, MySQL,... * Redis, graphDB * Data warehouse/data transform : * Snowflake, Bigquery (tr√®s important) * DBT Qualit√© & comp√©tences n√©cessaires * Communiquant.e dans l √¢me * Avoir une bonne capacit√© de synth√®se & l esprit critique * Travail d √©quipe * Curiosit√© aigu√´ * Comprendre les objectifs & les besoins Nice to have * Anglais courant * Connaissance de la m√©thodologie DevOps * Notions en Data-science The office Pas de full remote (pour l instant) mais de l hybride dans la plupart des missions. En moyenne, 2 jours de t√©l√©travail par semaine. Cependant, les portes de nos bureaux √† Wambrechies sont toujours ouvertes pour accueillir nos collaborateurs pendant leurs journ√©es de t√©l√©travail & passer une bonne journ√©e tous ensemble ! Le salaire Junior : 30K √† 36K Ma√Ætrisant : 37K √† 43K Expert : 44K √† 50K & plus + notre package avantage Profil recherch√©: Ton Profil Tu es une personne passionn√©e & passionnante. Tu as envie d'√©voluer, de partager, de participer √† une mission collective & d√©couvrir LA nouvelle fa√ßon de collaborer avec une ESN made in Lille. Tu peux justifier d'une exp√©rience forte & significative en tant que Tech Lead Java, dans le d√©veloppement Java ! Pas besoin d'avoir trop ou pas assez de dipl√¥mes, chez nous, ce sont les comp√©tences qui priment ‚ÄØ! On se rencontre, on discute, on √©change sur tes envies professionnelles & on laisse la magie op√©rer. L'envie de grandir & de monter en comp√©tences est ton moteur au quotidien. Tu aimes les probl√©matiques complexes et les d√©fis technologiques. On dit de toi que tu es un.e agiliste dans l'√¢me, qui effectue une veille constante, √† l'aff√ªt de tout ce qui √©volue autour de toi... Ne r√©fl√©chis plus, saute le pas & d√©couvre UpMan Consulting, tu ne seras pas d√©√ßu. Tu balances ta d√©mission ?
PROFIL SOUHAIT√â
Exp√©rience
Exp√©rience exig√©e de 1 An(s)
Source: Pole emploi (https://www.pole-emploi.fr)
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['MySQL', 'PostgreSQL', 'Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Hybride', 'Remote', 'Full', 'Junior'], 'TypeContract': [], 'Salary': ['30K', '1'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Consultant Data Engineer F/H,SOFTEAM,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/consultant-data-engineer-f-h-at-softeam-3839971789?position=3&pageNum=15&refId=4Y4I0MAYAq8eeUJ%2FxaKDAA%3D%3D&trackingId=vE0RySd%2Bbfx6mGbdJZuJRg%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous √©voluez dans le domaine de la Data et souhaitez int√©grer
un leader de la transformation num√©rique sp√©cialis√© dans les secteurs de la Banque-Finance-Assurance ?
Rejoignez notre communaut√© et d√©veloppez vos comp√©tences chez
SOFTEAM DATA !
VOTRE MISSION
Pour le compte d'un client grand compte, vos missions seront :
A
comprendre le besoin
de nos clients au travers de missions de type : aide aux choix d‚Äôoutils, cadrage des besoins, POC ;
Recueillir et analyser les besoins et proposer une architecture technique
adapt√©e aux cas d‚Äôusage des clients ;
Conduire des projets de
d√©ploiement des Modern Data Platform
(Applications Cloud Native, Migration d‚Äôapplications existantes) et participer √† la mise en ≈ìuvre
Fournir une expertise technique approfondie
aux √©quipes projets
R√©diger la documentation permettant √† l'IT d'assurer la maintenance ;
VOTRE PROFIL
Vos
comp√©tentes techniques
:
Vous avez un minimum de
3
ann√©es d‚Äôexp√©rience sur des
projets Data sur les outils ETL
(Talend, SQL Server) et
Reporting
(Power BI, Tableau Software).
Id√©alement au moins une premi√®re exp√©rience sur des projets
Cloud AWS ou Azure ou GCP
.
Vous avez une grande aisance dans la
communication orale et √©crite
alli√©e √† un esprit de synth√®se, de la rigueur et un tr√®s bon sens de la formalisation
Fournir une expertise technique
approfondie aux √©quipes projets
R√©aliser une veille technologique
permanente sur les tendances du march√© et les perspectives concurrentielles
Vos
atouts
:
Vous √™tes dipl√¥m√© d‚Äôune formation Bac+5 en informatique ;
Vous avez des comp√©tences approfondies dans un ou plusieurs de ces domaines : Op√©rations / Gestion des syst√®mes, Conception ou d√©veloppement de logiciels, Processus DevOps et outillage, Strat√©gie d'entreprise, Infrastructure Cloud (virtualisation, mise en r√©seau, stockage, base de donn√©es), S√©curit√© et conformit√© ;
Vous souhaitez vous impliquer dans le d√©veloppement d‚Äô√©quipes et de communaut√©s techniques autour du Cloud et des solutions Data
Vos exp√©riences pass√©es vous ont amen√© √† mettre en avant votre capacit√© √† int√©grer des probl√©matiques fonctionnelles complexes, comprendre les enjeux m√©tiers, analyser les risques et √™tre force de propositions,
Enfin, on vous appr√©cie pour vos qualit√©s de communication, de r√©daction et votre bon relationnel‚Ä¶and a good level of english would be a definite asset !
NOUS VOUS OFFRONS
Des missions engageantes aupr√®s des grands acteurs du march√©.
Un management de proximit√©, √† l‚Äô√©coute et bienveillant.
La possibilit√© d‚Äô√©voluer dans chacune des facettes des m√©tiers de l‚ÄôIT !
QUI SOMMES NOUS ?
Softeam Data est le d√©partement de Softeam, marque de Docaposte, sp√©cialis√© dans les diff√©rents domaines de la Data (Hadoop et Cloud) et de l‚Äôinformatique d√©cisionnelle. Nous apportons notre expertise √† nos clients, principalement des grands comptes de la place financi√®re fran√ßaise, dans des projets de transformation digitale et cognitive.
Plus de 1650 Softeamien.nes sont d√©di√©.es √† la transformation m√©tier et digitale de nos clients et ont g√©n√©r√© 191 M‚Ç¨ de chiffre d‚Äôaffaires en 2019.
SOFTEAM est labellis√© Happy At Work !
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['SQL Server'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
Data Engineer,MindPal,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-at-mindpal-3914438789?position=4&pageNum=15&refId=4Y4I0MAYAq8eeUJ%2FxaKDAA%3D%3D&trackingId=tzbXTPpYKqPNK%2FnKPcV6Lw%3D%3D&trk=public_jobs_jserp-result_search-card,"We are looking for
Data Engineer!
Responsibilities
Designing, creating, and maintaining data processing systems
Analyzing and optimizing data processing workflows
Collaborating with the team to ensure data quality and efficiency
Testing and implementing new solutions
Requirements
At least 2 years of experience in designing and creating data processing systems
Proficiency in tools and programming languages related to data engineering (e.g. Hadoop, Spark, Scala, Python)
Excellent knowledge of databases and SQL language
Ability to work in a team and communicate effectively with other departments
Communicative English skills
Experience with AWS/AWS Glue is a plus
We Offer
B2B contract
Full-time job
Remote work and flexible hours
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,MindPal,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-at-mindpal-3896997018?position=5&pageNum=15&refId=4Y4I0MAYAq8eeUJ%2FxaKDAA%3D%3D&trackingId=%2Fub5oFSbqtnXh5AwV%2Fm5NQ%3D%3D&trk=public_jobs_jserp-result_search-card,"We are looking for
Data Engineer!
Responsibilities
Designing, creating, and maintaining data processing systems
Analyzing and optimizing data processing workflows
Collaborating with the team to ensure data quality and efficiency
Testing and implementing new solutions
Requirements
At least 2 years of experience in designing and creating data processing systems
Proficiency in tools and programming languages related to data engineering (e.g. Hadoop, Spark, Scala, Python)
Excellent knowledge of databases and SQL language
Ability to work in a team and communicate effectively with other departments
Communicative English skills
Experience with AWS/AWS Glue is a plus
We Offer
B2B contract
Full-time job
Remote work and flexible hours
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer PySpark Senior H/F,DELANE SI,"Boulogne-Billancourt, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-pyspark-senior-h-f-at-delane-si-3907364439?position=6&pageNum=15&refId=4Y4I0MAYAq8eeUJ%2FxaKDAA%3D%3D&trackingId=uezP%2FZfGmiHzY1ZvRTUyGA%3D%3D&trk=public_jobs_jserp-result_search-card,"DELANE SI
est une soci√©t√© de conseil et de services, une ESN, intervenant sur des projets √† forte valeur ajout√©e aupr√®s de clients grands comptes des secteurs Banque, Assurance et Finance de March√©.
Nos engagements ?
√ätre √† votre
√©coute
, afin de rapidement comprendre vos attentes et objectifs.
Echanger en toute
transparence
afin d‚Äôengager un partenariat durable avec vous.
Et enfin, la
r√©activit√©
qui nous permet de r√©pondre √† vos attentes dans les meilleurs d√©lais.
Vous cherchez √†
booster votre carri√®re
? Vous cherchez un
nouveau d√©fi
dans une structure en pleine √©volution ?
De notre c√¥t√©, nous cherchons
un tout
: un parcours, une exp√©rience, mais avant tout ... une personnalit√© !
Rejoignez-nous !
Dans le cadre d‚Äôun projet d‚Äôenvergure chez l‚Äôun de nos clients grands comptes, nous cherchons notre futur
Data Engineer PySpark Senior
qui sera en charge des missions suivantes :
Passer de la donn√©e brute √† de la donn√©e exploitable, expos√©e sous forme de tables requ√™tables ;
Consolider ces donn√©es au fur et √† mesure de leur alimentation r√©currente ;
Accompagner les Data Engineer sur son p√©rim√®tre pour garantir la qualit√© des livrables.
Issu d'une formation de Bac+5, vous justifiez d'une premi√®re exp√©rience d'au moins 6 ans sur un poste de Data.
Vous justifiez d'une exp√©rience dans le domaine de l‚Äôassurance.
Vous avez des connaissances avanc√©es en d√©veloppement en Spark et id√©alement PySpark.
Connaissances requises sur les outils de BI comme Power BI.
Une exp√©rience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory.
R√©mun√©ration envisag√©e :
50-55K
Un anglais courant est exig√©.
Conform√©ment √† la r√®glementation en vigueur et √† notre politique d‚Äô√©galit√© professionnelle et de diversit√© ; nous encourageons tous les talents √† postuler, ind√©pendamment de leur origine, identit√©, √¢ge, handicap ou de leurs caract√©ristiques personnelles.
Un processus de recrutement
simple et rapide
:
Un premier entretien avec un(e) de nos charg√©(e)s de Recrutement, nos experts m√©tiers, qui seront amen√© √† en savoir plus sur
vous et votre parcours
afin de pouvoir vous pr√©senter √†
l‚Äôensemble
de nos ing√©nieurs d‚Äôaffaires ;
Un second entretien avec un ou plusieurs ing√©nieur(s) d‚Äôaffaires afin de pouvoir vous
pr√©senter une ou plusieurs missions
;
Un dernier entretien avec notre client dans le cadre d‚Äôune derni√®re validation.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Senior'], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '6', '6', '6']}"
"Data engineer - A√©ronautique, Spatial et D√©fense",MP DATA,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-a%C3%A9ronautique-spatial-et-d%C3%A9fense-at-mp-data-3731603307?position=7&pageNum=15&refId=4Y4I0MAYAq8eeUJ%2FxaKDAA%3D%3D&trackingId=uXhP2MeXYg5mj9%2BVe8QIRg%3D%3D&trk=public_jobs_jserp-result_search-card,"MP DATA recrute
un(e) Data Engineer (H/F).
Dans le cadre de la transformation digitale industrielle, l‚Äô√©quipe de data engineering en charge de l‚Äôexploitation du Cluster Big Data cherche √† se d√©velopper : afin de r√©pondre aux attentes des d√©partements op√©rationnels en termes de :
Valorisation et d'exploitation des donn√©es de l'entreprise
D√©ploiement des outils de traitement de donn√©es pour une utilisation industrielle.
Le Data Engineer doit faire l'interface entre plusieurs services :
L'infrastructure hardware du Cluster,
Les Data Architect,
Les Data Scientists.
Il doit √™tre capable de comprendre les contraintes industrielles li√©es √† chaque :
Use-case d'exploitation des donn√©es,
Les contraintes et les algorithmes propos√©s par les Data Scientists,
Proposer des solutions robustes d‚Äôimpl√©mentation des traitements d‚Äôingestion ou de transformation de donn√©es dans les √©cosyst√®mes Big Data.
Ta mission (si tu l'acceptes) :
En tant que membre du service DATA au sein du d√©partement Data Intelligence, le Data Ing√©nieur est un acteur cl√© dans le traitement et la mise √† disposition des donn√©es au sein de l‚Äôentreprise. Il sera en particulier impliqu√© dans les missions suivantes :
Conception et d√©veloppement de solutions permettant la collecte, l‚Äôorganisation, le stockage et la mod√©lisation des donn√©es. Ceux-ci doivent √™tre suffisamment s√©curis√©s et lisibles pour les Data Analysts et Data Scientists,
Assurer l‚Äôacc√®s aux diff√©rentes sources de donn√©es, et veiller √† la qualit√© des donn√©es,
Donner un acc√®s facilit√© aux Data Analysts et Data Scientists afin exploiter les donn√©es dans des conditions optimales,
Mise √† jour permanente sur les technologies et les langages utilis√©s dans le but de partager ses connaissances et aider √† l‚Äôavancement des projets,
Contribution, sous la responsabilit√© op√©rationnelle de notre Architecte, aux meilleures pratiques, normes, politiques, m√©thodes, outils et proc√©dures sur le Cluster Big Data,
Il est contributeur de la mise en place d‚Äôune politique de donn√©es respectueuse des r√©glementations en vigueur.
Profil recherch√© :
Ing√©nieur issu d‚Äôune grande √©cole, vous avez des connaissances en mod√©lisation et machine learning (deep learning, random forest, svm‚Ä¶). Acquises lors de votre scolarit√© ou de vos exp√©riences pass√©es (stage ou c√©sure).
Vous avez de bonnes connaissances en Python pour coder ces algorithmes.
Suite √† votre cursus ing√©nieur ou vos exp√©riences professionnelles, vous avez des app√©tences m√©tiers dans les domaines de l‚Äôa√©ronautique, spatial, d√©fense etc.
Vous √™tes reconnu(e) pour votre autonomie, votre excellent relationnel et votre capacit√© √† √™tre force de proposition.
Vous √™tes int√©ress√© pour vous d√©passer en data science & data engineering et vous avez une premi√®re exp√©rience dans ce domaine, comme :
C/C++ / Java / Rust
Spark / PySpark
Kafka
Cloud : AWS / GCP / Azure
Technologies de stockage : Snowflake / S3 / GCS / Azure Blob
Django / Flask
Git Lab
SQL : Postgres / MongoDB
CI/CD
D√©roulement des entretiens :
C‚Äôest tr√®s simple :
1. Pr√©qualification t√©l√©phonique de 5 min avec un membre de l'√©quipe,
2. Second √©change de 30 min (Visio / Physique) avec un Manager pour faire connaissance,
3. R√©alisation d'un Test Technique,
4. √âchange avec la Direction Technique
5. Bienvenue dans la Team
Avantages
‚ìÇÔ∏è Remboursement 50 % de ton titre de transport
üè• Mutuelle H√©lium
üí≥ Carte Edenred
‚òÄÔ∏è Des √©v√®nements et Team Building
üç¨ Candy bar
üòé Terrasse plein sud
Pour te faire une id√©e sur MP DATA, je t'invite √† regarder notre site et nos vid√©os sur Welcome to the jungle.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'R', 'Go'], 'DataBase': ['SQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer DevOps H/F,Inetum,"Courbevoie, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-devops-h-f-at-inetum-3843956952?position=8&pageNum=15&refId=4Y4I0MAYAq8eeUJ%2FxaKDAA%3D%3D&trackingId=7MW%2B24OTCIqkGbxkfdoiXw%3D%3D&trk=public_jobs_jserp-result_search-card,"D√©tail de l'offre
Informations g√©n√©rales
Entit√© de rattachement
Nous sommes une ESN agile, un groupe international certifi√© Top Employer Europe 2024.
A l'√®re de la post-transformation digitale, nous mettons tout en ≈ìuvre pour que chacun de nos 28 000 athl√®tes du digital puisse se renouveler perp√©tuellement, en vivant positivement son propre flow digital.
Chacun de nos talents peut ainsi fa√ßonner son parcours de carri√®re selon ses app√©tences, entreprendre de mani√®re pragmatique avec ses clients pour un monde √† impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-√™tre personnel.
Rejoignez Inetum. Live your positive digital flow.
Tous nos postes sont ouverts aux personnes en situation de handicap.
Description du poste
M√©tier
Conseil et Int√©gration - Business Consulting
Intitul√© du poste
Data Engineer DevOps H/F
Contrat
CDI
Description De La Mission
Qui sommes-nous ?
Nous sommes une ESN agile et un groupe international. A l'√®re de la post-transformation digitale, nous mettons tout en ≈ìuvre pour que chacun de nos 27 000 collaborateurs puisse se renouveler perp√©tuellement, en vivant positivement son propre flow digital. Chacun d'entre eux peut ainsi fa√ßonner son parcours de carri√®re selon ses app√©tences, entreprendre de mani√®re pragmatique avec ses clients pour un monde plus positif, innover localement dans 26 pays et harmoniser son investissement professionnel et son bien-√™tre personnel.
Rejoignez
Capital Market, entit√© Inetum en Finance de March√©
. Nous accompagnons les acteurs majeurs du secteur de la finance en France et √† l‚ÄôInternational.
Cultivant la double comp√©tence technique et fonctionnelle, nous intervenons sur des projets innovants √† haute valeur ajout√©e.
Quelles sont nos valeurs ?
üèÜ Excellence Notre culture de l‚Äôexcellence na√Æt de notre audace.
ü§ù Engagement S‚Äôassocier et grandir ensemble !
üõ∞ Innovation Nos FabLab au service de la transformation digitale de nos clients.
Missions propos√©es
Pour accompagner notre forte croissance, nous recherchons des
Data Engineer DevOps
pour le compte d‚Äôun acteur majeur de la finance de march√© en Europe et dans le monde. Dans ce contexte international et exigeant, vous travaillez sur la conception de solutions Big Data afin de r√©pondre aux besoins des op√©rationnels m√©tiers.
Pour mener √† bien ce projet, vous aurez pour responsabilit√©s de
Comprendre les enjeux des √©quipes Data et les accompagner. Faire le lien entre les environnements (datalake, datawarehouse et environnement de d√©ploiement du mod√®le) gr√¢ce √† des pipelines sophistiqu√©s
√ätre r√©f√©rent et garant des bonnes pratiques pour le d√©veloppement des langages utilis√©s par l'√©quipe. Accompagner les Data Scientists dans l'optimisation de leurs algorithmes
Assurer la viabilit√© des solutions de datamining et de machine learning de l'√©quipe Data et les mettre en production.Construire et optimiser des pipelines de donn√©es complexes (ETL et ELT)
Coordonner le d√©veloppement et les op√©rations gr√¢ce √† l‚Äôautomatisation des flux de travail, la cr√©ation de services Web pr√©dictifs.
D√©ployez ces mod√®les en utilisant les derni√®res techniques et pratiques (API REST, Docker, Tensorflow Serving, etc.)
Analyser et r√©soudre les anomalies li√©es aux performances et √† l‚Äô√©volutivit√© des solutions Cloud BI et Big Data
Profil
Profil souhait√©
De formation Ing√©nieur Grande Ecole ou √©quivalent, vous poss√©dez une premi√®re exp√©rience r√©ussite de trois ans minimum sur un poste √©quivalent id√©alement en banque d‚Äôinvestissement ou asset management.
Vous √™tes familier avec l‚Äôenvironnement Big Data (data grids, compute grids, REST based architectures, SGBDR, No-SQL Databases, GPUs)
Vous avez d√©j√† travaill√© avec la m√©thodologie Agile
Une certaine aisance technique est √©galement requise (Jenkins, Docker, Ansible, Git, Scala, Kubernetes, Python/Java, Maven)
Une double comp√©tence Cloud (AWS, Google Cloud, Azure) serait un v√©ritable plus
Evoluant dans un contexte international, la ma√Ætrise de l'Anglais est n√©cessaire.
L‚Äôaisance relationnelle, de l‚Äôautonomie, la gestion des priorit√©s, des capacit√©s d‚Äôanalyse et de synth√®se, ‚Ä¶ le savoir-√™tre est une composante importante dans notre processus de recrutement.
Tous nos postes sont ouverts aux personnes en situation de handicap.
Et pourquoi Inetum Capital Market ?
üòÑ Des missions int√©ressantes
ü§© Des perspectives d'√©volutions professionnelles et financi√®res
üòé Les avantages d'un grand groupe international
üòâ Un suivi r√©gulier
‚úàÔ∏è Une aide √† la mobilit√© g√©ographique que vous soyez localis√© en France ou √† l'√©tranger
üë®‚Äçüéì Des formations certifiantes
ü•≥ Des moments de FUN !
Localisation du poste
Localisation du poste
France, Ile-de-France, 75 Paris
Ville
Courbevoie
Crit√®res candidat
Niveau d'√©tudes min. requis
Bac+5
Niveau d'exp√©rience min. requis
Plus de 2 ans
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['TensorFlow'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Big Data engineer ‚Äì Ing√©nieur des donn√©es massives (H/F),DGSE - Direction G√©n√©rale de la S√©curit√© Ext√©rieure,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-%E2%80%93-ing%C3%A9nieur-des-donn%C3%A9es-massives-h-f-at-dgse-direction-g%C3%A9n%C3%A9rale-de-la-s%C3%A9curit%C3%A9-ext%C3%A9rieure-3778473628?position=9&pageNum=15&refId=4Y4I0MAYAq8eeUJ%2FxaKDAA%3D%3D&trackingId=iBOhk%2F4d%2BBZvLIrtTbFbPQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Introduction
La Direction G√©n√©rale de la S√©curit√© Ext√©rieure, DGSE, recrute Big Data engineer ‚Äì Ing√©nieur des donn√©es massives (H/F).
Le poste est situ√© √† Paris.
La nationalit√© fran√ßaise est obligatoire.
Domaine m√©tier
Sciences et Technologies
Votre environnement de travail
Le flux de donn√©es trait√©es par la DGSE est √©quivalent √† celui des GAFAM. Ces donn√©es sont au centre du travail des analystes de renseignement, qui doivent pouvoir compter sur des syst√®mes leur permettant de rechercher, croiser, traiter ces donn√©es, en temps r√©el ou en batch. Dans ce contexte, la DGSE cherche √† renforcer ses √©quipes de traitement de la donn√©e massive.
Au sein d'un service centr√© sur le stockage, l'exploitation et la valorisation des donn√©es, nous vous proposons d'int√©grer les √©quipes en charge des plateformes de stockage ou des traitements temps r√©el des donn√©es. Ces √©quipes pluridisciplinaires d√©veloppent et maintiennent de bout en bout diverses plateformes reposant sur les technologies Kafka, Yarn, Hadoop, HBase ou encore Elasticsearch. Plus sp√©cifiquement, l‚Äô√©quipe Stockage administre des entrep√¥ts Big Data ainsi que des couches d‚Äôacc√®s √† leurs donn√©es. L‚Äô√©quipe Temps r√©el con√ßoit des algorithmes r√©pondant √† des besoins de temps de r√©action tr√®s courts (lev√©e d‚Äôalertes, enrichissement √† la vol√©e, r√©ponse √† des besoins op√©rationnels).
En nous rejoignant, vous d√©couvrirez :
un environnement unique, qu'aucune autre structure ne peut vous proposer,
un m√©tier proche du renseignement et de l'op√©rationnel,
une action sur l'int√©gralit√© de la cha√Æne, du d√©veloppement au d√©ploiement en production,
un minimum de 48 jours de cong√©s par an,
une ambiance propice √† l‚Äô√©panouissement professionnel.
Vos missions
Les missions des √©quipes auxquelles vous serez amen√©s √† contribuer seront d√©termin√©es en fonction de votre exp√©rience et de vos app√©tences.
Vous serez en charge de plusieurs activit√©s parmi les suivantes :
concevoir, impl√©menter et optimiser des algorithmes de traitement de donn√©es distribu√©s (Scala, Spark, Java),
garantir le bon fonctionnement, la disponibilit√© et la performance des plateformes de traitement,
participer √† l‚Äô√©volution de l‚Äôarchitecture, en int√©grant de nouveaux composants (frameworks, biblioth√®ques, ‚Ä¶) permettant de mieux r√©pondre aux besoins,
assurer une veille technologique constante pour rester au plus haut niveau et garantir une ad√©quation des clusters existants avec l‚Äô√©tat de l‚Äôart du domaine,
contribuer √† l'am√©lioration continue de l'√©quipe,
interagir avec l‚Äô√©quipe SRE/Devops pour am√©liorer la fiabilit√© des architectures, l‚Äôautomatisation des d√©ploiements et l'observabilit√© des syst√®mes mis en ≈ìuvre.
Votre profil
Vous √™tes titulaire d‚Äôun dipl√¥me en informatique, niveau master ou √©cole d‚Äôing√©nieur, ou pouvez d√©montrer une exp√©rience √©quivalente.
Vous devez poss√©der les comp√©tences et qualit√©s suivantes :
bonnes connaissances fondamentales logicielles (structures de donn√©es, algorithmique, architecture),
ma√Ætrise des langages Scala, Java ou python, vous n'avez pas peur de monter en comp√©tences sur ceux que vous ne ma√Ætrisez pas,
adepte de l'int√©gration continue, vous √™tes familier de Gitlab CI, Github Actions ou Jenkins,
familier avec les bonnes pratiques de d√©veloppement collaboratif (usage de git, pratique de relecture de code).
En bonus :
premi√®re exp√©rience avec un framework de traitement en streaming (SparkStreaming, KStream, Storm, Flink, ...),
convaincu de l'importance de l'observabilit√© des syst√®mes qui regroupe m√©trologie, logging et tracing, vous avez d√©j√† mis en place une stack de ce type (Prometheus, Telegraph, OpenTelemetry, Jaeger, ELK, ‚Ä¶),
familier avec un outil de gestion de configuration (Ansible, Puppet, ...),
exp√©rience sur les clusters Kafka, Hadoop, HBase ou Elasticsearch de plusieurs n≈ìuds.
Les plus de l‚Äôoffre
Contexte d‚Äôactivit√©s unique
Diversit√© des projets
Technologies √† la pointe
Contact
Envoyez-nous votre candidature √† l‚Äôadresse :
dgse-macandidature.cer.fct@intradef.gouv.fr
Plus d‚Äôinformation sur www.dgse.gouv.fr > Nous rejoindre.
RESTEZ DISCRET SUR VOTRE CANDIDATURE A LA DGSE
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Ansible', 'Puppet'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,Harnham,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-harnham-3909639055?position=10&pageNum=15&refId=4Y4I0MAYAq8eeUJ%2FxaKDAA%3D%3D&trackingId=1CSnqICdRwScGUYo4BHNzQ%3D%3D&trk=public_jobs_jserp-result_search-card,"DATA ENGINEER
PARIS (75) / LILLE (59)
50K-65K EUR
Cloud AWS ‚Äì Python ‚Äì PySpark - Glue
Une nouvelle opportunit√© s‚Äôouvre pour un Data Engineer dans le domaine de l‚Äôassurance. La personne rejoindra une grande √©quipe ayant pour projet la cr√©ation d‚Äôune nouvelle plateforme Data ! Si vous recherchez un d√©fi stimulant dans un environnement qui encourage les nouvelles id√©es, cette opportunit√© est faite pour vous.
VOTRE MISSION :
Collaboration avec les Data Architectes pour garantir un bon alignement sur l‚Äôarchitecture
Developpement des processus d‚Äôingestion pour la diffusion des donn√©es dans le Datalake
Mise en place de m√©canisme pour g√©n√©rer les couches de donn√©es organis√©es
Implementation d‚Äôoutils MLOps pour la mise en ≈ìuvre d‚Äôalgorithmes ML
Conception de Data Warehouse pour acc√©l√©rer la g√©n√©ration de mod√®les en Etoile
Travail dans une √©quipe agile avec le train Agile Release, le Product Owner et le SCRUM Master
VOTRE PROFIL :
3 √† 5 ans d‚Äôexp√©rience en tant que Data Engineer
Comp√©tences solides en Cloud AWS, Python, PySpark et SQL
Comp√©tences avec les services AWS Cloud Computing : Glue ; Ath√©na ; Redshift
Capacit√© √† travailler en autonomie
Francais et Anglais : Fluent obligatoire
Les outils BI tels que Power BI ou QuickSight est un plus
N‚Äôh√©sitez plus pour postuler !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Engineer H/F,AXEAL,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-axeal-3913998011?position=1&pageNum=17&refId=l8SH%2B3yTgmzGUPyUpkaAhw%3D%3D&trackingId=cyRIjxyXCNx9BJ%2Fl7OpG9g%3D%3D&trk=public_jobs_jserp-result_search-card,"AXEAL, filiale d'HEVERETT Group porte une r√©elle ambition digitale et propose des solutions de conseil dans les domaines des technologies industrielles.
Nous sommes sp√©cialistes de l'Ing√©nierie du Num√©rique appliqu√©e √† l'Industrie 4.0 dans les secteurs de l'Energie, de la D√©fense, de l'A√©ronautique et du Naval.
Parce que nous ciblons des clients qui d√©veloppent des projets innovants, nous sommes en mesure de proposer les meilleures missions √† nos consultants.
Actuellement en forte croissance, nous sommes √† la recherche d'un(e) Data Engineer pour rejoindre cette aventure passionnante et participer aux transformations technologiques de demain.
Ce Que Nous Proposons
En tant que Data Engineer, vous aurez les responsabilit√©s suivantes :
D√©finir, architecturer, mettre en place et maintenir les outils et infrastructures permettant la valorisation des donn√©es dans un contexte ¬´ Data centric ¬ª.
Vous aurez √† garantir le p√©rim√®tre technique applicatif allant la captation des donn√©es (source h√©t√©rog√®ne, temps r√©el, structur√© ou non, multi protocole) √† son stockage (SQL, nosql) en passant par son traitement (batch, micro batch ou stream) dans un environnement on-Premise, cloud ou hybride.
Le dimensionnement, la s√©curit√©, la p√©rennit√© et l'accessibilit√© sont des √©l√©ments cl√©s √† prendre en compte.
La capacit√© √† travailler en √©quipe avec des m√©thodologies/outils collaboratifs est un pr√© requis.
Vous √™tes dipl√¥m√©(e) d'un doctorat, d'une grande √âcole d'Ing√©nieur et/ou d'un 3√®me cycle universitaire sp√©cialis√© en que Data Engineer ou Math√©matiques appliqu√©es.
Rigoureux(se) et curieux(se), vous faites preuve d'autonomie et aimez relever de nouveaux challenges scientifiques et techniques.
La connaissance des protocoles industriels serait appr√©ci√©e. Vous √©voluerez dans un environnement m√™lant projet industriel et projet de recherche/innovation.
Vous Avez Des Comp√©tences Sur
Captation de la donn√©e : Protocole MQTT, OPC-UA, SQL, API RestFul, WS
Transformation de la donn√©e : Kafka, Spark, storm, Hadoop, Elastic Search, NIFI, ESBMule, Talend, MLFLOW
Stockage de la donn√©e : SQL, NoSQL (timeseries, graph, document)
Monitoring/Visualisation : Grafana, PROMETHEUS, superset, BI
Infrastructure : Docker, Kubernetes
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['ML', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Hybride'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Junior Data Engineer,Constellium,"Voreppe, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/junior-data-engineer-at-constellium-3791294675?position=2&pageNum=17&refId=l8SH%2B3yTgmzGUPyUpkaAhw%3D%3D&trackingId=VuMdW2oTIzx9CYlGnswtXw%3D%3D&trk=public_jobs_jserp-result_search-card,"C
-TEC RECRUTE
Junior Data Engineer (all genders)
Constellium est un leader mondial du d√©veloppement et de la fabrication de produits et de solutions en aluminium √† haute valeur ajout√©e pour un large √©ventail de march√©s et d'applications, se concentrant en particulier sur l'a√©rospatiale, l'automobile et l'emballage.
L'√©quipe Digital centrale d√©ploie les technologies de l'industrie 4.0 partout dans le groupe pour cr√©er nos futurs processus de fabrication de classe mondiale. Elle est h√©berg√©e dans le centre R&D de Constellium √† Voreppe, en France. T√©l√©travail possible jusqu‚Äô√† 2 jours par semaine.
Responsibilit√©s:
Dans le cadre de notre strat√©gie digitale l‚Äôobjectif du poste est de concevoir, d√©velopper et maintenir des applications autour de la collecte, du stockage et de l‚Äôutilisation de la donn√©e, avec pour finalit√© sa valorisation pour notre activit√©.
Le titulaire du poste devra :
Interagir avec les sites de production et les experts m√©tiers pour comprendre leurs besoins.
Participer √† la d√©finition de l‚Äôarchitecture des solutions et des applications.
Concevoir, d√©velopper et maintenir les applications et les solutions ax√©es sur la donn√©e.
Promouvoir les applications digitales et participer activement √† leur d√©ploiement.
Travailler en √©troite collaboration avec une √©quipe de d√©veloppeurs.
Le poste implique des d√©placements professionnels occasionnels dans les usines du groupe en Europe et aux √âtats-Unis.
Profile :
Un dipl√¥me de niveau master en d√©veloppement informatique li√© √† la gestion des donn√©es
Une premi√®re exp√©rience en tant qu‚Äôing√©nieur de donn√©es, avec des r√©alisations dans les domaines suivants :
D√©veloppements d‚Äôapplication en Python ;
Architecture applicative ;
SQL / Mod√©lisation de donn√©es ;
Connaissance de Git / GitHub ;
La connaissance du cloud Azure est un plus.
Le candidat id√©al aura :
Un int√©r√™t prononc√© pour les donn√©es et les sujets li√©s √† l‚Äôindustrie ;
Une volont√© av√©r√©e √† apprendre et √† d√©livrer ;
Une capacit√© √† interagir avec des profils vari√©s (notamment non informaticiens) ;
Une curiosit√© pour √©valuer les technologies innovantes du monde digital.
Un niveau de Fran√ßais et d'anglais courant √©crit et parl√© est essentiel.
Nous offrons:
Une politique salariale attractive
Un syst√®me d'int√©ressement
Un syst√®me de bonus
Une possibilit√© de t√©l√©traviller
Un restaurant d'entreprise
Des avantages importants par les oeuvres sociales
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Junior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,Harnham,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-harnham-3909599777?position=3&pageNum=17&refId=l8SH%2B3yTgmzGUPyUpkaAhw%3D%3D&trackingId=G5qtrNaKlOVlK%2BC16Tnbdw%3D%3D&trk=public_jobs_jserp-result_search-card,"DATA ENGINEER
PARIS (75)
UP TO 65K‚Ç¨ FIXE
Python - AWS - Glue - Pyspark
Une entreprise sp√©cialis√©e dans l'assurance automobile des particuliers, recherche un Data Engineer. Dans le cadre de la cr√©ation d'une nouvelle plateforme data en Europe, l'entreprise recherche un data engineer pour renforcer son √©quipe.
LE POSTE
En tant que Data Engineer, vous allez construire les pipelines pour la pr√©paration et la transformation des donn√©es, y compris les donn√©es brutes, ingestion et donn√©es organis√©es. Vous serez responsable de la mise en ≈ìuvre des mod√®les de donn√©es qui contiennent les KPI et qui sont la source des analyses cl√©s d√©finies par le m√©tier. Vous accompagnerez aussi les data engineer juniors dans leur mont√©e en comp√©tences.
Voici vos responsabilit√©s au quotidien :
Travailler avec les data architectes pour garantir que le d√©veloppement est align√© sur l'architecture cible
D√©velopper les processus d'ingestion de donn√©es pour diffuser les donn√©es dans le Data Lake, √† la fois en temps r√©el et temps diff√©r√©
Impl√©menter le m√©canisme pour g√©n√©rer la couche de donn√©es organis√©e avec les diff√©rents ensembles de donn√©es disponibles pour l'entreprise
Impl√©menter l'outil MLOps pour acc√©l√©rer la mise en ≈ìuvre des algorithmes ML au niveau niveau de l'entreprise
Construire la data warehouse pour acc√©l√©rer la g√©n√©ration de mod√®les
Travailler dans une √©quipe agile en √©troite collaboration avec le train Agile Release, le Product Owner et le Scrum Master afin d'ex√©cuter la t√¢che assign√©e pour atteindre les objectifs d'AgileTeam, en particulier communiquer avec le Scrum Master pour faire remonter les obstacles ou les am√©liorations pour l'√©quipe Agile
VOTRE PROFIL
3 √† 5 ans d'exp√©rience en gestion de donn√©es et technologies Big Data, en particulier : SQL,PySpark et Python
Plus de 3 ans d'exp√©rience avec les services AWS Cloud Computing : Glue, Athena, Redshift et DynamoDB
Plus de 3 ans d'exp√©rience dans l'impl√©mentation de data warehouse
Fran√ßais et anglais courant
Une exp√©rience avec les outils BI (de pr√©f√©rence : QuickSight ou PowerBI) est un vrai plus
POUR POSTULER
Merci de me faire part de votre CV et je vous recontacterai au plus vite.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Junior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Senior Data Engineer,QUANT AI Lab,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-at-quant-ai-lab-3870444702?position=4&pageNum=17&refId=l8SH%2B3yTgmzGUPyUpkaAhw%3D%3D&trackingId=QQK86xMjdcq%2FXDnOI0H7%2BA%3D%3D&trk=public_jobs_jserp-result_search-card,"Chez QUANT AI LAB, nous travaillons avec nos clients pour les aider √† r√©soudre leurs probl√®mes, de la d√©finition de la strat√©gie √† la mise en ≈ìuvre de solutions robustes et durables. Nous nous appuyons sur notre approche op√©rationnelle qui lie conseil et outils.
Nous avons le projet d'accompagner nos clients sur le long terme avec nos convictions, nos approches et notre plateforme QUANT. Rejoindre QUANT AI LAB, c'est rejoindre une aventure entrepreneuriale o√π chaque collaborateur est un √©l√©ment important de ce projet.
C'est pourquoi, notre recherche vise √† recruter plusieurs profils sp√©cialis√©s, dont un
Senior
Data Engineer
pour rejoindre notre √©quipe interne de QUANT AI LAB.
Lieu de poste:
Paris.
Las comp√©tences du candidat sont:
Titul√© d'un dipl√¥me universitaire
(√âconomie, Ing√©nierie...)
Natif(ve) en fran√ßais.
Exp√©rience au moins 5 ans
autant que Data Engineer.
Exp√©rience avec
Scala.
Programmation en
Python.
Ma√Ætrise de l'environnement Cloud
Azure (Databricks).
Ma√Ætrise de
process ETLs.
QUANT AI LAB, ce que nous offrons:
Contribuer au d√©veloppement d'une entreprise internationale en croissance continue et d√©veloppant des projets et produits de pointe.
Int√©grer une √©quipe multidisciplinaire avec une formation professionnelle et acad√©mique de haut niveau, compos√©e de certains des meilleurs experts dans le domaine de l'intelligence artificielle, de l'analytique avanc√©e et du traitement des donn√©es.
L'opportunit√© de travailler directement avec des clients d'envergure internationale et certaines des plus grandes entreprises du pays et du monde.
Un environnement de travail collaboratif, entrepreneurial et solidaire, et une √©quipe jeune et dynamique o√π chacun s'entraide pour grandir ensemble.
Une ambiance ludique et conviviale et des √©v√©nements festifs (afterworks, s√©minaires...).
Un contrat √† dur√©e ind√©termin√©e et un salaire tr√®s comp√©titif, √† d√©terminer en fonction du profil et de l'exp√©rience.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Senior'], 'TypeContract': [], 'Salary': ['Salaire'], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Engineer Lille H/F,Jems Group,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-lille-h-f-at-jems-group-3887943159?position=5&pageNum=17&refId=l8SH%2B3yTgmzGUPyUpkaAhw%3D%3D&trackingId=YKBGlO4%2BmKgm4JyE4pKCsg%3D%3D&trk=public_jobs_jserp-result_search-card,"A propos de JEMS
Nous sommes le seul industriel de la donn√©e en Europe. Notre m√©tier est de cr√©er, manager et exploiter le patrimoine data de nos clients.
Nous avons la conviction que chaque entreprise peut adopter une d√©marche innovante de gestion de la donn√©e et cr√©er des cas d‚Äôusage disruptifs en r√©duisant l'impact √©cologique et en diminuant la dette technique.
Nous comptons plus de 840 collaborateurs en mission chez nos clients grands comptes dans tout secteur d‚Äôactivit√© : banque, assurance, sant√©, √©nergie, e-commerce, automobile, luxe, retail, transport, agritech‚Ä¶
Vos missions
Nous recherchons un(e) data engineer capable de trouver des solutions innovantes et robustes √† l'ensemble des probl√©matiques Data.
Vous aurez la charge de :
Participer √† la conception et r√©alisation d'une solution Data depuis l'acquisition jusqu'√† l'exploitation de la donn√©e en accompagnant la r√©flexion des directions m√©tiers
Identifier, collecter et int√©grer les donn√©es n√©cessaires √† la r√©solution de probl√©matiques m√©tier et op√©rationnelles
Garantir la qualit√© des donn√©es en mettant en place les outils de mesure et de suivi ad√©quats en appliquant les r√®gles de Data Gouvernance et de Data Management
Transcrire des besoins m√©tier en r√®gles de gestion data
Industrialiser le d√©ploiement de vos r√©alisations √† travers l'impl√©mentation de tests unitaires, d'int√©gration et de non-r√©gression
Vos comp√©tences
En tant que Data Engineer vous ma√Ætrisez :
Le langage SQL
Un langage objet (Python, JAVA, Scala)
Un framework de calcul distribu√©
L'int√©gration continue (Git, JUnit, SonarQube, Jenkins)
Un cloud provider (AWS, GCP, Azure) ou une distribution Big Data (Hortonworks, Cloudera, Datastax)
Les concepts de la mod√©lisation relationnelle et non-relationnelle
Votre profil
Dipl√¥m√©(e) d'une √©cole d'ing√©nieur ou d'un parcours acad√©mique bac+5 , vous justifiez d'une exp√©rience professionnelle d'au moins 3 ans dans un contexte projet Data. Rigoureux, proactif et autonome vous restez en veille technologique et √™tes force de proposition. Vous √™tes capable de prendre de la hauteur et vous adapter aux enjeux du projet.
Avantages √† travailler chez JEMS
Une JEMS Acad√©mie au service de votre mont√©e en comp√©tences (formations et certifications sur les technologies de pointe)
Un accompagnement personnalis√© et un management de proximit√© pour vous proposer des √©volutions de carri√®re
Une int√©gration dans des communaut√©s techniques et de pratiques JEMS (encadrement par des experts, √©changes sur les bonnes pratiques, favoriser l'innovation...)
Une entreprise reconnue ""Great Place To Work""
Des √©v√®nements et s√©minaires inoubliables, des soir√©es d'agence conviviales
Mobilit√©
Une mobilit√© nationale et internationale pour vous accompagner dans vos projets de vie.
Diversit√©
Le Groupe JEMS porte fi√®rement sa valeur ""Diversit√©"" en se mobilisant pour l'inclusion et l'√©galit√© des chances et en luttant contre toutes formes de discrimination.
Tous nos postes sont ouverts aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer Cloud Azure F/H,SOFTEAM,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-cloud-azure-f-h-at-softeam-3609925189?position=6&pageNum=17&refId=l8SH%2B3yTgmzGUPyUpkaAhw%3D%3D&trackingId=hEH4xMsVArxvZE38RT24qg%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous √©voluez dans le domaine de la Data et souhaitez int√©grer un leader de la transformation num√©rique sp√©cialis√© dans les secteurs de la Banque, du Luxe, de l'Assurance, de la Finance, de l'Energie et la possibilit√© d'√©voluer au sein du Groupe Docaposte !
Softeam est labellis√© ""HappyIndex¬Æ AtWork "" 2022 pour la 5√®me ann√©e cons√©cutive !
Nos collaborateurs travaillent en ¬´ mode projet ¬ª autour des Modern DATA Platform ‚òÅ et technologies Big Data Azure Cloud / On premise et autre ""playeur"" du march√©. Nous accompagnons de bout en bout nos clients sur des probl√©matiques de Gouvernance, d‚ÄôInt√©gration, de Visualisation et d‚ÄôIA.
CE QUE NOUS RECHERCHONS
SOFTEAM Data recherche un(e) Data Engineer Cloud, disposant de solides connaissances techniques.
CE QUE NOUS ATTENDONS DE VOUS
En tant que Data Engineer Cloud, vous concevez, mettez en place et administrez des clusters et des solutions big data.
Vos missions d√©taill√©es :
Analyse et compr√©hension des besoins m√©tiers,
Participation √† la d√©finition et √† la conception de l‚Äôarchitecture,
Gestion des donn√©es : pr√©paration, ingestion, traitement, contr√¥le qualit√©,
D√©veloppements des jobs Spark et automatisation des flux d‚Äôalimentation du Data Lake,
Tests de charge, tests unitaires‚Ä¶
Maintenabilit√© de la solution Big Data (Optimisation et performance des traitements Spark)
VOUS ETES
Ing√©nieur(e) de formation, vous disposez d'une exp√©rience de 3 ans minimum en tant que Data Engineer.
Vous ma√Ætrisez les langages Java, Scala ou Python et √™tes expert sur les framework Spark et Hadoop.
Vous avez une expertise sur les services Data suivants : Azure Data Lake, Azure synapse, Azure Data Factory, Azure Data Explorer‚Ä¶
NOUS VOUS OFFRONS
Des missions engageantes aupr√®s des grands acteurs du march√©.
Un management de proximit√© avec Gilles SALVADOR, Directeur du Centre d'Expertise Data, toujours bienveillant et √† √† l'√©coute et avec qui vous pourrez √©changer au quotidien sur les enjeux de votre mission et √©voquer vos futurs projets afin que nous puissions vous aider √† les r√©aliser.
La possibilit√© d‚Äô√©voluer et de monter en comp√©tences gr√¢ce √† des formations et √† des certifications aupr√®s de nos clients et de nos consultants, des 12@13, notre Entit√© Softeam Institute, Organisme de formation interne de renomm√© qui d√©livre des formations aupr√®s de nos clients...
QUI SOMMES-NOUS ?
SOFTEAM DATA est une marque de DOCAPOSTE sp√©cialis√©e dans l'informatique d√©cisionnelle et les nouvelles technologies. Nous apportons notre expertise √† nos clients, principalement des Grands Comptes de la place financi√®re fran√ßaise, dans des projets de transformation digitale et cognitive.
2000 Softeamien.nes sont d√©di√©.es √† la transformation m√©tier et digitale de nos clients et ont g√©n√©r√© 200 M‚Ç¨ de chiffre d‚Äôaffaires en 2020.
SOFTEAM SPIRIT
Des communaut√©s d'expertises sur les sujets de la Data
De super nouveaux locaux qui sont en plus accessibles facilement
Une √©cole de formation int√©gr√©e
Des √©v√®nements : des soir√©es avec les consultants, des 12@13...
Une entreprise labellis√©e ""Happy at Work"" pour la 5√®me ann√©e cons√©cutive.
N‚Äôattendez plus, rejoignez SOFTEAM et venez nous rencontrer dans nos nouveaux locaux situ√©s √† la D√©fense #DevenezSofteamien !
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
AI Engineer Intern,SITA,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/ai-engineer-intern-at-sita-3913856183?position=7&pageNum=17&refId=l8SH%2B3yTgmzGUPyUpkaAhw%3D%3D&trackingId=6d%2FsgnHB%2Futl0dC34z%2FiQw%3D%3D&trk=public_jobs_jserp-result_search-card,"ABOUT THE ROLE & TEAM:
The Data Intelligence team develops and deploys data-driven and AI-powered solutions to optimize operations in the aviation industry, with a specific focus on reducing the sector's CO2 emissions. For example, SITA Opticlimb helps to save fuel for each climb by computing optimal climb speeds considering number of factors like air density, weight, etc.
We are seeking a highly motivated
AI Engineer Intern
to join our Data Intelligence team. As an AI Expert Intern, you will have the opportunity to work closely with our AI Experts on cutting-edge projects, leveraging your skills and knowledge in AI development and optimization. This internship provides a valuable opportunity to gain hands-on experience in the field of AI and contribute to the success of our data intelligence solutions.
WHAT YOU WILL DO:
Collaborate with AI Experts to develop and optimize AI models and algorithms for aviation operations
Assist in implementing and maintaining the AI pipeline and infrastructure for data processing and model training
Support AI Experts in conducting experiments and tests to evaluate the performance and accuracy of AI models.
Pre-process¬†and analyze data using Python and relevant libraries (e.g., Pandas, NumPy) to prepare it for model training and evaluation
Contribute to the development of data pre-processing¬†techniques, feature engineering approaches, and model evaluation methodologies
Document development processes, procedures, and findings
Stay up-to-date with the latest AI research and industry trends to contribute innovative ideas to the team
EXPERIENCE:
Currently pursuing a Bachelor's or Master's degree in Computer Science, Data Science, or a related field.
Solid understanding of AI and machine learning concepts.
Proficiency in Python and experience with libraries such as Pandas, NumPy, and scikit-learn.
Knowledge of data pre-processing, feature engineering, and model evaluation techniques.
Strong analytical and problem-solving skills.
Excellent communication and teamwork abilities.
Passion for learning and staying up-to-date with AI advancements.
NICE-TO-HAVE:
Aeronautical background is a plus
WHAT WE OFFER:
SITA‚Äôs workplace is all about diversity, many different countries and cultures are represented in our workforce. We collaborate in our impressive offices, embracing a hybrid work format. As part of our global benefits, we offer:
üè°
Flex-week:
Work from home up to 2 days/week (depending on your Team's needs).
‚åö
Flex-day:
You may wish to flex your arrival time at the office, to beat the rush hours or you may want to leave the office earlier to pick up your kids from school or to go to your favorite game: We support you in being open about your needs and routine with you manager.
üåé
Flex-location:
Benefit for 30 working days from anywhere around the world each year!
üôåüèΩ
Competitive benefits
according to the local market
SITA is an Equal Opportunity Employer and values a diverse workforce. In support of our Employment Equity Program, women, aboriginal people, members of visible minorities, and/or persons with disabilities are encouraged to apply and self-identify in the application process
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication', 'Teamwork']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer - H/F - CDI,CubeRH,"Tourcoing, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-cdi-at-cuberh-3862951855?position=8&pageNum=17&refId=l8SH%2B3yTgmzGUPyUpkaAhw%3D%3D&trackingId=UcyKVwyyFAHcs5s4Wologg%3D%3D&trk=public_jobs_jserp-result_search-card,"La soci√©t√© :
Notre client est une entreprise de services sp√©cialis√©e dans le domaine de la Data, √† √©chelle humaine, qui se distingue par son expertise d√©velopp√©e autour de trois axes principaux : la Data g√©n√©raliste, l'outil de reporting Power BI et la solution cloud Microsoft Azure.
Au c≈ìur de sa mission, l'√©co-responsabilit√© constitue un pilier essentiel. En adoptant cette approche, elle offre une vision compl√®te et int√©gr√©e de la gestion des donn√©es. Gr√¢ce √† une √©quipe de consultants experts, elle simplifie les op√©rations, optimise les donn√©es et les valorise, offrant ainsi √† ses clients une opportunit√© de progression.
En pleine croissance, l'entreprise recherche √† agrandir son √©quipe avec un Data Engineer H/F.
Si vous recherchez une √©quipe qui met en avant votre d√©veloppement professionnel et votre √©panouissement, vous √™tes au bon endroit !
L'objectif de la mission :
Initier et d√©velopper des outils d‚Äôinfrastructure dans l‚Äôobjectif de fa√ßonner et transformer les donn√©es.
Agir tel un alli√© des Data Scientists, pour industrialiser leurs algorithmes et flux de donn√©es.
√ätre un acteur de choix dans l‚Äôarchitecture big data afin de r√©pondre aux diff√©rents cas m√©tiers.
Prot√©ger et garantir l‚Äôint√©grit√© des donn√©es en assurant leur s√©curit√© et leur accessibilit√©s
Mettre en ≈ìuvre des pratiques de s√©curit√© redoutables pour prot√©ger les donn√©es les plus confidentielles et sensibles
Travailler en collaboration avec les √©quipes techniques dans l‚Äôingestion des donn√©es.
Les conditions de travail :
Une mutuelle avantageuse et des tickets restaurants
Remboursement int√©gral de vos frais de transports en commun
Des trottinettes √©lectrique et des v√©los √† disposition
Primes (notamment de cooptation)
T√©l√©travail
Votre profil :
Vous maitrisez des technologies big data ainsi que les environnements Google cloud platform, Amazon web service et/ou Microsoft Azure
Vous connaissez le langage SQL et Python
Vous poss√©dez des bases solides en architecture data (notamment big data et informatique d√©cisionnelle
Etre force de proposition sur la mise en oeuvre et l'utilisation des solutions big data
Connaitre les principes de s√©curit√©
Process entretien :
Deux premiers √©changes avec le cabinet Cube RH;
Entretiens avec le client (RH et avec le manager).
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['Azure', 'Google Cloud Platform'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer Cloud (F/H),Apside,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-cloud-f-h-at-apside-3904088503?position=9&pageNum=17&refId=l8SH%2B3yTgmzGUPyUpkaAhw%3D%3D&trackingId=%2B%2BPQMVY2DJykjwzejMYJVg%3D%3D&trk=public_jobs_jserp-result_search-card,"üí•
D√©couvrez la Vie Apsidienne
üìπ
et vous aussi, devenez Apsidien
On aurait pu demander √† Chat GPT de vous d√©montrer en quoi
Apside est l‚ÄôESN qu‚Äôil vous faut,
mais on pr√©f√®re que vous le d√©couvriez vous-m√™mes üëáüòè
üî•
D√©couvrez votre future mission
üëâ
Contexte
Rejoignez notre Practise Cloud/Data, afin d‚Äôintervenir sur des sujets √† haute valeur ajout√©e !
Notre
client migre actuellement toutes ses applications vers le cloud AWS.
De plus, dans le cadre du d√©veloppement d'un produit de restitution automatis√©e de donn√©es, ils recherchent actuellement d√©veloppeur data ayant d√©j√† travaill√© sur un projet similaire. La solution produit est techniquement con√ßue en lien avec le Tech Lead validant l'architecture logicielle √† mettre en place sur le cloud AWS.
Secteur
: culture/m√©dia
M√©thode de travail
: Agile Safe
üòé Mission
Capter les donn√©es (structur√©es et non structur√©es) produites dans les diff√©rentes applications
Int√©grer les √©l√©ments
Structurer la donn√©e (s√©mantique, etc‚Ä¶)
Cartographier les √©l√©ments √† disposition
Nettoyer la donn√©e (√©limination des doublons, etc‚Ä¶)
Valider la donn√©e
Cr√©er les r√©f√©rentiels de donn√©es
Environnement technique
:
Python
Lambda
Step Function
AWS / AWS RDS
PostegreSQL
Snowflake
Spark
üìç
Localisation
La D√©fense
üí∞
Le package salarial que nous vous proposons
Contrat :
CDI
Avantages groupe :
carte ticket restaurant Swile, prime de mobilit√©, RTT, accord t√©l√©travail, Mutuelle, prime de cooptation, avantages CE, prise en charge de la mutuelle √† 100% etc‚Ä¶
Avantages agence :
Communaut√© Cloud/Data, afterworks, communaut√© techlead
Formation :
certifications techniques, cours particuliers d‚Äôanglais en interne, acc√®s √† un catalogue de formations gr√¢ce √† notre plateforme e-learning (
Academy by Apside
) ou via nos organismes partenaires.
üîÆ
√î vous futur Apsidien, qui √™tes-vous ?
Au moins 4 ans d'exp√©rience en tant que Data Engineer
Maitrise de l‚Äôenvironnement cloud AWS
Force de proposition, bon relationnel et autonome
üòè
Apside a suscit√© votre curiosit√© ?
Dans un environnement marqu√© par une acc√©l√©ration des √©volutions technologiques, de transformations des usages et de disruptions majeures, Apside est un partenaire de confiance qui accompagne ses clients √† cr√©er de la valeur et √† adresser leurs enjeux strat√©giques en leur mettant √† disposition des expertises technologiques (
Data / IA, Cloud, Cyber
) et une exp√©rience sectorielle (
Industrie, Banque, Assurance, Service, Secteur Public
). Pour un accompagnement global, le groupe propose des offres transverses autour du
Handicap
(Apsid‚ÄôEA), du
Digital Learning
, et du
Conseil
.
ü§î
Et votre place dans tout √ßa ?
üëâ Notre volont√©
est de vous accompagner dans la construction et l‚Äô√©panouissement de votre carri√®re
en nous appuyant notamment
sur 3 piliers :
Une
r√©mun√©ration
√† hauteur de vos investissements et de vos comp√©tences
Une
trajectoire professionnelle
stimulante sur mesure
Un
engagement
autour des valeurs Apsidiennes : la qualit√© de vie et des conditions de travail au c≈ìur de nos enjeux
Engag√©e pour
un monde plus inclusif et plus responsable
, Apside r√©invente l‚ÄôESN et propose l‚ÄôEngagement Soci√©tal et Num√©rique. D√©couvrez notre d√©marche RSE ainsi que notre vision de l‚ÄôEntreprise Engag√©e.
Convaincu ? A vous de jouer, envoyez-nous votre CV !
Rejoignez l‚Äôaventure Apsidienne et d√©couvrez notre vision d‚Äôune ESN singuli√®re et r√©siliente
üöÄ
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['100'], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Senior Data Engineer H/F ‚Äì CDI ‚Äì Paris,IODA Group,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/senior-data-engineer-h-f-%E2%80%93-cdi-%E2%80%93-paris-at-ioda-group-3908890202?position=10&pageNum=17&refId=l8SH%2B3yTgmzGUPyUpkaAhw%3D%3D&trackingId=En91OVaDWAVBsJRBkXEEVg%3D%3D&trk=public_jobs_jserp-result_search-card,"IODA Group, cabinet de conseil en plein essor en France et √† l'international, √† taille humaine et orient√© business, mixant la Data, le Marketing, le Digital & la Technologie, est √† la recherche de talents passionn√©s pour rejoindre son √©quipe.
Si tu es un(e)
Senior Data Engineer
chevronn√©(e) avec
au moins 4 ans d'exp√©rience
, ce poste est fait pour toi !
Ce poste est bas√© √† Paris mais nous avons √©galement des bureaux √† Bordeaux, l‚ÄôIle de la R√©union et Barcelone.
Le Job üíª
En tant
que Senior Data Engineer
chez IODA Group, tu seras aux commandes des missions suivantes :
D√©velopper de nouveaux mod√®les de donn√©es et des pipelines
Tester les solutions les plus innovantes et prometteuses du march√© en vue de pouvoir am√©liorer nos capacit√©s en mati√®re de donn√©es
Comprendre les enjeux business et savoir les traduire dans un environnement technique
Assister nos clients dans le cadrage des projets et contribuer au design fonctionnel et technique avec une vision avant-gardiste
Assumer le r√¥le de r√©f√©rent, coacher les consultants juniors et faire √©voluer son √©quipe
Comp√©tences techniques requises üîß
Pour ce poste, nous recherchons une personne aux comp√©tences multiples avec :
Une exp√©rience approfondie des technologies li√©es aux donn√©es, y compris les mod√®les d'architecture Big Data (Spark, Hive, Impala...)
Une exp√©rience approfondie des services Cloud (AWS / Azure / GCP)
Une expertise en langages de programmation : Python, Java, et si possible Scala
Une mise en production de cas d'usage Data, notamment en Machine Learning
Une capacit√© √† mettre en place des mod√®les de donn√©es flexibles et √©volutifs (optimisation de stockage et traitement, regroupement, agr√©gation, partitionnement‚Ä¶)
Une maitrise des bases de donn√©es SQL (conception, exploitation ‚Ä¶)
Une connaissance en DevOps et en d√©veloppement de flux de donn√©es (data pipelines) avec une ma√Ætrise de Docker/Kubernetes et des cha√Ænes CI/CD seraient un plus
Profil recherch√© üåü
Si tu es dipl√¥m√©(e) d'une √©cole d‚Äôing√©nieur / g√©nie informatique Bac+5, que tu as √† minima 4 ans d‚Äôexp√©rience et que tu as une exp√©rience solide dans le monde de la Data, alors nous voulons te rencontrer !
Si tu es une personne entreprenante, capable de travailler en √©quipe en s‚Äôadaptant √† divers profils, de superviser, de prioriser et de g√©rer plusieurs actions, d‚Äôavoir d'excellentes comp√©tences en communication, pr√©sentation et coordination, nous souhaitons toujours te rencontrer !
De plus, si tu as des comp√©tences av√©r√©es en analyse et r√©solution de probl√®mes, associ√©es √† une aptitude √† assimiler rapidement de nouvelles technologies, tu es bien la personne qu‚Äôil nous faut !
Ce qui t'attend chez IODA Group üåà
En nous rejoignant, tu auras droit √† :
Une √©quipe dynamique et motiv√©e qui reconna√Ætra et encouragera tes talents et tes id√©es
Une diversit√© de projets stimulants dans diff√©rents secteurs d'activit√©s
Des plateformes internes de R&D pour toujours √™tre √† la pointe de la technologie
Des perspectives d'√©volution concr√®tes pour faire d√©coller ta carri√®re
Un CDI avec une r√©mun√©ration fixe attractive et une part variable selon ton profil (voire des bonus compl√©mentaires si tu surperformes !)
Deux jours de t√©l√©travail par semaine apr√®s la p√©riode d'essai
Des avantages tels que des tickets restaurants, une participation au titre de transport, une mutuelle...
Une participation active √† la vie de l'entreprise avec des afterworks, des √©v√©nements, des s√©minaires et bien plus encore !
REJOINS-NOUS
d√®s maintenant pour une aventure o√π les donn√©es deviennent une source infinie d'opportunit√©s ! üöÄ‚ú®
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication', 'R√©solution de probl√®mes'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Junior', 'Senior'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Data Engineer,Harnham,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-harnham-3909658681?position=1&pageNum=20&refId=%2FS%2FUEqH%2F4ToPDYrc6skyJQ%3D%3D&trackingId=qUGt7EsqBEzusK1%2FE031NA%3D%3D&trk=public_jobs_jserp-result_search-card,"Data Engineer
Paris / Lille
Up to 65k‚Ç¨
CDI - Pas Freelance
Cette entreprise internationale dans le monde de l'assurance developpe son equipe data et recherche un nouveau Data Engineer.
Responsabilit√©s :
Collaborer avec les architectes de donn√©es pour garantir que le d√©veloppement est align√© sur l'architecture cible.
D√©velopper des processus d'ingestion de donn√©es, facilitant le streaming de donn√©es en temps r√©el et par lots dans le lac de donn√©es.
Mettre en ≈ìuvre des m√©canismes de g√©n√©ration de couches de donn√©es s√©lectionn√©es comprenant divers ensembles de donn√©es pour la consommation commerciale.
Diriger la mise en ≈ìuvre de MLOps pour rationaliser le d√©ploiement d'algorithmes ML √† l'√©chelle de l'entreprise.
√âtablir des cadres pour l'entreposage de donn√©es afin d'acc√©l√©rer la g√©n√©ration de mod√®les en √©toile.
Travailler en √©troite collaboration au sein d'une √©quipe agile aux c√¥t√©s des trains de publication agile, des propri√©taires de produits et des ma√Ætres scrum pour atteindre les objectifs de l'√©quipe.
Participer activement aux c√©r√©monies de la communaut√© de pratique de l'ing√©nierie des donn√©es, en particulier aux chapitres, pour partager des connaissances techniques et favoriser la collaboration.
Candidat id√©al :
Must have :
3 √† 5 ans d'exp√©rience en gestion de donn√©es et en technologies Big Data, avec une ma√Ætrise de SQL, PySpark et Python.
Une exp√©rience pratique approfondie (3+ ans) avec les services de Cloud Computing AWS : Glue, Athena, Redshift et DynamoDB.
Une exp√©rience av√©r√©e (3+ ans) dans la mise en ≈ìuvre des entrep√¥ts de donn√©es.
Ma√Ætrise de l'anglais.
Un Plus :
Connaissance suppl√©mentaire des services de Cloud Computing AWS : CDK, SageMaker, fonctions Lambda, Lake Formation, Kinesis.
Familiarit√© avec les outils BI (de pr√©f√©rence QuickSight ou PowerBI).
Ma√Ætrise de Git, Jupyter Notebook, pip, Java, Apache Airflow.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Apache Airflow'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Engineer,Pictarine,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-at-pictarine-3911913926?position=2&pageNum=20&refId=%2FS%2FUEqH%2F4ToPDYrc6skyJQ%3D%3D&trackingId=XgvgsQOypETxNXQ%2Bsrs8Vw%3D%3D&trk=public_jobs_jserp-result_search-card,"Mission and challenges üéØ
Si tu es enthousiaste √† embarquer dans la nouvelle √©quipe data de Pictarine pour la faire rayonner avec tout ton savoir-faire, alors c‚Äôest l‚Äôaventure qu‚Äôil te faut! üèîÔ∏è
Avec plus de 1K tables, 2M de clients et 4M de commandes en 2022, les √©quipes de Pictarine ne sont jamais √† court d‚Äôid√©es pour explorer de nouveaux horizons. üöÄ
En tant que Data Engineer chez Pictarine tu vas pouvoir utiliser toutes tes comp√©tences SQL pour garantir la qualit√© de la data sur GCP, accompagner et challenger les besoins data.
Tu √©volueras au sein de l‚Äô√©quipe Engineering, compos√©e des p√¥les dev & data.
Ton r√¥le comprendra les aspects suivants üëáüèª
Tu es garant de la qualit√© de la data !
En simplifiant la structure de la data et r√©duisant le nombre de tables
En transformant les donn√©es pour les rendre facilement utilisables
En orchestrant le flux des donn√©es de mani√®re continue et automatique
Tu accompagnes et challenges les √©quipes de Pictarine !
En co-construisant des solutions data appropri√©es
En √©levant le niveau de jeu des m√©thodes data existantes
En faisant rayonner la data autour de bonnes pratiques et d‚Äôoutillages ad√©quates
Profil Recherch√©
About you üíé
Tu as au moins 5 ans d‚Äôexp√©rience sur un poste similaire
Tu ma√Ætrises le data warehouse BigQuery et son langage SQL
Tu es √† l'aise avec les services GCP
Tu as de bonnes connaissances dans la conception de mod√®les de donn√©es et les strat√©gies d'optimisation des requ√™tes SQL
Tu as des comp√©tences en DevOps pour le d√©ploiement et la gestion efficace des pipelines de donn√©es
Tu as une bonne ma√Ætrise de Python & Github
Tu es organis√©, rigoureux et portes une grande attention aux d√©tails
Tu es dot√© d‚Äôexcellentes qualit√©s relationnelles, de communication et de vulgarisation
Tu as une passion pour r√©soudre des probl√®mes business avec la programmation
Tu es curieux de tester des nouvelles technologies
Tu es un team player et toujours √† l'aff√ªt de nouvelles id√©es
Work @ Pictarine‚ú®
Un environnement de travail agile, collaboratif, international et multiculturel
Des perspectives d‚Äô√©volution rapides
Des locaux tout beaux √† Lab√®ge avec du mat√©riel dernier cri (mais aussi des snacks √† profusion et un frigo √† boissons toujours bien rempli)
Un apprentissage permanent : conf√©rence, meet-up, Pictarine Academy, cours d‚Äôanglais.
Des events tous les mois : massage, pilates, TGIF, team building .
Un environnement de travail flexible : horaires, politique de remote hybride.
Un package de r√©mun√©ration attractif : salaire comp√©titif, RTT, mutuelle & pr√©voyance 100% prise en charge, int√©ressement.
Des petits + : D√©veloppement de photos gratuit, subvention sport, 3 jours ‚Äúentraide familiale‚Äù, jours de cong√©s en plus avec l'anciennet√©... ü§´ on ne te d√©voile pas tout !
Recruitment process ‚öôÔ∏è
Tu souhaites nous rejoindre ? Viens rencontrer les gens avec qui tu vas bosser :
1er √©change pour apprendre √† se conna√Ætre avec Marie - Engineering Manager Data (15‚Äô)
Entretien Manager avec Marie (60-90‚Äô)
Test pratique afin de nous montrer tes talents üôÇ (3 heures)
Entretien final avec 2 membres du Codir (90‚Äô)
Welcome aboard !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Hybride', 'Remote'], 'TypeContract': [], 'Salary': ['100', '100'], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Engineer,NW,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-nw-3904072453?position=3&pageNum=20&refId=%2FS%2FUEqH%2F4ToPDYrc6skyJQ%3D%3D&trackingId=vDQfEmvWaoDACO%2Fg0SceBQ%3D%3D&trk=public_jobs_jserp-result_search-card,,"{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Hybride', 'Remote'], 'TypeContract': [], 'Salary': ['100', '100'], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Engineer Paris H/F (H/F),Inventiv IT,"Levallois-Perret, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-paris-h-f-h-f-at-inventiv-it-3910222334?position=4&pageNum=20&refId=%2FS%2FUEqH%2F4ToPDYrc6skyJQ%3D%3D&trackingId=thOWBDZ31CHfsFXdwy4SpA%3D%3D&trk=public_jobs_jserp-result_search-card,"Cette offre d‚Äôemploi est fournie par P√¥le emploi
Description
Inventifs Wanted vous propose un CDI pr√©c√©d√© d'une formation professionnalisante acc√©l√©r√©e de 400h, dans le cadre d'une POEI (Pr√©paration Op√©rationnelle √† l'Emploi Individuel), pour que vous soyez pleinement op√©rationnel et 100% √† l'aise dans la mission qui vous sera confi√©e. Situ√© au c≈ìur de Levallois, un √©crin o√π il fait bon vivre et travailler, Inventiv IT b√©n√©ficie d'un cadre vibrant et dynamique, id√©al pour s'√©panouir. Nous sommes en qu√™te d'une √©toile filante avec une exp√©rience d'au moins 5 ans minimum dans le domaine de la data science et de la data engineering. Vous √™tes un leader galactique dot√© d'une expertise en data, optimisation de processus, et m√©thodologies Agile. Ce que vous apporterez √† notre galaxie : - Cartographier les constellations de donn√©es : √âtudier les besoins, cadrer les projets et d√©finir les p√©rim√®tres d'interventions afin de r√©aliser le release plan des diff√©rents livrables. - Ing√©nierie des √©toiles : Vous participerez au d√©veloppement des projets ou des services data en d√©veloppant une cha√Æne de traitement de donn√©es robuste et automatis√©e. - Architecture c√©leste: Participer activement √† l'ingestion et la mise en qualit√© des donn√©es selon les bonnes pratiques de la Factory et g√©rer le traitement, l'agr√©gation et la sauvegarde des donn√©es. En √©troite collaboration avec le chef de projet, les OPS et les architectes, vous participerez aux activit√©s d'architecture, conception et d√©veloppement. - Mise en production de la galaxie : Effectuer l'int√©gration continue (avec le versioning, le packaging, les tests et le d√©ploiement) pour assurer une bonne mise en production de notre appareil cosmique. - Surveillance des n√©buleuses: Contribuer professionnellement et activement √† la veille scientifique et technique, aux projets R&D, et √† la construction d'assets et de services techniques orient√©s data. Participer √©galement aux autres activit√©s du p√¥le Data Science & Engineering (reporting d'activit√©, communication interne et externe, collaboration avec les universit√©s et laboratoires associ√©s). Votre profil stellaire comprendra : - Ma√Ætrise de l'univers data : Votre expertise en data et mod√©lisation des donn√©es forme la colonne vert√©brale de notre exploration. Vous savez comment transformer des n√©buleuses de donn√©es brutes en syst√®mes solaires d'informations structur√©es et exploitables. - Architecte des flux de donn√©es: Vous √™tes expert dans la gestion de la cha√Æne de transformation des donn√©es, de l'ingestion √† la visualisation. Votre capacit√© √† optimiser les processus de traitement et de calcul assure la fluidit√© et l'efficacit√© de notre exploration. - Ing√©nieur de l'industrialisation: Gr√¢ce √† votre habilet√© √† industrialiser les flux de donn√©es, vous garantissez la scalabilit√© et la robustesse de nos syst√®mes, pr√©parant notre architecture √† l'inconnu. - Cr√©ateur d'Outils Visuels: Votre talent dans la conception d'outils graphiques et la data visualisation illumine le chemin, permettant √† tous de naviguer avec clart√© dans le cosmos des donn√©es. - Guide et Mentor: Vous accompagnez chaque projet data, assurant la compr√©hension et l'atteinte des objectifs. Votre capacit√© √† analyser et comprendre les besoins m√©tier, et √† r√©diger avec pr√©cision technique et scientifique enrichit la connaissance collective et solidifie notre qu√™te. - Arsenal Technologique: Votre ma√Ætrise de Microsoft Azure Data Lake Storage, Spark / Scala, Git / Azure DevOps, Airflow / DataDog / Nifi, et plus encore, est l'arsenal qui nous propulse dans cette aventure. Chaque outil, chaque langage, est une √©toile dans la galaxie de vos comp√©tences, illuminant notre chemin vers l'avant-garde technologique. Votre Mission, si vous l'acceptez: Faire partie de la Data Factory d' Inventiv IT, c'est accepter de naviguer vers l'inconnu, d'explorer de nouveaux horizons et pr√™ts √† s'embarquer dans cette aventure cosmique.
PROFIL SOUHAIT√â
Exp√©rience
2 An(s)
Source: Pole emploi (https://www.pole-emploi.fr)
Show more
Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
DATA Engineer Azure F/H,SOFTEAM,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-azure-f-h-at-softeam-3839971802?position=5&pageNum=20&refId=%2FS%2FUEqH%2F4ToPDYrc6skyJQ%3D%3D&trackingId=8Q3yQextnpgvyUs%2Brm5KYg%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous √©voluez dans le domaine de la
Data
et souhaitez int√©grer un leader de la transformation num√©rique sp√©cialis√© dans les secteurs de la
Banque, du
LGuxe
, de l'Assurance, de la Finance, de l'Energie
et la possibilit√© d'√©voluer au sein du Groupe
Docaposte
!
Softeam
est labellis√© ""
HappyIndex¬Æ AtWork
"" 2022 pour la
5√®me
ann√©e cons√©cutive !
Nos collaborateurs travaillent en ¬´
mode projet
¬ª autour des
Modern DATA Platform
‚òÅ et
technologies Big Data Azure Cloud / On premise
et autre ""playeur"" du march√©. Nous accompagnons de bout en bout nos clients sur des probl√©matiques de
Gouvernance, d‚ÄôInt√©gration, de Visualisation et d‚ÄôIA
.
CE QUE NOUS RECHERCHONS
SOFTEAM Data
recherche un(e)
Data Engineer Cloud Azure
, disposant de solides connaissances techniques.
CE QUE NOUS ATTENDONS DE VOUS
En tant que
Data Engineer Cloud Azure
, vous concevez, mettez en place et administrez
des clusters et des solutions big data
.
Vos missions d√©taill√©es :
A
comprendre le besoin de nos clients
au travers de missions de type : aide aux choix d‚Äôoutils, cadrage des besoins, POC ;
Recueillir et analyser les besoins et proposer une architecture technique
adapt√©e aux cas d‚Äôusage des clients ;
Conduire des projets de
d√©ploiement des Modern Data Platform
(Applications Cloud Native, Migration d‚Äôapplications existantes) et participer √† la mise en ≈ìuvre ;
D√©velopper et maintenir des cas d‚Äôusages clients avec
les outils et les infrastructures Big Data / Cloud Azure. Mod√©liser et analyser des donn√©es dans le Cloud
. Garantir la s√©curit√© / compliance des donn√©es ;
Fournir une expertise technique approfondie
aux √©quipes projets ;
R√©diger
la documentation permettant √† l'IT d'assurer la maintenance.
VOUS ETES
Ing√©nieur(e) de formation
, vous disposez d'une exp√©rience de
3 ans
minimum en tant que
Data Engineer
.
Vous avez un minimum de
4
ann√©es d‚Äôexp√©rience sur des
projets Data et id√©alement au moins une premi√®re exp√©rience sur des projets Cloud Azure
ou √† d√©faut une certification
Azure
avec l‚Äôambition de vous pr√©parer √† d‚Äôautres.
Vous ma√Ætrisez au minimum
un langage de programmation
(Spark, Scala, Python, Java, R) ;
Vous avez une grande aisance dans la
communication orale et √©crite
alli√©e √† un esprit de synth√®se, de la rigueur et un tr√®s bon sens de la formalisation ;
Fournir une expertise technique
approfondie aux √©quipes projets ;
R√©aliser une veille technologique
permanente sur les tendances du march√© et les perspectives concurrentielles.
NOUS VOUS OFFRONS
Des
missions engageantes
aupr√®s des
grands acteurs du march√©
.
Un
management de proximit√©
avec Gilles SALVADOR, Directeur du Centre d'Expertise Data, toujours bienveillant et √† l'√©coute et avec qui vous pourrez
√©changer au quotidien
sur les
enjeux de votre mission
et √©voquer vos
futurs projets
afin que nous puissions vous aider √† les r√©aliser.
La
possibilit√© d‚Äô√©voluer
et de
monter en comp√©tences
gr√¢ce √† des
formations et √† des certifications
aupr√®s de nos clients et de nos consultants, des 12@13, notre Entit√© Softeam Institute, Organisme de formation interne de renomm√© qui d√©livre des formations aupr√®s de nos clients...
QUI SOMMES-NOUS ?
SOFTEAM DATA
est une marque de
DOCAPOSTE
sp√©cialis√©e dans
l'informatique d√©cisionnelle
et les
nouvelles technologies
. Nous apportons notre expertise √† nos clients, principalement
des Grands Comptes
de la place
financi√®re fran√ßaise
, dans des projets de transformation digitale et cognitive.
2000 Softeamien.nes sont d√©di√©.es √† la transformation m√©tier et digitale de nos clients et ont g√©n√©r√©
200 M‚Ç¨ de chiffre d‚Äôaffaires
en 2020.
SOFTEAM SPIRIT
Des
communaut√©s d'expertises
sur les sujets de la
Data
;
De super
nouveaux locaux
qui sont en plus accessibles facilement ;
Une
√©cole de formation
int√©gr√©e ;
Des
√©v√®nements
: des soir√©es avec les consultants, des 12@13... ;
Une entreprise labellis√©e
""Happy at Work""
pour la 5√®me ann√©e cons√©cutive.
N‚Äôattendez plus, rejoignez SOFTEAM et venez nous rencontrer dans nos nouveaux locaux situ√©s √† la D√©fense #DevenezSofteamien !
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Senior Data Engineer,RSight¬Æ,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-at-rsight%C2%AE-3913324068?position=6&pageNum=20&refId=%2FS%2FUEqH%2F4ToPDYrc6skyJQ%3D%3D&trackingId=tY%2FcpQNsIOvXDKVnH0msxA%3D%3D&trk=public_jobs_jserp-result_search-card,"Nous recherchons activement un(e)
Data Engineer confirm√©
, pour le compte de l‚Äôun de nos clients,
une ESN, leader de l‚ÄôIng√©nierie et du Conseil en Technologies
. Vous interviendrez sur des
projets √† forte valeur ajout√©e
d‚Äôune
Leader mondial du secteur de la r√©assurance
.
Responsabilit√©s
Construire, livrer et maintenir les produits de donn√©es (pipelines de donn√©es, services, APIs...).
Collaborer √©troitement avec les √©quipes produits pour d√©velopper de nouvelles fonctionnalit√©s li√©es aux produits, notamment les fonctionnalit√©s li√©es :
Au pipelinage des donn√©es au sein ou entre plusieurs produits.
Aux capacit√©s d
‚Äô
analyse et de data warehousing pour l
‚Äô
exploration des donn√©es, la science des donn√©es et la BI.
Au calcul parall√®le sur de grands volumes de donn√©es.
D√©velopper des artefacts ou fonctionnalit√©s de donn√©es (pipelines de donn√©es, services de donn√©es, APIs...) en suivant des mod√®les de pointe (architecture Medaillon, gitflow).
Conseiller sur l
‚Äô
architecture des flux de donn√©es de bout en bout.
Collaborer avec divers intervenants (propri√©taires de produits, propri√©taires de solutions, analystes de solutions de donn√©es, d√©veloppeurs, chefs techniques, architectes) pour livrer des artefacts de donn√©es dans un esprit d
‚Äô
√©quipe.
Comp√©tences requises
Python, SQL, Databricks, Palantir Foundry, DataViz : Expert
MSDevOps, Jenkins, Artifactory, Container Registry : Confirm√©
Technique de parall√©lisation, programmation distribu√©e : Confirm√©
Delta Lake, architecture Medaillon, blobStorage, fileshare : Confirm√©
Comp√©tences humaines
Orientation vers la r√©solution de probl√®mes avec une forte pens√©e analytique.
Autonomie et rigueur dans la mani√®re d
‚Äô
aborder les d√©fis techniques.
Aptitude √† conseiller sur l
‚Äô
architecture des flux de donn√©es.
Capacit√© √† collaborer avec divers intervenants pour atteindre les objectifs dans un esprit d
‚Äô
√©quipe.
B√©n√©fices
Opportunit√© de travailler sur des projects d
‚Äô
envergure.
Un processus de recrutement court, un accompagnement personnalis√©, une √©volution qui s
‚Äô
adapte √† votre trajectoire de carri√®re.
En plus de votre quotidien li√© √† votre mission, vous pourrez entreprendre, √™tre form√©, passer des certifications.
Un environnement de collaboration positif o√π chacun est valoris√© et int√©gr√©.
Une culture forte et bienveillante, et une grande place laiss√©e √† la libert√©.
La diversit√© et l
‚Äô
envergure des projets.
Une approche pragmatique, qui r√©pond aux vrais enjeux des entreprises.
Une √©quipe d‚Äôing√©nieurs anim√©e par l‚Äôinnovation dans un environnement collaboratif h√©t√©rog√®ne et inclusif.
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps'], 'FrSoftSkills': ['R√©solution de probl√®mes', 'Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Confirm√©'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,MindPal,"Marseille, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-at-mindpal-3914442063?position=7&pageNum=20&refId=%2FS%2FUEqH%2F4ToPDYrc6skyJQ%3D%3D&trackingId=spIKVJhzAUv59XOxHP8m1w%3D%3D&trk=public_jobs_jserp-result_search-card,"We are looking for
Data Engineer!
Responsibilities
Designing, creating, and maintaining data processing systems
Analyzing and optimizing data processing workflows
Collaborating with the team to ensure data quality and efficiency
Testing and implementing new solutions
Requirements
At least 2 years of experience in designing and creating data processing systems
Proficiency in tools and programming languages related to data engineering (e.g. Hadoop, Spark, Scala, Python)
Excellent knowledge of databases and SQL language
Ability to work in a team and communicate effectively with other departments
Communicative English skills
Experience with AWS/AWS Glue is a plus
We Offer
B2B contract
Full-time job
Remote work and flexible hours
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
DATA Engineer GCP F/H,SOFTEAM,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-gcp-f-h-at-softeam-3852605158?position=8&pageNum=20&refId=%2FS%2FUEqH%2F4ToPDYrc6skyJQ%3D%3D&trackingId=WcFAXjIUmdRk9lGYaUhJog%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous √©voluez dans le domaine de la
Data
et souhaitez int√©grer un leader de la transformation num√©rique sp√©cialis√© dans les secteurs de la
Banque, du Luxe, de l'Assurance, de la Finance, de l'Energie
et la possibilit√© d'√©voluer au sein du Groupe
Docaposte
!
Softeam
est labellis√© ""
HappyIndex¬Æ AtWork
"" 2022 pour la
5√®me
ann√©e cons√©cutive !
Nos collaborateurs travaillent en ¬´
mode projet
¬ª autour des
Modern DATA Platform
‚òÅ et
technologies Big Data Azure Cloud / On premise
et autre ""playeur"" du march√©. Nous accompagnons de bout en bout nos clients sur des probl√©matiques de
Gouvernance, d‚ÄôInt√©gration, de Visualisation et d‚ÄôIA
.
CE QUE NOUS RECHERCHONS
SOFTEAM Data
recherche un(e)
Data Engineer Cloud GCP
, disposant de solides connaissances techniques.
CE QUE NOUS ATTENDONS DE VOUS
En tant que
Data Engineer Cloud GCP
, vous concevez, mettez en place et administrez
des clusters et des solutions big data
.
Vos missions d√©taill√©es :
A
comprendre le besoin de nos clients
au travers de missions de type : aide aux choix d‚Äôoutils, cadrage des besoins, POC ;
Recueillir et analyser les besoins et proposer une architecture technique
adapt√©e aux cas d‚Äôusage des clients ;
Conduire des projets de
d√©ploiement des Modern Data Platform
(Applications Cloud Native, Migration d‚Äôapplications existantes) et participer √† la mise en ≈ìuvre ;
D√©velopper et maintenir des cas d‚Äôusages clients avec
les outils et les infrastructures Big Data / Cloud GCP. Mod√©liser et analyser des donn√©es dans le Cloud
. Garantir la s√©curit√© / compliance des donn√©es ;
Fournir une expertise technique approfondie
aux √©quipes projets ;
R√©diger
la documentation permettant √† l'IT d'assurer la maintenance.
VOUS ETES
Ing√©nieur(e) de formation
, vous disposez d'une exp√©rience de
3 ans
minimum en tant que
Data Engineer
.
Vous avez un minimum de
4
ann√©es d‚Äôexp√©rience sur des
projets Data et id√©alement au moins une premi√®re exp√©rience sur des projets Cloud GCP
(Compute, Stockage), ou √† d√©faut une certification GCP avec l‚Äôambition de vous pr√©parer √† d‚Äôautres.
Vous ma√Ætrisez au minimum
un langage de programmation
(Spark, Scala, Python, Java, R) ;
Vous avez une grande aisance dans la
communication orale et √©crite
alli√©e √† un esprit de synth√®se, de la rigueur et un tr√®s bon sens de la formalisation ;
Fournir une expertise technique
approfondie aux √©quipes projets ;
R√©aliser une veille technologique
permanente sur les tendances du march√© et les perspectives concurrentielles.
NOUS VOUS OFFRONS
Des
missions engageantes
aupr√®s des
grands acteurs du march√©
.
Un
management de proximit√©
avec Gilles SALVADOR, Directeur du Centre d'Expertise Data, toujours bienveillant et √† l'√©coute et avec qui vous pourrez
√©changer au quotidien
sur les
enjeux de votre mission
et √©voquer vos
futurs projets
afin que nous puissions vous aider √† les r√©aliser.
La
possibilit√© d‚Äô√©voluer
et de
monter en comp√©tences
gr√¢ce √† des
formations et √† des certifications
aupr√®s de nos clients et de nos consultants, des 12@13, notre Entit√© Softeam Institute, Organisme de formation interne de renomm√© qui d√©livre des formations aupr√®s de nos clients...
QUI SOMMES-NOUS ?
SOFTEAM DATA
est une marque de
DOCAPOSTE
sp√©cialis√©e dans
l'informatique d√©cisionnelle
et les
nouvelles technologies
. Nous apportons notre expertise √† nos clients, principalement
des Grands Comptes
de la place
financi√®re fran√ßaise
, dans des projets de transformation digitale et cognitive.
2000 Softeamien.nes sont d√©di√©.es √† la transformation m√©tier et digitale de nos clients et ont g√©n√©r√©
200 M‚Ç¨ de chiffre d‚Äôaffaires
en 2020.
SOFTEAM SPIRIT
Des
communaut√©s d'expertises
sur les sujets de la
Data
;
De super
nouveaux locaux
qui sont en plus accessibles facilement ;
Une
√©cole de formation
int√©gr√©e ;
Des
√©v√®nements
: des soir√©es avec les consultants, des 12@13... ;
Une entreprise labellis√©e
""Happy at Work""
pour la 5√®me ann√©e cons√©cutive.
N‚Äôattendez plus, rejoignez SOFTEAM et venez nous rencontrer dans nos nouveaux locaux situ√©s √† la D√©fense #DevenezSofteamien !
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Ing√©nieur Data Talend (F/H),Thales,"V√©lizy-Villacoublay, √éle-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-talend-f-h-at-thales-3890948785?position=9&pageNum=20&refId=%2FS%2FUEqH%2F4ToPDYrc6skyJQ%3D%3D&trackingId=pENNDDIYneLegG1YTnqB5g%3D%3D&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?
Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr√©sents sur tous les continents. Le Groupe investit dans les innovations du num√©rique et de la ¬´ deep tech ¬ª ‚Äì big data, intelligence artificielle, connectivit√©, cybers√©curit√© et quantique ‚Äì pour construire un avenir de confiance, essentiel au d√©veloppement de nos soci√©t√©s, en pla√ßant l‚Äôhumain au c≈ìur des d√©cisions.
Thales propose des solutions, services et produits qui aident ses clients ‚Äì entreprises, organisations, Etats ‚Äì dans cinq grands march√©s vitaux pour le fonctionnement de nos soci√©t√©s : identit√© et s√©curit√© num√©riques, d√©fense, a√©ronautique, espace, et transport.
QUI ETES-VOUS ?
Dipl√¥m√© d‚Äôun Bac+5 en √©cole d‚Äôing√©nieur ou √©quivalent universitaire avec une sp√©cialisation en informatique, vous avez au moins 3 ans d'exp√©rience dans les technologies Big Data.
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
En tant que Data Engineer, vous jouerez un r√¥le cl√© dans la conception, le d√©veloppement et la maintenance de notre infrastructure de donn√©es, ainsi que dans la transformation et la gestion des flux de donn√©es.
VOS MISSIONS :
‚Ä¢ Concevoir, d√©velopper et d√©ployer des solutions Big Data en utilisant les technologies Talend.
‚Ä¢ Mettre en place des pipelines de donn√©es performants pour l'ingestion, le traitement et le stockage des donn√©es massives.
‚Ä¢ Collaborer √©troitement avec les √©quipes m√©tier pour comprendre leurs besoins en mati√®re d'analyse de donn√©es et proposer des solutions adapt√©es.
‚Ä¢ Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn√©es.
‚Ä¢ Assurer la qualit√© et la fiabilit√© des donn√©es trait√©es, en mettant en place des processus de validation et de nettoyage.
‚Ä¢ Identifier et r√©soudre les probl√®mes li√©s √† l'infrastructure Big Data et proposer des am√©liorations.
‚Ä¢ Travailler en √©troite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents √† partir des donn√©es.
Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Tech Lead Data Engineer,AXA en France,"Hauts-de-Seine, √éle-de-France, France",https://fr.linkedin.com/jobs/view/tech-lead-data-engineer-at-axa-en-france-3905641945?position=10&pageNum=20&refId=%2FS%2FUEqH%2F4ToPDYrc6skyJQ%3D%3D&trackingId=8BK0UmBOqb%2Be1Wnkmtu6Tw%3D%3D&trk=public_jobs_jserp-result_search-card,"Environnement
En tant que
Tech Lead Data Engineer F/H
, vous allez contribuer directement aux projets des directions m√©tier (ex : fraude sant√©, multi√©quipements, pricing IARD, optimisation du lead management, fragilit√© auto, ‚Ä¶) d‚ÄôAXA France et √† la construction du socle technique Big Data.
Vous allez int√©grer une √©quipe d'une dizaine de personne compos√©e de Data Engineer et des Tech Lead travaillant en mode Feature Team au sein des tribus m√©tier de la Direction Transformation Digital Tech et DATA (DT2).
La Direction Transfo. & Tech. d'AXA France en quelques mots :
Une organisation agile en feature teams : tribus, guildes, squads
Des projets sur des applications innovantes √† fort trafic (web, mobile‚Ä¶)
Des m√©thodologies craft (TDD, BDD, clean code, code review‚Ä¶) et DevOps
Une communaut√© de partage de bonnes pratiques (BBL, dojo, meetup, conf‚Ä¶)
Votre r√¥le et vos missions
Vous aurez pour missions principales de d√©velopper les projets Big Data demand√©s par le m√©tier, et notamment :
D‚Äôaccompagner techniquement les Data Engineer de l‚Äô√©quipe (coaching, code review, pair programming‚Ä¶)
Passer de la donn√©e brute √† de la donn√©e exploitable, expos√©e sous forme de tables requ√™tables dans le datalake
Consolider ces donn√©es au fur et √† mesure de leur alimentation r√©currente dans le data lake
Les exploiter pour atteindre la finalit√© business (exposition de business view, r√©int√©gration des r√©sultats dans le SI, service de scoring, ‚Ä¶)
De travailler √† la cr√©ation du socle technique Big Data et industrialiser le cycle de d√©veloppement de l'√©quipe
De mettre en place et de garantir le respect dans la dur√©e d'un processus qualit√© sur l'ensemble du cycle de DEV (documents, tests unitaires / int√©gration / fonctionnels, commentaires, versionning, etc.)
Votre profil
D'une formation sup√©rieure en informatique ou scientifique (Master ou Dipl√¥me d'ing√©nieur), vous justifiez de plusieurs exp√©riences significatives (+ de 7 ans)
sur du d√©veloppement big data, en particulier sur du PySpark.
Comp√©tences techniques :
Connaissances avanc√©es en d√©veloppement en
PySpark (Spark avec le langage Python)
Maitrise de l'environnement
Microsoft Azure
Connaissances avanc√©es d'outils de BI comme
PowerBI
Comp√©tences transverses :
Capacit√© √† interagir avec des parties prenantes diverses : Business analyst, Architectes, M√©tier
Exp√©rience en mode de delivery Agile (Scrum, Kanban, etc...)
Driver et accompagner des Data Engineer sur le plan op√©rationnel
Et Id√©alement :
Avoir une exp√©rience en tant que lead
Des Connaissances sur Azure DevOps, Azure Pipeline, GIT, JIRA
Maitrise des Traitements Big Data en mode Streaming avec Kafka
Maitrise des Bases de donn√©es relationnelles et NoSQL
Une exp√©rience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory
Mais pourquoi AXA France ?
Nous sommes persuad√©s que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs ! Les avantages que nous proposons √† nos salari√©s sont nombreux.
Nous choisir, c‚Äôest b√©n√©ficier par exemple :
D‚Äôun package de r√©mun√©ration complet comprenant un salaire fixe, un compl√©ment de r√©mun√©ration variable, des primes, de la participation et de l‚Äôint√©ressement, la possibilit√© d‚Äôacqu√©rir des actions AXA, ou encore des solutions d‚Äô√©pargne avantageuses ;
Equilibre vie Pro / Perso. : D‚Äôun cadre de travail flexible jusqu‚Äô√† 3 jours de t√©l√©travail possible par semaine, des tickets restaurant pour les jours t√©l√©travaill√©s ou encore une participation √† l‚Äôachat d‚Äôun √©cran ou fauteuil ergonomique ;
D‚Äôune politique visant √† concilier vie personnelle et vie professionnelle avec 28 jours de cong√©s pay√©s, entre 14 et 16 RTT selon les ann√©es, des formules de travail √† temps partiel ou encore des jours d‚Äôabsence r√©mun√©r√©es pour la rentr√©e scolaire ou un d√©m√©nagement par exemple ;
De la possibilit√© de s‚Äôengager pour une cause qui vous tient √† c≈ìur gr√¢ce √† nos associations telles que AXA Atout C≈ìur, AXA Comp√©tences Solidaires ou encore AXA Pr√©vention ;
Et bien plus encore ! Perspectives de d√©veloppement des comp√©tences et de carri√®res immenses, CE, conciergerie, offres privil√®ges, soutien en cas d‚Äô√©preuve personnelle‚Ä¶On s‚Äôarr√™te l√†, la liste est longue
Qui sommes nous ?
AXA est un des leaders de l‚Äôassurance et de la gestion d‚Äôactifs dans le monde.
Nous aidons nos 108 millions de clients √† traverser les petites et grandes difficult√©s de la vie.
Chaque jour, nous agissons ensemble pour inventer la meilleure mani√®re de les prot√©ger et voulons donner √† chacun les moyens de vivre une vie meilleure.
Un challenge qui donne le sourire et envie de se lever le matin !
Chez AXA, nous sommes persuad√©s que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs. C‚Äôest pour cette raison que nous menons une politique RH engag√©e qui favorise la diversit√©, qui pr√©serve l‚Äô√©quilibre vie priv√©e-vie professionnelle et acc√©l√®re le d√©veloppement des comp√©tences et des carri√®res.
Ainsi, en rejoignant AXA France vous travaillerez dans une entreprise responsable, offrant une v√©ritable culture d‚Äôexpertise, acc√©l√©rant le d√©veloppement des comp√©tences de chacun et proposant une r√©mun√©ration attractive.
Pourquoi nous rejoindre ?
Vous √™tes porteur d‚Äôid√©es et d‚Äôinitiatives innovantes ? Vous proposez des solutions et √™tes au service du client ? Faites partie de notre grande famille en rejoignant
Un leader mondial offrant des opportunit√©s de carri√®res int√©ressantes
Une entreprise qui donne une place de choix √† l‚Äôinnovation, √† l‚Äôinitiative et aux actions solidaires (notamment via l‚Äôassociation AXA Atout C≈ìur)
Un environnement inclusif √† tous les niveaux (mixit√©, handicap, initiatives pour favoriser l‚Äôinsertion des jeunes, orientation sexuelle, etc.)
Un acc√®s √† de multiples avantages (cong√©s, temps partiel, t√©l√©travail, etc.)
Un cadre stimulant, qui permet de rencontrer des collaborateurs performants et d‚Äôenrichir ses comp√©tences
Victime ou t√©moin, en cas de discrimination, vous pouvez adresser vos signalements et/ou alertes discrimination √† alerte.discrimination.harcelement@axa.fr
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['JIRA', 'Teams'], 'Other': ['DevOps', 'Big Data'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['3', '3'], 'Level': [], 'Experience': ['a', 'n', 's', '7', '7', '7']}"
Data Engineer (Cloud Azure) - Confirm√© F/H,VISEO,"Boulogne-Billancourt, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-cloud-azure-confirm%C3%A9-f-h-at-viseo-3904219460?position=1&pageNum=22&refId=xJ%2FHB6j7MCr9%2BdBcMIDMwQ%3D%3D&trackingId=zf%2FExEFZwQw2YJkORJaEPA%3D%3D&trk=public_jobs_jserp-result_search-card,"Rejoignez
VISEO
et explorez un univers de possibilit√©s o√π
l'Humain
, le
Collectif
et le
Challenge
sont au c≈ìur de notre ADN.
Qui √™tes-vous ?
Si pour vous √™tre
Data Engineer Cloud Azure Confirm√© F/H
, c'est :
Faire partie d'une communaut√© d'experts en ing√©nierie des donn√©es et en solutions cloud ;
Concevoir, construire et maintenir des pipelines de donn√©es robustes et √©volutifs sur Microsoft Azure ;
Ma√Ætriser les services Azure tels que Azure Data Factory, Azure Data Lake, Azure SQL Database, et Azure Synapse Analytics ;
D√©couvrir les nouveaut√©s tel que Microsoft Fabric
Appliquer les meilleures pratiques en mati√®re de s√©curit√©, de qualit√© des donn√©es et de gouvernance de l'information ;
√ätre familiaris√© avec les technologies de transformation de donn√©es √† grande √©chelle (Spark, Azure Databricks) ;
Collaborer √©troitement avec les √©quipes BI et analytics pour transformer les donn√©es en insights pr√©cieux...
Alors, vous √™tes le talent que nous recherchons !
Si vous avez une solide exp√©rience en tant que
Data Engineer
, une passion pour le cloud
Azure
et que vous √™tes pr√™t √† √©largir vos comp√©tences et √† avancer dans votre carri√®re, c'est le moment parfait pour nous rejoindre.
Ce que nous allons faire ensemble ?
D√©couvrez comment votre quotidien sera transform√© en rejoignant l‚Äô√©quipe projet de Nabil. Rattach√© √† notre agence de Boulogne-Billancourt, vous pourrez :
Accompagner et conseiller le client dans son adoption des Modern Data Platform dans Azure (Etude d‚Äôarchitecture, pr√©paration des DAT, FinOps, DevOps) ;
Concevoir des architectures Cloud Data exploitant efficacement les services de donn√©es manag√©s d'Azure ;
Conduire des projets de d√©ploiement des Modern Data Platform (Applications Cloud Native, Migration d‚Äôapplications existantes) et participer √† la mise en ≈ìuvre ;
Etablir des relations de confiance avec les d√©cisionnaires techniques et m√©tiers afin de favoriser l‚Äôadoption du Cloud Microsoft Azure √† long terme au sein de l‚Äôentreprise ;
R√©aliser une veille technologique permanente sur les tendances du march√© et les perspectives concurrentielles ;
Partager votre expertise et apprendre continuellement au sein d'une √©quipe anim√©e par l'innovation.
Ce que nous avons √† vous offrir ?
Des formations, des certifications Azure et un syst√®me de mentoring ;
Un environnement stimulant, souple et agile pour des parcours sans limite ;
Un engagement fort pour l‚Äôenvironnement, la soci√©t√©, l‚Äô√©galit√© et l‚Äôinclusion‚ÄØ: la plateforme Vendredi, atelier fresque du climat, Caf√© Joyeux, l'institut Imagine, Yumaincap...
Une organisation flexible pour un bon √©quilibre vie pro / vie perso.
Ce qui nous diff√©rencie ?
Une communaut√© engag√©e d'experts en data et cloud Azure : des talks toutes les semaines, la participation √† des √©v√®nements techniques (ateliers, rencontres d‚Äôexperts, Tech An Hour, BBL, Rex, Sponsoring‚Ä¶) ;
Des dispositifs collectifs d‚Äô√©pargne salariale‚ÄØ(PEE et PERECO) et la possibilit√© de devenir actionnaire VISEO ;
Un partenariat privil√©gi√© avec Microsoft (Gold Partner) vous donnant acc√®s aux derni√®res innovations et technologies Azure.
Envie de nous rejoindre ? Contactez-nous et faites partie du #VISEOspirit
En tant qu'employeur, VISEO promeut activement la diversit√© et l'inclusion.
√Ä propos de VISEO
Avec plus de 3 000 collaborateurs r√©partis sur 5 continents, VISEO allie agilit√© et expertise technique pour faire du digital un moteur essentiel de comp√©titivit√© et de performance.
#PositiveDigitalMakers
GDPR MESSAGE:
Our privacy policy has been updated to comply with the new regulations. We invite you to consult it by clicking here: https://www.viseo.com/fr/politique-de-confidentialite. The VISEO Group uses the data collected as part of your application to assess your suitability for the job in question. We use the Jazz HR tool to help us in our recruitment process. This tool complies with current regulations on the protection of personal data. The tool is hosted in the United States and is PrivacyShield certified for HR data. In all cases, we may keep your file for 5 years so that we can contact you again if another position matches your profile. You may, of course, object to this. To find out more about how your data is used and how you can exercise your rights, please consult our privacy policy https://www.viseo.com/fr/politique-de-confidentialite.
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': ['Confirm√©'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Lead Data & Cloud Engineer (H/F),fifty-five,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/lead-data-cloud-engineer-h-f-at-fifty-five-3910829083?position=2&pageNum=22&refId=xJ%2FHB6j7MCr9%2BdBcMIDMwQ%3D%3D&trackingId=8bM2m%2FNdFrusnjgAx55njQ%3D%3D&trk=public_jobs_jserp-result_search-card,"fifty-five est une data-company d'un genre nouveau qui aide les marques √† exploiter les donn√©es pour am√©liorer le marketing, les m√©dias et l'exp√©rience client gr√¢ce √† une combinaison de services de conseil et de technologie sp√©cialis√©s.
En tant que pilier data et marketing du Brandtech Group, nous offrons des services qui combinent le conseil en strat√©gie, les services de cloud, le conseil en m√©dia et l'exp√©rience client.
fifty-five, c'est plus de 400 experts du num√©rique. Des digital consultants, des sp√©cialistes du tracking et du m√©dia, des ing√©nieurs et des data scientists, travaillent tous en √©troite collaboration pour fournir des conseils marketing de haut niveau et une assistance technique aux marques, dans tout type d'industrie, partout dans le monde.
Partenaire des annonceurs de la collecte √† l'activation et l'exploitation des donn√©es, nous aidons les organisations √† devenir de v√©ritables entit√©s omnicanales ma√Ætrisant l'efficacit√© de leur √©cosyst√®me digital et ses synergies avec le monde physique.
Bas√© √† Paris, nous op√©rons sur 3 fuseaux horaires depuis nos 10 bureaux, situ√©s √† Paris, Londres, Gen√®ve, Milan, Shanghai, Hong Kong, Shenzhen, Taipei, Singapour et New York. fifty-five attache une importance particuli√®re au bien-√™tre de ses collaborateurs, ce qui lui a permis de figurer dans le classement Best Workplaces France en 2018.
Contexte :
L'√©quipe d'ing√©nierie d√©veloppe et met en oeuvre les solutions techniques permettant la r√©alisation de pipelines de donn√©es et de datalake pour nos clients : r√©cup√©ration de datas sur de multiples sources de donn√©es (APIs, files, etc.), data cleaning, data processing, automation et monitoring de l'ensemble. L'√©quipe s'appuie sur des technologies r√©centes (docker, kubernetes, terraform, notebooks, etc.) et met en place ses projets dans les diff√©rents clouds du march√© (GCP, Azure, AWS...).
Mission :
Nous sommes √† la recherche d'une personne capable de r√©aliser des projets techniques pour r√©pondre aux besoins de nos clients (par exemple: syst√®me de recommandations de produits, d√©tection d'anomalies, ranking). Les activit√©s vont du chiffrage et du sizing technique √† la mise en ≈ìuvre des architectures, en passant par la revue des sp√©cifications fonctionnelles et la production de code.
Le Data & Cloud Lead g√®re une √©quipe d'environ 4 Data & Cloud Engineer qu'il accompagne au quotidien (suivi des t√¢ches, validation des livrables, code review, suivi de la formation, etc.). Le Data & Cloud Lead intervient √©galement directement sur les missions, principalement dans les discussions avec nos clients (recueil des contraintes techniques, validation d'architecture, etc.) mais aussi dans le delivery (d√©ploiement d'infrastructure participation au code). Il sera √©galement amen√© √† participer √† la R&D et √† accompagner les √©quipes transverses dans la mise en place d'outils de travail internes (librairies pour les data scientists, environnement Notebooks pour les data analysts et data scientists, d√©veloppement de frameworks sur diff√©rents cloud providers, etc.).
Passionn√©.e par la data et le cloud ? Envie de partager tes connaissances et faire grandir des profils plus juniors ? Envie de collaborer avec des profils experts, aussi bien c√¥t√© technique (Data, Cloud, DevOps, Data Science, etc.) que business (digital marketing, analytics, media, CRM, CDP, etc.) ? N'h√©site plus et postule !
Comp√©tences et exp√©riences :
5 ans d'exp√©rience avec une premi√®re exp√©rience professionnelle en tant que Lead et/ou Architecte
Ma√Ætrise des architectures data
Ma√Ætrise de Python et SQL
Ma√Ætrise des environnements Cloud. Certifi√© sur GCP, Azure ou AWS
Ma√Ætrise d'au moins un data warehouse (BigQuery, Snowflake, etc)
Ma√Ætrise des concepts li√©s aux APIs (OAuth, REST, etc.)
Bonne connaissance de Docker
A l'aise avec les notions d'Infrastructure as Code (Terraform)
A l'aise avec les pratiques GitOps et les concepts autour du CI/CD
Connaissance autour des Notebooks (Jupyter)
La ma√Ætrise d'un orchestrateur,comme Apache Airflow, est un plus
Esprit d'√©quipe (collaborer aux tests unitaires, revue de code, partage de code, sprints)
Bon niveau en fran√ßais et en anglais
A d√©j√† travaill√© en mode projet avec des interlocuteurs vari√©s (consultant, data analyst, data scientist), id√©alement client facing
Une exp√©rience en marketing digital est un plus
Nous proposons :
un bureau au centre de Paris avec terrasse et jardin
un environnement multiculturel avec des collaborateurs aux nationalit√©s multiples (France, Royaume-Uni, Etats-Unis, Chine, Tunisie, Italie et plus)
des projets avec nos bureaux √† Londres, Hong Kong, New York, Shanghai, Gen√®ve, Shenzhen et Taipei
des TGIF et supers soir√©es
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Apache Airflow'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Junior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Ing√©nieur H/F,Alteca,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-ing%C3%A9nieur-h-f-at-alteca-3846531570?position=3&pageNum=22&refId=xJ%2FHB6j7MCr9%2BdBcMIDMwQ%3D%3D&trackingId=k2G88SleWl5Pfdf0F8CVuA%3D%3D&trk=public_jobs_jserp-result_search-card,"TRAVAILLER CHEZ ALTECA
Chez Alteca le management de proximit√©, le bien-√™tre et l'√©volution de nos collaborateurs sont des priorit√©s qui nous permettent, chaque jour, de proposer la meilleure expertise possible √† nos clients.
Et c'est gr√¢ce √† ces convictions, que nous sommes aujourd'hui r√©f√©renc√©s aupr√®s de partenaires grands comptes dans les secteurs de la Banque, de l'Assurance ou encore de la Distribution
(Si vous souhaitez en savoir plus sur Alteca, RDV sur l'onglet ""Qui sommes-nous ?"").
________________________________
>
En tant que
Data Ing√©nieur (H/F),
tu seras rattach√©(e) au
P√¥le Data
de notre Agence toulousaine
.
Ton Manager sera Christian COT (Responsable du P√¥le) ou l'un de ses R√©f√©rent technique.
Interlocuteur privil√©gi√©
, il assurera ton
int√©gration
durant tes trois premiers mois dans l'entreprise, ta mont√©e en comp√©tences, tes
points de suivi
tout au long de tes missions et tes
Entretiens Annuels
.
>
Tu auras √©galement acc√®s √† une
communaut√© technique d'experts
gr√¢ce aux nombreux
Webinar
organis√©s tout au long de l'ann√©e, tu pourras aussi participer aux
projets de notre Centre de R&D
ou encore assister aux
MID'INNO
(pr√©sentations de nos collaborateurs sur des th√©matiques donn√©es comme la Green Tech, l'IA...).
>
Rejoindre ALTECA c'est aussi rejoindre une entreprise engag√©e sur la RSE (labellis√©e
Ecovadis Silver 2022
), pour le bien-√™tre de ses salari√©s (labellis√©e
HappyAtWork
pour la 5√®me ann√©e cons√©cutive), et dans la formation de ses stagiaires et alternants (labellis√©e
HappyTrainees
pour la 4√®me ann√©e cons√©cutive).
TES MISSIONS
En coordination avec les √©quipes d'un de nos clients grands comptes, tes missions seront les suivantes
:
Concevoir les Data Models et Data Pipelines
: cartographier et documenter les types de donn√©es et leur usage, concevoir les solutions, les processus, √©laborer la strat√©gie de validation des solutions
Concevoir et sp√©cifier l‚Äôinfrastructure
: sp√©cifier les solutions d‚Äôacquisition en fonction des flux, les solutions de traitement adapt√©es aux mod√®les, estimer les besoins et co√ªts, sp√©cifier les solutions de gestion des donn√©es
Accompagner et guider les √©quipes : pr√©sentation des √©tudes et solutions, accompagnement dans les expertises, les parcours de formation‚Ä¶
Mettre en ≈ìuvre l‚Äôinfrastructure, d√©velopper et maintenir
les services de traitement de donn√©es, supervision / monitoring des infrastructures
La majeure partie des projets de nos clients sont sur des
environnements techniques r√©cents
: Python, FastAPI (ou Django / Flask) et des ORM type SQLAlchemy, Pandas, Numpy, Xarray, ETL, Airflow, BDD (timescaleDB, IngluxDB, MongoDB, Elastic, NoSQL Redis, PostgreSQL), Kafka, Prefect, Nifi, Pandas, Numpy, Xarray, Dask) Docker, Kubernetes, Gitlab et en m√©thodologie Agile Scrum.
Ton profil :
dipl√¥m√©(e) d'un Bac+5 dans le domaine de la Data (Universit√© ou Ecole d'Ing√©nieur), tu as au moins 7 ans d'exp√©rience sur un poste similaire et tu sais √©voluer en environnement Agile. Tu poss√®des √©galement une exp√©rience dans le d√©veloppement de logiciel (Python) dans une architecture orient√©e microservices et API
Ta personnalit√© :
tu es une personne organis√©e et rigoureuse. Tu disposes d'un bon relationnel et tu aimes le travail en √©quipe. Tu as la capacit√© de vulgarisation et de d√©monstration. Tu appr√©cies et contribues √† d√©velopper un contexte de travail bienveillant et qui favorise le partage de connaissances, l‚Äôaccompagnement au changement. Enfin, tu et motiv√© pour les grands projets d‚Äôinfrastructure (moyen / long terme)
Type de contrat propos√© :
temps plein |
Niveau de poste :
confirm√©
________________________________
Process de recrutement :
ŒΩ
Malivanh te contactera pour un premier √©change t√©l√©phonique, puis elle te recevra dans le cadre d'un
entretien RH
.
ŒΩ
Si cet entretien est valid√©, tu rencontreras alors Christophe, le Responsable du P√¥le Digital, pour un
entretien technique.
________________________________
NOS AVANTAGES
Transport pris en charge √† 75% | Tickets resto pris en charge √† 60% | Mutuelle prise en charge √† 60%
10 jours de RTT en plus des 25 jours de CP | Mode de travail : hybride | Acc√®s au CSE (billetterie, voyages...)
Des parcours de formations personnalis√©s (75% de nos collaborateurs ont suivis au moins 1 formation en 2022)
En tant que signataire de la charte de diversit√© en entreprise, Alteca favorise un environnement de travail inclusif et respectueux de tous. A comp√©tences √©gales, tous nos postes sont ouverts aux personnes en situation de handicap.
Votre chance c'est votre talent, la n√¥tre c'est de le d√©velopper : rejoignez-nous !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB'], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Hybride', 'Temps plein', 'Confirm√©'], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '7', '7', '7']}"
Senior Data Engineer,DCube,"Boulogne-Billancourt, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-at-dcube-3892422399?position=4&pageNum=22&refId=xJ%2FHB6j7MCr9%2BdBcMIDMwQ%3D%3D&trackingId=UesBbmydvpha%2B8AyqbhxKQ%3D%3D&trk=public_jobs_jserp-result_search-card,"La Data, c‚Äôest votre dada, vous √™tes c√¢bl√©(e) comme √ßa : vous aimez collecter et traiter des donn√©es pour les mettre √† disposition des autres.
Votre mission, si vous l'acceptez :
Comprendre et analyser des besoins m√©tiers.
Concevoir et r√©aliser des processus optimis√©s d‚Äôingestion et de traitement de donn√©es dans des architectures lakehouse et data mesh.
Organiser et urbaniser le stockage des donn√©es.
Industrialiser des mod√®les de Machine Learning.
Exposer des donn√©es via le d√©veloppement d‚ÄôAPIs.
R√©aliser des tests de validation des traitements.
√ätre consultant(e) chez dcube :
Nos consultant.e.s sont toutes et tous en CDI, ils interviennent en mission chez nos clients, mais ils ont aussi le choix de travailler depuis les locaux de dcube ou depuis chez eux en t√©l√©travail ponctuel.
Ils travaillent parfois √† plusieurs sur un projet, parfois en solo, mais ils peuvent toujours compter sur le soutien de leur manager r√©f√©rent et de leur lead practice pour √©changer sur des sujets techniques et/ou humains !
Nos clients sont majoritairement des PME, mais 30% d'entre eux sont des grands groupes. Nous proposons √† nos consultant.e.s des missions dans toutes sortes de secteurs : finance, assurances, BTP, m√©dias, services...
Nos consultant.e.s sont fier.e.s de leur apporter leur expertise pour r√©pondre √† leurs probl√©matiques techniques et m√©tiers en leur proposant des solutions sur mesure.
Vous seriez parfait(e) pour rejoindre nos √©quipes si :
Vous √™tes ceinture noire en Data Engineering avec une exp√©rience d‚Äôau moins 5 ans.
Vous √™tes rod√©(e) √† la mise en place de pipelines de donn√©es en mode batch et/ou streaming autour des technologies Snowflake, Databricks, Microsoft Fabrics ou Azure Synapse Analytics, DBT, Azure.
Vous avez un peu travaill√© sur des architectures lakehouse et/ou data mesh.
Vous ma√Ætrisez les principes de mod√©lisation Data Vault et sch√©ma en √©toile.
Quand votre grand-m√®re vous demande quel est votre m√©tier, pour faire simple, vous r√©pondez que vous √™tes facilitateur(trice) de la vie des gens. Vous aimez rendre service en accompagnant les clients dans leur transformation, en leur apportant de la valeur et en les aidant √† r√©soudre leurs probl√®mes gr√¢ce √† votre savoir-faire technologique.
Bonus :
Curieux(se) et gourmand(e), vous vous enfilez de grosses tartines d‚ÄôAzure au petit d√©j.
Vous √™tes une star du NoSQL, Machine Learning ou d√©veloppement d‚ÄôAPIs.
Les cubes de Power BI n'ont pas de secrets pour vous.
Pourquoi choisir dcube ?
Notre vision :
dcube rassemble des femmes et des hommes de valeur, engag√©s avec leurs partenaires, pour partager une exp√©rience humaine et technique enrichissante.
Quelques avantages :
R√©mun√©ration √† partir de 50k.
T√©l√©travail hybride et flexible.
Un accompagnement tout au long de votre carri√®re par un r√©f√©rent technique et un manager d√©di√© hyper sympas.
Une mont√©e en comp√©tence continue avec le financement de nombreuses formations et certifications, ainsi que la possibilit√© d‚Äô√©changer entre experts sur vos sujets techniques de pr√©dilection lors de nos dcube learning.
L‚Äôorganisation d‚Äô√©v√©nements internes qui rassemblent (Afterworks, Meetups, Webinars, etc.)
Un ordinateur portable et un package t√©l√©travail pour √©quiper votre bureau.
Votre pass Navigo pris en charge √† 100%.
Une mutuelle r√©active et g√©n√©reuse (Alan) et une carte ticket restaurant (Swile).
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': ['Hybride'], 'TypeContract': ['CDI'], 'Salary': ['100'], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Engineer Cloud - Azure Confirm√© F/H,VISEO,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-cloud-azure-confirm%C3%A9-f-h-at-viseo-3904216858?position=5&pageNum=22&refId=xJ%2FHB6j7MCr9%2BdBcMIDMwQ%3D%3D&trackingId=xRPBF%2Bq%2F%2BS2quxjA%2BssoLQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Rejoignez VISEO et explorez un univers de possibilit√©s o√π l'Humain, le Collectif et le Challenge sont au c≈ìur de notre ADN.
Qui √™tes-vous ?
Si pour vous √™tre
Data Engineer Cloud Azure Confirm√© F/H
, c'est :
Faire partie d'une communaut√© d'experts en ing√©nierie des donn√©es et en solutions cloud ;
Concevoir, construire et maintenir des pipelines de donn√©es robustes et √©volutifs sur Microsoft Azure;
Ma√Ætriser les services Azure tels que Azure Data Factory, Azure Data Lake, Azure SQL Database, et Azure Synapse Analytics ;
D√©couvrir les nouveaut√©s tel que Microsoft Fabric
Appliquer les meilleures pratiques en mati√®re de s√©curit√©, de qualit√© des donn√©es et de gouvernance de l'information ;
√ätre familiaris√© avec les technologies de transformation de donn√©es √† grande √©chelle (Spark, Azure Databricks) ;
Collaborer √©troitement avec les √©quipes BI et analytics pour transformer les donn√©es en insights pr√©cieux...
Alors, vous √™tes le talent que nous recherchons !
Si vous avez une solide exp√©rience en tant que Data Engineer, une passion pour le cloud Azure et que vous √™tes pr√™t √† √©largir vos comp√©tences et √† avancer dans votre carri√®re, c'est le moment parfait pour nous rejoindre.
Ce que nous allons faire ensemble ?
D√©couvrez comment votre quotidien sera transform√© en rejoignant l‚Äô√©quipe projet de Gr√©gory. Rattach√© √† notre agence de Toulouse, vous pourrez :
Accompagner et conseiller le client dans son adoption des Modern Data Platform dans Azure (Etude d‚Äôarchitecture, pr√©paration des DAT, FinOps, DevOps) ;
Concevoir des architectures Cloud Data exploitant efficacement les services de donn√©es manag√©s d'Azure ;
Conduire des projets de d√©ploiement des Modern Data Platform (Applications Cloud Native, Migration d‚Äôapplications existantes) et participer √† la mise en ≈ìuvre ;
Etablir des relations de confiance avec les d√©cisionnaires techniques et m√©tiers afin de favoriser l‚Äôadoption du Cloud Microsoft Azure √† long terme au sein de l‚Äôentreprise ;
R√©aliser une veille technologique permanente sur les tendances du march√© et les perspectives concurrentielles ;
Partager votre expertise et apprendre continuellement au sein d'une √©quipe anim√©e par l'innovation.
Ce que nous avons √† vous offrir ?
Des formations, des certifications Azure et un syst√®me de mentoring ;
Un environnement stimulant, souple et agile pour des parcours sans limite ;
Un engagement fort pour l‚Äôenvironnement, la soci√©t√©, l‚Äô√©galit√© et l‚Äôinclusion‚ÄØ: la plateforme Vendredi, atelier fresque du climat, Caf√© Joyeux, l'institut Imagine, Yumaincap ... https://www.viseo.com/fr/notre-demarche-rse
Une organisation flexible pour un bon √©quilibre vie pro / vie perso
Ce qui nous diff√©rencie ?
Une communaut√© engag√©e d'experts en data et cloud Azure : des talks toutes les semaines, la participation √† des √©v√®nements techniques (ateliers, rencontres d‚Äôexperts, Tech An Hour, BBL, Rex, Sponsoring‚Ä¶) ;
Des dispositifs collectifs d‚Äô√©pargne salariale‚ÄØ(PEE et PERECO) et la possibilit√© de devenir actionnaire VISEO ;
Un partenariat privil√©gi√© avec Microsoft (Gold Partner) vous donnant acc√®s aux derni√®res innovations et technologies Azure.
Envie de nous rejoindre ? Contactez-nous et faites partie du #VISEOspirit
En tant qu'employeur, VISEO promeut activement la diversit√© et l'inclusion.
√Ä propos de VISEO
Avec plus de 3 000 collaborateurs r√©partis sur 5 continents, VISEO allie agilit√© et expertise technique pour faire du digital un moteur essentiel de comp√©titivit√© et de performance.
#PositiveDigitalMakers
GDPR MESSAGE:
Our privacy policy has been updated to comply with the new regulations. We invite you to consult it by clicking here: https://www.viseo.com/fr/politique-de-confidentialite. The VISEO Group uses the data collected as part of your application to assess your suitability for the job in question. We use the Jazz HR tool to help us in our recruitment process. This tool complies with current regulations on the protection of personal data. The tool is hosted in the United States and is PrivacyShield certified for HR data. In all cases, we may keep your file for 5 years so that we can contact you again if another position matches your profile. You may, of course, object to this. To find out more about how your data is used and how you can exercise your rights, please consult our privacy policy https://www.viseo.com/fr/politique-de-confidentialite.
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': ['Confirm√©'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Consultant¬∑e Data Engineer,Ntico,"Villeneuve-d‚ÄôAscq, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/consultant%C2%B7e-data-engineer-at-ntico-3902424755?position=6&pageNum=22&refId=xJ%2FHB6j7MCr9%2BdBcMIDMwQ%3D%3D&trackingId=sfs99cvTMUAxpvjSb9EVrQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Sois acteur de ta r√©ussite et rejoins notre √©quipe de 140 collaborateurs¬∑trices qui ne font pas que des projets, mais qui vivent une vraie exp√©rience humaine unique !
üí° Partage, Progr√®s, Plaisir : nos valeurs, ton avenir !
üåê Pr√©sents √† Lille, Orl√©ans, Montpellier : des expert¬∑e¬∑s partout en France !
üíº + de 40 clients qui nous font confiance
üßë‚Äçüíª Recrutement sur profil
üéØ
TA MISSION :
* Tu int√®gres une communaut√© Data, en tant que Data Engineer.
* Tu con√ßois et mod√©lises les donn√©es et identifies les sources et flux √† r√©aliser.
* Tu es en lien permanent avec les √©quipes m√©tiers et IT.
* Tu formes et transmets ton savoir.
* Tu es garant¬∑e de la qualit√© des livraisons.
üßë‚Äçüíª
TES COMP√âTENCES :
Talend, ODI, Stambia, Kafka, API, Bases SQL, et NoSQL, GCP, AWS
ü•á
TON PROFIL :
Tu es expert¬∑e des flux de donn√©es.
La manipulation et le traitement des donn√©es est une seconde nature.
Tu as le sens du service et tu apportes des solutions innovantes.
Tu aimes transmettre et partager ton savoir.
Tu justifies imp√©rativement d‚Äôau moins 3 ans d‚Äôexp√©rience et tu as d√©velopp√©¬∑e une autonomie sur ton domaine de comp√©tence.
Tu souhaites diversifier tes comp√©tences pour √™tre toujours √† la pointe des cas d‚Äôusages m√©tiers et des nouvelles technologies Data.
üôå
NOS AVANTAGES :
‚ú® Pourquoi nous rejoindre ?
üí™
D√©veloppement Continu
: Chez Ntico, tu montes en comp√©tences gr√¢ce √† nos communaut√©s d‚Äôexperts et nos formations !
ü§ù
Management de proximit√©
: On t'√©coute, on te valorise et on t'accompagne dans ton projet pro, en toute transparence !
üéâ
Moments conviviaux
: Sport, culture, DIY, insolite‚Ä¶ Tu peux participer √† nos √©v√©nements tous les mois, et en proposer ! On n‚Äôest jamais √† court d‚Äôid√©es pour des animations uniques !
Ntico, c'est un cadre de travail bienveillant, un environnement dynamique o√π l'√©panouissement personnel est aussi important que le succ√®s collectif !
Postule d√®s maintenant et pr√©pare-toi √† vivre une exp√©rience humaine unique ! ‚ú®
De notre c√¥t√©, on te contacte dans les 72h suivant ta candidature et on te propose un processus de recrutement rapide. üöÄ
Ntico s'engage activement en faveur de l'inclusion professionnelle des personnes en situation de handicap, tout en promouvant la mixit√©, la diversit√© et l'√©galit√© au sein de son effectif.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
"Data Analyst ‚Äì Lille, France (H/F)",Astek,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-%E2%80%93-lille-france-h-f-at-astek-3839093481?position=7&pageNum=22&refId=xJ%2FHB6j7MCr9%2BdBcMIDMwQ%3D%3D&trackingId=2nnLsE%2BysTgP0uI%2B0%2FQPuA%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Lille - France
Publi√©e il y a 2 mois
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Nous rejoindre en tant que
Data Analyst (H/F),
afin d‚Äôaccompagner un op√©rateur t√©l√©coms, Leader en Europe dans la gestion de ses solutions robustes, efficientes et s√©curis√©es √† destination d‚Äôenvironnements vari√©s.
Un challenge portant sur des millions d‚Äôutilisateurs dans un environnement technique innovant, strat√©gique et o√π l‚Äôentraide et la bonne humeur priment !
Votre Mission, Si Vous L‚Äôacceptez :
Etude sur les donn√©es pour aide au cadrage du besoin M√©tier.
Force de proposition sur des solutions analytiques adapt√©es aux besoins utilisateurs (avec nos √©quipes UX).
Analyse des besoins m√©tiers, accompagnement √† la formulation et √† la d√©finition de KPI m√©tiers.
Mod√©lisation des donn√©es.
Conception de Datasets Big Query.
Conception et R√©alisation de Datamarts et de Dashboards (PowerBI / Looker)
Analyse de la qualit√© de la donn√©e source, pour challenger les √©quipes Digitales / Data Engineers.
Votre Future √âquipe :
Au sein d‚Äôun environnement riche et complexe, vous √©voluerez avec des experts passionn√©s √† la fois techniques et fonctionnels (Ing√©nieurs sp√©cialis√©s, chef de projet, scrum master, product owner ‚Ä¶).
L‚Äô√©quipe est en interaction avec des clients √† la fois internes et externes.
Votre stack de jeu
SQL ‚Äì Confirm√©
Mod√©lisation de Donn√©es ‚Äì Confirm√©
Outils de Data Viz ‚Äì Confirm√©
GCP ‚Äì Junior
Anglais ‚Äì Professionnel
Les Petits Plus Du Projet :
Vous interviendrez de A √† Z sur des projets riches fonctionnellement et ambitieux techniquement. Un challenge portant sur des millions d‚Äôutilisateurs dans un environnement technique innovant et strat√©gique.
Vous ?
Dipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieur ou √©quivalent de niveau Bac+5.
Vous justifiez id√©alement d‚Äôune exp√©rience d‚Äôau moins 3 ans d‚Äôexp√©riences sur un poste similaire ?
Vous faite preuve d‚Äôun bon relationnel et d‚Äôesprit d‚Äô√©quipe, √™tes dot√©(e) d‚Äôun excellent sens de l‚Äôorganisation et vous aimez les challenges et la r√©solution de probl√®me ?
Alors ce poste est fait pour vous, n‚Äôh√©sitez plus et rejoignez l‚Äôaventure ASTEK !
Astek
Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.
Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de
ses 7800 collaborateurs
qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.
Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.
Tous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Notre projet commun vous plait ?
Postulez √† cette annonce, et soyez transparent !
Maud, notre Talent Acquisition Referent, vous contactera pour un premier √©change.
Puis vous rencontrerez Martin, votre futur manager, avec lequel vous √©changerez autour d‚ÄôAstek, de votre parcours, de vos attentes et de votre future mission .
Enfin, vous rencontrerez J√©r√©my, notre Directeur d‚Äôagence avec lequel vous pourrez valider votre int√©r√™t et ad√©quation pour le poste et finaliser les √©l√©ments contractuels.
Nos Plus
Astek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo
Une politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversit√©
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì data ‚Äì analyst ‚Äì mod√©lisation ‚Äì donn√©es
Caract√©ristiques de l'emploi
Cat√©gorie Ing√©nieur
Job Industry T√©l√©com / M√©dia
Postuler en ligne
Nom *
Pr√©nom *
Email *
Un email valide est requis.
T√©l√©phone *
Un num√©ro de t√©l√©phone valide est requis.
Joindre un CV *
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì data ‚Äì analyst ‚Äì mod√©lisation ‚Äì donn√©es
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Big Query'], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': ['Confirm√©', 'Junior'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Consultante/Consultant Data Engineer alternance - GRENOBLE,Capgemini,"Grenoble, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/consultante-consultant-data-engineer-alternance-grenoble-at-capgemini-3862396000?position=8&pageNum=22&refId=xJ%2FHB6j7MCr9%2BdBcMIDMwQ%3D%3D&trackingId=iEnQtBt6OzplzL6ySEaPBA%3D%3D&trk=public_jobs_jserp-result_search-card,"Choisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations. Avec le soutien et l'inspiration d‚Äôune communaut√© d‚Äôexperts dans le monde entier, o√π vous pourrez r√©√©crire votre futur. Rejoignez-nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la valeur de la technologie pour les plus grandes organisations et participer √† la construction d‚Äôun monde plus durable et inclusif.
Vos missions
:
Faisant partie int√©grante de l‚Äô√©quipe DataValue, compos√©e d‚Äôune quarantaine de collaborateurs, vous participerez activement √† :
‚Ä¢ Intervenir sur les diff√©rentes phases d'un projet dans un environnement Cloud et Agile.
‚Ä¢ Contribuer √† la gestion de la qualit√© des donn√©es et extraction et analyse de celle-ci, ainsi qu‚Äô√† la pr√©sentation des donn√©es dans leur forme raffin√©e.
‚Ä¢ Proposer des nouvelles lectures de donn√©es via un travail de fouille sur les gisements d‚Äôinformation, notamment client.
‚Ä¢ Adopter une posture de consultant : proposer de nouvelles solutions et accompagner le client dans ses choix.
Votre profil
:
‚Ä¢ En √©cole d‚Äôing√©nieur ou en universit√©, vous √™tes √† la recherche d'une alternance d'une dur√©e de 1 an.
‚Ä¢ Connaissances approfondies des ETL (Talend, Informatica ou SSIS), du traitement de donn√©es (Spark, Python, Scala) ainsi que des bases de donn√©es (Oracle, SQL Server, Postgres).
‚Ä¢ Facult√© pour se montrer curieux, autonome et proactif dans la r√©alisation de ses t√¢ches.
‚Ä¢ Capacit√© √† faire preuve de rigueur et √† travailler en √©quipe.
‚Ä¢ Bon niveau d‚Äôanglais (B2 minimum).
3 raisons de nous rejoindre
:
Qualit√© de vie au travail
: accord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√© professionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.
Apprentissage en continu
: certifications et formations en libre acc√®s, accompagnement sur mesure avec votre career manager, parcours d‚Äôint√©gration sur 9 mois.
Avantages groupes & CSE
: plan actionnariat, tarifs pr√©f√©rentiels, remboursement partiel vacances, remboursement de votre abonnement sportif ou culturel.
Nos engagements et priorit√©s
:
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handiaccueillant.
En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.
√Ä propos de Capgemini
:
Capgemini est un leader mondial, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d‚Äôexp√©rience, nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Oracle', 'SQL Server'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '55', '55', '55']}"
Senior Data Engineer (H/F),Believe,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-h-f-at-believe-3726297642?position=9&pageNum=22&refId=xJ%2FHB6j7MCr9%2BdBcMIDMwQ%3D%3D&trackingId=PWmdK6CxbV%2FSaJRt2OQbCA%3D%3D&trk=public_jobs_jserp-result_search-card,"Description De L'entreprise
Believe est l'un des leaders mondiaux du march√© de la musique num√©rique. Believe a pour mission d‚Äôaccompagner les artistes et les labels locaux dans l‚Äô√©cosyst√®me digital en leur offrant des solutions √† chaque √©tape de leur carri√®re et d√©veloppement
Ce sont plus de 1900 salari√©s dans 50 pays qui accompagnent artistes avec expertise, respect, √©quit√© et transparence.
Afin de soutenir notre forte croissance sur tous les continents, nous sommes constamment √† l‚Äôaff√ªt de nouveaux Believers. Rejoignez-nous afin qu‚Äôensemble, nous ayons un impact fort et plus positif sur l‚Äôindustrie musicale‚ÄØ!
Believe est cot√©e sur le compartiment A du march√© r√©glement√© d‚ÄôEuronext Paris (Ticker : BLV, ISIN : FR0014003FE9).
www.believe.com
Ready to #setthetone with Believe?
Description Du Poste
Contexte
Le Tribe ¬´‚ÄØCustomer Finance‚ÄØ¬ª est compos√© de plusieurs Squad, parmi elles la squad‚ÄØFinance Ingestion qui a pour mission de d√©velopper des outils et des applications pour la collecte de royalties aupr√®s des plateformes de streaming de musique ainsi que pr√©parer les donn√©es afin de faire la distribution des royalties aupr√®s des producteurs de musiques.
En tant que Senior Data Engineer, tu int√©gras une √©quipe de Data Engineering travaillant avec les principes du framework agile Scrum. Cette √©quipe est compos√©e essentiellement de 5 Data Engineer et 1 Software Engineer.
Nous Avons Un √âcosyst√®me Compos√© De
Un socle de gestion des donn√©es (Delta Lake) plus d‚Äô1.5 milliard de lignes /mois
Data processing avec Scala et Spark utilisant le runtime de Databricks
Orchestration de nos data pipelines avec Airflow manag√©
Des APIs d√©ploy√©es avec AWS Lambda et API Gateway pour faire interagir les utilisateurs avec notre interface front (PHP)
AWS RDS pour hoster la base de donn√©es back-end sous PostgreSQL
Versionning du code sous GitLab avec un environnement de dev, staging et production
Infrastructure sous AWS
Les missions du Senior Data Engineer au sein de l‚Äô√©quipe :
Accompagner les d√©veloppeurs √† √©crire du code propre, qualitatif et conforme aux standards de l‚Äô√©quipe
Interagir avec l‚Äôarchitecte, les √©quipes infrastructures Cloud pour concevoir les solutions de data engineering
Proposer des am√©liorations continues et √™tre garant de r√©duire les dettes techniques
D√©velopper des flux de donn√©es (data pipelines) avec de l‚ÄôApache Spark et du Scala
Faire de l‚Äôorchestration via Airflow avec du Python
Maintenir le workflow GitLab afin de garantir une bonne productivit√© de l‚Äô√©quipe de d√©veloppement
Effectuer des revues de codes des autres membres de l‚Äô√©quipe
Collaborer les membres de l‚Äô√©quipe dev pour atteindre l‚Äôobjectif du sprint
Faire du support applicatif et fonctionnel de l‚Äôapplication aupr√®s des op√©rationnel
Qualifications
Qualifications du Data Engineer
5-8 ans d‚Äôexp√©rience en Scala
Une maitrise horizontale de tous les composants d‚Äôune plateforme de data
Exp√©rience en programmation fonctionnel
Connaissance d‚Äôun effect system en Scala (ZIO ou cats)
Excellente ma√Ætrise de l‚ÄôAPI Spark en Scala avec pour but de guider l‚Äô√©quipe sur les bonnes pratiques
Exp√©rience en d√©veloppement backend
Une bonne maitrise des services AWS (API Gateway, Lambda, SNS, SQS, S3, Cloudwatch, VPC)
D√©velopper avec un √©tat d‚Äôesprit Keep it Simple, Stupid (KISS)
Excellente comp√©tence dans la gestion de relation avec une √©quipe en remote
Bonne communication pour g√©rer les diff√©rents points de vue et expliquer les contraintes aux utilisateurs
Optionnel
Exp√©rience en PHP (framewok Symfony ou Laravel)
Informations suppl√©mentaires
Set the tone with us
Chez Believe, nous avons deux c≈ìurs : nos collaborateurs et nos artistes.
Nous croyons en la force de nos collaborateurs, qui s'√©panouissent chaque jour en d√©veloppant leur potentiel... Notre objectif est d'offrir √† nos collaborateurs le meilleur environnement possible pour qu'ils puissent s'√©panouir.
Rock the job
Programme de formation et de coaching sur mesure
Une politique de t√©l√©travail
Un programme de bien-√™tre ""Pauses"" avec de nombreuses activit√©s et animations en interne
Acc√®s √† Eutelmed, la plateforme num√©rique de sant√© mentale et de bien-√™tre qui permet de parler √† un psychologue exp√©riment√©
Un restaurant d'entreprise sain et √©co-responsable
Une assurance sant√© individuelle ou familiale
Avantages CE
Un rooftop
Une salle de sport avec des cours gratuits
Sing in harmony
Des groupes d'ambassadeurs pour s'engager sur la r√©duction de l'empreinte carbone et environnementale de Believe et l‚Äô√©quit√© professionnelle Femme/Homme.
Mise en place du Forfait mobilit√© durable: remboursement jusqu‚Äô√† 600‚Ç¨ des frais de transport en commun/avec une faible empreinte carbone.
Cong√© 2nd parent de 5 jours calendaires r√©mun√©r√©s √† 100% (en plus du cong√© l√©gal paternit√© ou du cong√© d‚Äôadoption, nous ne l‚Äôattribuons pas au cong√© maternit√©)
Believe s‚Äôengage √† garantir l‚Äô√©galit√© des chances en mati√®re d‚Äôemploi, sans tenir compte de l‚Äôorigine, du sexe, des m≈ìurs, de l‚Äôorientation sexuelle, du genre, de l‚Äô√¢ge, de la situation de famille, de l‚Äô√©tat de grossesse, d‚Äôune pr√©tendue race, des opinions politiques, des activit√©s syndicales, des convictions religieuses, de l‚Äôapparence physique, du nom de famille, du lieu de r√©sidence, de l‚Äô√©tat de sant√©, ou en situation de handicap.
D√©couvrez nos nouveaux locaux : bit.ly/believeoffice
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Remote', 'Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '8', '8', '8']}"
Alternance - Data Engineer Junior (H/F),Transdev,"Issy-les-Moulineaux, √éle-de-France, France",https://fr.linkedin.com/jobs/view/alternance-data-engineer-junior-h-f-at-transdev-3879679114?position=10&pageNum=22&refId=xJ%2FHB6j7MCr9%2BdBcMIDMwQ%3D%3D&trackingId=UCZZDRclG746BsTGQUMbdw%3D%3D&trk=public_jobs_jserp-result_search-card,"Transdev recrute un Data Engineer Junior (H/F) en alternance
Rejoignez un Groupe international fortement ancr√© dans les territoires
Votre destination
La Direction ""IT, Data, Digital, Cybersecurity"" d√©finit la Strat√©gie de Transformation du Groupe et suit sa mise en oeuvre au travers de 9 programmes strat√©giques.
Parmi ces programmes, au sein du d√©partement Digital, notre √©quipe ""Data & Technology Office"" anime le programme Data Powered qui vise √† augmenter la maturit√© Data du Groupe Transdev et de ses filiales √† l'international, ainsi qu'√† valoriser ses assets Data encore peu exploit√©s autour d‚Äôune m√©thodologie innovante ax√©e sur la valeur des cas d‚Äôusage √† destination de profils bien d√©finis.
Dans ce contexte, nous mettons en place un certain nombre d‚Äôenvironnements techniques qui ont besoin d‚Äô√™tre gouvern√©s et nous r√©alisons des d√©veloppements de manipulation de donn√©es pour les besoins propres du Groupe. Nous aidons aussi les pays √† lancer leurs propres programmes et nous les accompagnons sur tous les volets du changement.
Votre feuille de route
Le/la Data Engineer Junior a la responsabilit√© :
de la structuration des d√©veloppements des traitements d‚Äôint√©gration de donn√©es h√©t√©rog√®nes (en lien avec l‚ÄôArchitecte Data et le/la Data Engineer Senior)
de la mise en place de processus fiables et automatis√©s de test et de d√©ploiement.
En parall√®le, il/elle travaille avec l‚Äô√©quipe de Data Science afin de comprendre leurs besoins et pr√©parer les donn√©es n√©cessaires aux cas d‚Äôusage.
Votre parcours
Actuellement en √©cole d'ing√©nieur ou universit√©, vous pr√©parez un Master en Sciences de l'information, Sciences de la donn√©e et vous recherchez une entreprise o√π r√©aliser vos deux ann√©es d‚Äôalternance (M1/M2).
Vous avez un vrai int√©r√™t pour l‚Äôing√©nierie de la donn√©e.
Enfin, vous avez id√©alement une premi√®re exp√©rience significative (stage, projet √©tudiant solide) en tant que Data Engineer.
Vos atouts
Vous √™tes tr√®s √† l'aise (voire bilingue)
en fran√ßais et anglais
√† l'oral comme √† l'√©crit. C'est un pr√©requis pour ce poste car vous serez amen√©(e) √† travailler avec les filiales de Transdev √† l'√©tranger.
Vous avez une bonne compr√©hension du Data Engineering, vous connaissez les environnements Cloud (notamment Amazon Web Services) ainsi que les technologies Git.
La connaissance accrue des langages SQL et Python est indispensable. La c onnaissance de Snowflake est un vrai plus.
Enfin, rigoureux(se), curieux(se), et proactif(ve), vous avez une r√©elle capacit√© √† vous adapter, √† g√©rer vos projets de mani√®re autonome, tout en travaillant de mani√®re collaborative dans des √©quipes pluridisciplinaires.
A savoir
Alternance bas√©e √† Issy-les-Moulineaux (92)
D√©marrage en septembre 2024 pour un an ou deux ans
Rythme id√©al : 4 jours/1 jour (ou 3 semaines /1 semaine)
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Junior', 'Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Senior Data Engineer,netcarbon,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-at-netcarbon-3909777157?position=1&pageNum=25&refId=bvabfaeIkTn6w1fyYCK6qA%3D%3D&trackingId=hrlicBfcntsfyCNt8%2F4V%2BA%3D%3D&trk=public_jobs_jserp-result_search-card,"A propos de netcarbon
Le rapport du GIEC est clair pour lutter contre le changement climatique, nous devons :
üè≠
R√©duire nos √©missions de CO2
üå±
Capter le CO2 de l'atmosph√®re
Quand il s‚Äôagit de capter du CO2,
la v√©g√©tation a un super pouvoir.
Gr√¢ce √† la photosynth√®se, les plantes absorbent le CO2 contenu dans l‚Äôatmosph√®re pour le stocker dans le sol.
Le probl√®me c‚Äôest que ce qui ne peut pas √™tre mesur√©, ne peut pas √™tre am√©lior√©.
Netcarbon
entre alors en sc√®ne ! Netcarbon est une startup
sp√©cialis√©e dans la mesure du carbone.
Mais pas n‚Äôimporte quelle mesure, nous utilisons des donn√©es satellites pour avoir une vision globale, homog√®ne et quotidienne du carbone. Heureusement nous ne travaillons pas seuls, Netcarbon est soutenu par le CNES et l‚ÄôAgence Spatiale Europ√©enne.
Comment cela fonctionne ?
üõ∞Ô∏è
La donn√©e satellite pour mesurer le carbone
Le coeur de netcarbon, c‚Äôest les donn√©es issues des satellites en orbite au dessus de nos t√™tes. Gr√¢ce √† cela, nous pouvons mesurer le CO2 absorb√© par la v√©g√©tation en temps r√©el et partout sur Terre.
üñ•Ô∏è
Un SaaS pour am√©liorer et valoriser sa captation carbone
Pour rendre accessible la mesure du carbone √† tous, netcarbon a con√ßu une application qui permet √† nos clients de conna√Ætre leur captation carbone et d‚Äôidentifier la v√©g√©tation √† mettre en place pour capter plus de CO2.
Qui sont nos clients ?
üë®‚Äçüåæ
L‚Äôagriculture
Gr√¢ce √† leurs champs les agriculteurs peuvent stocker √©norm√©ment de CO2. En utilisant l‚Äôapplication netcarbon, les coop√©ratives et agro industriels peuvent encourager les agriculteurs √† stocker plus de CO2 et donc contribuer √† lutter contre le changement climatique.
üå≥
Les villes
Pour lutter contre le changement climatique et rendre nos villes plus agr√©ables √† vivre, il est indispensable de mettre plus de v√©g√©tation. L‚Äôapplication netcarbon aide les d√©cideurs politiques √† concevoir des villes plus durables en mettant la v√©g√©tation et ses bienfaits au centre de tous projets.
Le poste
Ton poste consistera √† consolider les infrastructures de traitement de donn√©es de Netcarbon incluant le traitement de donn√©es satellites pour que notre produit puisse √™tre d√©ploy√© massivement. Pour cela, tu travailleras sur deux axes cl√©s :
Datafactory (ETL) :
Pour suivre la captation de carbone, nous avons construit une datafactory qui permet d‚Äôanalyser des donn√©es satellites partout sur Terre. L‚Äôobjectif sera de consolider la datafactory.
Cloud / Architecture :
Netcarbon s‚Äôappuie sur plusieurs Cloud Providers pour le traitement de donn√©es, pour le stockage ainsi que le d√©ploiement de son produit. Tu aideras l‚Äô√©quipe √† construire la meilleure strat√©gie cloud pour d√©ployer notre produit.
En tant que membre central de la team data, tu porteras une mission indispensable pour le d√©veloppement de netcarbon :
consolider nos ETL et insuffler les meilleurs pratiques de data engineering √† la team.
Tu interagiras avec la Science Team, la Dev Team et surtout, tu auras l‚Äôoccasion de faire grandir une solution r√©pondant au d√©fi de notre si√®cle : lutter contre le changement climatique.
Tes missions
R√©aliser un audit de nos ETL et de notre Architecture cloud.
Consolider nos ETL & notre Architecture afin de soutenir le d√©veloppement et l‚Äôam√©lioration de notre solution de mesure du carbone.
D√©ployer les meilleures pratiques de data engineering au sein de la Team.
Garder un ≈ìil sur les nouvelles technologies et les avanc√©es dans le domaine de la data engineering et des donn√©es satellites (stac, cog, xarray, zarr, dask, ...)
Profil id√©al
Tu es le candidat id√©al si:
Tu as une exp√©rience solide avec des bases de donn√©es SQL et noSQL dans le cloud.
Tu as d√©j√† travaill√© avec des donn√©es g√©ospatiales / imagerie / satellite.
Tu sais ce que signifient GCP, GeoPandas, STAC, GEE, COG, xarray et Dask.
Tu es proactif et tu n‚Äôas pas peur de mettre les mains dans le cambouis pour faire un peu de dev ops ou proposer une nouvelle architecture data.
Tu sais qu‚Äôune data pipeline bien huil√©e vaut mieux qu‚Äôun mod√®le chiad√©. (ie: tu as d√©j√† collabor√© avec une √©quipe machine learning).
Tu as un bon esprit de synth√®se et capable de communiquer efficacement avec ton √©quipe.
Tu n‚Äôas pas pour projet de devenir data scientist.
Formation et Exp√©rience
3 ans d‚Äôexp√©rience minimum dans une √©quipe data.
master ou √©quivalent en informatique, ing√©nierie ou science des donn√©es.
Process de recrutement
Le processus de recrutement se divise en 3 √©tapes :
Un entretien en visio de 30/45 minutes avec le head of data
R√©alisation d‚Äôun cas d‚Äôusage √† effectuer en une semaine
Un entretien final avec les co-fondateurs de Netcarbon (id√©alement en pr√©sentiel pour que tu puisses rencontrer ta future team ü§©)
Processus de recrutement
Merci de postuler sur notre job indeed pour nous permettre de centraliser les demandes.
https://fr.indeed.com/job/senior-data-engineer-97612e2a2f4cf205
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Senior Data Engineer Databricks,Visian,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-databricks-at-visian-3893237152?position=2&pageNum=25&refId=bvabfaeIkTn6w1fyYCK6qA%3D%3D&trackingId=V8EstfE8XicXmnSHXYl6dQ%3D%3D&trk=public_jobs_jserp-result_search-card,"La Direction des Syst√®mes d‚ÄôInformation de notre client grand compte dans l‚Äô√©nergie recherche un profil
Data Engineer Databricks Senior
pour concevoir, d√©velopper et maintenir les architectures Data n√©cessaires √† l‚Äôexploitation de ses donn√©es par les analystes m√©tiers et data scientists.
Le D
ata Engineer Senior
int√®gre une √©quipe en charge du lakehouse (AWS + Databricks) pour la B2C.
Missions
:
Contribution √† la conception de outils de traitement BigData (Ingestion / Traitement / Analyse)
Cadrage technique des besoins √©mis par les consommateurs de la plateforme Data
Garantir la mise en production des traitements au sein de la plateforme
Optimisation du code et de la capacit√© des VMs mise en ≈ìuvre pour chaque traitement
Garantir la disponibilit√© et l‚Äôoutillage pour les √©quipes m√©tier, ainsi qu‚Äôaux utilisateurs de la plateforme (data scientists / data analystes / data engineer)
Etre en relation avec les √©quipes infrastructure afin d‚Äôassurer le cadrage et le d√©ploiement des solutions valides
Support aux √©quipes consommatrices
Analyse d‚Äôanomalies et proposition solution court / moyen terme
D√©veloppement sous Databrick (Python / SQL / Spark / Airflow)
Etre force de propositions techniques
Profil recherch√© :
Formation ing√©nieure ou universitaire de niveau Bac+5 √† dominante informatique et math√©matiques
Exp√©rience de 3 √† 5 ans minimum sur un poste similaire
Code source (composants applicatifs et tests unitaires)
Ma√Ætrise de Databricks + Python + SQL + Spark + Airflow
Avoir une premi√®re exp√©rience sur de la MCO et Support
Comp√©tences en langage SQL et en programmation (Python et PowerShell)
Aisance dans l‚Äôutilisation des API (REST, SOA)
Ma√Ætrise de l‚Äôanglais
Rigueur, capacit√© d‚Äôanalyse et d‚Äôadaptation
Autonome, vous savez travailler en √©quipe et avez l‚Äôesprit d‚Äôinitiative
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': ['Senior'], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Engineer,eXalt,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-exalt-3901508929?position=3&pageNum=25&refId=bvabfaeIkTn6w1fyYCK6qA%3D%3D&trackingId=M%2BMvcApOtpH2QjDIjUux3A%3D%3D&trk=public_jobs_jserp-result_search-card,"Descriptif du poste
Nous recherchons un
Data Engineer Confirm√© H/F (minimum 4 ans d‚Äôexp√©rience dans la fonction)
pour rejoindre notre communaut√© sur le
pilier Data Engineering & Big Data.
Vos missions:
Concevoir et d√©velopper des pipelines et des flux de donn√©es.
Int√©grer et transformer des donn√©es provenant de diff√©rentes sources.
D√©velopper et mettre en ≈ìuvre des algorithmes de traitement de donn√©es avanc√©s.
Collaborer √©troitement avec les √©quipes clients pour comprendre leurs besoins et fournir des solutions adapt√©es.
Assurer la qualit√© et la fiabilit√© des solutions d√©velopp√©es.
Conseiller les √©quipes clients sur les solutions √† mettre en place.
Profil recherch√©
Titulaire d‚Äôun Bac+5, Ecole d‚ÄôIng√©nieur
Ma√Ætrise d‚Äôun ou plusieurs langages de programmation (Python, Scala, Spark, etc.).
Exp√©rience approfondie des technologies Big Data (Hadoop, Spark, Kafka, Talend, etc.)
Exp√©rience av√©r√©e en environnement Cloud (AWS, GCP, ou Azure).
Solides comp√©tences en conception et en optimisation de pipelines de donn√©es.
Exp√©rience de travail en m√©thode Agile
Capacit√© √† travailler de mani√®re autonome et en √©quipe.
Excellentes comp√©tences en communication et en r√©solution de probl√®mes.
Ma√Ætrise de l‚Äôanglais (oral & √©crit dans un contexte international professionnel).
D√©roulement des entretiens
Un entretien RH avec Estelle, √† la suite duquel vous saurez tout (ou presque) d‚ÄôeXalt Value,
Un entretien technique avec un Manager assorti d‚Äôun test technique, lors duquel vous aurez l‚Äôoccasion de d√©montrer vos talents mais aussi d‚Äôapprendre avant m√™me de dire oui,
Un entretien final avec la Directrice Associ√©e ou le Directeur Op√©rationnel, pour finir de vous convaincre de nous rejoindre üòä
Votre environnement eXalt√©:
Un environnement de travail Collaboratif favorisant les initiatives et projets transverses √† la Practice Data & IA (Lab IA, Data Hub, etc.).
Un collectif de consultants passionn√©s, s‚Äôint√©ressant aux tendances innovantes du secteur.
Une Practice de proximit√©, privil√©giant la mont√©e en comp√©tence de ses collaborateurs (formations, coachings, mentorats, etc.)
Un suivi individualis√© et de proximit√© par un.e Data Sales Manager r√©f√©rent du compte client, un.e Charg√©.e RH et un.e Practice Manager
Une √©quipe ouverte et dynamique, qui privil√©gie les moments de partage et de convivialit√© (s√©minaires, eXaltemps, meet-up, d√©jeuners d‚Äô√©quipe, etc.)
Qui sont-ils ?
eXalt
est un cabinet de conseil IT
Pure player Data
& IA bas√© √† Paris (1er arrondissement).
Notre offre s‚Äôarticule autour de 4 piliers r√©unis au sein d‚Äôune m√™me communaut√© pour un accompagnement √† 360¬∞ alliant une expertise technique et m√©thodologique √† une approche conseil m√©tier:
Data Gouvernance & Project
Data Engineering & Big Data
Data Performance‚ÄØ& Analytics
Data Science & IA
Filiale du groupe eXalt cr√©√© en 2018,
regroupant plus de
950 collaborateurs en France
(Paris, Lyon, Bordeaux, Lille, Nantes, Marseille)
et √† l‚Äôinternational
(Colombie, Etats-Unis, Espagne, Belgique),
eXalt Value
d√©montre une
expertise approfondie
dans le domaine de la Data & IA et conseille les entreprises dans le d√©ploiement de leurs strat√©gies data-driven.
B√©n√©ficiant de la renomm√©e et des relations client du groupe eXalt
(1er dans la cat√©gorie Conseil & Audit au classement des Champions de la Croissance 2024), eXalt Value
est en pleine croissance et regroupe aujourd‚Äôhui une communaut√© d‚Äôexpertise de plus de 60 collaborateurs en r√©gion parisienne.
Nos consultants interviennent sur d
es projets d‚Äôenvergure stimulants
dans divers secteurs d‚Äôactivit√©, Banque & Assurance, M√©dias, Transports, Retail, Tourisme, etc.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Communication', 'R√©solution de probl√®mes'], 'EnSoftSkils': ['Communication', 'Initiative']}","{'JobDetail': ['Confirm√©'], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Data Engineer H/F,Proxiel,"Montpellier, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-proxiel-3913995044?position=4&pageNum=25&refId=bvabfaeIkTn6w1fyYCK6qA%3D%3D&trackingId=w8S9Uma4TwjKIiHoLu%2Bw%2Bw%3D%3D&trk=public_jobs_jserp-result_search-card,"Depuis 1999, PROXIEL accompagne des entreprises dans leur d√©veloppement en assurant des prestations de conseil et d'ing√©nierie dans le domaine des technologies.
Proxiel : C'est plusieurs p√¥les d'activit√©s.
Nous mettons un point d honneur √† associer votre bien-√™tre - adaptabilit√© en fonction de vos contraintes (possibilit√© de t√©l√©travail). Des solutions alternatives, peuvent √™tre envisag√©es, dans la mesure o√π elles sont compatibles avec le business que nous entreprenons. Nous souhaitons que chacun de nos salari√©s s investissent dans nos projets et que notre entreprise soit anim√©e par un projet commun : la r√©ussite de chacun !
Notre approche est simple alors restons transparents dans nos √©changes.
Notre si√®ge est implant√© √† Montpellier PROXIEL. Nous disposons √©galement d une agence sur Paris
Vous pr√©sentez des comp√©tences dans les nouvelles technologies en qualit√© de techniciens d√©veloppeurs ing√©nieurs, cot√© d√©veloppement ou r√©seau, vous √™tes bas√©s ou mobile sur MONTPELLIER PARIS LYON TOULOUSE MARSEILLE AIX EN PROVENCE, NICE rejoignez-nous !
Bonjour,
Nous recherchons pour notre partenaire un grand compte sur Montpellier un Data engineer :
Comp√©tences
Exp√©rience en architecture de syst√®mes distribu√©s Big Data
Scala/Java (exp√©rience obligatoire dans l'un des deux langages)
Ecosyst√®me Big Data (Hadoop, Spark, Apache Kafka, Avro, Nifi)
Ma√Ætrise de la CI/CD et des outils de d√©ploiement et orchestration (Jenkins, GitLab, Kubernetes, Docker, Ansible)
Concepts fondamentaux de Kafka
Bases de donn√©es NoSQL (Cassandra, BigTable)
Moteur de recherche (Elastic Search)
Bac +5 ou √©quivalent
Min 3 ans d'exp√©rience
Show more
Show less","{'ProgLanguage': ['Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': ['Avro'], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['Apache Kafka'], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['Big Data', 'CI/CD'], 'FrSoftSkills': ['Adaptabilit√©'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer | Python - Spark - Hadoop | Sp√©cialis√© en Big Data | Paris ou Remote Partiel,Octopus IT - Expert du recrutement tech,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-python-spark-hadoop-sp%C3%A9cialis%C3%A9-en-big-data-paris-ou-remote-partiel-at-octopus-it-expert-du-recrutement-tech-3837194913?position=5&pageNum=25&refId=bvabfaeIkTn6w1fyYCK6qA%3D%3D&trackingId=HYiCQ7lqeOTOgLlDeC8znA%3D%3D&trk=public_jobs_jserp-result_search-card,"La soci√©t√©
Cr√©√©e il y a 7 ans, cette entreprise de conseil en hyper croissance, se compose d'environ 90 personnes. Elle est devenue experte en Data et IA (NLP, Deep Learning, Machine Learning) et accompagne leurs clients sur l‚Äôensemble de leurs projets data √† travers la valorisation de leurs donn√©es.
Leur valeur ajout√©e ? Leur sp√©cialisation en Data ce qui leur permet d'offrir 3 expertises m√©tiers distinctes : la Data Science, la Data Engineering et le Machine Learning Engineering. Autour de ces expertises gravitent bien s√ªr les m√©tiers de Lead et d'Architecte.
Une autre de leur force est leur formation interne (avec des profils de seniors ou d'architectes) et externe (avec des partenaires pour passer les certifications).
Chez eux, le collaborateur est plac√© au centre des pr√©occupations, permettant ainsi de cr√©er une coh√©sion et une v√©ritable culture au sein de l'entreprise. Par exemple la majorit√© des projets se font en √©quipe et non seul.
Connu et reconnu pour leur expertise en Big Data, ils sont devenu le partenaire principal d'un grand groupe du CAC 40 et ont pris le lead sur tous les sujets touchant √† la transformation Big Data de ce groupe.
Pour poursuivre leur croissance, r√©pondre √† leurs ambitions et d√©velopper de nouveaux march√©s, nous recherchons plusieurs profils pour renforcer leurs effectifs.
Le poste
En les rejoignant vous travaillerez sur les probl√©matiques suivantes :
Mise en place et/ou scale d'architectures
Construction de Datalake
Mise en production de model de ML
Pipelining de donn√©es
Streaming de donn√©es et temps r√©el
La stack sur laquelle vous travaillerez :
Python, Scala, Spark, Architectures distribu√©es : Hadoop, HDFS, Cloud : Aws, GCP, Azure
Votre profil
A partir de 3 ans d'exp√©rience en CDI
Vous avez une exp√©rience significative sur des probl√©matiques Big Data
Tr√®s bonne comp√©tences en Python et/ou Scala et en Spark
Vous √™tes familier avec Hadoop, Hive, Hbase
Une logique cloud (Aws, GCP ou Azure)
Le salaire & avantages
50-60 K‚Ç¨ selon exp√©rience
RTT
Carte Swile & Mutuelle
3/4 jours de t√©l√©travail par semaine
Et plus encore‚Ä¶
Ce qu‚Äôon pr√©f√®re
√ätre impliqu√© √† fond dans une aventure avec de nombreux challenges techniques
Belles opportunit√©s d'√©volutions sur des postes d'Architecte, de Lead ou de Ml Ops
Tr√®s bonne ambiance, √©quipe solidaire et orient√©e partage d‚Äôinformations
Beaucoup de workshops en interne et catalogue de formations √† votre guise
Ce poste a √©t√© soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d‚ÄôExperts en Recrutement Tech (CDI et clients finaux uniquement) ‚Äì Visitez nous pour plus d‚Äôopportunit√©s :
www.octopusit.fr
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Senior'], 'TypeContract': ['CDI'], 'Salary': ['50'], 'Level': [], 'Experience': ['a', 'n', 's', '7', '7', '7']}"
DATA ENGINEER - H/F - (STG-4572),Banque de France,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-stg-4572-at-banque-de-france-3814497304?position=6&pageNum=25&refId=bvabfaeIkTn6w1fyYCK6qA%3D%3D&trackingId=gQMqXLid0WUm%2BDlp1dyxLg%3D%3D&trk=public_jobs_jserp-result_search-card,"Pr√©sentation de la direction g√©n√©rale et du service
La Direction G√©n√©rale du Syst√®me d‚ÄôInformation (DGSI) a pour r√¥le de concevoir et mettre en ≈ìuvre la strat√©gie informatique de la Banque de France. Elle veille √† la mise √† niveau de l'architecture informatique, √† l'int√©gration de l'innovation, √† la s√©curit√© num√©rique de la Banque de France mais aussi √† la bonne gestion de son patrimoine de donn√©es. La DGSI regroupe plus de 2 000 personnes (internes et externes) r√©parties sur diff√©rents sites, √† Paris, Vincennes, Marne-la-Vall√©e, Paris La Courneuve et Poitiers.
Au sein de la Direction G√©n√©rale du Syst√®me d‚Äôinformation, le Lab incarne le centre d‚Äôinnovation de la Banque de France. Outil d‚Äôanticipation, de facilitation et de construction des offres innovantes, le Lab Banque de France a pour mission de faire d√©couvrir aux m√©tiers de la banque centrale les nouveaux usages, les nouvelles technologies et les nouvelles m√©thodes pour conduire des projets de transformation de fa√ßon agile et rapide.
Descriptif de mission
Dans le cadre de son plan de travail sur l'Intelligence Artificielle, le Lab propose un stage afin de d√©velopper et de concr√©tiser les sujets suivants :
Maintenance de scraping de sites avec l‚ÄôIA (√©valuer si √† partir de scraping existant, l‚ÄôIA pourrait corriger les erreurs li√©es aux √©volutions des sites scrap√©s.)
√âvaluation du produit Giskard (framework pour tester les mod√®les LLM)
Gestion des CRA (Comptes Rendus d‚ÄôActivit√©s) des prestataires (traitement √† base de OCR les CRA transmis par les prestataires, contr√¥le sur les consommations, voir la possibilit√© de faire des traitements IA)
Profil recherch√©
Formation recherch√©e :
Master (1 ou 2) Data Engineer, Data Scientist
Master (1 ou 2) Ing√©nierie des syst√®mes num√©riques
Comp√©tences :
Technologie: IA, IA G√©n√©rative
outils de gestion/analyse de la data: PowerBI ou autres
Langages de programmation: Python, ReactJS, Java
Environnements: Cloud, Docker, Git
Qualit√©s :
Capable de travailler √† la fois en autonomie et en √©quipe.
Force de proposition dans son domaine d'expertise
Une tr√®s bonne communication autant √† l'√©crit qu'√† l'oral
Contactez nos ambassadeurs
La Banque de France est une institution socialement responsable, attach√©e au respect de la diversit√© sous toutes ses formes, √† la lutte contre les discriminations, √† favoriser la parit√© Femme/Homme et √† garantir un environnement de travail de qualit√©.
Des am√©nagements de poste peuvent √™tre organis√©s pour tenir compte des handicaps des personnes recrut√©es.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data ing√©nieur (H/F),Abeille Assurances,"Bois-Colombes, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-ing%C3%A9nieur-h-f-at-abeille-assurances-3819474490?position=7&pageNum=25&refId=bvabfaeIkTn6w1fyYCK6qA%3D%3D&trackingId=wLLtaB7AES6VNQd3lV%2Bm1Q%3D%3D&trk=public_jobs_jserp-result_search-card,"Rejoignez les √©quipes de la Data Factory d‚ÄôAbeille assurances ! Au sein de cette direction compos√©e d‚Äôune 40aine de collaborateurs, l‚Äôenjeu pour vous sera de g√©rer les plateformes Data pour les rendre disponibles et accessibles au business ! Ainsi, vous contribuez √† la modernisation du SI Data, accompagnez les directions m√©tiers dans la mise en ≈ìuvre de leur besoin en termes de donn√©es, et assurer la disponibilit√© des services au quotidien.
A ce titre, vos missions principales sont les suivantes :
Mise en place et maintenance des architectures d√©cisionnelles en int√©grant des nouveaux outils ou services en conformit√© avec la strat√©gie d‚Äôentreprise. A ce titre vous serez amen√© √† tester des solutions (benchmark/POC), √† coordonner ou √™tre lead technique Data pour des projets d‚Äôint√©gration et de d√©ploiement de solution en fonction de votre exp√©rience, documenter les divers aspects y compris des best practice et normes d‚Äôutilisation, ainsi que d√©velopper des outillages facilitant l‚Äôint√©gration ou l‚Äôindustrialisation des nouvelles applications.
Mise en place de nouvelles interfaces techniques pour des sources de donn√©es encore non r√©f√©renc√©es dans le SI Data et participation √† leur standardisation et d√©ploiement.
Participer activement √† tous les process transverse de gestion IT au quotidien pour le SI Data : Gestion des identit√©s, Conformit√©, Cartographie, Audit, Test d'intrusion, Rem√©diations des vuln√©rabilit√©s, Plan de recours, Plan de tests et Plan de maintenance.
Facilitation de l‚Äôusage des donn√©es dans l‚Äôentreprise dans un environnement de plus en plus hybride On-Premise, Cloud, SaaS
Profil et comp√©tence :
BAC +5 Master ou Ing√©nieur IT sp√©cialit√© Data et IT
Comp√©tences techniques : Python, Big Data,
La connaissance d‚Äôoutils de DataVIZ (Qlik serait un plus) ainsi que Dataiku ou des outils d‚ÄôIA.
Gestion de projet indispensable .
Sens de l‚Äôanalyse pr√©cise du contexte afin de trouver la solution la plus efficace et pertinente
Vous √™tes autonome , √™tes dot√©(e) d‚Äôun bon relationnel notamment face √† des interlocuteurs m√©tiers et experts techniques vari√©s. √ätre bien organis√©. Faire preuve d‚Äôune grande rigueur .Vous avez une aisance naturelle pour le travail en √©quipe et avez l‚Äôhabitude de vulgariser les demandes, faire comprendre avec p√©dagogie les contraintes m√©tiers et des √©quipes IT.
Vous √©voluez dans un environnement √©voluant tr√®s rapidement. Aussi, vous √™tes curieux.se, apprendre en permanence, La veille technologie est essentielle
Contraintes li√©es au poste
: astreintes occasionnelles
Anglais :
indispensable (travail avec les √©diteurs)
Ce que nous avons √† vous proposer ?
Une r√©mun√©ration globale, compos√©e :
D‚Äôune part fixe,
D‚Äôune part variable : Individuelle, et collective, via l‚ÄôEpargne salariale (Participation / int√©ressement),
Une surcompl√©mentaire retraite (PERE - Plan d‚ÄôEpargne Retraite Entreprise)
Du t√©l√©travail, encadr√© par un accord qui pr√©voit jusqu‚Äô√† 2,5 jours de t√©l√©travail par semaine, accessible apr√®s la p√©riode d‚Äôint√©gration (sauf exception), Le t√©l√©travail donne droit √† des titres restaurant, une aide √† l‚Äô√©quipement et une indemnit√© internet mensuelle.
Une mutuelle interentreprise avantageuse.
Un remboursement de transport flexible, encadr√© par un forfait mobilit√© durable, pour favoriser les mobilit√©s douces.
Entre 26 et 29 jours de cong√©s pay√©s et 15 jours de RTT pour un temps plein.
Un CSE avec des offres et services attractifs.
Des offres de produits d‚Äôassurance et un accompagnement personnalis√©,
Un environnement de travail chaleureux et convivial 100% en flex-office, facilement accessible en transport
Et apr√®s ?
Chez Abeille Assurances, la mobilit√© interne est un vrai levier pour d√©velopper la carri√®re et les comp√©tences de nos collaborateurs et collaboratrices, avec un objectif ambitieux de 50% des postes pourvus en interne.
Nous favorisons les mobilit√©s au sein du Groupe A√©ma, de Macif, Aesio Mutuelle, Ofi Invest. Ensemble, nous formons le 5√®me groupe d‚Äôassurance en France.
Quels sont nos engagements ?
L‚Äôassurance d‚Äô√™tre soi-m√™me :
Chez Abeille Assurances nous sommes convaincus que la diversit√© est une richesse. Nous nous engageons √† traiter les candidatures sans consid√©ration de sexe, d‚Äô√¢ge, d‚Äôorigine, de handicap ou de conviction. La direction et les collaborateurs s‚Äôengagent au quotidien sur les sujets de diversit√© et d‚Äôinclusion, en t√©moigne nos diff√©rentes communaut√©s : LGBT+, Egalit√© professionnelle et Handicap.
Et nous ?
Compagnie majeure de l‚Äôassurance en France forte de ses 3000 collaborateurs, 1000 agents g√©n√©raux d‚Äôassurance et de ses 180 ans d‚Äôexp√©rience, Abeille Assurances dispose d‚Äôune gamme √©tendue de produits et services d‚Äôassurance, de protection, d‚Äô√©pargne et de retraite. Abeille Assurances est par ailleurs le partenaire historique de l‚ÄôAFER, la premi√®re association d‚Äô√©pargnants en France (avec pr√®s de 754 000 adh√©rents).
Plus d‚Äôinformations sur abeille-assurances.fr
Abeille Assurances est une entit√© d‚ÄôA√©ma Groupe, n√© en janvier 2021 du rapprochement entre A√©sio Mutuelle, Macif, et Ofi Invest. Ce groupe imagine chaque jour les contours d‚Äôun monde plus juste et plus humain en pla√ßant la pr√©venance au c≈ìur de la relation avec ses adh√©rents, soci√©taires et entreprises clientes. Il couvre les besoins de protection de 11 millions de personnes et r√©pond aux besoins assurantiels et serviciels de 1 fran√ßais sur 6.
Plus d‚Äôinfos sur aemagroupe.fr
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Hybride', 'Temps plein'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '180', '180', '180']}"
Data Analyst H/F,Valeuriad,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-valeuriad-3741219622?position=8&pageNum=25&refId=bvabfaeIkTn6w1fyYCK6qA%3D%3D&trackingId=lOT9PrrG2hiHK9%2BBwW%2FxsQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Rejoins la Team Data
cr√©√©e par Nicolas Greffard,
Docteur en Intelligence Artificielle
, d√©j√† compos√©e de 20 Data Scientists et Data Engineer talentueux üòç
Nous recherchons de nouvelles p√©pites pour rejoindre notre √©quipe de choc et r√©pondre aux multiples probl√©matiques Data science de nos clients nantais mais √©galement contribuer √† nos projets de R&D et travailler sur des conf√©rences incroyables (DevFest, Salon de la Data) ü§©
Ta future mission si tu l'acceptes üòâ
Nous te proposons d'intervenir au sein de nos grandes DSI clientes, sur des sujets de collecte, d'alimentation et de transformation de donn√©es autour de l‚Äôintelligence artificielle.
Le job en d√©tail ü§©
Toutes Les Missions Ne Sont Pas Identiques, Mais Voici Des Exemples De Choses Sur Lesquelles Nos Data Analyst Sont Intervenus
Mettre en oeuvre des outils informatiques, des techniques et des m√©thodes statistiques pour permettre d'organiser, synth√©tiser et traduire efficacement des donn√©es ;
Fournir un appui analytique √† la conduite d'exploration et √† l'analyse complexe de donn√©es ;
Cr√©er des algorithmes de recherche de donn√©es qui permettent d'explorer les donn√©es utiles ;
Proc√©der √† l'industrialisation du proc√©d√© pour les donn√©es les plus int√©ressantes. Et organiser, synth√©tiser et traduire les informations pour faciliter la prise de d√©cision ;
G√©rer les op√©rations et l'administration, la mod√©lisation et l'architecture des sources de donn√©es. Et s'assurer que les bases de donn√©es existantes soient op√©rationnelles et int√®gres ;
Donner un sens aux donn√©es √† l'aide de ses connaissances analytiques (SQL, analytics/BI, statistiques basiques) ;
D‚Äôint√©grer de nouveaux jeux de donn√©es (Open Data, crowd sourcing, API, fichiers, etc.).
Nous intervenons sur
des donn√©es Big Data
(Hadoop, Hive, Spark, etc...), NoSQL (Neo4j, Redis Graph, Redis, mongo) avec toujours quelques bases de donn√©es Oracle ind√©boulonnables. Mais aussi r√©guli√®rement sur des environnements
Cloud
(principalement AWS et GCP). C√¥t√© outillage et ETL, les missions r√©centes √©taient principalement sur Informatica, Dataiku et Dig Dash. A retenir : nous faisons de tout !
Pourquoi choisir Valeuriad ? üòä
En plus d‚Äô√™tre aujourd‚Äôhui un acteur nantais reconnu de l‚Äôexpertise IT, nous nous inscrivons depuis notre cr√©ation dans une d√©marche d'entreprise
Opale
et
Holacratique
, o√π l'ensemble de nos prises de d√©cisions et projets sont r√©alis√©s par et avec l'ensemble de nos 120 co√©quipiers üí™
Rejoindre Valeuriad, c'est
pouvoir s'investir dans la co-construction
de l'entreprise :
Par un r√¥le, avec une fiche de poste et un temps d√©di√© (gestionnaire des Ci‚Äôs, porteur des partenariats √©coles, organisateur d‚Äô√©v√©nements, PO des projets internes, gestion de l'Acad√©mie Valeuriad‚Ä¶).
Par les projets strat√©giques (200 jours mis √† disposition pour les co√©quipiers chaque ann√©e) pour cr√©er et faire grandir des projets structurants (cr√©ation de nouveaux avantages √† l'anciennet√©, cr√©ation d'indicateurs mensuels pour √™tre toujours plus transparents, m√©c√©nat de comp√©tences pour des associations caritatives...).
Par les projets cagnottes (150‚Ç¨ par co√©quipiers et par an) pour r√©aliser des projets collaboratifs qui te tiennent √† c≈ìur avec d'autres Valeurieux (d√©couverte du c√©cifoot, challenge √©cologique, challenges sportifs pour des dons √† des associations humanitaires, borne photo...).
Par les ateliers collaboratifs, chaque mois des brainstorming et ateliers de travail sont propos√©s par les diff√©rents porteurs de projets et sont ouverts √† tous les volontaires.
Mais avant-tout nous sommes une
√©quipe soud√©e
, des coll√®gues qui appr√©cient passer du temps ensemble lors de nos soir√©es hebdomadaires et se cr√©er des souvenirs inoubliables ü§© C'est pour √ßa que chez Valeuriad, le plus important pour nous reste le savoir-√™tre : des passionn√©s, du dynamisme, des sourires, de l'√©coute et le sens de la f√™te üòâ
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'Neo4j'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Statistiques', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (M/F),SESAMm,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-m-f-at-sesamm-3771461770?position=9&pageNum=25&refId=bvabfaeIkTn6w1fyYCK6qA%3D%3D&trackingId=oH%2FhN4EBRj4DmceeTT87Lw%3D%3D&trk=public_jobs_jserp-result_search-card,"SESAMm
SESAMm (www.sesamm.com) extracts behavioral insights from millions of unstructured text data sources across the public internet in over 100 languages, helping clients distill valuable intelligence on businesses and their customers to make investment decisions and manage risk.
We work with many well-known firms around the world in private equity, investment banking, insurance, and asset management to apply Natural Language Processing and Artificial Intelligence algorithms to track e-reputation, competitive positioning, sentiment analysis, risk and ESG factors.
SESAMm is growing quickly, with over 90 team members around the globe and offices in Paris, New York, London, Metz, Tunis, and Tokyo.
Key technologies: Alternative Data, Natural Language Processing, Machine Learning and Quantitative Analysis.
Are you looking for a new challenge? Do you dream of joining a growing company, proposing new ideas, and taking part in innovative processes?
At SESAMm, everyone brings their ideas, skills, and creativity. We value collaboration, support and teamwork. We learn every day from the experience of this great team and we constantly take up new challenges. We are proud of the work accomplished and to participate in the success of this great adventure!
The Data Engineer Role
As a Data Engineer, you will build and scale data components to key SESAMm products, such as raw data ingestion pipeline, job scheduling and ETL design/optimization,t optimize cloud solutions for Product Data Platform, and set up the best data development practices for other tech members. Communicate the work of your team with weekly updates.
You're joining a team that is already highly dynamic and adaptable, ready for expansion. This is a chance for you to play a key role in influencing and shaping the team's culture.
Key Activities
‚ùñ Design and implement best data pipeline for our Text-based products (ingestion, processing, exposition) :
Test and design state-of-the-art data ingestion pipelines
Implement efficient streaming services
‚ùñ Take part in the acquisition of new data sources
For each new data source, describe its feasibility and potential
Create and maintain data collection and centralization pipelines
Integration of data enrichment modules created by Data Scientists
‚ùñ Develop data request tooling for Technical teams
Ease the use of data requesting engines
Optimize architecture and data pipelines
‚ùñ Implement and maintain critical data systems
Process and integrate data in our systems
Ensure maintainability and efficiency
Used technologies : PySpark, AWS EMR, Databricks, SQL, MongoDB,,, An excellent level of English proficiency, very good interpersonal skills and strong motivation are required. The candidate will need to demonstrate autonomy and innovation in the face of a constantly changing environment. The list of tasks described is not necessarily exhaustive and may be modified according to the constraints of the company and the evolution of its needs.
Desired Background and Skills
Education
Engineering school/university with specialization in IT, software engineering or data science. Other types of profiles are welcome to apply as long as they have significant IT experience
Experience
At least 3 years of experience in data engineering with a successful implementation of a cloud-based data processing pipeline
Skills
Good understanding of different databases and data storage technologies
Very good knowledge of distributed computing systems, such as Spark
Good knowledge of cloud computing systems, such as AWS, GCP, Azure ML
Development: Be at ease with Python
Good communication and popularization skills: understand technical team needs and issues, collaborate with several internal teams. Team player.
Additional skills: strong interest in Data Science / Natural Language Processing.
You should be able to work in a product team and show high motivation. This job requires autonomy, curiosity toward a changing environment and real dedication to solving problems for clients
Benefits of Working at SESAMm
Flexibility:
Team members can work remotely and have the opportunity to work with colleagues around the world.
Work environment:
SESAMm is multicultural, with technology, sales, and management teams in the US, France, and Tunisia making important contributions to the company's growth.
Career development:
SESAMm is growing quickly, which means the opportunities for your own growth are continually expanding, and that you can shape the company's culture and evolution.
Professional evolution:
SESAMm values training and knowledge-sharing. We organize internally and externally led training sessions and pay for access to educational platforms.
Transparency:
You will be kept apprised of the company's continuing evolution and performance through monthly ""Ask Me Anything"" meetings, frequent business/finance updates, and strategy-sharing discussions.
Well-being:
Building a good culture is key to building a good business at SESAMm. We focus on being a learning organization that values and supports teamwork, thoughtfulness, and work/life balance.
Job Specifics
Location: Paris or Metz
Duration: Permanent contract
Type of contract: Full time
Start Date: As soon as possible
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Teamwork', 'Creativity', 'Collaboration', 'Organization', 'Flexibility', 'Interpersonal Skills']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Analyst / Analytics Engineer (H/F),METEOJOB by CleverConnect,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-analytics-engineer-h-f-at-meteojob-by-cleverconnect-3902873375?position=10&pageNum=25&refId=bvabfaeIkTn6w1fyYCK6qA%3D%3D&trackingId=HEC1%2BOT9CwGgp%2Bz4EHoEpQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Entreprise
Description de l'entreprise
CleverConnect est une scale-up franco-allemande de la HR Tech en croissance fond√©e il y a 10 ans par des ing√©nieurs. Nous sommes pr√©sents en France et Allemagne. Depuis la fusion avec Talentry en 2022, nous partageons l'ambition de devenir le leader des software solutions du Talent Acquisition en Europe
Nous accompagnons actuellement plus de 10 millions de candidats par an √† trouver le bon poste Pour cela, nous mettons en relation les recruteurs et les candidats avec des solutions digitales et des plateformes SaaS innovantes pour rendre le processus de recrutement plus efficace. Nos technologies permettent aux candidats de trouver des opportunit√©s plus cibl√©es et de valoriser leur personnalit√© et motivation
Rejoignez notre √©quipe internationale de 200 coll√®gues qui partagent la m√™me culture et les m√™mes valeurs, et qui sont pleinement engag√©s dans un projet √† fort impact soci√©tal
Si vous voulez en savoir plus : www.cleverconnect.com
Description Du Poste
Description du poste
En tant que Data Analyst, quelles seront vos responsabilit√©s ?
Collaborer avec les d√©partements Product, Sales, Marketing et Communication pour comprendre les besoins m√©tier et les traduire en solutions de donn√©es.
Impl√©menter et optimiser des mod√®les de donn√©es √† l'aide de DBT et garantir la qualit√© et l'int√©grit√© des donn√©es. Vous serez en charge de transformer et mettre en forme les donn√©es du datawarehouse en approche ELT.
Utiliser BigQuery et DBT pour analyser de grands ensembles de donn√©es et en tirer des insights exploitables.
Cr√©er et maintenir des rapports et des tableaux de bord dans des outils de dataviz type Looker Studio, Superset, PowerBI ou Metabase. Ces tableaux de bords peuvent concerner les besoins internes (product, communication, marketing, sales, etc.) et externes (embedded dans nos solutions √† destination des clients).
Participer √† la conception des pipelines d'ingestion de donn√©es avec le Data Engineer.
Effectuer des analyses ad hoc et fournir des recommandations bas√©es sur les donn√©es pour soutenir les d√©cisions m√©tier.
Qualifications
Description du profil :
Qui √™tes-vous ?
Vous avez au moins 5 ann√©es d'exp√©rience en tant que Data Analyst dans un environnement similaire.
Techniquement et id√©alement ,
Ma√Ætrise avanc√©e de SQL et exp√©rience de travail avec des ensembles de donn√©es √† grande √©chelle.
Exp√©rience pratique avec BigQuery, DBT ou √©quivalents requis. Exp√©riences Snowplow et Elasticsearch appr√©ci√©es.
Familiarit√© avec les outils de visualisation de donn√©es tels que Looker Studio, Superset, PowerBI ou Metabase.
√ätre √† l'aise dans le scripting python pour automatiser certaines transformations de donn√©es.
Avoir d√©j√† manipul√© un outil de Web Analytics tel que Google Analytics.
Exp√©rience dans un environnement Agile et capacit√© √† travailler en collaboration dans des √©quipes interfonctionnelles.
Q
ue trouverez-vous chez CleverConnect ?
Une √©quipe dirigeante accessible, bienveillante et √† l'√©coute
Des bureaux au c≈ìur des villes et la possibilit√© de faire du t√©l√©travail
Des opportunit√©s de formation, d'√©volution et de mobilit√© en Europe
RTT, mutuelle, carte d√©jeuner, remboursement 50% transport, forfait mobilit√© durable
Notre Processus De Recrutement Comprend
Entretien initial avec un Responsable de l'Acquisition de Talents
Entretien avec le Manager (d√©couverte/√©valuations techniques)
Dernier entretien avec le Directeur IT ou CPTO.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '10', '10', '10']}"
Data Engineer - H/F,Free Pro,"Marseille, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-free-pro-3861276685?position=1&pageNum=27&refId=Uq1oQzOiE7s5uwPCeaspnQ%3D%3D&trackingId=8580IxIBEcGpb2%2B5NQW08Q%3D%3D&trk=public_jobs_jserp-result_search-card,"Au sein de la Direction Technique & innovation, dans le service recherche et innovation, vous travaillez sur des projets d‚Äôenvergure, notamment autour de la 5G et du Edge. Ce p√¥le d‚Äôinnovation d√©friche et pr√©pare les technologies de demain, le tout dans un contexte de croissance avec une forte composante technique. Dans une √©quipe d‚Äôing√©nieurs experts FULL STACK passionn√©s dans les d√©veloppements Back / Front / DevOps / Syst√®me / Embarqu√© ainsi que PO / CP, vous int√©grez une √©quipe dont le moteur est sa capacit√© √† apporter des r√©ponses techniques innovantes en rupture de l‚Äôexistant, via des POC fiables et rapides, qui pr√©figureront les produits Free Pro de demain.
Vos Missions
D√©velopper les solutions techniques de collecte, stockage et transformation de la donn√©e, dans un contexte MLOps :
Ma√Ætrise avanc√©e des langages de programmation pour le traitement des donn√©es, tels que Python, et SQL
Capacit√© √† construire et √† maintenir des architectures de donn√©es robustes et des pipelines de donn√©es √©volutifs
Exp√©rience approfondie avec les syst√®mes de gestion, le maintien et la documentation de base de donn√©es (SQL, NoSQL) et des outils d'extraction de donn√©es.
Exp√©rience dans la manipulation et l'analyse de grands ensembles de donn√©es (Big Data) avec des outils tels que Hadoop, Spark, ou Kafka
Industrialiser et automatiser le nettoyage de la donn√©e
Mettre en place et maintenir les batchs, c‚Äôest-√†-dire les automatisations d‚Äôune s√©rie de traitements en vue de l'int√©gration dans des mod√®les statistiques
Compr√©hension des algorithmes d'apprentissage automatique et de leur mise en ≈ìuvre pratique
G√©rer le cycle de vie de la donn√©e conform√©ment √† la politique de gouvernance des donn√©es de l'entreprise (RGPD...)
R√©aliser les tests unitaires et d‚Äôint√©gration
Assurer le suivi de production et la maintenance
De formation Bac+3 √† Bac+5, vous justifiez d‚Äôune exp√©rience r√©ussie sur ce type de poste. Si vous souhaitez monter en comp√©tence sur la technique et √©voluer dans un environnement en perp√©tuel √©volution, ce poste est fait pour vous.
Comp√©tences Requises
Comp√©tences solides en statistique et en mod√©lisation math√©matique en vue de l'int√©gration dans des mod√®les de Machine Learning
Aptitude √† travailler avec des outils de visualisation de donn√©es comme Matplotlib, Seaborn, Tableau, Power BI.
Des connaissances sp√©cifiques dans les domaines de la 5G du Edge computing ou de l‚ÄôIA seraient un atout suppl√©mentaire.
Autonomie et prise d‚Äôinitiative
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI', 'Matplotlib', 'Seaborn'], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'ML', 'Machine Learning', 'Statistiques'], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': ['Full'], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5', 'Bac+3'], 'Experience': ['a', 'n', 's']}"
DATA ENGINEER ‚Äì F/H ‚Äì ALTERNANCE,La Mutuelle G√©n√©rale,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-f-h-%E2%80%93-alternance-at-la-mutuelle-g%C3%A9n%C3%A9rale-3909189678?position=2&pageNum=27&refId=Uq1oQzOiE7s5uwPCeaspnQ%3D%3D&trackingId=t8Ie4MR4QMK2e8YkVMymPA%3D%3D&trk=public_jobs_jserp-result_search-card,"A PROPOS DE NOUS
D√©butez ou faites √©voluer votre carri√®re
au sein d‚Äôun acteur singulier de l‚Äô√©conomie sociale et solidaire,
avec un m√©tier et une culture qui vous ressemblent!
La possibilit√© de t√©l√©travailler de 1 √† 4 jours par semaine, selon la fonction et l‚Äôorganisation du site, permet √† nos 1900 collaborateurs de
b√©n√©ficier d‚Äôun cadre de travail source de sens, de confiance mutuelle et de responsabilisation
.
89% d‚Äôentre eux recommandent La Mutuelle G√©n√©rale !
Posez vos questions √† nos ambassadeurs ici:
https://lamutuellegenerale.career-inspiration.com/
VOTRE ENVIRONNEMENT DE TRAVAIL
La Direction des Syst√®mes d‚ÄôInformation est un partenaire aupr√®s des M√©tiers et a pour ambition de leur d√©livrer l‚Äôoffre, la valeur ajout√©e, les services et les comp√©tences. Dans ce contexte, nous renfor√ßons l‚Äô√©quipe Datalake de la Direction des Syst√®mes d‚ÄôInformation en recrutant un(e) apprenti(e) Data Engineer.
MISSIONS
Vous identifiez et vous r√©pondez aux besoins des directions fonctionnelles ;
Vous participez √† la conception et au d√©veloppement des solutions performantes pour la construction, la maintenance et l'enrichissement du Datalake de la Mutuelle G√©n√©rale ;
Vous participez au d√©veloppement et √† l‚Äôindustrialisation des projets Data Sciences avec les m√©thodologies Agiles et DevOps ;
Vous contribuez ainsi √† des uses case innovants ;
Vous assurez une veille technologique autour de l'√©cosyst√®me Big Data.
CE QUE VOUS POUVEZ ATTENDRE DE NOUS
Une mont√©e en comp√©tences sur des technologies r√©centes et innovantes
Un r√©el accompagnement pour d√©couvrir le m√©tier de Data Engineer
Un environnement de travail bienveillant et responsabilisant
Jusqu‚Äô√† quatre jours de t√©l√©travail par semaine
VOS ATOUTS POUR REUSSIR
Formation:
De formation sup√©rieure BAC + 4/5, vous avez une app√©tence pour travailler dans un environnement Data/BIG Data (AWS, Snowflake, Python, Spark, SQL ‚Ä¶)
Dans votre bo√Æte √† outils:
De nature curieuse, vous appr√©ciez prendre des initiatives
Autonome, vous √™tes capable de remonter les difficult√©s / alertes
Structur√©(e), vous avez une bonne capacit√© d‚Äô√©coute, d‚Äôanalyse et de synth√®se
Rigoureux(se), vous savez prioriser et trouver sans cesse des axes d‚Äôam√©lioration
Si vous vous reconnaissez, alors n‚Äôh√©sitez plus, postulez et rencontrons-nous au plus vite !
Contrat
{{:}}
Apprentissage 12 ou 24 mois, √† compter de septembre 2024
Lieu de travail:
75013 - Paris
Vous trouverez √©galement chez nous:
Open travail, Tickets restaurant, RIE, Mutuelle, Remboursement transport, ‚Ä¶
Mots cl√©s: #devops, #bigdata, #assurance, #alternance
Pour aller plus loin, visionnez cette vid√©o
https://www.youtube.com/watch?v=GdYDg60Ryus
et/ou rendez-vous sur
https://www.lamutuellegenerale.fr/ et https://www.lamutuellegenerale.fr/les-salaries-de-lamutuelle-generale-plebiscitent-lopen-travail-et-pres-de-9-sur-10-la-recommandent
Conform√©ment aux engagements pris par La Mutuelle G√©n√©rale en faveur de l'int√©gration des personnes en situation de handicap, le poste propos√© est ouvert √† tous.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Ing√©nieur data Spark exp√©riment√© (F/ H),Thales,"V√©lizy-Villacoublay, √éle-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-spark-exp%C3%A9riment%C3%A9-f-h-at-thales-3886251447?position=3&pageNum=27&refId=Uq1oQzOiE7s5uwPCeaspnQ%3D%3D&trackingId=oSyZoLohhtClt8DitaAKHw%3D%3D&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?
Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr√©sents sur tous les continents. Le Groupe investit dans les innovations du num√©rique et de la ¬´ deep tech ¬ª ‚Äì big data, intelligence artificielle, connectivit√©, cybers√©curit√© et quantique ‚Äì pour construire un avenir de confiance, essentiel au d√©veloppement de nos soci√©t√©s, en pla√ßant l‚Äôhumain au c≈ìur des d√©cisions.
Thales propose des solutions, services et produits qui aident ses clients ‚Äì entreprises, organisations, Etats ‚Äì dans cinq grands march√©s vitaux pour le fonctionnement de nos soci√©t√©s : identit√© et s√©curit√© num√©riques, d√©fense, a√©ronautique, espace, et transport.
QUI ETES-VOUS ?
Dipl√¥m√© d‚Äôun Bac+5 en √©cole d‚Äôing√©nieur ou √©quivalent universitaire avec une sp√©cialisation en informatique, vous avez au moins 5 ans d'exp√©rience dans les technologies Big Data.
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
En tant que Data Engineer, vous jouerez un r√¥le cl√© dans la conception, le d√©veloppement et la maintenance de notre infrastructure de donn√©es, ainsi que dans la transformation et la gestion des flux de donn√©es.
VOS MISSIONS :
‚Ä¢ Concevoir, d√©velopper et d√©ployer des solutions Big Data en utilisant les technologies Spark.
‚Ä¢ Mettre en place des pipelines de donn√©es performants pour l'ingestion, le traitement et le stockage des donn√©es massives.
‚Ä¢ Collaborer √©troitement avec les √©quipes m√©tier pour comprendre leurs besoins en mati√®re d'analyse de donn√©es et proposer des solutions adapt√©es.
‚Ä¢ Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn√©es.
‚Ä¢ Assurer la qualit√© et la fiabilit√© des donn√©es trait√©es, en mettant en place des processus de validation et de nettoyage.
‚Ä¢ Identifier et r√©soudre les probl√®mes li√©s √† l'infrastructure Big Data et proposer des am√©liorations.
‚Ä¢ Travailler en √©troite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents √† partir des donn√©es.
Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Engineer (F/H),Akuo,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-akuo-3905522805?position=4&pageNum=27&refId=Uq1oQzOiE7s5uwPCeaspnQ%3D%3D&trackingId=IwoO0Zykt%2F%2BB1AG8NMgw8g%3D%3D&trk=public_jobs_jserp-result_search-card,"Fond√© en 2007, Akuo est un producteur ind√©pendant d‚Äô√©nergie renouvelable implant√© dans plus d'une vingtaine de pays √† travers le monde. Le Groupe est pr√©sent sur l‚Äôensemble de la cha√Æne de valeur : d√©veloppement, financement, construction et exploitation de centrale d‚Äô√©nergie solaire, √©olienne et de stockage.
Les √©quipes d'Akuo allient pertinence technologique, valeur ajout√©e environnementale et gain soci√©tal pour d√©velopper des projets exemplaires et porteurs de sens dans les territoires. Le Groupe est notamment le pionnier de l'agrivolta√Øsme, des solutions de stockage et a √©t√© le premier √† d√©velopper des centrales solaires flottantes de grande envergure en France.
Fid√®le √† ses valeurs et ses convictions, Akuo est une entreprise responsable, attach√©e √† la diversit√© de ses √©quipes, engag√©e et d√©termin√©e dans l'inclusion de tous.
Description du poste
Le poste est √† pourvoir √† Paris, dans le d√©partement IT/OT d'Akuo, et plus particuli√®rement au sein du p√¥le Data, dont l‚Äôobjectif est de construire et faire √©voluer la strat√©gie ‚Äòdata‚Äô du groupe.
En tant que Data Engineer, vous ferez √©voluer la base de donn√©es d‚ÄôAkuo. Vous aurez pour objectif de faciliter l‚Äôexploitation de ces donn√©es en optimisant tout le chemin de la donn√©e, de l‚Äôextraction jusqu‚Äôau stockage et au nettoyage de la donn√©e.
Vos
missions op√©rationnelles
seront les suivantes:
BUILD :
Mise en place de l'architecture Data : concevoir et mettre en place les flux d'int√©gration de donn√©es,
R√©pondre aux demandes du m√©tier (√©quipes techniques et supports)
:
participer √† toutes les phases de projets, de l'analyse des besoins √† la r√©alisation des tests tout en respectant les crit√®res de qualit√©, de d√©lai et de co√ªt.
RUN :
Traitement, structuration et transformation de donn√©es (Python),
Collecter en temps r√©el, stocker et mod√©liser les donn√©es issues des centrales √©lectriques (Time Series) en relation avec nos √©quipes op√©rationnelles,
Assurer un support technique sur les probl√©matiques Data : remont√©e des tickets.
Qualifications
Nous sommes √† la recherche d‚Äôun profil junior qui aurait entre 2 et 3 ans d‚Äôexp√©rience, alternance incluse, au sein d‚Äô√©quipe ‚Äòdata‚Äô.
Python & SQL: vous savez coder. Vous connaissez et savez lancer des proc√©dures stock√©es,
Maitrise des concepts de mod√©lisation de donn√©es et de conception d'architectures Data,
Comp√©tences en gestion de bases de donn√©es relationnelles,
Langue
: La ma√Ætrise de l‚Äôanglais est requise pour pouvoir √©changer avec une partie de nos √©quipes qui n‚Äôest pas francophone.
Informations suppl√©mentaires
El√©ments essentiels:
La localisation: si√®ge d‚ÄôAkuo au 140 avenue des Champs-Elys√©es,
La r√©mun√©ration: fourchette entre 45k‚Ç¨ et 49k‚Ç¨ fixe selon profil + 5% de r√©mun√©ration variable,
Le type de contrat: CDI,
Le poste est ouvert au t√©l√©travail, jusqu‚Äô√† 2 jour par semaine + 10 jours flottants par an (soit 100 jours par an).
Autres avantages:
Jusqu‚Äô√† 12 jours de repos par an,
Prime vacances, ch√®ques-cadeaux,
Int√©ressement / participation,
Ticket-restaurant (10‚Ç¨ x 19 par mois) pris en charge √† 60%,
Prise en charge des transports en commun √† 75% du tarif actuellement en vigueur ou forfait mobilit√© durable,
Locaux agr√©ables avec terrasses am√©nag√©es et salle de sport.
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Junior'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
"Data Analyst ‚Äì Paris, France (H/F)",Astek,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-%E2%80%93-paris-france-h-f-at-astek-3839098102?position=5&pageNum=27&refId=Uq1oQzOiE7s5uwPCeaspnQ%3D%3D&trackingId=F63flraIlpTMmewFRIj9ZA%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Paris - France
Publi√©e il y a 2 mois
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Nous rejoindre en tant que
Data Analyst (H/F),
afin d‚Äôaccompagner un op√©rateur t√©l√©coms, Leader en Europe dans la gestion de ses solutions robustes, efficientes et s√©curis√©es √† destination d‚Äôenvironnements vari√©s.
Un challenge portant sur des millions d‚Äôutilisateurs dans un environnement technique innovant, strat√©gique et o√π l‚Äôentraide et la bonne humeur priment !
Votre Mission, Si Vous L‚Äôacceptez :
Etude sur les donn√©es pour aide au cadrage du besoin M√©tier.
Force de proposition sur des solutions analytiques adapt√©es aux besoins utilisateurs (avec nos √©quipes UX).
Analyse des besoins m√©tiers, accompagnement √† la formulation et √† la d√©finition de KPI m√©tiers.
Mod√©lisation des donn√©es.
Conception de Datasets Big Query.
Conception et R√©alisation de Datamarts et de Dashboards (PowerBI / Looker)
Analyse de la qualit√© de la donn√©e source, pour challenger les √©quipes Digitales / Data Engineers.
Votre Future √âquipe :
Au sein d‚Äôun environnement riche et complexe, vous √©voluerez avec des experts passionn√©s √† la fois techniques et fonctionnels (Ing√©nieurs sp√©cialis√©s, chef de projet, scrum master, product owner ‚Ä¶).
L‚Äô√©quipe est en interaction avec des clients √† la fois internes et externes.
Votre stack de jeu
SQL ‚Äì Confirm√©
Mod√©lisation de Donn√©es ‚Äì Confirm√©
Outils de Data Viz ‚Äì Confirm√©
GCP ‚Äì Junior
Anglais ‚Äì Professionnel
Les Petits Plus Du Projet :
Vous interviendrez de A √† Z sur des projets riches fonctionnellement et ambitieux techniquement. Un challenge portant sur des millions d‚Äôutilisateurs dans un environnement technique innovant et strat√©gique.
Vous ?
Dipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieur ou √©quivalent de niveau Bac+5.
Vous justifiez id√©alement d‚Äôune exp√©rience d‚Äôau moins 3 ans d‚Äôexp√©riences sur un poste similaire ?
Vous faite preuve d‚Äôun bon relationnel et d‚Äôesprit d‚Äô√©quipe, √™tes dot√©(e) d‚Äôun excellent sens de l‚Äôorganisation et vous aimez les challenges et la r√©solution de probl√®me ?
Alors ce poste est fait pour vous, n‚Äôh√©sitez plus et rejoignez l‚Äôaventure ASTEK !
Astek
Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.
Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de
ses 7800 collaborateurs
qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.
Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.
Tous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Notre projet commun vous plait ?
Postulez √† cette annonce, et soyez transparent !
Maud, notre Talent Acquisition Referent, vous contactera pour un premier √©change.
Puis vous rencontrerez Martin, votre futur manager, avec lequel vous √©changerez autour d‚ÄôAstek, de votre parcours, de vos attentes et de votre future mission .
Enfin, vous rencontrerez J√©r√©my, notre Directeur d‚Äôagence avec lequel vous pourrez valider votre int√©r√™t et ad√©quation pour le poste et finaliser les √©l√©ments contractuels.
Nos Plus
Astek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo
Une politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversit√©
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì data ‚Äì analyst ‚Äì mod√©lisation ‚Äì donn√©es
Caract√©ristiques de l'emploi
Cat√©gorie Ing√©nieur
Job Industry T√©l√©com / M√©dia
Postuler en ligne
Nom *
Pr√©nom *
Email *
Un email valide est requis.
T√©l√©phone *
Un num√©ro de t√©l√©phone valide est requis.
Joindre un CV *
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì data ‚Äì analyst ‚Äì mod√©lisation ‚Äì donn√©es
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Big Query'], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': ['Confirm√©', 'Junior'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Lead data engineer,Ippon Technologies,Greater Tours Area,https://fr.linkedin.com/jobs/view/lead-data-engineer-at-ippon-technologies-3893228101?position=6&pageNum=27&refId=Uq1oQzOiE7s5uwPCeaspnQ%3D%3D&trackingId=7a8Vs0HE7rPte%2FjFc20ZEw%3D%3D&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ?
Ippon, c'est l‚Äô√©nergie du collectif au service de la technologie !
Nous sommes un cabinet de conseil et d‚Äôexpertise technique.
Nos √©quipes ont pour leitmotive de transformer des id√©es innovantes en solutions de haute qualit√© avec un focus particulier sur la valeur apport√©e aux utilisateurs.
Aujourd‚Äôhui, nous souhaitons recruter un Lead Data Engineer pour lancer et d√©velopper l'√©quipe data tourangelle et int√©grer la Practice Data compos√©e de 70 consultants au national.
Notre sp√©cialit√© est de r√©pondre aux enjeux de nos clients et avoir un impact fort dans leur volont√© de devenir Data-driven.
Membre de la Practice Data, le futur Lead Data Engineer apportera son exp√©rience et son mindset pour lead des √©quipes sur des missions √† forte valeur ajout√©e. Encadr√© par un mentor et le support de notre communaut√© Data dynamique, il pourra s'√©panouir sur des sujets tendance et assurera sa mont√©e en comp√©tence et celle des autres.
La communaut√© Data propose un cadre et des √©v√®nements pour faire de la veille collective, partager leurs retours d'exp√©riences, d√©battre de sujets Data, etc. Notre lead sera un acteur majeur au sein de ce cadre.
Les missions
Intervenir sur les data platforms de nos clients pour d√©velopper de nouveaux pipelines de donn√©es en appliquant les bonnes pratiques de d√©veloppements
Travailler en collaboration avec les m√©tiers, les data analystes et les data scientists pour leur fournir un support √† l‚Äôindustrialisation de leurs travaux (tests, int√©gration continue, scalabilit√© des mod√®les, craftsmanship, etc.)
S'appuyer sur des sachants Cloud Builders pour construire des assets Data sur une infrastructure r√©siliente aux petits oignons
Apporter son expertise sur un domaine en constante √©volution
Participer aux √©v√®nements internes √† la communaut√© data (BBL, webinar, datap√©ro interne, meetup, blog, dojos) et externes (Salon du Big Data, GCP Summit, Spark Summit, AWS Summit, Devoxx, workshop partenaire, meetups)
Capitaliser sur les missions et les diff√©rents √©v√®nements de la communaut√© au travers d‚Äôarticles de blogs, REX, BBL interne
Le profil recherch√©
Tu es de temp√©rament curieux, force de proposition, tu as le sens du partage, l‚Äôenvie de t'am√©liorer en continue et de participer activement √† une communaut√© data pleine de projets.
Une exp√©rience sur le cloud est un gros (gros, gros) plus, une veille active sur des sujets cloud est indispensable.
Id√©alement, notre curieux saura identifier le pok√©mon parmi cette liste et nous expliquer les autres mots qui n'en sont pas un :
Modern Data Platform
Data Warehouse
Data Lakehouse
Pikachu
Cloud Native
Serverless
Si pour toi aussi ""tout part du besoin m√©tier"", que tu t'identifies dans cette liste au p√®re no√´l et sauras nous en parler par exp√©rience :
Public Cloud Provider (AWS, GCP, Azure)
Query engine (Spark, EMR, Databricks, Starburst, Athena...)
Langage de programmation data (Python, SQL, Scala...)
Stockage (Redshift, Snowflake, BigQuery, Stockage objet S3/CloudStorage...)
Framework d'ingestion/streaming de donn√©es (Kafka, Amazon Kinesis, Google DataFlow, ...)
Outil de visualisation (Tableau, Metabase, Superset...)
Le delivery et les projets en production faisant partie de notre ADN, tu es capable de livrer du code de qualit√© dans des environnements agiles.
Les + du job
Travailler avec une √©quipe o√π tu pourras apporter tes propres id√©es !
Devenir ceinture noire en Data gr√¢ce √† notre programme d‚Äôaccompagnement de carri√®re Blackbelt ! (formations, certifications AWS/Azure, mentoring, coaching)
Une √©volution de carri√®re adapt√©e √† tes exp√©riences et tes souhaits
Le partage de connaissances (articles, meetup, blog), participation des √† conf√©rences nationales ou internationales (AWS Summit, Salon du big data)
Une charte de t√©l√©travail
Et Tours alors ?
Cr√©√©e en 2023, l‚Äôagence est en plein d√©veloppement et nous comptons sur toi pour y jouer un r√¥le majeur afin de construire l‚Äôagence qui te, et nous, ressemble. Tu int√©greras une petite √©quipe de consultants experts et passionn√©s par la technique, et o√π le partage et la bonne humeur sont de mise.
Tu l‚Äôauras compris, en tant que lead data engineer, tu seras le r√©f√©rent Data au niveau de l‚Äôagence et tu accompagneras nos prochains data engineers tourangeaux dans l‚Äôacc√©l√©ration de leur carri√®re et expertises.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
"Data Engineer, Wheat",Louis Dreyfus Company,"Villeurbanne, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-wheat-at-louis-dreyfus-company-3892567948?position=7&pageNum=27&refId=Uq1oQzOiE7s5uwPCeaspnQ%3D%3D&trackingId=1XqpxPIHqCkfK%2B%2B3ZoLmkA%3D%3D&trk=public_jobs_jserp-result_search-card,"Company Description
Louis Dreyfus Company is a leading merchant and processor of agricultural goods. Our activities span the entire value chain from farm to fork, across a broad range of business lines, we leverage our global reach and extensive asset network to serve our customers and consumers around the world. Structured as a matrix organization of six geographical regions and ten platforms, Louis Dreyfus Company is active in over 100 countries and employs approximately 17,000 people globally.
Job Description
LDC is looking for a Data Engineer to join the Global Digital Transformation and Analytics (DT & A) team of data engineering experts, supporting innovative solutions whose impact is transforming our business.
As a data engineer, you will provide the data to enable faster, better, data-informed decision-making within our business. You will be working with the
You will focus on creating high performant, easy to maintain, state of the art data pipelines, bringing data from source to insight. You will use the latest technology and you will see the impact of your work in transforming our business.
Duties & Responsibilities:
Ensure data availability, quality, and timeliness by designing and implementing performant pipelines and proactive monitoring. Ideate meaningful tests and monitoring to be proactively informed in case of data problems and to minimize regressions.
Create and maintain high quality, well documented code and data transformations to feed models and insights reliably.
Act as data steward with researchers, traders and operations to help them leverage the best data sets for their use case and the most relevant best practices to ensure data is always available
Retrieve, clean, model, transform and maintain data from many sources to better understand the factors influencing wheat global and local flows and prices
Troubleshoot and solve data issues from data ingestion to display in dashboards and reports
Provide technical support and guidance to data scientists and researchers
Experience
3-5 years of experience in technical, hands on roles
2+ years' experience in data manipulation in SQL: DB design, data modelling, data transformation pipelines, ETL, data management
2+ years‚Äô experience with Python, including data manipulation and visualization packages (e.g., Pandas, Numpy, Plotly‚Ä¶)
Experience with data visualisation tools and technologies like PowerBI, Tableau, Looker.
Data mining principles: data collection, wrangling and quality checks using multiple data systems
Experience working with cloud technologies like Azure, AWS or GCP
Experience with any of the following will be considered a plus:
Hands on experience with data storage solutions and their application: SQL, NoSQL, data lakes
Principles of modern full stack development and exposure to Python frameworks like Dash or Flask, familiarity with APIs
Agile development and DevOps tools: CI / CD pipelines, testing and monitoring best practices.
Support for business-critical data transformation and applications via monitoring and alerting, and contributing to the solution of critical incidents under time pressure
What Soft Skills will make you successful
:
Quick learner with the ability to work independently and with little prompting
Excellent communication, collaboration and engagement skills
Critical thinking, inclination to make improvements, find new ideas and challenge the status quo
Flexibility and sense of adaptability in a quick paced, constantly evolving context
Passionate about improving data literacy and spreading best practices
Ability to perform under pressure, prioritize and escalate
Strong problem solving, quantitative and analytical abilities
Fluent in English
Experience in the commodities sector is considered as a plus
Education:
A Bachelor or Master in Computer Science, Business/Management Information Systems, Computer/Systems/Industrial Engineering, Business Analytics, Data Science, Operations Research or Statistics. Other backgrounds will be considered with relevant work experience.
Additional Information
Why you should apply for this role
:
You will be working in a very concrete line of business whose impact literally feeds the world. You will get a unique point of view on major data flows of commodities around the world, including the impact of climate change and major geo political events, the importance of sustainability and regenerative agriculture.
You will become an expert of the latest cutting-edge technologies in Data Engineering, leveraging Microsoft Azure Platform, working in collaboration with a team of technology and data science experts and accessing high quality training and development opportunities
You will see the impact of your role in transforming our business
What We Offer
We provide a dynamic and stimulating international environment, which will stretch and develop your abilities and channel your skills and expertise with outstanding career development opportunities in one of the largest and most solid private companies in the world.
We offer
Competitive salary and benefits
Flexible working
Access to Training and Development
Diversity & Inclusion
LDC is driven by a set of shared values and high ethical standards, with diversity and inclusion being part of our DNA. LDC is an equal opportunity employer committed to providing a working environment that embraces and values diversity, equity and inclusion.
LDC encourages diversity, supports local communities and environmental initiatives. We encourage people of all backgrounds to apply.
Sustainability
Sustainable value is at the heart of our purpose as a company.
We are passionate about creating fair and sustainable value, both for our business and for other value chain stakeholders: our people, our business partners, the communities we touch and the environment around us
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'PowerBI', 'Plotly'], 'Statistics': ['Statistics'], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Cloud', 'CI / CD'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Adaptability', 'Problem Solving', 'Collaboration', 'Organization', 'Flexibility', 'Initiative', 'Critical Thinking']}","{'JobDetail': ['Full'], 'TypeContract': [], 'Salary': ['Salary', 'Package'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer H/F,ELOSI,"Villeneuve-d‚ÄôAscq, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-elosi-3842107940?position=8&pageNum=27&refId=Uq1oQzOiE7s5uwPCeaspnQ%3D%3D&trackingId=LEzdD9K6u9P8NJ4vMYEhtg%3D%3D&trk=public_jobs_jserp-result_search-card,"A propos d'Elosi
Cr√©√©e en 2005, Elosi r√©unit maintenant 120 collaborateurs pour mener √† bien les projets digitaux de ses clients depuis leurs locaux ou depuis notre centre de service et R&D √† Villeneuve d‚ÄôAscq.
Le poste et vos missions
Pour l'un de nos clients grand compte de la m√©tropole lilloise, nous recherchons un data engineer. Vous travaillerez en collaboration avec les √©quipes de d√©veloppement.
Vos missions
:
Correction et cr√©ation des nouvelles features d'int√©gration de donn√©es sur plusieurs produits digitaux ;
Cr√©ation des pipeline d'int√©gration des donn√©es stambia ou outils internes vers google BigQuery ;
Mise en place des dashboard powerBI ;
Transformation des donn√©es en √©laborant des mod√®les conceptuels.
L'environnement technique
Stambia, Google BiQuery, PowerBI
Votre profil
De formation sup√©rieure en informatique, vous avec une exp√©rience en d√©veloppement de flux Stambia d'au moins 2 ans, vous connaissez Google BigQuery.
Vous aimez ""pr√©parer"" les donn√©es brutes, faciliter leur exploitation et les rendre ""propres"" pour l'analyse qui suivra.
Votre anglais est op√©rationnel.
Nous rejoindre, c'est :
Rejoindre une communaut√© de passionn√©s et la participation √† des conf√©rences techniques (DevoXX, DevFest Lille, atelier LiveCoding, Pair programming, Ap√©r‚ÄôOps‚Ä¶) ;
De la convivialit√©, du partage, de la proximit√© ;
Des perspectives d‚Äô√©volutions tant technique que m√©tier !
Des avantages : carte restaurant, formations, primes‚Ä¶
Si ce poste vous anime, n'h√©sitez plus et postulez !
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Data Engineer Snowflake/ Azure Senior F/H,NODYA Group - Digital Services,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-snowflake-azure-senior-f-h-at-nodya-group-digital-services-3911222296?position=9&pageNum=27&refId=Uq1oQzOiE7s5uwPCeaspnQ%3D%3D&trackingId=5UYfKxaHdBePWNbdCSMLqg%3D%3D&trk=public_jobs_jserp-result_search-card,"Les missions du poste
Nous cherchons un Data Engineer Snowflake/ Azure Senior pour rejoindre l'√©quipe Data Factory d'un grand leader fran√ßais, situ√© en √éle-de-France. Ce r√¥le implique la responsabilit√© de nouveaux d√©veloppements de pipelines de donn√©es, en adh√©rant aux normes, meilleures pratiques, et principes CI/CD complets.
Responsabilit√©s :
Cr√©ation et modification d'objets de base de donn√©es Snowflake (bases de donn√©es, tables, vues, etc.).
D√©veloppement de proc√©dures stock√©es Snowflake avec SQL & Javascript.
Mise en ≈ìuvre de l'environnement de d√©veloppement vers l'environnement de production, en suivant le processus CI/CD.
Garantir un haut niveau de service, incluant la d√©finition, la construction, l'ex√©cution, et la gestion des incidents.
Garantir une qualit√© irr√©prochable des codes fournis par l'√©quipe de d√©veloppement.
Le profil recherch√©
Dipl√¥me d'ing√©nieur Bac+5 en informatique.
Plus de 5 ans d'exp√©rience hors alternance et stage dans un poste similaire.
Une exp√©rience dans le d√©veloppement SQL et une ma√Ætrise en technologies de plateformes de donn√©es (Snowflake, Azure SQL, MS SQL, etc.).
Exp√©rience avec Azure DevOps et familiarit√© avec d'autres produits et technologies Azure (ADLS Gen2, Azure Data Factory, Azure Function, Azure Logicapp, Azure batch, ...).
Comp√©tences en programmation Javascript appr√©ci√©es mais non obligatoires.
Anglais courant indispensable pour collaboration avec des √©quipes internationales.
Connaissance des m√©thodologies Agile et outils tels que JIRA.
Qualit√©s attendues :
Autonomie et confort dans le soutien aux besoins en donn√©es de plusieurs √©quipes.
Capacit√© √† op√©rer techniquement d√®s le premier jour et √† soutenir le d√©veloppement de profils juniors.
Excellentes comp√©tences en communication et en formalisation.
Bienvenue chez NODYA Group
Chez NODYA Group, votre parcours vers l'excellence et l'innovation commence d√®s le premier jour. Fond√© sur la conviction que la Data et l'IA sont les catalyseurs de la transformation num√©rique, NODYA Group s'est positionn√© comme un pionnier, anticipant l'essor de l'IA d√®s 2016 et int√©grant cette vision √† l'ensemble de nos strat√©gies. En tant que membre de notre √©quipe, vous contribuerez √† guider nos clients-partenaires √† chaque √©tape de leur √©volution dans l'univers de la Data et de l'IA pour cr√©er un impact business positif et durable.
Votre avenir chez nous est non seulement une promesse de croissance mais aussi une opportunit√© de faire partie d'une vision qui valorise la cr√©ativit√©, le professionnalisme, l'√©quilibre et l'encouragement, des valeurs qui fa√ßonnent l'exp√©rience que nous offrons √† nos clients et collaborateurs.
Chez NODYA Group, vous serez au centre d'une culture d'entreprise dynamique et visionnaire, o√π chaque projet est une aventure, chaque d√©fi une chance d'innover. Vous serez entour√© par une √©quipe dirigeante qui valorise l'excellence, la proximit√© et le d√©veloppement durable des comp√©tences, dans un environnement o√π le mentoring et le d√©veloppement personnel sont cl√©s.
Si vous √™tes pr√™t √† exploiter le plein potentiel de la Data et de l'IA, √† transformer les entreprises et √† d√©velopper une carri√®re sans pr√©c√©dent, NODYA Group est l'endroit o√π vous devez √™tre. Rejoignez-nous et ensemble, fa√ßonnons l'avenir de la technologie et du business. Parlons de votre projet, parlons de votre carri√®re ‚Äì votre aventure commence maintenant chez NODYA Group.
Show more
Show less","{'ProgLanguage': ['Java', 'R', 'JavaScript'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['JIRA'], 'Other': ['DevOps', 'CI/CD'], 'FrSoftSkills': ['Communication', 'Cr√©ativit√©', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': ['Junior', 'Senior'], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Analyst (H/F),Technology & Strategy,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-technology-strategy-3909691608?position=10&pageNum=27&refId=Uq1oQzOiE7s5uwPCeaspnQ%3D%3D&trackingId=fGc7VNvq1a5kgMCd9yukZQ%3D%3D&trk=public_jobs_jserp-result_search-card,"D√©couvrez Novencia
:
Expert en Data et Intelligence Artificielle, nous aidons nos clients √† exploiter et √† valoriser leurs donn√©es sous toutes ses formes en les accompagnant sur des projets de Data Analyse, Data Gourvernance, Data Architecture, Data Science, et Data Engineering‚Ä¶
Vous avez une solide exp√©rience de minimum 3 ans dans l'analyse des donn√©es et vous √™tes √† la recherche de nouveaux d√©fis ? N'h√©sitez plus, la suite est pour vous !
Type de contrat : CDI
D√©marrage : D√®s que possible
Lieu : Lyon
Description du poste
:
Nous recherchons un Data Analyst exp√©riment√© pour rejoindre notre √©quipe dynamique en r√©gion lyonnaise. Le candidat id√©al devrait avoir une solide exp√©rience dans l‚Äôanalyse de donn√©es, ainsi que des comp√©tences techniques en SQL, Python et Power BI (ou tout autre outil de visualisation de donn√©es).
En qualit√© de Data Anlayst (H/F)*, vous serez en charge de :
Collecter, nettoyer et analyser des donn√©es commerciales provenant de diff√©rentes sources.
Cr√©er des rapports et des tableaux de bord pertinents pour les √©quipes op√©rationnelles et de gestion.
Identifier les tendances, les opportunit√©s et les domaines d‚Äôam√©lioration √† partir des donn√©es.
Collaborer avec les √©quipes m√©tier pour comprendre leurs besoins et fournir des analyses approfondies.
Pr√©-requis :
Exp√©rience professionnelle de minimum 3 ans en tant que Data Analyst.
Ma√Ætrise des langages SQL et Python pour l‚Äôextraction, la transformation et l‚Äôanalyse des donn√©es.
Connaissance approfondie de Power BI ou d‚Äôautres outils de visualisation de donn√©es.
Capacit√© √† travailler de mani√®re autonome et √† communiquer efficacement avec les parties prenantes.
Vous disposez des savoir-√™tre suivants :
Ambidextre : Agile √† droite, Data √† gauche
Coordinateur.trice : man≈ìuvre un projet et une √©quipe
Fin.e connaisseur.euse : alimente, reporte et con√ßoit des entrep√¥ts de donn√©es
Diplomate : r√©sout les in√©vitables complexit√©s de la r√©alisation d‚Äôun projet d‚Äôentreprise
N√©gociateur.trice : met du tact dans chaque discussion
Tenace : un seul objectif, la satisfaction client
Notre objectif commun est de co-construire votre carri√®re en fonction de vos aspirations et de vos comp√©tences.
Contactez-moi en message priv√© ou par mail √† s.ziki@technologyandstrategy.com !
Let's make it possible #together
*Nos postes sont ouverts aux personnes b√©n√©ficiant d‚Äôune Reconnaissance de la Qualit√© de Travailleur Handicap√© (RQTH). T&S Groupe encourage la diversit√© et l‚Äô√©galit√© sur le lieu de travail. Tous les candidats qualifi√©s H/F/* sont pris en consid√©ration pour un emploi sur un m√™me pied d'√©galit√©.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer / Tech Lead,Eulidia,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-tech-lead-at-eulidia-3915040845?position=1&pageNum=30&refId=xJJSxqDLDzWu7D%2BmiW7m%2BA%3D%3D&trackingId=3o0LKiJc0VGmZOodpXCl0A%3D%3D&trk=public_jobs_jserp-result_search-card,"A propos d‚ÄôEulidia :
Eulidia est un cabinet de conseil pure-player Data nich√© au sein du 1er arrondissement de Paris, France. Depuis 2008, nous utilisons les leviers de la Data (architecture, Data ing√©ni√©rie, Data management & gouvernance, Business Intelligence) et de la Data Science (GenAI & Machine learning) pour aider nos clients √† se r√©inventer, innover et rendre leur business model plus performant.
Eulidia recherche un(e) Data Engineer/Tech Lead.
Si vous √™tes int√©ress√© √† l'id√©e de rejoindre une soci√©t√© de sp√©cialiste, partenaire des √©diteurs Data & Cloud les plus innovants (Snowflake, Google, Dataiku, Azure, Talend-Qlik ...) et par le management de projets Data complexes, cette opportunit√© est tr√®s probablement votre prochain challenge professionnel et l'occasion d'int√©grer un ecosyst√®me Data en pleine croissance.
Vos Activit√©s :
Accompagner sur le choix des technologies pour concevoir une plateforme de donn√©es r√©pondant aux diff√©rents besoins
Concevoir et maintenir des pipelines de donn√©es r√©silients et scalable (Batch et/ou streaming)
Collecter, nettoyer et transformer la donn√©e en provenance de diverses sources
D√©velopper et impl√©menter des processus de data quality et gouvernance
Travailler avec des data scientists et analysts afin d‚Äôimpl√©menter des solutions data-driven
Collaborer avec les ing√©nieurs et autres collaborateurs pour assurer la livraison des projets
Accompagner la mont√©e en comp√©tence technique de vos collaborateurs
D√©couvrez un exemple de projet auquel vous pourriez contribuer sur notre site internet :
https://www.eulidia.com/data-stories-12.html
Vous correspondez √† notre poste si :
Vous maitrisez les bases de donn√©es relationnelles et analytiques
Le data warehousing et les concepts de mod√©lisation n‚Äôont aucun secret pour vous
Vous √™tes familier voire certifi√© sur des plateformes cloud telles que AWS, Azure ou GCP
Vous avez Une bonne compr√©hension des besoins de s√©curit√© des donn√©es
Vous avez Une connaissance des technologies de big data tels que Spark et Hive.
Vos Soft skills :
Une excellente capacit√© √† r√©soudre des probl√®mes
Une bonne communication et travail d‚Äô√©quipe
Une attention au d√©tail particuli√®re et de la rigueur
De la curiosit√© et du partage de connaissances
Ce que nous offrons :
De la formation en continue via notre organisme de formation interne (certifications, 5 √† 7, conf√©rence avec les √©diteurs partenaires, squads interne)
Un accompagnement en mission et un suivi manag√©rial de proximit√© bas√© sur la performance
Les avantages de nos partenariats avec Google Cloud et Snowflake
Un espace de travail hybride, convivial et confortable au c≈ìur de Paris (baby foot, ping pong, caf√©, fruits, jeux de soci√©t√© ‚Ä¶)
Un package comp√©titif et une prime annuelle qui r√©compense la performance globale de l‚Äôentreprise
Une excellente assurance et couverture sant√© pour prendre soin de nos employ√©s
Un s√©minaire d‚Äôentreprise annuel et de nombreux √©venements afterworks
Show more
Show less","{'ProgLanguage': ['Scala', 'R', 'Go', 'HTML'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Hybride'], 'TypeContract': [], 'Salary': ['Package'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer - F/H,Niji,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-niji-3848294394?position=2&pageNum=30&refId=xJJSxqDLDzWu7D%2BmiW7m%2BA%3D%3D&trackingId=kQVKXOCWIKbTTV931R6N9g%3D%3D&trk=public_jobs_jserp-result_search-card,"Nous sommes plus qu‚Äôun simple cabinet de conseil, qu'une agence de design et qu'une soci√©t√© de mise en ≈ìuvre technologique. Nous sommes le partenaire de la transformation digitale de nos clients grands-comptes et ETI, que nous accompagnons de l‚Äôid√©e √† la r√©alit√©.
Nous associons, dans une m√™me cha√Æne de valeur, conseil en strat√©gie, design de service et design √©motionnel, management et valorisation de la donn√©e, ing√©nierie et conseil technologique, r√©alisation logicielle et expertise en cybers√©curit√©.
Notre singularit√© repose sur les talents pluriels de nos √©quipes, au service de la satisfaction et de la performance de nos clients.
Le P√¥le Data De Niji C'est Avant Tout Une √âquipe √† Taille Humaine Et Pluridisciplinaire, Compos√©e De Consultants Et Experts Qui Conseillent Et Appuient Nos Clients Sur Toutes Les √âtapes Du Cycle Des Donn√©es
de la collecte √† la valorisation dans des services innovants,
en passant par les architectures de stockage et de services.
Nos consultants sont bas√©s en Ile-de-France et en r√©gions (Nantes, Rennes, Lille, Lyon et Bordeaux).
Nos 3 directeurs : experts confirm√©s de la gouvernance des donn√©es, de la data science de l'IA et des m√©thodologies d'industrialisation de l'IA (MLOps, DataOps), recherchent de nouveaux talents tous compl√©mentaires avec plusieurs niveaux de qualification et s√©niorit√©, qui travailleront en synergie avec la large palette de comp√©tences de Niji en d√©veloppement, communication, cybers√©curit√© et en conseil.
Int√©grer le P√¥le Data de Niji c'est avoir l'assurance d'√™tre accompagn√© dans sa progression et le d√©veloppement rapide de ses comp√©tences ,vous suivez un
parcours de formation
riche et diversifi√©, visant √† vous faire rapidement monter en expertise et √† vous certifier.
En tant que
Data Engineer
, vos principales missions seront les suivantes :
Concevoir, d√©velopper et maintenir une architecture de donn√©es robuste, √©volutive et s√©curis√©e, en tenant compte des besoins sp√©cifiques des clients.
Participer activement √† la r√©daction de propositions commerciales, en contribuant aux aspects techniques (outils, make or buy ‚Ä¶) et en fournissant des estimations de projet.
G√©rer et optimiser les pipelines de donn√©es, en assurant la collecte, le stockage, le traitement et la mise √† disposition des donn√©es de mani√®re fiable et performante.
Assurer la qualit√© des donn√©es en mettant en place des contr√¥les de qualit√©, des tests et des processus de validation, conform√©ment aux exigences des clients.
Encadrer les projets de bout en bout, en veillant √† ce qu'ils soient livr√©s √† temps, dans les limites du budget afin d‚Äôassurer la satisfaction des clients.
Assurer la documentation technique, les bonnes pratiques et les standards de d√©veloppement au sein de l'√©quipe.
Profil recherch√©
Si Vous
Avez obtenu un dipl√¥me en universit√©, √©cole de commerce ou √©quivalent type bac +5
Ma√Ætrisez l'anglais √† l'√©crit comme √† l'oral
Avez de solides connaissances en architecture et en mod√©lisation des donn√©es
Ma√Ætrisez des technologies et des outils li√©s au Big Data (Hadoop, Spark, Hive, etc.)
Ma√Ætrisez les outils d‚Äôindustrialisation des pipelines data tel que docker, kubernetes, Dataiku, Jenkins‚Ä¶
Avez une exp√©rience avec les langages de programmation utilis√©s dans le domaine des donn√©es, tels que : Python,R, Scala, SQL, etc.
Avez une exp√©rience dans la conception et la mise en ≈ìuvre de pipelines de donn√©es
Avez des comp√©tences en gestion d'√©quipe et en leadership technique
Avez des capacit√©s √† r√©diger des propositions commerciales convaincantes
Alors‚Ä¶ Venez participer au dynamisme de notre site en rejoignant notre Team Data Lyonnaise !
L'aventure Niji
Process de recrutement : premier contact RH puis rencontre avec nos op√©rationnels.
Rejoindre l'exp√©rience Niji c'est avoir l'assurance de participer √† une aventure humaine dans un environnement de travail motivant, challengeant et innovant.
NijiU: notre plateforme de formation digital learning contenant pr√®s de 3 000 modules en acc√®s libre.
Nos valeurs : Audace - Bienveillance - Performance ‚Äì Talent.
Si ces mots vous parlent, venez faire la diff√©rence chez Niji !
En rejoignant Niji, vous int√©grez une entreprise dont la politique RSE contribue √† la promotion de la diversit√© et de l‚Äô√©galit√© des chances, notamment pour les personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['Big Data', 'ML'], 'FrSoftSkills': ['Communication', 'Leadership'], 'EnSoftSkils': ['Communication', 'Leadership']}","{'JobDetail': ['Confirm√©'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Python Software Engineer,Redslim,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/python-software-engineer-at-redslim-3749529490?position=3&pageNum=30&refId=xJJSxqDLDzWu7D%2BmiW7m%2BA%3D%3D&trackingId=zZI5Gfd%2BYp%2B0ns3BE0%2Fkxw%3D%3D&trk=public_jobs_jserp-result_search-card,"Salary Range:
EUR 50k-80k
About Role:
The engineer we are looking for will work in the platform developer team on all aspects of the software development cycle; design, develop, test and deploy. The work will be composed of developing a low & no-code solution that enables users to configure and run batch data operations for the purpose of data reporting & visualisation. The solution is deployed and hosted in Azure and services used include Azure Web App, Storage Accounts, Azure Data Factory and Databricks. The main programming languages used by the team are either Python or C#.
About Team:
The central mission of the Redslim Product Team revolves around developing tools and services that support Redslim's data management services. The team's collaboration extends to various business domains, both internally and externally, helping develop products that support operational activities, activation, and client reporting solutions.
Key Responsibilities:
Collaborate with cross-functional teams to understand and define data harmonisation & transformation requirements.
Design, develop, and maintain data processing libraries, pipelines using Databricks and Python.
Optimize data processes for performance and scalability.
Ensure data quality and reliability by implementing data validation and testing procedures.
Requirements:
4+ years of software development experience.
Fluent English as a working language.
Extensible experience with Databricks and Python for data engineering.
Professional experience of deploying and testing software solutions in a cloud environment (ideally Azure).
Professional experience containerising software solutions to work at scale in the cloud.
Database experience including analytical SQL queries and OLAP databases.
Nice to Have:
Domain experience involving market research and/or retail data management.
Experience with modern software development methodologies, for example Test Driven Development, Agile Scrum and Lean Software Development.
Experience using Large Language Models to enhance user experience.
Front end development experience, preferably using React.
What We Offer:
Competitive salary and benefits package.
Opportunities for professional development and growth.
A supportive and collaborative work environment.
The chance to work on meaningful projects with real-world impact.
A remote or office based working environment with irregular face to face team meetings throughout the year.
Show more
Show less","{'ProgLanguage': ['Python', 'C#', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': ['50k'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Senior Data Engineer - Snowflake,FRG Technology Consulting,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-snowflake-at-frg-technology-consulting-3904054143?position=4&pageNum=30&refId=xJJSxqDLDzWu7D%2BmiW7m%2BA%3D%3D&trackingId=kkgSmI6CEzxxiNjUPdZBcA%3D%3D&trk=public_jobs_jserp-result_search-card,"Mon client, un End User sur Paris, est √† la recherche d'un(e) Data Ops, pour intervenir sur l'ensemble de la cha√Æne d√©cisionnelle au sein du p√¥le data.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer H/F,Groupe Havana,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-groupe-havana-3913990947?position=5&pageNum=30&refId=xJJSxqDLDzWu7D%2BmiW7m%2BA%3D%3D&trackingId=4NVBmhdECDN4o9JVXvp%2F7A%3D%3D&trk=public_jobs_jserp-result_search-card,"Groupe Havana : Cr√©√© en 2011, nous incarnons la transformation digitale en misant sur l'innovation, la performance et le bien-√™tre au travail.
Notre Identit√©
200 experts d√©ploy√©s √† travers la France.
Acteurs cl√©s dans les domaines de la DATA, du Cloud et de l'intelligence artificielle.
Nous accompagnons nos clients dans la transformation digitale de leur SI
Nous recherchons un(e) data ing√©nieur(e) qualifi√©(e) pour nous aider √† concevoir, construire et g√©rer nos syst√®mes de donn√©es.
Missions
Migration des donn√©es du SI entreprise vers la plateforme de donn√©es GCP
Participer √† l'industrialisation des cas d'usage m√©tiers du groupe
Assurer la qualit√©, la fiabilit√© et l'accessibilit√© des donn√©es.
Collaborer avec les √©quipes de data science pour comprendre les besoins en donn√©es et mettre en place les solutions appropri√©es.
Assurer la maintenance et l'optimisation des syst√®mes de donn√©es existants.
Comp√©tences Attendues
Exp√©rience en ing√©nierie de donn√©es, en particulier avec les technologies de big data
Connaissances GCP Big Query
Connaissances des langages de programmation tels que Python
Exp√©rience avec les bases de donn√©es SQL et NoSQL
Connaissances des technologies de conteneurisation (Docker, Kube)
Comp√©tences des technologies de CI/CD et IaC (Gitlab, Terraform)
Capacit√© √† travailler en √©quipe et √† communiquer efficacement
Comp√©tences interpersonnelles
Avoir une capacit√© √† travailler de mani√®re autonome et √† g√©rer efficacement plusieurs t√¢ches simultan√©ment
Int√©ress√©(e) ?
Voici notre processus de recrutement apr√®s envoi de votre CV :
Un 1er √©change t√©l√©phonique avec notre responsable recrutement Vincent, d'environ 10 minutes
Un 2√®me √©change t√©l√©phonique avec l'√©quipe commerciale, Christelle, Yves ou Lucas
Un entretien physique ou en visio avec le client final et le business manager en charge de vous accompagner
Ce poste n'est pas ouvert √† l'alternance ou aux stages !
Poste ouvert aux personnes en situation d'handicap !
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Big Query'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': [], 'Other': ['Big Data', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer senior Spark / Scala,Sibylone,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-senior-spark-scala-at-sibylone-3909127442?position=6&pageNum=30&refId=xJJSxqDLDzWu7D%2BmiW7m%2BA%3D%3D&trackingId=zWRvA8cUYHO5VrPJ4rS%2BAA%3D%3D&trk=public_jobs_jserp-result_search-card,"SIBYLONE
, soci√©t√© de conseil sp√©cialis√©e dans les syst√®mes d‚Äôinformation de synth√®se et de pilotage, aide ses clients √† tirer toute la valeur de leur patrimoine de donn√©es, levier strat√©gique majeur de d√©veloppement et de rentabilit√©.
Notre ambition
: rendre les diff√©rents acteurs de l‚Äôentreprise autonomes dans l‚Äôexploitation des donn√©es, lib√©rer les usages M√©tier, pour qu‚Äôils soient en mesure de relever les d√©fis de performance, de couverture de risque, de financement, de conqu√™te client, de RSE‚Ä¶ qui s‚Äôimposent √† eux.
Sp√©cialistes reconnus,
nos consultants s‚Äôappuient pour cela sur une connaissance approfondie de l‚Äôactivit√© business de nos clients, en lien avec nos trois piliers que sont le M√©tier, la Data et le Projet.
SIBYLONE
emploie environ 250 salari√©s et r√©alise un CA de 30m‚Ç¨ dans la prestation de services aupr√®s de grandes entreprises (8 grands comptes repr√©sentant 80% du CA). SIBYLONE est une filiale du Groupe Smart 4 Engineering cr√©√© en 2020. Le groupe s‚Äôest constitu√© en proc√©dant √† l‚Äôacquisition de 12 soci√©t√©s en France (dont SIBYLONE), Italie, et en Espagne dans le domaine de l‚Äôing√©nierie. Le groupe est d√©tenu par Dzeta Conseil, acteur familial de l‚Äôinvestissement. Avec nos 3,000 ing√©nieurs / consultants hautement qualifi√©s, le Groupe offre ses services dans les domaines tr√®s porteurs du Digital, de la Data, de l‚ÄôIntelligence Artificielle, de la Cybers√©curit√©, du Cloud et des Logiciels.
Dans le cadre du d√©veloppement de notre activit√© Data, nous recherchons
plusieurs Data Engineer
√† l'aise avec spark et scala!
Le Data Engineer participe √† la conception, la construction, le d√©ploiement et le maintien en production d‚Äôarchitectures Big Data, ces derni√®res ayant pour objectif de permettre tant l‚Äô√©volution que l‚Äôoptimisation du syst√®me d‚Äôinformation d√©cisionnel existant en permettant de nouveaux usages Analytics et IA.
Vous int√©grerez une √©quipe projet Big Data dont l‚Äôobjectif premier est de conduire des projets ayant traits √† des probl√©matiques d‚Äôarchitecture et de conception dans un contexte Big Data & Cloud.
Vos missions
Analyser, comprendre et cadrer une architecture permettant de r√©pondre aux besoins m√©tiers des clients
Concevoir et mettre en place des plateformes Data en tenant compte des contraintes tant techniques que fonctionnelles
Intervenir sur la conception et le d√©ploiement d‚Äôenvironnements ¬´ clusteris√©s ¬ª (Hadoop sur des distributions telles que Cloudera ou Hortonworks) ou Cloud public
D√©veloppement de pipelines d‚Äôingestion et de pr√©paration
Gestion du stockage de donn√©es (syst√®mes de fichiers comme HDFS, bases SQL ou NoSQL)
Alimentation d‚Äôentrep√¥ts de donn√©es (Hive, Impala, ‚Ä¶)
D√©velopper des applications d‚Äôexploration et de manipulation de donn√©es (SPARK / pySpark, Scala) afin d‚Äôalimenter les flux sortants, les reporting et d‚Äôexposer les donn√©es
Evoluer sur l‚Äôordonnancement des traitements de donn√©es (Oozie, Bash / Shell)
Assurer le maintien en conditions op√©rationnelles des plateformes produites
Etablir, formaliser, et promouvoir les best practices
Pourquoi pas vous ?
Profil recherch√© :
De formation sup√©rieure ing√©nieur en Informatique, vous justifiez d‚Äôune premi√®re exp√©rience r√©ussie en data engineering acquise dans un contexte projet au sein d‚Äôune start-up, d‚Äôun pure player, ou d‚Äôune ESN.
Vous disposez d‚Äôune bonne maitrise des langages propres aux environnements Big Data tels que :
Hadoop et ses distributions
Les solutions Cloud (Azure, AWS, GPC)
Spark, Scala, Python, Unix, SQL.
Une connaissance de : Docker, ELK, Kubernetes, Cassandra, Kafka, ‚Ä¶ serait un plus, de m√™me que des fondamentaux DevOps (CI / CD).
Vous avez d√©j√† √©volu√© dans un contexte projet agile ou scrum et faites preuve de flexibilit√©, d‚Äôadaptabilit√© et savez √™tre force de proposition.
Au-del√† de vos comp√©tences techniques, vous √™tes curieux, autonome, organis√©, dot√© d‚Äôun bon sens relationnel et d‚Äôun esprit de synth√®se.
Les PLUS Sibylone !
Evoluer au sein d‚Äôune soci√©t√© qui exige le meilleur de ses collaborateurs tout en cultivant la coh√©sion et l‚Äôesprit d‚Äô√©quipe !
S‚Äôengager dans une politique RSE exigeante : labellisation Ecovadis
Avoir un Partenariat EcoTree France : 1 recrutement = 1 arbre plant√© !
Contribuer activement au bien-√™tre de ses collaborateurs : participation aux frais d‚Äôabonnements activit√©s ou achat 2 roues
Avoir de nombreux moments de convivialit√©s : s√©minaires, afterworks, conf√©rences et petits d√©jeuners, sports en groupe via l‚Äôapplication United Heroes
Donner une offre de formation innovante et √† la pointe des nouvelles technologies
Accord de t√©l√©travail en vigueur
Vous vous reconnaissez dans la description du poste ?
Vous souhaitez travailler dans un environnement stimulant et dynamique ?
Vous souhaitez rejoindre une soci√©t√© ambitieuse ?
Vous souhaitez comprendre l‚Äôorigine de Sibylone ?
Venez-nous rencontrer : L'√©quipe TA sera ravie d‚Äô√©changer avec vous !
Ce poste est ouvert aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Bash'], 'DataBase': ['SQL', 'NoSQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud', 'CI / CD'], 'FrSoftSkills': ['Adaptabilit√©', 'Flexibilit√©'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Ing√©nieur Data confirm√© F/H,Mobile Tech People,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-confirm%C3%A9-f-h-at-mobile-tech-people-3887689223?position=7&pageNum=30&refId=xJJSxqDLDzWu7D%2BmiW7m%2BA%3D%3D&trackingId=hPIySwJlTshaog2MYOJd3Q%3D%3D&trk=public_jobs_jserp-result_search-card,"Missions :
Participer √† la prise en charge du d√©veloppement et de la maintenance de l infrastructure adapt√©e √† l analyse de donn√©es (D√©veloppement de nouvelles fonctionnalit√©s via des d√©veloppements sp√©cifiques ou ETL),
Intervenir en mode support (Suivre le d√©veloppement et apporter du support aux autres d√©veloppeurs sur les solutions logicielles),
Gestion de base de donn√©es SQL sur Azure
Documenter les r√©alisations effectu√©es via des manuels d exploitation,
Cr√©ations de script python pour r√©cup√©rer les donn√©es depuis le Web Scraping
Faire les revus de codes,
Intervenir sur la mise √† jour des langages et technologie,
Cultiver des relations op√©rationnelles avec les √©quipes m√©tiers.
Formation d'ing√©nieur data juniors.
Environnement technique :
Java SE, Python, Spark, Hadoop, Hive, Scala, NoSQL, SQL, PSQL, Oracle Database, Dataiku, Informatica, Teradata, Azure, Datbricks, Git
Requirements
Description du profil
Nous cherchons une personne :
Qui a id√©alement 4 ans min d exp√©riences en tant que Data Engineer,
Ayant de solides comp√©tences en programmation et bases de donn√©es sur les technologies ci dessus ainsi qu en Math√©matiques appliqu√©es pour la construction des algorithmes,
Aimant le travail d √©quipe,
Qui cultive sa curiosit√© et se tient inform√© des √©volutions technologiques,
Autonome, autodidacte, proactive.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Junior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
DATA ENGINEER - Azure H/F,Squaar,"√âcouflant, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-azure-h-f-at-squaar-3896400467?position=8&pageNum=30&refId=xJJSxqDLDzWu7D%2BmiW7m%2BA%3D%3D&trackingId=XwQWwVcKXaNeQhtCZ50OMg%3D%3D&trk=public_jobs_jserp-result_search-card,"Nous recherchons pour notre client, √©diteur de logiciels sp√©cialis√©s, un DATA ENGINEER - Azure H/F dans le cadre d'une mission Freelance de 6 mois renouvelable plusieurs fois.
Le Poste
Lieu : ANGERS (49) ,
TJM : 500-550‚Ç¨ (frais inclus) / Jour,
Rythme : 2j sur site / semaine pendant le 1er mois?
Nous recherchons pour notre client, √©diteur de logiciels sp√©cialis√©s, un DATA ENGINEER - Azure H/F dans le cadre d'une mission Freelance de 6 mois renouvelable plusieurs fois.
Vos Missions
Au sein d'une √©quipe informatique d'une dizaine de personnes et rattach√© au CTO, vous intervenez dans une cadre d'un projet de refonte compl√®te de la plateforme du client.
Vos Missions Sont Les Suivantes
D√©veloppement et maintenance de pipelines de donn√©es sur Azure.
Mise en place d'architectures de donn√©es efficaces.
Transformation de donn√©es en temps r√©el
Validation des donn√©es selon les r√®gles m√©tier et mod√©lisation des structures.
Gestion de gros volumes de donn√©es clients.
Environnement technique : √âcosyst√®me Azure (Azure Data Factory, SQL, Azure Data Lake Store, Spark, Hive, Airflow, Python, Scala)
Vous
De formation au minimum Bac+4/5 en Informatique, vous justifiez d'au moins 3 ann√©es d'exp√©rience en Data Engineering autour de l'√©cosyst√®me Azure. (imp√©ratif).
Attention, vous serez LE r√©f√©rent sur ces sujets, votre capacit√© √† travailler de fa√ßon autonome et √† trouver l'√©quilibre entre qualit√© et efficacit√© tout en proposant des solutions fiables et durables est donc √©galement imp√©rative.
Vous √™tes int√©ress√© par le fait de r√©pondre √† des probl√©matiques techniques notamment, de qualit√©, de performance et de s√©curit√©.
Process
Apr√®s une visio avec un membre de notre √©quipe, vous rencontrez :
Le CTO et le Responsable Infrastructure en visio
D√©cision sous quelques jours
Envoyez-nous votre CV et si votre profil correspond vous serez contact√© par un membre de l'√©quipe dans les 24h.
Au plaisir d'√©voquer votre projet,
Squaar
Profil
De formation au minimum Bac+4/5 en Informatique, vous justifiez d'au moins 3 ann√©es d'exp√©rience en Data Engineering autour de l'√©cosyst√®me Azure. (imp√©ratif).
Attention, vous serez LE r√©f√©rent sur ces sujets, votre capacit√© √† travailler de fa√ßon autonome et √† trouver l'√©quilibre entre qualit√© et efficacit√© tout en proposant des solutions fiables et durables est donc √©galement imp√©rative.
Vous √™tes int√©ress√© par le fait de r√©pondre √† des probl√©matiques techniques notamment, de qualit√©, de performance et de s√©curit√©.
Environnement technique : √âcosyst√®me Azure (Azure Data Factory, SQL, Azure Data Lake Store, Spark, Hive, Airflow, Python, Scala)
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer H/F,Externatic,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-externatic-3911263499?position=9&pageNum=30&refId=xJJSxqDLDzWu7D%2BmiW7m%2BA%3D%3D&trackingId=x2FW23%2F4UjVmsyr5eUj%2F3g%3D%3D&trk=public_jobs_jserp-result_search-card,"Pr√©sentation de la soci√©t√©
Cabinet de recrutement Tech, la mission d‚ÄôExternatic est de faciliter la rencontre entre candidats et entreprises finales (hors donc 0% d'ESN). Nous mettons √† votre disposition notre r√©seau et notre connaissance du march√© de la Tech (√©tude des salaires, tendances).
Notre moteur : vous accompagner sur du long terme pour trouver l‚Äôopportunit√© en CDI, qui correspond √† votre projet professionnel, et surtout vous proposer un acc√®s privil√©gi√© √† des opportunit√©s cach√©es au sein de p√©pites (startup / √©diteur / DSI / PME).
Externatic en bref :
Plus de 13 ans de professionnalisme
+700 postes ouverts HORS ESN
33 consultants
Plus de 400 clients tous hors ESN : DSI, √©diteurs, ETI/PME, Centre R&D, Startup/scaleup, organismes publiques et para-publiques, ...
Plus de 370 candidats accompagn√©s par an
Mission
Moi c'est Hadrien, Consultant chez Externatic et j‚Äôai une offre tr√®s sympa √† te partager, surtout si tu as envie de rejoindre une aventure ambitieuse √† ses d√©buts !
Voici quelques infos ci-dessous, et je serais ravi d‚Äô√©changer ensemble plus de d√©tails !
L'entreprise
Le march√© du recrutement est au d√©but d'une grande r√©volution avec le d√©veloppement de l'IA. Cependant, beaucoup de recruteurs sont encore mal outill√©s, ou ne sont pas familiers avec ces nouvelles technologies.
C'est dans ce contexte que cette jeune startup cr√©√©e il y a un an est en train de cr√©er une solution SaaS int√©grant de l'IA d√©di√©e aux acteurs du recrutement en France puis en Europe !
En quelques mois, ils ont d√©j√† sorti un premier MVP qui est d√©j√† utilis√© chez une 30aine de clients !
La startup r√©unit une √©quipe solide de 6 personnes et un investisseur de renom qui soutient le projet.
Le poste
Tu int√®gres l'√©quipe Tech qui est compos√©e de 3 d√©veloppeurs actuellement et qui recherche son premier Data Engineer !
C'est un r√¥le crucial et cl√© qui va permettre d'aller encore plus loin au niveau de la roadmap et proposer une solution r√©volutionnaire sur le march√©.
Ton r√¥le sera de mettre en place et maintenir une infrastructure Data performante et scalable, qui sera capable de g√©rer une mont√©e en puissance au niveau des volumes de donn√©es √† capter, structurer et traiter.
Tes enjeux seront par exemple de :
Concevoir, d√©velopper et optimiser le Data Model et l'architecture Data
Mettre en place et maintenir les pipelines de donn√©es
Optimiser les performances du syst√®me (vitesse de traitement des donn√©es, capacit√© de stockage, scalabilit√©...)
Assurer la s√©curit√© et la confidentialit√© des donn√©es
Collaborer √©troitement avec les d√©veloppeurs, le fondateur et le CSM pour d√©velopper, tester et d√©ployer de nouvelles features
Environnement technique : Python, PostgreSQL, Cloud et autres technos de la stack data √† d√©finir
Profil
Tes atouts
Tu as une formation Data et une exp√©rience d'au moins 3 ans autour de sujets Data Engineering, o√π tu as travaill√© sur des projets BUILD autour des infrastructures data (cloud, pipelines, data platforms, ...)
Tu as une solide expertise en Python, SQL, et une bonnes connaissances des technos que l'on retrouve sur les stacks data modernes (par exemple AWS, GCP, Snowflake, Databricks, DBT, Airflow, ...)
Et surtout, tu as envie de rejoindre une aventure startup √† ses d√©buts et t'impliquer dans un projet passionnant !
Avantages
Conditions de travail
Localisation : Bureaux √† Nantes et Bordeaux ou full remote
R√©mun√©ration fixe : entre 45 et 50K
BSPCE
Remote friendly
Le process (rapide et efficace !)
RDV avec Hadrien d‚ÄôExternatic
Entretien avec CTO et Founder
Rencontre √©quipe
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': ['PostgreSQL', 'Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': ['CDI'], 'Salary': ['13'], 'Level': [], 'Experience': ['a', 'n', 's', '13', '13', '13']}"
Data Engineer | LLM/Python,Jus Mundi,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-llm-python-at-jus-mundi-3901457116?position=10&pageNum=30&refId=xJJSxqDLDzWu7D%2BmiW7m%2BA%3D%3D&trackingId=ZaL7tqq8Pl09fbrpRxRK5g%3D%3D&trk=public_jobs_jserp-result_search-card,"*Only applicants who send their CV on Welcome to the Jungle will be considered for this position.*
‚≠êWho We are‚≠ê
Contributing to building the rule of law internationally is everyone‚Äôs responsibility. Jus Mundi facilitates and democratizes access to global legal information with unprecedented efficiency, thanks to a search engine that combines international legal expertise with artificial intelligence.
Based in Paris and NYC, 90% of Jus Mundi‚Äôs turnover is 40% from the US and 30% from the UK.
Clients include big law firms, such as DLA Piper, Freshfields, Dentons, and legal departments of multinationals such as governments including Japan and the UK, and universities such as the Sorbonne, and Cambridge.
Our team: Vision is nothing without a team to carry it!
Our team has friendly people from diverse backgrounds who are committed and strive to be the best!
70+ Team Members, with 30+ nationalities from different backgrounds, ambitious & innovative talents in a journey to disrupt and reinvent the entire legal industry.
Be Part of This Exciting Journey. Join Our International Team.
You will live your best life while working at Jus Mundi. We work hard, and we play hard! The impact of our work is meaningful. If you would like to have a career in which you are making a real impact, join us.
‚ÑπÔ∏è Job Description:
Today, we are looking for an engineer to join our new Team to work specifically around LLMs and ship more organic experiences to our users.
We‚Äôre leveraging LLM models to revolutionize legal research and build valuable products for our users. What we‚Äôre building in the short term? We‚Äôre developing interactive assistants and agents that leverage our database and perform tasks for our users and partners. But we want to do much more!
The legal industry is being revolutionized by LLMs. Lawyers are eagerly adopting cutting-edge technologies, and we are riding this wave! The moment is now.
We mainly follow a Kanban/Lean paradigm cherry-picking Events or Artifacts from other methods to create our own practice, matching our own organization.
We have an Engineering Culture. And have some practical principles
Do what you say, Say what you do.
Communication builds Trust. Trust improves Performance.
Try, fail and, learn. Iterate until success.
Leave your ego at the door.
Big Ideas, Pragmatical Implementation.
Our technical stack:
Main: Python, Go, Nuxt.js, Vue.js, and Node.js
Databases: PostgreSQL, Elasticsearch, Neo4j and Redis
Legacy (being replaced): Symfony with JQuery
Development and CI/CD: Docker, Git and Gitlab
‚ö° Your Missions:
What you‚Äôll do:
Create, test, maintain, and consume internal & external APIs (mainly Python, a little bit of Go)
Write conception Proposals, RFC and analysis
Help to create Proof Of Concept, Minimum Viable Product
Implement new features and fix bugs
Work on LLM application (llama-3, GPT-4, Mixtral, etc‚Ä¶)
Do prompt engineering, few short learning and fine-tuning
üíº Preferred Experience & Skills:
Who you are:
You are passionate about your craft and can communicate it
You are trustworthy
You have 3+ years in your field and have worked on part of our Tech Stack
You thrive in a fast-paced environment
You are climbing the slope of enlightenment (Dunning‚ÄìKruger effect)
Having worked on at least one LLM project
Knowing how to leverage LLM
üöÄ Company Perks and Benefits:
üòç Working for a fast-growing global legal tech offering a disruptive product that is revolutionizing the way lawyers around the world interconnect and conduct legal research,
üíª Hybrid working organization, mix between remote and on-site,
üí∞Competitive salary & equity
üèñ 5 weeks of vacation
üçº Paid parental leave (under specific conditions)
ü©∫ A great complementary private health insurance (paid 100% for the employee and his children by the company)
üöä50% of public transportation reimbursed.
üç¥Personal credit card to buy lunches during the week (
Swile
)
üòç Every quarter we organize a company-wide summit to
üåç Travel (work abroad) policy: 8 weeks per year, you can live and work from where you want across the globe,
‚úàÔ∏è Relocation Package (to France)
Why us, why now?
We are structuring our organization to scale. There is a lot to do with high levels of ownership and freedom. Building and creating the practices and processes the Engineering will follow.
Confidence can sometimes hold us back from applying for a job. But we‚Äôll let you in on a secret: there‚Äôs no such thing as a ‚Äòperfect‚Äô candidate. So however you identify and whatever background you bring with you, please apply if this is a role that would make you excited to come to work every day.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'Neo4j', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': [], 'Other': ['CI/CD'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication', 'Organization']}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': ['5'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Ing√©nieur/e,AXA en France,"Nanterre, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-ing%C3%A9nieur-e-at-axa-en-france-3919473325?position=1&pageNum=32&refId=FUgWcwWTfkSy1LADz3eV7w%3D%3D&trackingId=9eIjBWMHrblYtuA%2Fvy7XHQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Votre r√¥le et vos missions
Cr√©er des outils
Etablir des cahiers des charges avec les utilisateurs, en comprenant leurs besoins pour d√©finir les solutions les plus adapt√©es
Lotir les d√©veloppements en ayant le souci de la valeur ajout√©e du 1er lot et de la coh√©rence des livraisons
D√©velopper les interfaces des applications
Mettre en place des pipelines de traitement de donn√©es (nettoyage, transformation) et des pipelines de d√©ploiement des applications sur le cloud
Assurer et garantir la production d'un code de qualit√© et de sa documentation technique
Etablir des plans de tests
Faire la maintenance des outils
Assurer la mise √† jour r√©guli√®re des outils et documents techniques
D√©velopper les usages des mod√®les de donn√©es
√ätre r√©f√©rent pour les actuaires produits vis-√†-vis de la DSI
Porter et suivre techniquement les demandes de d√©veloppements de l‚ÄôActuariat IARD Entreprises aupr√®s de la DSI
Prendre de la hauteur sur les probl√©matiques techniques afin d'orienter l'√©quipe et anticiper les blocages et risques dans les phases de d√©veloppement
G√©n√©raliser les bonnes pratiques d'industrialisation sur les diff√©rents traitements, en √©tant support p√©dagogue aupr√®s des actuaires
Votre profil
Techniques
Savoir coder en Python, R, SAS
Savoir planifier un projet informatique
Conna√Ætre Git
Comprendre le fonctionnement de l‚Äôarchitecture d‚Äôun cloud
Conna√Ætre le domaine de l‚ÄôActuariat IARD, serait un +
Relationnelles
Savoir √™tre √† l‚Äô√©coute des interlocuteurs nombreux et pluridisciplinaires (Actuariat, Directions Techniques, Informatique, Souscriptions, ‚Ä¶)
Faire preuve de pragmatisme et de souplesse d‚Äôesprit pour imaginer des solutions permettant de concilier contraintes techniques et commerciales
Esprit de rigueur et de synth√®se, sachant d√©montrer son assertivit√© et sa curiosit√©
Pourquoi nous rejoindre ?
Nous sommes persuad√©s que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs ! Les avantages que nous proposons √† nos salari√©s sont nombreux.
Nous choisir, c‚Äôest b√©n√©ficier par exemple
D‚Äôun package de r√©mun√©ration complet comprenant un salaire fixe, un compl√©ment de r√©mun√©ration variable, des primes, de la participation et de l‚Äôint√©ressement, la possibilit√© d‚Äôacqu√©rir des actions AXA, ou encore des solutions d‚Äô√©pargne avantageuses ;
D‚Äôun cadre de travail flexible jusqu‚Äô√† 3 jours de t√©l√©travail possible par semaine, des tickets restaurant pour les jours t√©l√©travaill√©s ou encore une participation √† l‚Äôachat d‚Äôun √©cran ou fauteuil ergonomique ;
D‚Äôune politique visant √† concilier vie personnelle et vie professionnelle avec 28 jours de cong√©s pay√©s, entre 14 et 16 RTT selon les ann√©es, des formules de travail √† temps partiel ou encore des jours d‚Äôabsence r√©mun√©r√©es pour la rentr√©e scolaire ou un d√©m√©nagement par exemple ;
De la possibilit√© de s‚Äôengager pour une cause qui vous tient √† c≈ìur gr√¢ce √† nos associations telles que AXA Atout C≈ìur, AXA Comp√©tences Solidaires ou encore AXA Pr√©vention ;
Et bien plus encore ! Perspectives de d√©veloppement des comp√©tences et de carri√®res immenses, CE, conciergerie, offres privil√®ges, soutien en cas d‚Äô√©preuve personnelle‚Ä¶On s‚Äôarr√™te l√†, la liste est longue
Votre environnement de travail
Notre raison d‚Äô√™tre chez AXA ? Chaque jour, nous agissons ensemble pour le progr√®s humain en prot√©geant ce qui compte. Une mission qui donne le sourire et envie de se lever le matin !
Un des leaders mondiaux de l‚Äôassurance dans la protection des biens, des personnes et des actifs, AXA c‚Äôest 145 000 collaborateurs et contributeurs qui s‚Äôengagent au quotidien pour nos clients, c‚Äôest 51 pays dans lesquels nous distribuons nos produits et services et plus de 90 millions de client qui nous font confiance dans le monde. Employeur citoyen et responsable, AXA s‚Äôengage au quotidien pour des causes soci√©tales & environnementales. Nous menons une politique inclusive engag√©e pour reconna√Ætre et valoriser les diff√©rences individuelles. Ces ambitions vous parlent ? Alors venez changer le monde avec nous !
Victime ou t√©moin, en cas de discrimination, vous pouvez adresser vos signalements et/ou alertes discrimination √† alerte.discrimination.harcelement@axa.fr
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['3', '3'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Analyst - Lyon (F/H),Novencia Group,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-analyst-lyon-f-h-at-novencia-group-3842056375?position=2&pageNum=32&refId=FUgWcwWTfkSy1LADz3eV7w%3D%3D&trackingId=pcb3zG3EL0bwAd9WUF3fkw%3D%3D&trk=public_jobs_jserp-result_search-card,"Carnet de route
Novencia accompagne ses clients dans leurs projets de transformation digitale, technologique et data.
Expert en Data et Intelligence Artificielle nous aidons nos clients √† exploiter et valoriser leurs donn√©es sous toutes ses formes en les accompagnant sur des projets de Data Gouvernance, Data Architecture, Data Science, et Data Engineering.
Data Analyst
depuis au moins
3 ans,
tu es √† la recherche de nouveaux d√©fis. Boucle ta ceinture, la suite est pour toi !
Ton R√¥le
Rattach√©.e aux consultants de l‚Äôagence Lyonnaise, tu seras amen√©.e √† travailler chez les clients finaux et/ou au sein de notre Datalab‚Äô.
En tant que Data Analyst, tu auras les missions suivantes :
T‚Äôimmerger dans le contexte client ;
Mener des ateliers avec les √©quipes m√©tier pour recueillir/ d√©finir leurs besoins ;
Challenger leurs demandes ;
Participer au recueil et √† la mod√©lisation des donn√©es ;
Contr√¥ler la fiabilit√© et la qualit√© des donn√©es ;
Structurer et exploiter les donn√©es gr√¢ce √† des outils de Data visualisation ;
Analyser ces donn√©es et partager les r√©sultats ;
Faire des recommandations au client.
Ton profil
De formation Bac+5 dans le domaine de la Data, tu as au moins 3 ans d‚Äôexp√©rience sur un poste similaire.
Comp√©tences techniques recherch√©es :
Exp√©rience significative sur un outil de Data visualisation pour l‚Äô√©laboration de rapports/tableaux de bord (Power BI/Tableau/QlikSense etc.)
Langage SQL (Python est un plus)
Mod√©lisation de donn√©es
Connaissance des bases de donn√©es (e.g. Snowflake, Google BigQuery, SQL Server ou Oracle)
Utilisation d‚Äôun ETL (e.g. Azure Data Factory, SSIS, Informatica, Talend, Matillion)
Une exp√©rience dans le fonctionnement d‚Äôune √©quipe agile.
Tu es passionn√©.e par la Data et souhaites √©voluer au sein d‚Äôune communaut√© d‚ÄôExperts de la Data, tu veux t‚Äôinvestir dans des projets data innovants au sein de notre Datalab‚Äô, tu aimes le travail en √©quipe mais sais √™tre autonome sur tes sujets, tu es curieux.euse et force de proposition, tu es capable de chercher et trouver des solutions, tu as un bon niveau d‚Äôanglais.
Enfin, tu souhaites int√©grer une agence √† taille humaine o√π la bienveillance n‚Äôest pas qu‚Äôun mot marketing.
S‚Äôengager en faveur du handicap c‚Äôest garantir l‚Äô√©galit√© des chances d√®s le recrutement. √Ä comp√©tences √©gales, nos postes sont ouverts aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Oracle', 'SQL Server', 'Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer F/H,ARMOR GROUP,"La Chevroli√®re, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-armor-group-3828365820?position=3&pageNum=32&refId=FUgWcwWTfkSy1LADz3eV7w%3D%3D&trackingId=l1gCM7cu9ZgGc%2FpuLpFSwA%3D%3D&trk=public_jobs_jserp-result_search-card,"Qui sommes nous ?
Centenaire (en 2022), ARMOR GROUP poursuit sa croissance gr√¢ce √† une solide implantation, √† la fois localement avec son site industriel situ√© √† la Chevroli√®re en Loire Atlantique et mondialement avec ses diff√©rentes implantations industrielles, logistiques et commerciales.
Notre c≈ìur de m√©tier consiste √† produire des films encr√©s, de la conception des encres √† la fabrication de rubans, jusqu‚Äô√† leur commercialisation.
Nous d√©veloppons √©galement de nouvelles activit√©s industrielles innovantes : films collecteurs de courant, films photovolta√Øques organiques et mat√©riaux pour la fabrication additive (impression 3D).
Nous Sommes Une Entreprise Engag√©e Dans
La satisfaction de nos clients et la production de produits de qualit√©
L‚Äôinvestissement de notre outil de production pour am√©liorer la s√©curit√© et les conditions de travail de nos salari√©s.
Les Plus D‚ÄôARMOR GROUP
Les conditions de travail, une politique sociale engag√©e (cr√®che d‚Äôentreprise, universit√© interne pour les m√©tiers de la production‚Ä¶)
Salaire fixe avec des primes li√©es au poste de travail, au transport, int√©ressement et participation, primes mensuelles etc.
Un comit√© d‚Äôentreprise et un restaurant d‚Äôentreprise sur site √† tarif pr√©f√©rentiel.
Votre quotidien en nous rejoignant
Au sein de l'√©quipe Informatique Industrielle du Groupe, votre mission consiste √† g√©rer et am√©liorer les syst√®mes de donn√©es industrielles du P√¥le Industriel France et de ses filiales de production √† l‚Äôinternational.
A Cet Effet, Vous √ätes En Charge De
Maintenir et faire √©voluer l‚Äôarchitecture n√©cessaire √† la valorisation de donn√©es,
G√©rer et organiser les donn√©es industrielles et les flux de donn√©es entrants et sortants (SQL Server, SSIS, Historian),
Consolider les diff√©rentes sources de donn√©es On Premise dans notre Datalake Azure et Cubes de donn√©es,
Participer √† la conception des reportings en lien avec les services m√©tiers (Am√©lioration continu, process, qualit√©, production, ‚Ä¶),
Optimiser et p√©renniser les syst√®mes existants en temps r√©el,
Assurer l'accompagnement des utilisateurs cl√©s.
Profil recherch√©
Dot√© d'un BAC+5 en Informatique dans le domaine de l'informatique d√©cisionnelle (BI), vous avez une premi√®re exp√©rience r√©ussie en tant que Data Engineer.
Ma√Ætrise des outils d‚ÄôETL tels que SSIS, Azure data factory.
Connaissance de la plateforme Azure Databricks est appr√©ci√©.
Connaissances g√©n√©rales en informatique (architecture, bases de donn√©es, m√©thodologies de d√©veloppement‚Ä¶).
Connaissance du milieu industriel appr√©ci√©e.
Qualit√©s personnelles recherch√©es : capacit√© d‚Äô√©coute et sens relationnel, force de proposition, pragmatisme, capacit√© de synth√®se, go√ªt du terrain, capacit√© de travail en √©quipe et √† communiquer.
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['SQL Server'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['5'], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
Data Analyst / Analytics Engineer (H/F),CleverConnect,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-analytics-engineer-h-f-at-cleverconnect-3904533153?position=4&pageNum=32&refId=FUgWcwWTfkSy1LADz3eV7w%3D%3D&trackingId=JXSKMWdUYxr6hXO64nKJ6g%3D%3D&trk=public_jobs_jserp-result_search-card,"Description de l'entreprise
CleverConnect est une scale-up franco-allemande de la HR Tech en croissance fond√©e il y a 10 ans par des ing√©nieurs. Nous sommes pr√©sents en France et Allemagne. Depuis la fusion avec Talentry en 2022, nous partageons l‚Äôambition de devenir le leader des software solutions du Talent Acquisition en Europe
Nous accompagnons actuellement plus de 10 millions de candidats par an √† trouver le bon poste Pour cela, nous mettons en relation les recruteurs et les candidats avec des solutions digitales et des plateformes SaaS innovantes pour rendre le processus de recrutement plus efficace. Nos technologies permettent aux candidats de trouver des opportunit√©s plus cibl√©es et de valoriser leur personnalit√© et motivation
Rejoignez notre √©quipe internationale de 200 coll√®gues qui partagent la m√™me culture et les m√™mes valeurs, et qui sont pleinement engag√©s dans un projet √† fort impact soci√©tal
Si vous voulez en savoir plus : www.cleverconnect.com
Description du poste
En tant que Data Analyst, quelles seront vos responsabilit√©s ‚Äç‚Äç?
Collaborer avec les d√©partements Product, Sales, Marketing et Communication pour comprendre les besoins m√©tier et les traduire en solutions de donn√©es.
Impl√©menter et optimiser des mod√®les de donn√©es √† l'aide de DBT et garantir la qualit√© et l'int√©grit√© des donn√©es. Vous serez en charge de transformer et mettre en forme les donn√©es du datawarehouse en approche ELT.
Utiliser BigQuery et DBT pour analyser de grands ensembles de donn√©es et en tirer des insights exploitables.
Cr√©er et maintenir des rapports et des tableaux de bord dans des outils de dataviz type Looker Studio, Superset, PowerBI ou Metabase. Ces tableaux de bords peuvent concerner les besoins internes (product, communication, marketing, sales, etc.) et externes (embedded dans nos solutions √† destination des clients).
Participer √† la conception des pipelines d‚Äôingestion de donn√©es avec le Data Engineer.
Effectuer des analyses ad hoc et fournir des recommandations bas√©es sur les donn√©es pour soutenir les d√©cisions m√©tier.
Qualifications
Qui √™tes-vous ?
Vous avez au moins 5 ann√©es d'exp√©rience en tant que Data Analyst dans un environnement similaire.
Techniquement et id√©alement ,
Ma√Ætrise avanc√©e de SQL et exp√©rience de travail avec des ensembles de donn√©es √† grande √©chelle.
Exp√©rience pratique avec BigQuery, DBT ou √©quivalents requis. Exp√©riences Snowplow et Elasticsearch appr√©ci√©es.
Familiarit√© avec les outils de visualisation de donn√©es tels que Looker Studio, Superset, PowerBI ou Metabase.
√ätre √† l‚Äôaise dans le scripting python pour automatiser certaines transformations de donn√©es.
Avoir d√©j√† manipul√© un outil de Web Analytics tel que Google Analytics.
Exp√©rience dans un environnement Agile et capacit√© √† travailler en collaboration dans des √©quipes interfonctionnelles.
Q
ue trouverez-vous chez CleverConnect ?
Une √©quipe dirigeante accessible, bienveillante et √† l‚Äô√©coute
Des bureaux au c≈ìur des villes et la possibilit√© de faire du t√©l√©travail
Des opportunit√©s de formation, d‚Äô√©volution et de mobilit√© en Europe
RTT, mutuelle, carte d√©jeuner, remboursement 50% transport, forfait mobilit√© durable
Notre processus de recrutement comprend:
Entretien initial avec un Responsable de l'Acquisition de Talents
Entretien avec le Manager (d√©couverte/√©valuations techniques)
Dernier entretien avec le Directeur IT ou CPTO.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '10', '10', '10']}"
Data Engineer F/H,CGI,Greater Clermont-Ferrand Area,https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-cgi-3883952151?position=5&pageNum=32&refId=FUgWcwWTfkSy1LADz3eV7w%3D%3D&trackingId=hb9obuz0c%2BwRgicTmsXWsQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Description de poste
Big Data, Data Science, Data analyse, Data architecture, ... √áa n‚Äôa pas de secret pour vous?
Que vous commenciez votre carri√®re professionnelle ou que vous soyez sp√©cialiste de l‚Äôune de ces disciplines, int√©grer notre communaut√© Data, c‚Äôest l‚Äôassurance de progresser, innover, partager, vous certifier et rendre service √† nos clients.
Fonctions et responsabilit√©s
Alors venez rejoindre nos √©quipes de Data Engineer. Vous pouvez √™tre amen√© √† intervenir sur tout ou partie de ces missions :
Mod√©lisation des Data Concepts d'un DataLake
D√©veloppement et maintenance des traitements d'int√©gration et de transformation de donn√©es
Int√©gration des d√©veloppements dans la chaine CI/CD
Documentation technique et fonctionnelle
R√©daction de plan de tests
R√©alisation de tests unitaires/qualifications
Au sein de la communaut√© Data, vous serez accompagn√© et vous pourrez √©changer avec des coll√®gues exp√©riment√©s et experts vous permettant de vous d√©velopper, de grandir et d‚Äôaccomplir pleinement vos missions de conseil.
L‚Äôaccompagnement manag√©rial, la communaut√© Data et de nombreux √©v√®nements tout au long de l‚Äôann√©e nous permettront de vous aider √† atteindre vos objectifs dans un esprit de convivialit√©.
En rejoignant CGI, vous b√©n√©ficiez notamment d‚Äôune offre compl√®te de formations (techniques, m√©tiers, d√©veloppement personnel,‚Ä¶), de flexibilit√© gr√¢ce √† notre accord t√©l√©travail (jusqu‚Äô√† 3 jours de t√©l√©travail par semaine), d‚Äôune politique de cong√©s avantageuse (27 jours de cong√©s pay√©s, RTT, cong√©s anciennet√© et enfant malade,‚Ä¶) et d‚Äôun package d‚Äôavantages int√©ressant (r√©gime d‚Äôachats d‚Äôactions, participation, CSE,...).
Qualit√©s requises pour r√©ussir dans ce r√¥le
Vous avez une formation Bac+3/5 en informatique, au minimum 1 an d‚Äôexp√©rience et des aptitudes sur l‚Äôun ou plusieurs des domaines suivants :
Vous maitrisez :
Data Visualisation : Power BI, MicroStrategy, Tableau, Cognos‚Ä¶
Langages : SQL, Python, DAX, R‚Ä¶
Applications Cloud : Azure, Snowflake, Databricks, AWS...
Bases de donn√©es : Oracle, PostgreSQL, MySQL, Mongo db, Sybase‚Ä¶
ETL : Datastage, Talend, Informatica (PowerCenter) ‚Ä¶
Vous avez/ Vous √™tes :
Passionn√© du monde de la data
Curieux et appr√©ciez le travail en √©quipe
CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, √† l‚Äô√©volution de carri√®res des hommes et des femmes et au bien-√™tre de nos salari√©s LGBT+. Dans un souci d‚Äôaccessibilit√© et de clart√©, le point m√©dian n‚Äôest pas utilis√© dans cette annonce. Tous les termes employ√©s se r√©f√®rent aussi bien au genre f√©minin que masculin.
Ensemble, en tant que propri√©taires, mettons notre savoir-faire √† l‚Äô≈ìuvre.
La vie chez CGI est ancr√©e dans l‚Äôactionnariat, le travail d‚Äô√©quipe, le respect et un sentiment d‚Äôappartenance. Chez nous, vous pourrez exploiter votre plein potentiel parce que‚Ä¶
Nous vous invitons √† devenir propri√©taire d√®s le jour 1 alors que nous travaillons ensemble √† faire de notre r√™ve une r√©alit√©. C‚Äôest pourquoi nous nous d√©signons comme associ√©s de CGI, plut√¥t que comme employ√©s. Nous tirons profit des retomb√©es de notre succ√®s collectif et contribuons activement √† l‚Äôorientation et √† la strat√©gie de notre entreprise.
Votre travail cr√©e de la valeur. Vous √©laborerez des solutions novatrices et d√©velopperez des relations durables avec vos coll√®gues et clients, tout en ayant acc√®s √† des capacit√©s mondiales pour concr√©tiser vos id√©es, saisir de nouvelles opportunit√©s, et b√©n√©ficier d‚Äôune expertise sectorielle et technologique de pointe.
Vous ferez √©voluer votre carri√®re en vous joignant √† une entreprise b√¢tie pour cro√Ætre et durer. Vous serez soutenus par des leaders qui ont votre sant√© et bien-√™tre √† c≈ìur et qui vous permettront de saisir des occasions afin de parfaire vos comp√©tences et √©largir les horizons.
Joignez-vous √† nous, l‚Äôune des plus importantes entreprises de conseil en technologie de l‚Äôinformation (TI) et en management au monde.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['MySQL', 'PostgreSQL', 'Oracle', 'Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Flexibilit√©'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['3'], 'Level': ['Bac+3'], 'Experience': ['a', 'n', 's']}"
Lead Data Engineer H/F,Neosoft,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/lead-data-engineer-h-f-at-neosoft-3879749134?position=6&pageNum=32&refId=FUgWcwWTfkSy1LADz3eV7w%3D%3D&trackingId=KSuIL63EhPi3OfQhBM92XA%3D%3D&trk=public_jobs_jserp-result_search-card,"Tous nos postes sont ouverts au t√©l√©travail
Groupe ind√©pendant de conseil en transformation digitale de pr√®s de 1800 collaborateurs, N√©osoft s‚Äôest construit, depuis 2005, sur un mod√®le qui place l‚Äôexcellence, le d√©passement de soi et la RSE au c≈ìur de sa strat√©gie.
En nous rejoignant, vous int√©grez des communaut√©s d‚Äôexperts et de talents qui vous permettent de d√©velopper vos comp√©tences et d‚Äôoffrir √† nos clients le meilleur accompagnement possible.
Notre savoir-faire s‚Äôarticule autour de nos 6 domaines d‚Äôexpertise :
Conseil & Agilit√©
Cybers√©curit√©
Data
DevOps
Infrastructures & Cloud
Software Engineering
Nous recherchons pour int√©grer notre
agence lilloise
un(e)
Lead Data Engineer H/F.
Nous aimerions vous voir rayonner au sein de notre communaut√© DATA (+100 collaborateurs) anim√©e par Nicolas Huche, son practice leader et Thibaud Blanchard son Technical Officer. Vous aiderez les clients √† consolider un patrimoine Data responsable.
Vos missions :
Apr√®s une p√©riode d‚Äôint√©gration, en tant que
Lead Data Engineer
, voici √† quoi ressembleront vos activit√©s dans des contextes clients Retail ou Banque / Assurance / Finance :
D√©finir la strat√©gie d'ing√©nierie technique des donn√©es
Participer √† la conception d'architectures de donn√©es robustes et √©volutives
Optimiser les performances et la scalabilit√©
Exercer un v√©ritable r√¥le de Leader technique
Votre profil :
Nous vous imaginons avec au moins 6 ans d‚Äôexp√©riences sur des projets autour de la Data, une ma√Ætrise des bases de donn√©es (SQL), des outils de transformation de la donn√©e (Talend, BigQuery, Airflow), un socle de comp√©tences solides autours des langages Python, Spark, Scala, Hadoop, Java et dans un environnement Cloud.
üëâ
Votre carri√®re chez N√©osoft
Depuis sa cr√©ation, N√©osoft place ses collaborateurs au c≈ìur de sa strat√©gie. Notre culture pourrait se r√©sumer en un mot : le collectif.
Nos communaut√©s d‚Äôexperts vous donnent la possibilit√© d‚Äôapprendre, mais aussi de transmettre et de partager vos savoirs pour faire progresser les autres.
Nous veillons √† ce que chacun b√©n√©ficie d‚Äôun accompagnement de proximit√© et d‚Äôun suivi de carri√®re personnalis√© aupr√®s de votre manager d√©di√© :
1 bilan d‚Äôactivit√© trimestriel pour suivre le d√©veloppement de vos comp√©tences
1 entretien d‚Äô√©valuation qui a lieu chaque ann√©e pour √©valuer votre performance et d√©terminer vos nouveaux objectifs
1 entretien annuel aupr√®s de votre RH dans le but de cartographier vos nouvelles comp√©tences pour √©changer sur vos projets professionnels et souhaits de formation
üëâ
Vos avantages
Formations et d√©veloppement de l‚Äôexpertise :
Vous disposez de temps allou√© et r√©mun√©r√© en contribuant au d√©veloppement de votre expertise technique et de celle du groupe (Participations √† des Tech days, animation d‚Äôune conf√©rence √† l‚Äôinterne ou √† l‚Äôexterne, r√©daction d‚Äôarticles, rencontres avec nos candidats en processus de recrutement‚Ä¶)
Un abonnement illimit√© LinkedIn Learning offert
Bien-√™tre au travail :
Un accord de t√©l√©travail flexible jusqu‚Äô√† 100% de t√©l√©travail et personnalisable
Un partenariat avec Gymlib qui favorise le sport en entreprise
Des initiatives locales (afterworks, d√©fis sportifs, team buildings, ‚Ä¶)
Et bien plus encore :
Parce que les meilleurs cooptent les meilleurs, une politique de cooptation attractive r√©mun√©r√©e d√®s l‚Äôarriv√©e du collaborateur
En plus de votre salaire : participation, compte √©pargne temps, actionnariat...
üëâ
Votre parcours candidat
Notre processus de recrutement se compose de deux √©tapes cl√©s :
Un entretien de recrutement RH avec un Talent Acquisition Sp√©cialiste pour dresser un bilan de votre parcours professionnel et identifier les trajectoires de carri√®re possibles au sein de notre groupe
Un entretien d‚Äô√©valuation technique pour r√©aliser un diagnostic de vos comp√©tences techniques et identifier les comp√©tences sur lesquels poursuivre votre √©volution
Vous aurez √©galement la possibilit√© de rencontrer pour compl√©ter votre processus un acteur de notre p√¥le Business ou un pair de votre m√©tier pour √©changer sur son exp√©rience collaborateur.
Nous avons h√¢te de vous rencontrer !
A bient√¥t,
L‚Äô√©quipe N√©osoft üñê
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'ML', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['Salaire'], 'Level': [], 'Experience': ['a', 'n', 's', '6', '6', '6']}"
Data Engineer & Architect - 100% T√©l√©travail H/F,Proxiel,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-architect-100%25-t%C3%A9l%C3%A9travail-h-f-at-proxiel-3913994350?position=7&pageNum=32&refId=FUgWcwWTfkSy1LADz3eV7w%3D%3D&trackingId=WogUOlUm8i9QjgIdZLo3FQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Cr√©√©e en 1998, Proxiel est une soci√©t√© de services num√©riques. Proxiel est une soci√©t√© fran√ßaise bas√©e √† Montpellier et Paris. Proxiel a d√©velopp√© son expertise pour fournir une gamme de service compl√®te qui va de l'√©tude √† la r√©alisation, dans le domaine de la maintenance informatique, du d√©veloppement de logiciel et de solutions informatiques.
Proxiel, fort de son exp√©rience, d√©l√®gue √©galement, son savoir au coeur des organisations, au niveau national.
Depuis plusieurs ann√©es le Groupe Proxiel s'est dot√© d'un P√¥le Formation, pour conseiller, mettre en oeuvre et accompagner ses collaborateurs et partenaires, dans le d√©veloppement de leurs comp√©tences.
Nous sommes experts dans le recrutement de profils tech. Nos consultants se donnent √† fond pour entrer en contact avec vous !
Notre politique se poursuit lors de la contractualisation, le service ressources humaines est √† la disposition de l'ensemble des collaborateurs.
Chez Proxiel, nous valorisons la collaboration et la proximit√©, tout en laissant place √† l'autonomie.
Nous recherchons un Data Engineer & Architect (F/H) pour int√©grer notre partenaire Grand Compte en 100% t√©l√©travail (d√©placements ponctuels √† effectuer sur Lyon).
Vous jouerez un r√¥le central dans la construction de pipelines de donn√©es robustes pour alimenter des syst√®mes d'IA g√©n√©rative de pointe. Ce r√¥le offre une opportunit√© passionnante de contribuer √† des projets r√©volutionnaires √† l'intersection de l'ing√©nierie des donn√©es et de l'intelligence artificielle, tout en assumant des responsabilit√©s dans l'architecture des donn√©es.
Les Principales Responsabilit√©s Sont Les Suivantes
Vous √™tes en charge de la conception et de la construction de pipelines de donn√©es √©volutifs permettant de r√©cup√©rer, d'agr√©ger et de pr√©traiter efficacement les donn√©es provenant de diff√©rentes sources, tout en garantissant une fiabilit√© et des performances √©lev√©es.
Vous √™tes en charge de la conception des mod√®les de donn√©es, des solutions de stockage et des sch√©mas d'acc√®s.
Vous avez la possibilit√© de collaborer avec les parties prenantes pour comprendre les besoins et pour d√©finir et faire √©voluer la strat√©gie d'architecture des donn√©es, y compris la mod√©lisation des donn√©es, le stockage et les sch√©mas d'acc√®s.
Vous travaillez avec une √©quipe agile interfonctionnelle pour int√©grer des donn√©es provenant de divers syst√®mes et sources, effectuer des processus d'extraction, de transformation et de chargement (ETL) et maintenir l'int√©grit√© des donn√©es tout au long du pipeline, en it√©rant sur les solutions et en communiquant sur les progr√®s r√©alis√©s.
Ma√Ætrise des langages de programmation
Une solide compr√©hension des technologies de base de donn√©es (par exemple, SQL, NoSQL), des entrep√¥ts de donn√©es et d'Azure
Exp√©rience en architecture de donn√©es la conception de mod√®les de donn√©es, la d√©finition de solutions de stockage et les sch√©mas d'acc√®s aux donn√©es.
Familiarit√© avec le Machine learning, les concepts de traitement du langage naturel (NLP) et la G√©n√©ration Augment√©e de R√©cup√©ration (RAG) est un plus.
Vous avez d'excellentes comp√©tences en mati√®re de communication et de collaboration, et √™tes capable de travailler efficacement dans un environnement d'√©quipe et dans le cadre de projets agiles.
Issu d'une Formation Bac +2 √† Bac +5 en informatique, vous √™tes polyvalent.
Vous d√©tenez 3 ans d'exp√©rience √† minima sur un poste similaire.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Communication', 'Collaboration', 'Organisation'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Analyst F/H,Allianz France,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-f-h-at-allianz-france-3909179361?position=8&pageNum=32&refId=FUgWcwWTfkSy1LADz3eV7w%3D%3D&trackingId=%2F%2BCWe%2FLugj4ZcvfLAHVgjw%3D%3D&trk=public_jobs_jserp-result_search-card,"AIM Paris (Allianz Investment Management Paris), l‚Äôunit√© Investissement d‚ÄôAllianz France, a la charge de la gestion des investissements des diff√©rentes entit√©s d‚ÄôAllianz France tant sur les portefeuilles d‚Äôactifs g√©n√©raux qu‚Äôen unit√©s de compte (UC), sur toute la cha√Æne de valeur des investissements, qui couvre la gestion actif-passif, la strat√©gie d'investissement, ainsi que la planification des revenus des investissements, le suivi des risques, le reporting et les op√©rations.
Le r√¥le de l‚Äô√©quipe :
Pour soutenir ces activit√©s, l‚Äô√©quipe AIM Finance & Op√©rations, en charge des donn√©es d‚Äôinvestissements, des reportings et du suivi des risques des investissements, est √† la recherche d‚Äôun
Data Analyst
. Ce dernier, rattach√© hi√©rarchiquement √† AIM Finance & Op√©rations, couvrira l‚Äôensemble des besoins des diff√©rentes √©quipes d‚ÄôAIM (AIM Investment Strategy, AIM Asset-Liability Management, AIM Finance) et interviendra de fa√ßon op√©rationnelle sur des projets de transformation locaux et Groupe.
Voici vos principales missions :
¬∑
L‚Äôautomatisation
de sourcing des donn√©es, des contr√¥les et des r√©conciliations entre diff√©rents syst√®mes d‚Äôinformations
¬∑
Le d√©veloppement
de macros/codes afin d‚Äôautomatiser/optimiser les t√¢ches
¬∑
L‚Äôam√©lioration continue
des bases de donn√©es Investissements
¬∑
La fiabilisation et l‚Äôam√©lioration
continue des bases de donn√©es
¬∑
La mise en place
de nouveaux reportings (Power BI)
¬∑
Le pilotage de projets
en lien avec les initiatives groupes et locales
Vous travaillerez en lien √©troit avec les autres √©quipes d'AIM France ainsi que les √©quipes AIM centrales √† Munich. La maitrise de
l‚Äôanglais
est alors indispensable.
Votre parcours :
Dipl√¥m√©(e) en informatique/gestion des donn√©es ou d‚Äôune √©cole d‚Äôing√©nieur (
BAC +5),
vous disposez d‚Äôune exp√©rience significative dans la manipulation de donn√©es
(5-10 ans).
Ma√Ætrise de plusieurs langages de d√©veloppement du type
Python, VBA, Access, SAS
Bonne ma√Ætrise des outils bureautiques Powerpoint, Excel et VBA, et id√©alement une premi√®re exp√©rience significative dans l‚Äôutilisation d‚Äôoutils de datavisualisation
(Power BI)
Capacit√© d‚Äôanalyse et de synth√®se, ouverture d‚Äôesprit, rigueur, organisation et autonomie,
Fran√ßais et
anglais
professionnel courants indispensables, √† l‚Äô√©crit comme √† l‚Äôoral.
Vous aimez travailler en √©quipe dans une entreprise qui met ses collaborateurs au c≈ìur de sa strat√©gie de d√©veloppement ! Alors rejoignez-nous chez Allianz ! Toute l‚Äô√©quipe de Marwen NAJAR vous y attend !
En tant qu‚Äôentreprise reconnue et internationale, nous vous offrons des avantages attractifs tels qu‚Äôune flexibilit√© du temps de travail, le t√©l√©travail (3 jours par semaine), 9 semaines de cong√©s, une restauration sur site, des taux pr√©f√©rentiels collaborateurs, des cong√©s maternit√© et paternit√© √©largis, des places en cr√®che et bien plus encore.
En tant qu‚Äôemployeur, nous mettons tout en ≈ìuvre pour vous assurer un bien √™tre propice √† votre √©panouissement.
Allianz est la 1√®re marque mondiale d'assurance pr√©sente dans 70 pays. Les #Allianzers, c'est 9.000 salari√©s en France qui accompagnent leurs clients tout au long de leur vie, des collaborateurs qui associent innovation, performance et agilit√© pour relever des d√©fis permanents au quotidien. Parce qu'en nous pr√©occupant de l‚Äôavenir de nos collaborateurs, nous pouvons encore mieux nous pr√©occuper de l‚Äôavenir de tous nos clients. Pour cela, Allianz innove et met la technologie aux services des hommes pour pr√©parer leur avenir, un avenir plus s√ªr.
En qualit√© d‚Äôemployeur engag√©, Allianz reconna√Æt que sa force se trouve dans la diversit√© de ses collaborateurs. Nous sommes fiers de promouvoir l‚Äôint√©gration et l‚Äô√©galit√© des chances quel que soit le sexe, l‚Äô√¢ge, l‚Äôorigine, la nationalit√©, la religion, le handicap, ou l‚Äôorientation sexuelle de nos collaborateurs.
Allianz, We secure your future !
Informations compl√©mentaires :
Poste base √† PARIS, La D√©fense, M√©tro Esplanade
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Organisation', 'Flexibilit√©'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '10', '10', '10']}"
"Big Data Engineer Confirm√© ‚Äì Paris, France (H/F)",Astek,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-confirm%C3%A9-%E2%80%93-paris-france-h-f-at-astek-3839098103?position=9&pageNum=32&refId=FUgWcwWTfkSy1LADz3eV7w%3D%3D&trackingId=NcjHVVoQEj9b2qUQVZUuKA%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Paris - France
Publi√©e il y a 2 mois
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Nous rejoindre en tant que
Big Data Engineer Confirm√© (H/F),
afin d‚Äôaccompagner un op√©rateur t√©l√©coms, Leader en Europe dans l‚Äôassistance et le support applicatif de niveau 3 (r√©solution des probl√®mes utilisateurs, exploitation des environnements hors production).
Un challenge portant sur des millions d‚Äôutilisateurs dans un environnement technique innovant, strat√©gique et o√π l‚Äôentraide et la bonne humeur priment !
Votre Mission, Si Vous L‚Äôacceptez :
Supervision et d√©tection et r√©solution des probl√®mes utilisateurs (d√©veloppeurs, exploitants et data exploreurs)
D√©veloppement de solutions de self-service ou d‚Äôune solution de r√©solutions automatiques des probl√®mes
Qualifier les donn√©es et les r√©sultats
Conception technique des solutions
Assurer l‚Äôaccompagnement et le d√©ploiement des √©volutions des processus et outils
Accompagner la phase de mise en production
Votre Future √âquipe :
Vous int√©grerez une √©quipe √† la fois technique et fonctionnel, qui ≈ìuvre chaque jour pour d√©velopper et maintenir en conditions op√©rationnelles l‚Äôensemble des solutions IT !
L‚Äô√©quipe est en interaction avec des clients √† la fois internes et externes.
Votre stack de jeu
Syst√®me d‚Äôexploitation : Linux
Outils des distributions : HDP, HDF, ELK
Environnement Big data : Hadoop, Spark,
Langage : Scala, Shell, Python
Cloud computing : GCP ou AWS
Base de donn√©es : No SQL (Cassandra, Mongo DB), Shell, Ansible
Dataviz : Power BI ou Kibana
Des notions en R√©seau et Syst√®mes feront la diff√©rence !
Les Petits Plus Du Projet :
Vous √©voluerez au sein d‚Äôune √©quipe impliqu√©e et r√©active et interviendrez sur un projet polyvalent et √† forte valeur ajout√©e.
Vous ?
Dipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieur ou √©quivalent de niveau Bac+5.
Vous justifiez id√©alement d‚Äôune exp√©rience d‚Äôau moins 3 ans d‚Äôexp√©riences sur un poste similaire ?
Vous faite preuve de proactivit√© et d‚Äôesprit d‚Äô√©quipe, √™tes dot√©(e) d‚Äôun excellent sens de l‚Äôorganisation et vous aimez les challenges et la r√©solution de probl√®me ?
Alors ce poste est fait pour vous, n‚Äôh√©sitez plus et rejoignez l‚Äôaventure ASTEK !
Astek
Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.
Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de
ses 7800 collaborateurs
qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.
Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.
Tous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Notre projet commun vous plait ?
Postulez √† cette annonce, et soyez transparent !
Maud, notre Talent Acquisition Referent, vous contactera pour un premier √©change.
Puis vous rencontrerez Martin, votre futur manager, avec lequel vous √©changerez autour d‚ÄôAstek, de votre parcours, de vos attentes et de votre future mission .
Enfin, vous rencontrerez J√©r√©my, notre Directeur d‚Äôagence avec lequel vous pourrez valider votre int√©r√™t et ad√©quation pour le poste et finaliser les √©l√©ments contractuels.
Nos Plus
Astek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo
Une politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversit√©
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì Hadoop ‚Äì Scala ‚Äì Data
Caract√©ristiques de l'emploi
Cat√©gorie Ing√©nieur
Job Industry T√©l√©com / M√©dia
Postuler en ligne
Nom *
Pr√©nom *
Email *
Un email valide est requis.
T√©l√©phone *
Un num√©ro de t√©l√©phone valide est requis.
Joindre un CV *
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì Hadoop ‚Äì Scala ‚Äì Data
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': ['Confirm√©'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Lead Data Engineer,Ippon Technologies,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/lead-data-engineer-at-ippon-technologies-3851535052?position=10&pageNum=32&refId=FUgWcwWTfkSy1LADz3eV7w%3D%3D&trackingId=yY%2FhyCA7DHFhXuAJwymR4g%3D%3D&trk=public_jobs_jserp-result_search-card,"Cabinet de conseil et d'expertise en technologie, international et ind√©pendant.
En quelques mots : 700 passionn√©s de tech, 12 agences dans le monde, 6 communaut√©s d‚Äôexpertise d‚Äôexcellence, contributeur actif et sponsor de l'√©cosyst√®me num√©rique, des publications soutenues et reconnues sur nos r√©seaux.
Rejoignez notre communaut√© de 70 experts en data, dont 30 √† Paris, o√π la collaboration dynamique entre data engineers, data analysts et data architects est le moteur de notre succ√®s. Avec une communication proactive sur des canaux internes, restez constamment inform√© des derni√®res tendances, participez √† des discussions stimulantes et contribuez √† l'organisation d'√©v√©nements passionnants (dataday, datap√©ro, datalunch‚Ä¶).
Faites partie d'une √©quipe o√π l'innovation et l'engagement sont les cl√©s de notre excellence collective !
Notre sp√©cialit√© ? construire des data platforms dans le cloud public avec les meilleures technos du moment.
En tant que tech lead, tu interviendras sur la cr√©ation d'un entrep√¥t de donn√©es pour les KPIs d‚Äôun grand groupe dans le secteur de l‚Äô√©nergie. Le but √©tant de leur permettre de superviser leurs activit√©s afin de supporter leurs d√©cisions strat√©giques.
Ton r√¥le :
Intervenir sur l‚Äôarchitecture et le d√©veloppement d‚Äôune pipeline d'alimentation de donn√©es
Travailler sur la mod√©lisation et l‚Äôimpl√©mentation de l'entrep√¥t de donn√©es
Conseiller et accompagner les √©quipes dans la r√©alisation des dashboards de suivi des KPIs
DevOps: projet enti√®rement Terraform√© (ressources + droits), CI/CD Gitlab, administration GCP
Faire une veille technologique active et partager tes connaissances en interne
Travailler en collaboration avec les m√©tiers et les data analysts pour leur fournir un support √† l‚Äôindustrialisation de leurs travaux (tests, int√©gration continue, scalabilit√© des mod√®les, craftsmanship etc‚Ä¶)
Si tu le souhaites, tu pourras √©galement :
Participer aux √©v√®nements internes √† la communaut√© data (BBL, webinar, datap√©ro interne, meetup, blog, dojos) et externes (Salon du Big Data, GCP Summit, Spark Summit, AWS Summit, Devoxx, workshop partenaire, meetups)
Capitaliser sur les missions et les diff√©rents √©v√®nements de la communaut√© au travers d‚Äôarticles de blogs, REX, BBL interne.
Tes connaissances :
Tu ma√Ætrises le d√©veloppement en Python
Tu as de l‚Äôexp√©rience dans la mise en place de pipeline de donn√©es jusqu‚Äôen production (CI/CD Gitlab, Terraform)
Tu as une exp√©rience dans un environnement Cloud (GCP de pr√©f√©rence, AWS, Azure)
Tu as une bonne connaissance d‚Äôun outil de visualisation (Looker Studio, Power BI)
Tu accompagnes des data engineers dans la mise en place des bonnes pratiques
Tu es capable de proposer/challenger la stack technique
Ippon c‚Äôest aussi :
Travailler en √©quipe au sein d'une communaut√© data √† la pointe des √©volutions
Un suivi de proximit√© r√©alis√© par ton manager (expert data)
Devenir ceinture noire en data gr√¢ce √† notre programme d‚Äôaccompagnement de carri√®re Blackbelt
Participer √† nos ap√©ros et divers √©v√®nements internes pour consolider la coh√©sion d‚Äô√©quipe
Notre process de recrutement :
Pr√©qualification t√©l√©phonique - 20 min
Un entretien RH / Sales - 1H00
Un entretien technique avec 2 consultants data
Si le match est bon des deux c√¥t√©s : Hadjim√© ! Tu te lanceras sur le tatami Ippon !
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication', 'Collaboration', 'Organisation'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data & Software Engineer Intern,Ledger,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-software-engineer-intern-at-ledger-3884430248?position=1&pageNum=35&refId=dZ1gMrOpD8AXyzg1FiBMxg%3D%3D&trackingId=vWJk2DfCNQCU7uPn3dV2bA%3D%3D&trk=public_jobs_jserp-result_search-card,"We're making the world of digital assets accessible and secure for everyone.
Join the mission.
Founded in 2014, Ledger is the global platform for digital assets and Web3. Over 20% of the world‚Äôs crypto assets are secured through our Ledger Nanos. Headquartered in Paris and Vierzon, with offices in UK, US, Switzerland and Singapore, Ledger has a team of more than 600 professionals developing a variety of products and services to enable individuals and companies to securely buy, store, swap, grow and manage crypto assets ‚Äì including the Ledger hardware wallets line with more than 6 millions units already sold in 200 countries.
At Ledger, we embody the values that make us unique: Pragmatism, Audacity, Commitment, Trust and Transparency. Hear from our employees how they shape the work we do here.
Data at Ledger
As a data driven company, we ensure all major decisions are backed by data. To continue meeting that goal, we are looking for an intern to reinforce our data engineering team.
You will be responsible for optimizing our new data platform, building and maintaining reliable data pipelines. The ideal candidate is a software builder who will enjoy optimizing data systems and building them from the ground up in a fast paced environment and innovative space (blockchain is one of our key data sources!). You will also support data analysts and data scientists on data initiatives.
This internship will be a valuable opportunity to gain hands-on experience in all the aspects of a modern data stack: software engineering best practices, DevOps, SecOps concerns, Cloud infrastructure, legal compliance, etc.
Start date: As soon as possible
Length of internship: 6 months
Your mission
Work on data extractions from various sources (relational databases, API, flat files, etc.) and their transformations
Perform code reviews to guarantee code quality
Monitor data pipelines and investigate discrepancies
Contribute to migration of existing pipelines on AWS
Contribute to the improvement of the data engineering stack. We are an open-minded team and your opinion will be valued
Team tech stack
ELT: custom development (Python, SQL), Fivetran, Stitch, Adverity + dbt
Cloud: AWS
DWH: Redshift, migration to Snowflake underway
Orchestration: Airflow
BI: Tableau, Mixpanel
Versionning: Github
IaC: Terraform
What we're looking for
Fluent English
SQL & Python are among your best friends
You know how to fix conflicts in Git
Plus Points
Airflow, dbt, Snowflake, Github Actions
Knowledge about crypto
Experience working with Cloud infrastructure (ideally AWS)
What‚Äôs in it for you?
Flexibility: A hybrid work policy
Social: Frequent social events, snacks and drinks
High tech: Access to high performance office equipment and gadgets, including Apple products
Transport: Ledger reimburses 75% of your preferred means of transportation
Food: We offer lunch vouchers with Swile
Vacation: 1 day off for every full month worked
We are an equal opportunity employer for all without any distinction of gender, ethnicity, religion, sexual orientation, social status, disability or age
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': ['Flexibility', 'Initiative']}","{'JobDetail': ['Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer Talend (confirm√©/s√©nior) - H/F - CDI,Talan,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-talend-confirm%C3%A9-s%C3%A9nior-h-f-cdi-at-talan-3902901378?position=2&pageNum=35&refId=dZ1gMrOpD8AXyzg1FiBMxg%3D%3D&trackingId=py96T5xv7qfymnc5Nn1EyA%3D%3D&trk=public_jobs_jserp-result_search-card,"Talan est un groupe international de conseil en transformation et en innovation par la technologie, cr√©√© en 2002.
Nos 5000 consultantes et consultants partagent √† travers le monde l‚Äôaudace d‚Äôinnover, le go√ªt de l‚Äôexcellence, et l‚Äôenvie de relever les d√©fis les plus complexes.
Nous accompagnons les entreprises dans des secteurs vari√©s‚ÄØ: √©nergie, industrie, transport, finance, luxe‚Ä¶ √† travers 3 grandes expertises‚ÄØ:
Le Conseil en Management et Innovation (320 Consultants en France)
La valorisation des donn√©es, leurs structurations, et leurs usages (Data et Technologies)
L‚Äôint√©gration de solutions logicielles (Cloud et Applications Services)
Nos valeurs‚ÄØ: engagement, respect, partage, esprit d‚Äô√©quipe et optimisme.
Talan est une entreprise responsable, reconnue par ses collaborateurs et attach√©e √† la diversit√©. Des am√©nagements peuvent √™tre propos√©s si vous √™tes en situation de handicap.
Retrouvez nos engagements RSEiciet nos actions en faveur de la diversit√©ici
Job Description
VOTRE ROLE SUR NOS PROJETS :
Vous interviendrez sur des projets de:
Mise en place de Modern Data Platform
Interconnexion d‚Äôapplications op√©rationnelles en temps r√©el
Au sein d‚Äô√©quipes projet, votre r√¥le sera de:
Concevoir et mettre en place des flux d‚Äôint√©gration de donn√©es
Garantir la qualit√© des d√©veloppements
R√©diger des sp√©cifications fonctionnelles et techniques
Mod√©liser l‚Äôentrep√¥t de donn√©es
Mettre en place des solutions de suivi et pilotage des flux de donn√©es
Proposer des solutions d‚Äôoptimisation
Mettre en place ou faire √©voluer des cha√Ænes CI/CD
VOTRE ROLE CHEZ TALAN :
Au sein du p√¥le Tech for Data, vous contribuerez √† la croissance et la prosp√©rit√© de la communaut√© au travers des activit√©s suivantes:
Benchmark de solutions et conseil aupr√®s de nos clients sur les solutions technologiques √† adopter, en lien avec leurs besoins
R√©alisation de POC (Proof Of Concept)
Partage de connaissances et formations internes
Passage de certifications
Veille technologique
Participation √† la r√©daction de r√©ponse √† appel d‚Äôoffre
Qualifications
VOTRE PROFIL:
Dipl√¥m√© d‚Äôun Bac+5 en informatique/data, vous justifiez d‚Äôune exp√©rience d‚Äôau moins 3 ans sur des probl√©matiques d‚Äôint√©gration, traitement et mise en qualit√© de donn√©es en ayant mis en ≈ìuvre des flux de donn√©es sur un Talend (la ma√Ætrise d‚Äôautres solutions de traitement de donn√©es est un plus).
Vous ma√Ætrisez les concepts de mod√©lisation de donn√©es et les architectures de type DataLake, DWH, Datamarts (la connaissance de la mod√©lisation Datavault est un plus).
Vous savez √©voluer dans un environnement avec un mod√®le de donn√©es complexe et √©volutif.
Vous disposez d‚Äôun tr√®s bon relationnel et vous √™tes reconnu pour votre capacit√© √† √©voluer efficacement avec des interlocuteurs aussi bien techniques que non-techniques.
Force de proposition, vous savez mobiliser autour de vos id√©es et de vos projets.
Vous savez √©voluer dans un contexte data ops et avez une connaissance des cha√Ænes CI / CD (gitlab, Azure Devops, ...)
La ma√Ætrise de la m√©thodologie Agile est un plus.
Ensemble r√©alisons de nouveaux projets Talantueux!!
VOTRE SOUHAIT D‚ÄôEVOLUTION:
Si vous √™tes passionn√© par l‚Äôinnovation, et souhaitez √©largir vos comp√©tences techniques dans la data, acc√©der √† des fonctions de management de projet et d‚Äô√©quipe, participer au d√©veloppement commercial et organisationnel, ou tout simplement pouvoir valoriser vos prises d‚Äôinitiatives et d√©velopper de nouveaux terrains de jeux, alors rejoignez-nous!
Additional Information
AVANTAGES
:
Plan de formation pour accompagner votre carri√®re (formations √©diteurs, certifications) gr√¢ce √† nos partenariats nous accordant une position de partenaire privil√©gi√©, et management de proximit√© par des experts
Locaux modernes en centre-ville
Top 5 du Palmar√®s Great Place to Work
T√©l√©travail jusqu‚Äô√† 5 jours selon les missions, prime d‚Äô√©quipement de 100‚Ç¨
Mobilit√© en France et √† l‚Äô√©tranger
Top 1% des entreprises √©valu√©es par Ecovadis dans le domaine social, environnemental et √©thique
Tickets restaurant, prime vacances, 50% transport (abonnement transport public), mutuelle
Permanence handicap (consultant d√©di√© aux collaborateurs en situation de handicap et aux proches aidants)
Actionnariat salari√©
Prime de cooptations
RTT
PROCESS RECRUTEMENT
:
L‚Äô√©quipe recrutement s‚Äôengage √† vous proposer un processus de recrutement rapide et fluide
1 entretien RHpar Teams (45min)
1 entretien op√©rationnel avec le responsable de domaine, au si√®ge (1heure)
1 entretien avec le directeur de p√¥le, au si√®ge(1heure)
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'Cloud', 'CI/CD', 'CI / CD'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data engineer F/H,DOCAPOSTE,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-docaposte-3879674310?position=3&pageNum=35&refId=dZ1gMrOpD8AXyzg1FiBMxg%3D%3D&trackingId=4DW5b8oYCvw49FhS2q2jkg%3D%3D&trk=public_jobs_jserp-result_search-card,"Intitul√© du poste
Data engineer F/H
Contrat
CDI
T√©l√©travail
Oui
Description de la mission
Au sein du p√¥le, vous avez la charge de manipuler les donn√©es de la plus grosse base de donn√©es m√©dicale du monde, transmises par l'Assurance Maladie. Votre mission est de pr√©parer et de mettre √† disposition les donn√©es pour les diff√©rents acteurs de l'entreprise. Vous industrialisez les flux de donn√©es de centaines de milliers de patients, pour les suivre sur une dizaine d'ann√©es et rep√©rer certains √©v√©nements de leur prise en charge. Ainsi, les analyses pourront mettre en √©vidence les diff√©rents cycles des parcours de soin. Ce travail collaboratif se d√©roule en mode projet pluridisciplinaire.
Ainsi vous devez :
√Ä partir de bases de donn√©es complexes et volumineuses, r√©aliser les op√©rations de contr√¥le d'int√©grit√©, d'extraction, de nettoyage, et programmer leurs automatisations pour constitution des bases de donn√©es d'√©tudes
Coder des algorithmes sp√©cifiques de s√©lection de soins (hospitalisations, d√©livrance de m√©dicaments, consultations ‚Ä¶) et de s√©quences de traitement en utilisant toutes les particularit√©s des donn√©es,
R√©aliser des jointures complexes entre les diff√©rentes tables de donn√©es,
Optimiser les temps de traitement et de l'espace de stockage : millions de patients sur des T√©ra de donn√©es, en automatisant au maximum les op√©rations de traitement,
Travailler en mode collaboratif pour la r√©daction de macros/fonctions g√©n√©riques pour que votre travail puisse servir √† toute l'√©quipe,
Votre nouvel environnement
Filiale du groupe DOCAPOSTE SANTE, nous sommes leader en France dans le traitement et l‚Äôanalyse des donn√©es de sant√© en vie r√©elle, et plus particuli√®rement celles issues des bases du Syst√®me National des Donn√©es de Sant√© (SNDS) et des bases en OPEN DATA. Nous √©laborons et produisons pour nos clients (industries pharmaceutiques, fabricants de dispositifs m√©dicaux, institutionnels) des √©tudes pharmaco-√©pid√©miologiques, m√©dico-√©conomiques et de parcours de soins √† partir de solides m√©thodes statistiques et de solutions innovantes s'appuyant sur l'Intelligence Artificielle (Machine Learning, Deep Learning, ‚Ä¶).
2jours de T√©l√©travail
Nous vous accompagnons
Un programme de formation et d'accompagnement est pr√©vu en fonction de vos comp√©tences pr√©c√©demment acquises et de votre exp√©riences
Localisation du poste
Europe, France, Auvergne-Rh√¥ne-Alpes, Rh√¥ne (69)
Lieu
Niveau d'√©tudes min. requis
Dipl√¥me
Niveau d'exp√©rience min. requis
Langues
Profil : Pour l‚Äô√©galit√© des chances, Docaposte fait vivre la diversit√©. Nos postes sont ouverts √† tous.
LYON
Crit√®res candidat
Profil : Pour l‚Äô√©galit√© des chances, Docaposte fait vivre la diversit√©. Nos postes sont ouverts √† tous.
Rigueur
manipulation de donn√©es de sant√©
Analytique
Donn√©es riches et complexes
R√©f√©rence
2023-4471D
Entit√© qui recrute
HEVA
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Statistiques'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data engineer - Dev - Alternance H/F,Assystem,"Courbevoie, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-dev-alternance-h-f-at-assystem-3888473931?position=4&pageNum=35&refId=dZ1gMrOpD8AXyzg1FiBMxg%3D%3D&trackingId=aJ6OHI9E7yPzGHW%2BOkjCjQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Trouver des solutions au d√©r√®glement climatique est la priorit√© du 21√®me si√®cle, et implique de switcher √† l‚Äô√©nergie bas-carbone. Chez Assystem, on s‚Äôest donc donn√© pour mission d‚Äôacc√©l√©rer la transition √©nerg√©tique partout dans le monde. Et pour y parvenir, nos 7500 Switchers couplent leur expertise historique en ing√©nierie et en management de projet aux technologies digitales.
Pr√©sent dans 12 pays (Europe, Moyen-Orient, Asie), nous travaillons sur la production et la distribution d'√©lectricit√© bas-carbone, √† travers le d√©veloppement des √©nergies nucl√©aires et renouvelables. Nous participons √©galement √† modernisation des r√©seaux √©lectriques et l'√©lectrification des usages, √† travers l'hydrog√®ne pour d√©carboner les secteurs des transports et de l'industrie.
Description du poste
Vous serez int√©gr√© sur notre plateau de data science √† la D√©fense.
En tant qu'alternant(e) en gestion des donn√©es, vous serez charg√©(e) de :
Participer √† la conception, au d√©veloppement et √† la maintenance des processus de gestion des donn√©es.
Collaborer avec l'√©quipe pour r√©soudre les probl√®mes techniques et proposer des solutions.
Contribuer aux revues des projets, en comprenant les d√©fis li√©s aux donn√©es et en proposant des solutions appropri√©es.
Effectuer des tests et des analyses pour assurer la qualit√© des applications.
Suivre les bonnes pratiques de d√©veloppement logiciel et contribuer √† l'am√©lioration continue des processus.
Participer √† la mise en place des pratiques MLOPS √† travers l'int√©gration et le d√©ploiement continu.
Votre r√¥le inclura √©galement de proposer des solutions technologiques pour r√©pondre aux contraintes de productivit√© et de s√©curit√©.
¬´Pourquoi r√©aliser votre alternance chez Assystem? On a 3 bonnes raisons pour vous convaincre!
ü•ê Travailler au sein d‚Äôune √©quipe engag√©e qui ram√®ne expertise et croissants le matin!
üòé D√©couvrir pourquoi 92% de nos stagiaires/alternants appr√©cient l‚Äôambiance et leur environnement de travail
üèÜ Gagner en comp√©tences et d√©velopper votre expertise m√©tier en √©changeant au quotidien avec les collaborateurs Assystem, ainsi que le client en direct pour plus de proximit√© !¬ª
Qualifications
Nous recherchons un candidat titulaire d'un dipl√¥me de
niveau BAC+2
avec des comp√©tences dans les domaines de SQL, NoSQL, UML, Python, React.js, Node.js et l'architecture des syst√®mes d'information.
La ma√Ætrise du fran√ßais et de l'anglais est n√©cessaire.
Nous valorisons √©galement des qualit√©s telles qu'un bon relationnel, un esprit de synth√®se, une autonomie et un esprit innovant chez nos candidats.
Informations suppl√©mentaires
Nous nous engageons au respect de l‚Äô√©galit√© de traitement entre les candidats, et c√©l√©brons toutes les formes de diversit√©. Chez Assystem, seules les comp√©tences comptent!Si vous souhaitez porter √† la connaissance d‚ÄôAssystem une quelconque situation ou des besoins sp√©cifiques, n‚Äôh√©sitez pas vous serez accompagn√©(e)!
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
"Senior Data Engineer (Spark, Hive, Impala) - Paris - CDI",METEOJOB by CleverConnect,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-spark-hive-impala-paris-cdi-at-meteojob-by-cleverconnect-3862148207?position=5&pageNum=35&refId=dZ1gMrOpD8AXyzg1FiBMxg%3D%3D&trackingId=%2FRXOfDy2If%2BTy%2BVQXX5s8w%3D%3D&trk=public_jobs_jserp-result_search-card,"Entreprise
Chez LJE Solutions, nous pla√ßons l‚Äôhumain au c≈ìur de chaque projet. Au-del√† des comp√©tences, nous valorisons les
aspirations
et les
valeurs
de chaque individu.
Nous intervenons dans tous les secteurs d'activit√© en France et en Suisse.
Description Du Poste
LJE Solutions recherche, pour un de ses clients, cabinet de conseil sp√©cialis√© dans la technologie, un/une S√©nior Data Engineer pour compl√©ter son √©quipe.
Notre client est un cabinet de conseil mixte qui allie la technologie, la data & l'IA, le CRM & le digital.
Le Poste
En tant que Senior Data Engineer, vous serez responsable du d√©veloppement de nouveaux mod√®les de donn√©es et de pipelines. Vous aurez l'opportunit√© de tester les solutions les plus innovantes du march√© pour am√©liorer nos capacit√©s en mati√®re de donn√©es. Vous jouerez √©galement un r√¥le crucial dans l'assistance aux clients, le cadrage des projets et le coaching des consultants juniors.
Vos Responsabilit√©s
D√©veloppement de mod√®les de donn√©es et de pipelines,
Test des solutions innovantes pour am√©liorer les capacit√©s en donn√©es,
Assistance aux clients dans le cadrage des projets,
Coaching des consultants juniors,
Participation au d√©veloppement de l'entreprise.
R√©mun√©ration Et Avantages
Tickets restaurant,
Mutuelle d'entreprise,
Environnement de travail dynamique et motivant,
Diversit√© de projets stimulants,
Perspectives d'√©volution de carri√®re,
CDI avec r√©mun√©ration fixe attractive et part variable, √† partir de 50k‚Ç¨/an et d√©finie en fonction du profil et de l'exp√©rience,
Deux jours de t√©l√©travail par semaine,
Participation active √† la vie de l'entreprise.
Description Du Profil
Profil recherch√© :
Dipl√¥me d'une √©cole d‚Äôing√©nieur / g√©nie informatique Bac+5,
Minimum 4 ans d'exp√©rience dans le domaine de la data,
Capacit√© √† travailler en √©quipe et √† superviser plusieurs actions,
Excellentes comp√©tences en communication, pr√©sentation et coordination,
Capacit√© d'analyse et de r√©solution de probl√®mes,
Aptitude √† assimiler rapidement de nouvelles technologies,
Mindset positif et volont√© de contribuer au d√©veloppement de l'entreprise.
Comp√©tences Techniques
Technologies Big Data (Spark, Hive, Impala...),
Services Cloud (AWS / Azure / GCP),
Langages de programmation : Python, Java, Scala,
Mise en production de cas d'usage Data, notamment en Machine Learning,
Bases de donn√©es SQL,
DevOps et d√©veloppement de flux de donn√©es (data pipelines) avec Docker/Kubernetes et cha√Ænes CI/CD.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication', 'R√©solution de probl√®mes'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Junior', 'Senior'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Data Engineer (F/H) ‚Äì en stage,Carrefour,"Massy, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-%E2%80%93-en-stage-at-carrefour-3884393188?position=6&pageNum=35&refId=dZ1gMrOpD8AXyzg1FiBMxg%3D%3D&trackingId=oRZJtJ4lw6LlmZ%2BTwf0kow%3D%3D&trk=public_jobs_jserp-result_search-card,"Nous rejoindre, c‚Äôest rejoindre l‚Äôun des leaders mondiaux de la distribution qui met l'accent au quotidien sur la diversit√©, la RSE et le digital, pour satisfaire nos clients et nos collaborateurs. En tant que partenaire premium des Jeux Olympiques et Paralympiques de Paris 2024, nous partageons les valeurs du sport en permettant √† nos √©quipes de se d√©passer et encourageons une alimentation saine au juste prix pour tous.
Vous cherchez √† travailler dans une entreprise dynamique o√π votre travail rime avec impact social et environnemental ? Bienvenue chez nous !
Porteuse de cette ambition, la Direction D&A Technology recrute un(e)
Data Engineer (F/H) ‚Äì en stage
Au sein de Carrefour, la Direction D&A Technology a pour mission la construction d‚Äôun socle de donn√©es mutualis√©es d‚ÄôEntreprise.Les √©quipes de la Direction travaillent conjointement √† une plateforme unique pour collecter, structurer, stocker et diffuser les donn√©es du Syst√®me d‚ÄôInformations Carrefour. Un socle Data Centric est mis en ≈ìuvre pour permettre des usages op√©rationnels, d√©cisionnels et analytiques. Vous aurez un r√¥le de Data Engineer sur un scope fonctionnel, ce qui se traduira par le d√©veloppement de traitements d‚Äôingestion, stockage et exposition de donn√©es, que ce soit avec un framework Temps R√©el ou avec un framework de type ETL
üéØ Les missions
Dans ce cadre, vous serez amen√© √†
Comprendre les volets technique et fonctionnel du Produit Data en charge
Appliquer les bonnes pratiques et les normes de d√©veloppement
Contribuer √† l‚Äôautomatisation du delivery
D√©livrer les cas d‚Äôusages attendus sur le Produit Data
Proposer des axes d‚Äôam√©lioration sur la Plateforme
üë• Profil
Vous √™tes √©tudiant dans une √©cole d‚Äôing√©nieurs informatique cherchant un stage de fin d‚Äô√©tudes et souhaitant √©voluer dans un environnement BigData avec de forts enjeux pour l‚Äôentreprise.
Vous avez un int√©r√™t pour l‚Äôarchitecture de syst√®mes distribu√©s Big Data et des capacit√©s d‚Äôanalyse
Vous avez une bonne connaissance des m√©thodes de gestion de projets en mode agile (SCRUM)
Vous avez une bonne capacit√© √† travailler en √©quipe, tout en √©tant tr√®s autonome
Vous avez des comp√©tences techniques sur ces domaines
‚óã Scala/Java (Connaissance d‚Äôun des deux langages)
‚óã Ecosyst√®me Big Data (Spark, Apache Kafka, Avro ...)
‚óã Outils de d√©ploiement et orchestration (Kubernetes, Docker, Ansible ‚Ä¶)
‚óã Google Cloud Plateform (GCS, BigQuery, GKE, Cloud Pub/Sub, Dataproc, ‚Ä¶)
‚óã Bases de donn√©es NoSQL (Cassandra, BigTable‚Ä¶) & Moteur de recherche (Elastic Search...)
‚óã CI/CD (Git, Jenkins, Nexus, Docker Registry, ‚Ä¶)
Vous √™tes une personne passionn√©e, curieuse, autonome, et int√©ress√©e par le Software Craftsmanship.
Encore plus de bonnes raisons de nous rejoindre
Int√©grer une √©quipe conviviale √† taille humaine au sein d‚Äòun grand groupe
Pour le site de Massy  Un campus attractif avec plusieurs restaurants d‚Äôentreprises, salle de sport avec cours, offres Comit√© d‚Äôentreprise.
12 % de remise sur achat
üìù Informations compl√©mentaires
Date de d√©but  02 janvier 2024
Dur√©e  6 mois
Lieu  Massy (91) ‚Äì RER B/RER C Massy-Palaiseau
Chez Carrefour, nous avons √† c≈ìur de ne passer √† c√¥t√© d‚Äôaucun talent et sommes fiers de compter des √©quipes repr√©sentatives de la soci√©t√© dans son ensemble. Nous encourageons ainsi tous types de profils √† postuler √† cette offre et garantissons un processus de recrutement d√©nu√© de toutes formes de discriminations.
Show more
Show less","{'ProgLanguage': ['Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': ['Avro'], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': ['Apache Kafka'], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['Big Data', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Intermediate/Senior Data Engineer - Scientific Engine - CDI,Descartes Underwriting,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/intermediate-senior-data-engineer-scientific-engine-cdi-at-descartes-underwriting-3863474083?position=7&pageNum=35&refId=dZ1gMrOpD8AXyzg1FiBMxg%3D%3D&trackingId=KFHl0gad8reCli%2FEGp2aVQ%3D%3D&trk=public_jobs_jserp-result_search-card,"ABOUT DESCARTES UNDERWRITING
Descartes was born out of the conviction that the ever-increasing complexity of risks faced by corporations, governments and vulnerable communities calls for a renewed approach in insurance. Our team brings together industry veterans from the most renowned institutions (AXA, SCOR, Swiss Re, Marsh, Aon, ...) and scientists on top of their field to bring underwriting excellence. After 5 years of existence, Descartes has secured a leading position in parametric insurance for weather and climate-related risks utilizing machine learning, real-time monitoring from satellite imagery & IoT. After a successful Series B raise of $120M USD, we launched Descartes Insurance, a 'full stack' insurer licensed to underwrite risk by the French regulator ACPR. With a growing corporate client base (350+ and counting), our diverse team is headquartered in Paris and operates out of our 13 global offices in North America, Europe, Australia, Singapore, Hong Kong and Japan. Descartes is trusted by a panel of A-rated (re)insurers to carry out its activities.
ABOUT YOUR ROLE
Due to our consistent growth, we are expanding our Data, Software and DevOps team. We are seeking profiles dedicated to data engineering. At the core of the development of our scientific engine modeling climate phenomena, your main missions will be to create, improve and maintain the data pipelines used to train our model and infer the different scenarios to make a climate risk assessment. You will have to take initiative and assess the viability of proof-of-concept projects.
You will have to work with data scientists and software engineers to run and develop our models. You will be working alongside DevOps engineers to reliably put models in production and selected the compute/store instance needed to perform these tasks. Your secondary mission will be to automate the flow of information between the tech and business to monitor climate events.
üîî
KEY MISSIONS üîî
Design, setup, and maintain:
Data pipelines and associated datalakes;
Connections to external and internal APIs;
Associated CI/CD and release pipelines;
Notification tools to inform the team of the status of the operations.
Propose and setup data storage, data processing and data visualizing tools including:
Assessing the pains and needs of the teams;
Benchmarking different solutions;
Assessing the security, price and reliability of data architecture;
Following the development the evolution of technologies on the topic;
Forecasting and tracking cloud spend.
Participate in:
Tech stack evolution;
Discussions with tech partners;
Training of other tech teams;
Support and debug of internal users.
TECH STACK üñ•Ô∏è
Cloud provider: GCP
Code versioning tool: Git + Gitlab
OS: Linux
Container: Docker
Container orchestrator: Kubernetes
Code base: Python
Notification tool: Slack
DATA STACK
Types: images, time series, data frames, etc.
Pipeline orchestrator: Apache Airflow
Data stores: Cloud SQL, FireStore, BigQuery
In our project, data is collected by sensors (satellite, weather station, IoT). We don‚Äôt work with personal or sensitive data, in most cases the data is publicly available (earthquake magnitude, cyclone track, precipitation ‚Ä¶).
ABOUT YOU
EXPERIENCE & QUALIFICATIONS üíªüñ•Ô∏è
[Hard skills]
Knowledge of the tech stack and demonstrated proficiency in production environments;
Minimum 3 years‚Äô experience in Python object-oriented programming;
Experience converting Python code to efficient data engineering tools;
Production experience with Docker;
Production experience with a cloud provider (GCP, AWS or Azure);
CI/CD and release pipelines;
Good knowledge in English and fluency in French.
[Soft skills]
Excellent communication skills, in both formal and informal settings, and in English and French;
Contribute to a rigorous data engineering culture;
Propagate Data Engineer best practices to other tech teams;
Well versed in Agile;
Mentoring junior engineers.
[Nice-to-have]
Prior experience working in data science or scientific computing projects;
Working knowledge of DevOps;
Contribution to an open source project.
MINDSET üí•
Strong interest with climate issue (it‚Äôs not a hoax, many people suffer from it);
Being comfortable to work alongside corporate insurers (some still wear suits üëî);
You enjoy CI/CD automation (or at least appreciate the elegance of a well-crafted pipeline);
Strong team spirit and ability to work (you‚Äôll have to review code and have your code reviewed);
Rigorous, creative and meticulous mind (we handle large insurance, we take our time);
Strong desire to learn (there‚Äôs no limitation to the tech used, we‚Äôre happy to test and learn new tools);
Eagerness to work in a multi-cultural environment (policies and teams are from all around the world üó∫Ô∏è).
WHY JOIN DESCARTES UNDERWRITING?
Opportunity to work and learn with teams from the most prestigious schools and research labs in the world, allowing you to progress towards technical excellence;
Commitment from Descartes to its staff of continued learning and development (think annual seminars, training etc.) ;
Work in a collaborative & professional environment ;
Be part of an international team, passionate about diversity ;
Join a company with a true purpose ‚Äì help us help our clients be more resilient towards climate risks;
A competitive salary, bonus and benefits;
You can benefit from a punctual home office days.
If you want to develop your skills and work in a friendly startup atmosphere, don‚Äôt hesitate and send us your application!
At Descartes Underwriting, we cherish value of diversity whatever it may be. We are committed to fighting against all forms of discrimination and for equal opportunities. We foster an inclusive work environment that respects all differences.
With equal skills, all our positions are open to people with disabilities.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Apache Airflow'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': ['Linux'], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': ['Slack', 'Teams'], 'Other': ['DevOps', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication', 'Initiative']}","{'JobDetail': ['Full', 'Junior'], 'TypeContract': [], 'Salary': ['Salary'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer H/F,Davidson consulting,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-davidson-consulting-3913991399?position=8&pageNum=35&refId=dZ1gMrOpD8AXyzg1FiBMxg%3D%3D&trackingId=r1M1AAERTfnl0evdu2IjpQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Rejoindre Davidson, ce n'est pas seulement int√©grer un groupe de 3000 consultants dans 8 pays et 3 continents, c'est int√©grer LA soci√©t√© qui a √©t√© √©lue par ses salari√©s Great Place To Work France et Europe pendant 4 ans ainsi que la plus grande B Corp (Benefit Corporation) de France !
Les ¬´ B Corp ¬ª formant une communaut√© de soci√©t√©s qui ont d√©cid√© d'√™tre non pas les meilleures du monde mais les meilleures POUR le monde.
Parce que notre d√©veloppement repose sur des principes forts :
Un profond respect de l'ensemble de nos parties prenantes : consultants, clients et fournisseurs. Car si le travail ne fait pas le bonheur, il peut cependant faire le malheur. Nous nous engageons donc √† √©couter, agir avec honn√™tet√© et promouvoir l'√©quit√©.
Une empreinte environnementale minimale, et soci√©tale maximale. C'est pourquoi, au-del√† des missions que vous r√©aliserez, vous pourrez √©galement contribuer √† des projets que Davidson soutient : missions de solidarit√© internationale (avec Plan√®te Urgence), accompagnement d'√©tudiant(e)s issus de milieux peu favoris√©s (avec Article 1), investissement dans des startups d√©veloppant des solutions innovantes !.
Un Management adhocratique bas√© sur la mise en oeuvre des principes de l'entreprise horizontale et du management tribal.
Sur ce dernier point une pr√©cision d'importance : le bien-√™tre au travail est un luxe qu'il faut pouvoir s'offrir en √©tant une entreprise solide. Ceci induit pour les davidsonien(ne)s d'allier prises d'initiative, engagement et professionnalisme. Car sans travail, le talent n'est qu'une sale manie. Et nous incite √† chercher √† recruter des √©l√©ments meilleurs que nous. Dans une organisation classico-hi√©rarchique, il peut √™tre b√©n√©fique d'avoir une arm√©e de gens qui travaillent pour vous. Dans une adhocratie, ils causent des d√©g√¢ts.
Pour Le Compte D'un De Nos Clients Grand Compte, Et Sous La Responsabilit√© Du Manager Davidson, Vous Apporterez Votre Expertise En Tant Que Data Engineer. Vos Missions Seront Entre Autres
Assurer la collecte, le stockage et l'exploitation des donn√©es.
D√©velopper des applications distribu√©es √† grande √©chelle.
Construire des mod√®les de stockage performants.
De formation Bac +5, vous √™tes dipl√¥m√© d'une Ecole d'Ing√©nieurs ou de l'Universit√©, avec une sp√©cialisation en informatique et d√©veloppement.
Vous avez une bonne ma√Ætrise des diff√©rentes technologies/outils suivants :
Spark / Hadoop.
Scala, Java.
SQL (MariaDB), HBase, Hive, Impala.
Vertica, Elastic Search, HDFS (Parquet, ORC).
Kafka.
Airflow.
Vous avez un tr√®s bon niveau d'anglais et id√©alement une exp√©rience de travail en m√©thodes agiles.
Vos capacit√©s d'analyse et votre rigueur vous permettent de mener √† bien les attendus techniques de vos projets dans le respect des d√©lais impartis.
Votre ouverture d'esprit et votre disponibilit√© vous permettront de r√©ussir et d'appr√©cier le m√©tier de consultant au sein d'une entreprise en forte croissance.
Show more
Show less","{'ProgLanguage': ['Java', 'Scala', 'R'], 'DataBase': ['SQL', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Consultant Microsoft Data & BI (H/F),EXAKIS NELITE,"Clermont-Ferrand, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/consultant-microsoft-data-bi-h-f-at-exakis-nelite-3905645675?position=9&pageNum=35&refId=dZ1gMrOpD8AXyzg1FiBMxg%3D%3D&trackingId=IJwuqp4QuWYYzre07ojdbQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Exakis Nelite, entit√© du groupe
Magellan Partners
, est le
1er partenaire pure-player Microsoft
ind√©pendant en France avec l‚Äôambition de devenir le premier partenaire Europ√©en et en Afrique Francophone avec sa forte pr√©sence au Maroc.
N√©s du rapprochement de 2 leaders sp√©cialistes de l‚Äôint√©gration des solutions Microsoft, nous allions expertise technique et fonctionnelle pour r√©pondre concr√®tement aux enjeux de demain : acc√©l√©ration de la transformation digitale,
CyberS√©curit√©, Intelligence Artificielle, IoT, Data, transformation vers le cloud Azure, Services Cognitifs ‚Ä¶
En rejoignant la communaut√© Exakis Nelite dans l‚Äôune de nos 12 agences (680 collaborateurs), vous int√©grerez une √©quipe passionn√©e et impliqu√©e dans les projets les plus innovants. Vous rejoindrez une structure construite autour de valeurs tourn√©es vers ses collaborateurs : intelligence collective, convivialit√© et bienveillance.
Exakis Nelite a re√ßu la certification
Great Place to Work
et se place
3√®me de sa cat√©gorie
en 2024 parmi les entreprises o√π il fait bon travailler en France !
Poste et missions:
En tant que Consultant(e) Microsoft Data / BI, vous intervenez dans le cadre de projet d‚Äôinformatiques d√©cisionnelles, en forfait ou en r√©gie aupr√®s de nos clients. Les missions sont les suivantes :
‚Ä¢ Accompagner le client dans une d√©marche de mise en ≈ìuvre d'un syst√®me d√©cisionnel classique ou d'un outil de Modern BI
‚Ä¢ Analyser et qualifier le besoin
‚Ä¢ R√©diger des sp√©cifications fonctionnelles, techniques
‚Ä¢ Concevoir et d√©velopper les solutions BI
‚Ä¢ Mod√©liser et enrichir des bases de donn√©es
‚Ä¢ Mettre en place des outils de restitution BI pour la production de tableaux de bord et de reporting
‚Ä¢ Mod√©liser et impl√©menter des Datamarts et Datawarehouses
‚Ä¢ Pr√©parer et animer des formations et des s√©ances de coaching BI en entreprise
‚Ä¢ Mod√©liser des algorithmes de calculs statistiques permettant de faire diverses analyses (pr√©diction,clustering,‚Ä¶)
Profil:
De formation BAC+5 id√©alement en ing√©nierie, vous justifiez d‚Äôun minimum de 2 ans d‚Äôexp√©rience sur des technologies de Business Intelligence et/ou d‚Äôoutils statistiques.
Vous avez une r√©elle expertise sur un ou plusieurs environnements et langages suivants :
SQL server (2012 et suivants) et d√©veloppement de requ√™tes SQL complexes
Ma√Ætrise de la suite Microsoft BI (SSIS, SSAS, SSRS)
Ma√Ætrise de l'outil de Modern BI (Power BI)
Pr√©paration de la donn√©e
Mod√©lisation de la donn√©e (conception d'un mod√®le de donn√©e optimal)
Cr√©ation de rapports interactifs et tableaux de bords
Connaissance des probl√©matiques de connexion aux donn√©es (une exp√©rience en d√©veloppement de Custom Connectors est un plus)
Mise en ≈ìuvre de serveur Power BI Report Server
Vous √™tes √† l‚Äôaise avec les syntaxes DAX ou MDX
Bonne connaissance des services Data de Microsoft Azure (SQL Database, SQL Datawarehouse, Cosmos DB, Azure Data Lake Store, Azure Data Lake Analytics, Azure Data Factory, Azure Databricks, Azure HDInsight)
Bonne connaissance des services IA de Microsoft Azure (Azure Machine Learning, Azure Cognitive Services)
Bonne connaissance d‚Äôun langage de programmation (R,Python)
Maitrise de l'anglais.
Des exp√©riences dans les domaines du Big data et du machine learning sera un r√©el avantage (profils Data Scientists ou Data Citizens appr√©ci√©s). Maitrise de l‚Äôanglais indispensable.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': ['Statistiques'], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['SQL Server'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning', 'Statistiques', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Data Engineer en Alternance,Archery Data & Analytics,"Tours, Centre-Val de Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-en-alternance-at-archery-data-analytics-3907527785?position=10&pageNum=35&refId=dZ1gMrOpD8AXyzg1FiBMxg%3D%3D&trackingId=fuMbh5r3Mmp72P1Au75CNg%3D%3D&trk=public_jobs_jserp-result_search-card,"Description de l'entreprise
Archery Data & Analytics est un cabinet d‚Äôexpertise Data, filiale d‚ÄôArchery Strategy Consulting, cabinet de conseil en direction g√©n√©rale sp√©cialis√© dans 3 secteurs‚ÄØ: a√©ronautique/spatial/d√©fense, transports/logistique et √©nergie.
Nous intervenons chez nos clients sur des probl√©matiques :
De strat√©gie et de transformation data/digitale (gouvernance des donn√©es, roadmap data, digitalisation‚Ä¶)
De ma√Ætrise d‚Äô≈ìuvre et gestion de projets Data √† forts enjeux (utilisation des m√©thodes Agiles, Scrum, DevOps‚Ä¶)
De r√©alisation de projets Data & Analytics (Business Intelligence, MDM, BIG DATA, Data Sciences, Low Coding‚Ä¶)
Enfin, nous d√©veloppons et commercialisons des solutions m√©tiers √† haute valeur ajout√©e (ing√©nierie, gestion de projets, outils grands programmes, suivi de production, maintenance‚Ä¶).
Le cabinet a √©t√© constitu√© en 2021 et est aujourd‚Äôhui repr√©sent√© par 13 consultants Data & Analytics r√©partis sur nos sites de Tours, Paris et Toulouse.
Description de la mission
Archery Data & Analytics √† la recherche d‚Äôun.e alternant.e en Data Engineering en Master 1 (4√®me ann√©e) afin de compl√©ter notre √©quipe.
Au sein du cabinet, vous √©voluerez dans l‚Äôenvironnement de travail suivant :
Fonctionnel : Industrie, supply-chain, logistique, fonctions transverses (qualit√©, finance, informatique‚Ä¶)
Plateformes Cloud : Microsoft AZURE
Plateformes Data Onpremise : Hadoop/Spark
Outils de Reporting : Microsoft Power BI ou QlikView ou Tableau.
Plateformes d‚Äôint√©gration : SQL Integration Services, Informatica, Azure Data Factory
Langages de programmation : SQL, DAX, Python, .NET
Outils de Data Science : Data Bricks
Des connaissances dans cet environnement sont un v√©ritable plus, aucune maitrise n‚Äôest demand√©e.
Vos Missions au quotidien :
Apporter conseils et expertises √† nos clients lors des missions Data.
Concevoir, d√©velopper et mettre en place des solutions Data & Analytics de bout en bout :
Participer √† la captation et l‚Äôanalyse des besoins de nos clients avec l‚Äôaide de nos consultants Data.
Concevoir les solutions √† mettre en ≈ìuvre de fa√ßon √† r√©pondre aux exigences et attentes des utilisateurs.
Contribuer √† la conception, puis √† la mise en place des infrastructures que ce soit en IaaS, SaaS ou PaaS‚Ä¶
Concevoir et mettre en place des flux de donn√©es automatis√©s, des mod√®les de donn√©es‚Ä¶
Concevoir et d√©velopper des reporting d‚Äôaide √† la d√©cision (calculs complexes et algorithmes inclus).
Documenter les solutions d√©velopp√©es et en assurer le maintien en conditions op√©rationnelles (MCO).
Assurer le suivi du projet et la relation avec le client final.
3. Participer aux projets de d√©veloppements de produits internes du cabinet Archery.
4. Assurer la veille technologique et contribuer √† √©tendre nos expertises.
Profil recherch√©
Niveau du dipl√¥me vis√© : Bac+5 avec des bases en syst√®mes d‚Äôinformations
Autonomie, rigueur, esprit d‚Äô√©quipe et force de proposition
Tr√®s bon relationnel, bonnes capacit√©s d‚Äôanalyse, de synth√®se et de r√©daction.
Localisation du poste : Tours (37)
Prise de fonctions : Septembre 2024
Types de contrats : Contrat d‚Äôapprentissage ou contrat de professionnalisation selon profil sur 24 mois
Processus de recrutement
Un premier entretien avec Meghann, notre charg√©e RH et Paul, notre manager du p√¥le Date engineering
Un deuxi√®me entretien avec Julien, notre Pr√©sident
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
D√©veloppeur Big Data - Spark,NEXTON,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/d%C3%A9veloppeur-big-data-spark-at-nexton-3911787310?position=1&pageNum=37&refId=3scIT4h7LcxHkowem3t5kA%3D%3D&trackingId=lNIo4gI17gKIgLn8o6MPpw%3D%3D&trk=public_jobs_jserp-result_search-card,"Mission (fiche m√©tier)
NEXTON recrute un
D√©veloppeur Big Data - Spark
, en CDI, √†
Lyon
!
Qui sommes-nous ?
NEXTON c‚Äôest avant tout une entreprise qui accompagne ses clients dans leur transformation digitale. Tous les jours, nous travaillons avec des grands comptes et des pures players (SNCF, Orange, BNP PARIBAS‚Ä¶).
Nous sommes experts du digital aussi bien sur de l‚Äôaccompagnement strat√©gique qu‚Äôop√©rationnel.
Fort du succ√®s, Nexton conna√Æt aujourd‚Äôhui un d√©veloppement significatif, autour de ses valeurs piliers : coh√©sion, confiance et performance.
Et pour toi ? Notre politique de d√©veloppement des comp√©tences dynamique saura te s√©duire avec un programme de suivi de carri√®re sur-mesure.
Le contexte :
Pour l'un de nos clients, dans le secteur de l'√©nergie, nous sommes √† la recherche d'un d√©veloppeur Big Data.
Les missions :
Apporter une expertise
Big Data
pour faciliter la manipulation des donn√©es.
D√©finir les solutions techniques permettant le traitement massif des donn√©es.
Mettre en place des
solutions de stockage de donn√©es
(SQL, NoSQL etc.)
Veiller la s√©curisation et la clart√© des pipelines de donn√©es pour faciliter
l'analyse
et la
transformation
.
Assurer la cr√©ation, la maintenance, l'optimisation et la s√©curit√© des bases de donn√©es.
Assurer le support aux √©quipes de
d√©veloppement
afin d'identifier et proposer des solutions performantes.
Profil (fiche m√©tier)
De formation sup√©rieure, tu justifies d'une exp√©rience d'au moins
4 ans
dans le domaine.
Tu maitrises
Spark
,
Python
et
SQL
.
Tu es
autonome
,
rigoureux
et
force de proposition
.
De plus, tu as acquis une
capacit√© d'analyse
et de
synth√®se
gr√¢ce √† tes diff√©rentes exp√©rience.
Tu maitrises √©galement les fondamentaux de
l'agilit√©
.
Enfin, ton
esprit d'√©quipe
te permet de communiquer et de travailler dans les meilleures conditions.
NEXTON c‚Äôest aussi et surtout de nombreux moments de rencontres tout au long de l‚Äôann√©e :
- Des communaut√©s : 2 Meet Up par mois pour partager et √©changer avec des experts
- De nombreux moments de rencontres professionnels et extra professionnels tout au long de l‚Äôann√©e
- Des moments privil√©gi√©s avec ton manager
Pr√™ts √† nous rejoindre ? Rencontrons-nous !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': ['Orange'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Data Engineer Snowflake (confirm√©/s√©nior) - H/F - CDI,Talan,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-snowflake-confirm%C3%A9-s%C3%A9nior-h-f-cdi-at-talan-3890985747?position=2&pageNum=37&refId=3scIT4h7LcxHkowem3t5kA%3D%3D&trackingId=7fDmrg36TdmiPiOJV45ifA%3D%3D&trk=public_jobs_jserp-result_search-card,"Talan est un cabinet de conseil en innovation et transformation par la technologie.
Depuis 20 ans, Talan conseille les entreprises et les administrations, les accompagne et met en ≈ìuvre leurs projets de transformation et d‚Äôinnovation en France et √† l'international. Pr√©sent sur cinq continents, le groupe pr√©voit de r√©aliser un chiffre d'affaires de 600 millions d'euros en 2022 pour plus de 6000 consultant¬∑e¬∑s et vise √† d√©passer la barre du milliard d‚Äô‚Ç¨ de CA √† horizon 2024.
Le Groupe met l'innovation au c≈ìur de son d√©veloppement et intervient dans les domaines li√©s aux mutations technologiques des grands groupes, comme le Big Data, l'IoT, la Blockchain et l'Intelligence Artificielle.
Pr√©sent dans les √©v√©nements incontournables du secteur, comme Viva Technology, Talan prend r√©guli√®rement la parole sur les enjeux de ces technologies r√©volutionnaires aux c√¥t√©s d'acteurs majeurs du secteur et de parlementaires (Syntec Num√©rique, Forum de l'intelligence artificielle, French Fab Tour, Forum de Giverny‚Ä¶).
Talan est une entreprise responsable, attach√©e √† la diversit√©. Des am√©nagements de poste peuvent √™tre organis√©s pour tenir compte des personnes en situation de handicap.
Retrouvez nos engagementsRSEiciet nos actions en faveur de la diversit√©ici
Job Description
Nous sommes √† la recherche d‚Äôun Big Data Engineer Snowflake qui sera en charge des mod√©lisations data et de l‚Äôint√©gration des donn√©es: acquisition, pr√©paration, mod√©lisation et stockage, exposition, . Vous devrez faire preuve d‚Äôun √©tat d‚Äôesprit √† la fois innovant, m√©thodique, orient√© solution (et non probl√®me!), et communiquant.
Responsabilit√©s
Analyse des besoins techniques m√©tiers, participation √† la d√©finition des architectures solution SQL, d√©veloppement et optimisation, code review, maintenir les pratiques Devops ‚ÄúYou build IT, You run IT‚Äù, support √† recette et mise en production, documentation,‚Ä¶
Mod√©lisation de la Cloud Database Snowflake
Benchmark de solutions et conseil aupr√®s de notre client sur les solutions technologiques √† adopter, en lien avec leurs besoins
Partage de connaissances et formations interne
Qualifications
Issu d‚Äôune formation sup√©rieure (√©cole d‚Äôing√©nieur, master‚Ä¶) avec une exp√©rience dans le domaine du conseil (orient√© satisfaction client et vision partenariale)
Vous disposez d‚Äôau moins 6 ann√©es d‚Äôexp√©rience dans le domaine du SQL/ETL et ayant une exp√©rience d‚Äôau moins 1 an sur Snowflake
Ma√Ætrise du d√©veloppement data (SQL, Python, ‚Ä¶) et vous disposez de solides exp√©riences dans la mise en place de pipeline de donn√©es
Ma√Ætrise d‚Äôau moins une technique de mod√©lisation: Star Sch√©ma, DataVault, DataMesh,‚Ä¶
Exp√©rience sur une plateforme Cloud (id√©alement AWS)
Exp√©rience sur des flux temps r√©el
La connaissance de concepts comme les suivants serait un +: DataOps, FinOps,..
Exp√©rience de l‚ÄôAgilit√©
Autonomie, organisation, sens du partage
Bonne communication
Orientation produit et solution
Additional Information
AVANTAGES
:
Plan de formation pour accompagner votre carri√®re (formations √©diteurs, certifications) gr√¢ce √† nos partenariats nous accordant une position de partenaire privil√©gi√©, et management de proximit√© par des experts
Locaux modernes en centre-ville
Top 5 du Palmar√®s Great Place to Work
T√©l√©travail jusqu‚Äô√† 5 jours selon les missions, prime d‚Äô√©quipement de 100‚Ç¨
Mobilit√© en France et √† l‚Äô√©tranger
Top 1% des entreprises √©valu√©es par Ecovadis dans le domaine social, environnemental et √©thique
Tickets restaurant, prime vacances, 50% transport (abonnement transport public), mutuelle
Permanence handicap (consultant d√©di√© aux collaborateurs en situation de handicap et aux proches aidants)
Actionnariat salari√©
Prime de cooptations
RTT
L‚Äô√©quipe recrutement s‚Äôengage √† vous proposer un processus de recrutement rapide et fluide :
Un premier √©change de 30 min en visio avec le recruteur pour vous pr√©senter le poste et comprendre votre projet professionnel
2 entretiens m√©tier, dont au moins 1 dans nos locaux, pour entrer dans les d√©tails du poste et rencontrer votre futur manager
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Communication', 'Organisation'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '20', '20', '20']}"
Data engineer - d√©veloppeur C# H/F,Reboot Conseil,"Strasbourg, Grand Est, France",https://fr.linkedin.com/jobs/view/data-engineer-d%C3%A9veloppeur-c%23-h-f-at-reboot-conseil-3909657286?position=3&pageNum=37&refId=3scIT4h7LcxHkowem3t5kA%3D%3D&trackingId=Bu0VwR8Z3%2FIHjniwIutgYA%3D%3D&trk=public_jobs_jserp-result_search-card,"En 2020, dans un climat d√©favorable et d√©moralisant, nous avons d√©cid√© d‚Äô√™tre cette jeune pousse porteuse d‚Äôespoir que l‚Äôon voit apr√®s un incendie ayant d√©cim√© toute une for√™t, d‚Äô√™tre ce vent nouveau qui veut faire √©voluer les choses, d‚Äô√™tre ce bouton Reboot qu‚Äôon presse pour corriger ce qui n‚Äôallait pas et repartir sur une bonne base. Voil√† comment notre soci√©t√© est n√©e.
Jour apr√®s jour, nous portons nos ambitions et nos r√™ves pour nous r√©aliser individuellement et collectivement avec un socle culturel atypique issu du livre ¬´ Reinventing organizations ¬ª dont d√©coule des valeurs fortes de bien-√™tre au travail, de partage, de libert√© et de transparence.
Chez Reboot Conseil, nous ne nous contentons pas de fournir des prestations de conseil, nous cr√©ons de la valeur pour nos clients, que ce soit par des conseils en pr√©sentiel ou √† distance, l‚Äôaccompagnement de candidats en immersion dans les √©quipes de nos clients, la conception de projets innovants depuis notre centre d'expertise, le recrutement de talents exceptionnels ou m√™me la commercialisation de nos propres produits.
Notre mission est de ne jamais s'ennuyer et de toujours repousser les limites de ce que nous pouvons r√©aliser. Rejoignez-nous pour une aventure passionnante o√π chaque membre est une source in√©puisable de nouveaut√©s.
Nous recherchons actuellement un/e Data Engineer - analyste d√©veloppeur
Contexte_:
L'avancement des solutions informatiques permettant le traitement automatique du langage naturel et l'apprentissage par l'exemple ouvre de nouvelles perspectives pour am√©liorer le soutien aux collaborateurs et mieux servir les clients.
Le client a ainsi choisi d'investir consid√©rablement dans le domaine de l'informatique cognitive, en √©tant parmi les premi√®res en France √† d√©ployer la technologie. Plusieurs solutions dites ont √©t√© mises en place, comprenant des Assistants Virtuels (chatbots), des Analyseurs d'emails et des Assistants Vocaux t√©l√©phoniques.
Au sein du d√©partement d√©di√©, dans un environnement innovant, vous aurez l'opportunit√© de rejoindre une √©quipe sp√©cialis√©e dans l'exploitation des donn√©es et les architectures.
Cette √©quipe a pour mission de d√©finir l'architecture applicative des solutions, de d√©velopper des outils d'analyse des donn√©es collect√©es et d'enrichir les processus m√©tiers de l'entreprise.
Selon les projets en cours, les technologies utilis√©es incluent notamment C#, SQL Server, NOSQL, Kibana, Kafka et d'autres technologies √©mergentes. En tant que membre de cette √©quipe dynamique, vous serez impliqu√© dans diverses t√¢ches li√©es √† la gestion des donn√©es.
Vous serez amen√© √† concevoir et r√©diger des sp√©cifications fonctionnelles, applicatives et techniques, √† d√©velopper des applications intranet pour l'exploration et la restitution des donn√©es, √† mod√©liser les donn√©es des solutions dans le syst√®me d'information d√©cisionnel, √† cr√©er des tableaux de bord et √† fournir un support aux autres √©quipes. Vous serez √©galement charg√© d'organiser la recette des solutions applicatives, de g√©rer les demandes d'√©volution et de suivre la production, tout en travaillant en mode projet conform√©ment aux normes de qualit√© en vigueur.
Profil
Titulaire d'une formation sup√©rieure en informatique de niveau bac +4/5, vous avez acquis une expertise dans les ETL, les bases de donn√©es orient√©es Analytique, les solutions BI ainsi que dans les langages de programmation objet comme le C#.
Ce qui retiendra notre attention chez vous, c'est avant tout votre personnalit√© ! Nous recherchons des candidats curieux, ouverts aux innovations technologiques, pr√™ts √† relever des d√©fis techniques tout en √©tant √† l'√©coute et rigoureux, car ces qualit√©s vous permettront de mener √† bien votre mission.
Vous disposez √©galement de capacit√©s d'analyse et de synth√®se, vous attachez de l'importance au respect des normes et standards qualit√©, et vous √™tes enthousiaste √† l'id√©e d'apprendre de nouveaux outils et langages.
Vous appr√©ciez la communication et le travail en √©quipe, mais vous savez √©galement collaborer efficacement avec d'autres √©quipes.
Informations contractuelles
Poste en CDI bas√© √† Strasbourg
Salaire: 32-42K‚Ç¨
D√©placements: non
Les avantages chez Reboot
Une prime de mobilit√© durable de 200‚Ç¨/an, 2 jours de t√©l√©travail/semaine, 2 charity days par an, un abonnement √† Gymlib pris en charge par Reboot √† 50%, une √©volution salariale annuelle, automatique, une bonne mutuelle, abonnement transports en commun pris en charge √† 50%, des BSPCE...
Soit au total, un Package Salarial de 3.5k‚Ç¨ en compl√©ment de votre salaire annuel brut.
‚ûïdes tech party days 1x/trimestre
‚ûïun Hackathon 1x/an
Show more
Show less","{'ProgLanguage': ['C#', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['SQL Server'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication', 'Organization']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['32', '3.5k'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,Societe Generale,"La D√©fense, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-societe-generale-3889843774?position=4&pageNum=37&refId=3scIT4h7LcxHkowem3t5kA%3D%3D&trackingId=K%2BeDgWn%2FwNWyqx33YjAVSA%3D%3D&trk=public_jobs_jserp-result_search-card,"240006K4
Vos missions au quotidien
Vous souhaitez exercer votre talent et exprimer votre cr√©ativit√© au sein de notre √©quipe (Feature Team) en charge des services Big Data en tant que Data Engineer ? Rejoignez-nous !
En tant qu'alternant(e) Data Engineer, vous rejoindrez l'√©quipe M√©trologie, en charge le service Big Data h√©bergeant les donn√©es techniques logs, m√©triques‚Ä¶du cloud priv√© de la Soci√©t√© G√©n√©rale. Ces donn√©es sont expos√©es pour des utilisations diverses : monitoring, maintenance pr√©dictive, capacity planning, am√©liorations des services...
Concr√®tement, vous serez amen√©(e), sous la supervision de votre tuteur et/ou votre manager, √† :
Participer √† l'√©volution des services offerts par cette √©quipe en enrichissant son offre
Participer √† la production du Cloud Priv√© Soci√©t√© G√©n√©rale qui est au service des DSI m√©tiers
Travailler sur des technologies Big Data tr√®s r√©centes, h√©berg√©es sur le Cloud Priv√© de la banque
Et si c‚Äô√©tait vous ?
Vous pr√©parez un Bac +4/5 en √©cole de Commerce, d'Ing√©nieur ou Universit√© avec une sp√©cialisation en D√©veloppement, Informatique.
Vrai(e) team player, vous vous √©panouissez dans un environnement collaboratif et favorisez la r√©ussite de votre √©quipe
Vous avez des connaissances sur certaines des technologies suivantes : Python, Kafka, Hadoop, Bigdata, Elastic Search, Druid
Vous avez de bonnes bases autour de la CI/CD (Jenkins)
Rigoureux(se), autonome et organis√©(e), vous avez un bon relationnel
You're fluent in english ! Vous √™tes notre candidat(e) id√©al(e) !
Pensez √† accompagner votre CV de votre planning de formation
Plus qu‚Äôun poste, un tremplin
D√®s votre arriv√©e, vous serez int√©gr√© dans nos √©quipes et apprendrez chaque jour aux c√¥t√©s de nos experts qui vous accompagneront dans vos missions. Progressivement, vous gagnerez en autonomie sur vos projets pour faire de cette exp√©rience un vrai acc√©l√©rateur de carri√®re. Vous d√©couvrirez √©galement toute la diversit√© de nos m√©tiers, dans un secteur qui √©volue et innove en permanence.
A la fin de vos √©tudes, diverses opportunit√©s pourront s‚Äôoffrir √† vous, en France et √† l‚Äôinternational.
Pourquoi nous choisir ?
Attentif √† votre qualit√© de vie et conditions de travail, vous b√©n√©ficiez d‚Äôavantages :
Prime* de participation et d‚Äôint√©ressement
Jours de t√©l√©travail (selon le rythme de votre service et celui de votre alternance)
Prise en charge de 50% de votre titre de transport
Billetterie √† prix r√©duits de notre Comit√© d‚ÄôEntreprise (concerts, cin√©ma, sport‚Ä¶).
Offre vari√©e de restaurants d‚Äôentreprise et de caf√©t√©rias √† tarifs comp√©titifs ainsi que des titres restaurants d√©mat√©rialis√©s quand vous √™tes en t√©l√©travail
Si vous avez 3 mois d‚Äôanciennet√© sur l‚Äôexercice de r√©f√©rence
Cr√©er, oser, innover, entreprendre font partie de notre ADN. Si vous aussi vous souhaitez √™tre dans l‚Äôaction, √©voluer dans un environnement stimulant et bienveillant, vous sentir utile au quotidien et d√©velopper ou renforcer votre expertise, nous sommes faits pour nous rencontrer !
Vous h√©sitez encore ?
Sachez que nos collaborateurs peuvent s‚Äôengager quelques jours par an pour des actions de solidarit√© sur leur temps de travail : parrainer des personnes en difficult√© dans leur orientation ou leur insertion professionnelle, participer √† l‚Äô√©ducation financi√®re de jeunes en apprentissage ou encore partager leurs comp√©tences avec une association. Les formats d‚Äôengagement sont multiples.
Nous sommes un
employeur garantissant l'√©galit√© des chances
et nous sommes fiers de faire de la diversit√© une force pour notre entreprise. Le groupe s‚Äôengage √† reconna√Ætre et √†
promouvoir tous les talents
, quels que soient leurs croyances, √¢ge, handicap, parentalit√©, origine ethnique, nationalit√©, identit√© de genre, orientation sexuelle, appartenance √† une organisation politique, religieuse, syndicale ou √† une minorit√©, ou toute autre caract√©ristique qui pourrait faire l‚Äôobjet d‚Äôune discrimination.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Cr√©ativit√©', 'Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,MS Amlin,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-ms-amlin-3910914411?position=5&pageNum=37&refId=3scIT4h7LcxHkowem3t5kA%3D%3D&trackingId=k4225ovXcJ%2FeYbTYQOOjbQ%3D%3D&trk=public_jobs_jserp-result_search-card,"We are looking for a highly skilled and motivated Data Engineer to join our dynamic team. As a Data Engineer you will play an important role in designing, building and maintaining the systems and architecture that enable MS AISE to collect, store and analyze large volumes of data. The ideal candidate is passionate about data, possesses strong analytical skills and has a proven track record of implementing robust and scalable data solutions in the cloud.
As an MS AISE Data Engineer you will reportin into MS AISE‚Äôs Data Engineering Team Manager and will work closely with the MS AISE‚Äôs Reporting & Analytics team as well as other key stakeholders with a strong interest in data, such as technical pricing, actuarial and finance.
Key Responsibilities
Data architecture design: design and implement scalable and robust data architectures to support MS AISE‚Äôs data needs. Collaborate with stakeholders to understand data requirements and translate them into technical specifications.
Data Integration: Develop and implement ETL (Extract, Transform, Load) processes to integrate data from various sources into a unified data lake. Ensure data integrity, accuracy and reconciliation throughout the integration process
Data Management: Manage and optimize database / datamart design including schema design, indexing and performance tuning as well as data security and access controls to ensure protection of sensitive data.
Data Modeling: Create and maintain data models to represent the structure and relationships within the data of MS AISE.
Data Pipeline Development: Build and maintain data pipelines to ensure automated collection, processing and storage of data. Monitor and troubleshoot data pipeline issues to ensure smooth and reliable data flow and availability.
Collaboration with cross-functional teams: Collaborate with the MS AISE Reporting & Analytics team and other key stakeholders to understand data requirements and contribute to the delivery of solutions that meet business objectives.
Documentation: contribute to creating and maintaining comprehensive documenatation for data engineering processes, workflows and data dictionaries.
Technological Evaluation: Ensure you stay informed about emerging technologies and evaluate their applicability to the organization‚Äôs data architecture and processes.
Key Skills / Experience
Minimum 3+ years of Experience as a Data Engineer
Strong Experience with relational data structures, theories, principles and practices
Strong hands-on experience with SQL Language, data transformation and modelling tools.
Proven experience with building Data Lake, Delta lake and large scale Data Warehouses
Strong experience in implementing large scale cloud data architecture using Azure, Synapse, Azure Databricks, Data Fabric etc
Proficient in Azure Data Factory, Azure Data Lake, Azure DevOps, Azure Databricks, Azure SQL Database, Stream Analytics. Knowledge of Microsoft Fabric is a strong plus
Good knowledge of tools associated with data ingestions & data transformations (e.g. SQL, Spark, Python)
Good knowledge or experience with Python Programming Language
Good knowledge or experience with other Cloud platforms is a strong plus (Google Cloud, Databricks, AWS, Snowflake, etc)
Knowledge of insurance market business applications & procedures and/or from an equivalent industry
Competencies
Strong analytical & conceptual mindset
Strong teamplayer
Ability to deliver from start to finish with minimal oversight
Ability to work in a structured and efficient manner
Ability to work in line with standard development framework & practices
Pragmatic, self-starter and solution oriented
Ability to identify and anticipate on problems early and communicate timely
Good communication skills
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration', 'Organization']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
"Data Engineer F/H - Syst√®me, r√©seaux, donn√©es (H/F)",HelloWork,"Rennes, Brittany, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-syst%C3%A8me-r%C3%A9seaux-donn%C3%A9es-h-f-at-hellowork-3900073980?position=6&pageNum=37&refId=3scIT4h7LcxHkowem3t5kA%3D%3D&trackingId=M433s5A%2B6fw3NFQES954wQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Cette offre d‚Äôemploi est fournie par P√¥le emploi
Description
Descriptif du poste: Participez au d√©veloppement d'hellowork.com au sein de l'√©quipe Data Ing√© d'Antoine ! hellowork.com, c'est : * Plus de 4 millions de visites par mois * Plus de 500 000 candidats uniques par mois Vous √©voluerez dans un environnement o√π la qualit√©, la performance et l'accessibilit√© sont au c≈ìur de tous nos d√©veloppements ! Et bien s√ªr, tout √ßa se d√©roule dans un cadre accueillant, motivant et bienveillant pour vous permettre de mener √† bien la multitude de sujets actuels ou √† imaginer pour faire avancer le produit ;) Plus concr√®tement, votre quotidien sera compos√© de : * Faire √©voluer et maintenir l'infrastructure recommandation principalement en Python en collaboration avec l'√©quipe Data Science ; * Assurer la haute disponibilit√© de la donn√©e ; * Collaborer avec les √©quipes expertes et produit pour r√©soudre les probl√®mes, remettre en question et am√©liorer les pratiques de travail sur la donn√©e, les process, les architectures et les technologies ; La stack technique : * Python sur les services li√©s √† la Data Science, NodeJs sur les services orient√©s API ; * Des services scalables d√©ploy√©s sur Kubernetes via une CI Gitlab aux petits oignons cr√©√©e en collaboration avec l'√©quipe DevOps ; * GPU ou CPU ? Il y a qu'√† tester ! * Du monitoring cl√© en main Prometheus / Grafana / Log Elastics ; * Des challenges sur des DB vari√©es plut√¥t NoSQL : Elastics, MongoDB, Redis. * Broker de message via Azure Event Hubs Profil recherch√©: Pour √™tre tr√®s simple, voici les points importants pour nous dans le profil recherch√© : * Vous avez une expertise sur le langage Python et √™tes pr√™t √† utiliser d'autres langages (principalement NodeJs). * Vous √™tes curieux et passionn√© par les nouvelles technologies ; * Vous justifiez de minimum 2 ans d'exp√©rience sur un poste similaire. Une expertise Python est un vrai plus mais nous cherchons avant tout quelqu'un sachant s'adapter ! * Vous avez un esprit d'√©quipe, aimez collaborer avec des profils diff√©rents du v√¥tre, et √™tes familier des m√©thodes agiles ; Si vous √™tes int√©ress√©, alors rencontrons nous ! Promis, on est tr√®s sympa. Et si vous h√©sitez √† postuler parce que vous ne cochez pas toutes les cases, surtout venez nous en parler ! Nous favorisons la diversit√© et nous formons et accompagnons les personnes qui nous rejoignent tout au long de leur √©volution.
PROFIL SOUHAIT√â
Exp√©rience
Exp√©rience exig√©e de 1 An(s)
Source: Pole emploi (https://www.pole-emploi.fr)
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['DevOps'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Data engineer SQL server / Dev SSIS / C# (H/F) üë®üèªüíª,XRAYS TRADING,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-sql-server-dev-ssis-c%23-h-f-%F0%9F%91%A8%F0%9F%8F%BB%E2%80%8D%F0%9F%92%BB-at-xrays-trading-3813760880?position=7&pageNum=37&refId=3scIT4h7LcxHkowem3t5kA%3D%3D&trackingId=PpuTStCeaf%2BEecpbgYcOag%3D%3D&trk=public_jobs_jserp-result_search-card,"XRAYS TRADING
est depuis 19 ans la structure la plus
atypique
du monde de la bourse !
Nous faisons en sorte pour que ton quotidien soit bourr√© d'
adr√©naline
et de
moments inoubliables
, le tout en t‚Äôaidant √† construire ta
carri√®re
au sein d'un groupe de travail sans √©quivalent üë©üèº‚Äçüíª
Pour r√©sumer : Tu vas int√©grer une boite d‚Äô
ing√©nieurs
totalement barr√©s qui savent s‚Äô√©clater pendant et apr√®s le boulot ! üòâ
NOTRE BESOIN :
Participer aux projets li√©s aux Stress Tests Risques de March√©s en tant que data engineer et d√©veloppeur (MS SQL, packages SSIS, cubes SSAS et composants C#)
Fournir des solutions pour des nouveaux besoins
Assurer le support et la maintenance de l'outil
Traitements ETL complexes (SSIS) pour fournir des donn√©es via des cubes OLAP (Multidimensionnel). Ecosyst√®me d'outils en C#. Gestion du code dans Git/ BitBucket. Pipe de livraison Jenkins & XL Release.
Une connaissance des produits financiers et de mesures de risque de march√© serait un plus sur ce poste ainsi qu'un Anglais op√©rationnel obligatoire.
TOI
:
Tu es dipl√¥m√©(e) d'une belle √©cole d'ing√©nieur.
Tu es √©veill√©(e) et tu communiques sans difficult√© tant en Fran√ßais qu'en Anglais.
Tu es passionn√©(e) par la finance de march√©, tu es donc quelqu'un de curieux qui cherche √† comprendre comment fonctionne notre √©cosyst√®me.
Tu recherches une port√©e internationale dans tes attributionsüåç
Ton temp√©rament te m√®ne √† sortir de ta zone de confort afin de gagner en autonomie tout en d√©couvrant un immense p√©rim√®tre dont on ne fait jamais le tour : la finance de march√© !
NOTRE OFFRE :
Avec une exp√©rience minimale de 5 ans, tu peux partir du principe o√π nous te proposons un salaire minimal de 3800 euros nets.
Ce salaire est √©videment tr√®s bien revaloris√© en fonction de ton dipl√¥me mais surtout de ton exp√©rience !
Nous te formerons √† nos outils, m√©tier et m√©thodes, nous sommes souples, ouverts et humains. Nous souhaitons t'accompagner dans ta mont√©e en comp√©tences.
Passe nous faire un check sur www.xrays.fr ! üöÄ
Show more
Show less","{'ProgLanguage': ['C#', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['3800', '5'], 'Level': [], 'Experience': ['a', 'n', 's', '19', '19', '19']}"
Data Analyst H/F,Inetum,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-inetum-3843955768?position=8&pageNum=37&refId=3scIT4h7LcxHkowem3t5kA%3D%3D&trackingId=iHtnLky7lKLcRpf5Mbva9Q%3D%3D&trk=public_jobs_jserp-result_search-card,"D√©tail de l'offre
Informations g√©n√©rales
Entit√© de rattachement
Inetum est un leader europ√©en des services num√©riques. Pour les entreprises, les acteurs publics et la soci√©t√© dans son ensemble, les 28 000 consultants et sp√©cialistes du groupe visent chaque jour l'impact digital des solutions qui contribuent √† la performance, √† l'innovation et au bien commun.
Pr√©sent dans 19 pays au plus pr√®s des territoires, et avec ses grands partenaires √©diteurs de logiciels, Inetum r√©pond aux enjeux de la transformation digitale avec proximit√© et flexibilit√©.
Port√© par son ambition de croissance et d'industrialisation, Inetum a g√©n√©r√© en 2023 un chiffre d'affaires de 2,5 milliards d'‚Ç¨.
Pour r√©pondre √† un march√© en croissance continue depuis plus de 30ans, Inetum a fait le choix d√©lib√©r√© de se recentrer sur 4 m√©tiers afin de gagner en puissance et proposer des solutions sur mesure, adapt√©es aux besoins sp√©cifiques de ses clients le conseil (Inetum Consulting), la gestion des infrastructures et applications √† fa√ßon (Inetum Technologies), l'impl√©mentation de progiciels (Inetum Solutions) et sa propre activit√© d'√©diteur de logiciels (Inetum Software). Inetum a conclu des partenariats strat√©giques avec 4 grands √©diteurs mondiaux - Salesforce, ServiceNow, Microsoft et SAP et poursuit une strat√©gie d'acquisitions d√©di√©e afin d'entrer dans le top 5 europ√©en sur ces technologies et proposer la meilleure expertise √† ses clients.
Tous nos postes sont ouverts aux personnes en situation de handicap.
Description du poste
M√©tier
Applications Delivery - Software Development
Intitul√© du poste
Data Analyst H/F
Contrat
CDI
Description De La Mission
Dans le cadre de la croissance de notre agence lilloise, nous d√©veloppons notre Practice Data et recrutons des profils Data de divers horizons Data Analyst, Data Engineer, Data Scientist et Data Gouv. Les besoins m√©tiers de nos clients et la multitude des technologies font qu'il nous faut nous appuyer sur une diversit√© de comp√©tences. Vous pourriez √™tre l‚Äôun d‚Äôeux et rejoindre Inetum.
En tant que Data Analyst, vos principales missions consistent √†
Analyser et retranscrire le besoin client
Identifier, extraire et exploiter les sources d'acquisition de donn√©es les plus pertinentes
Valoriser de la donn√©e
D√©velopper l'outil de data visualisation pour accompagner les √©quipes m√©tiers dans leurs aides √† la d√©cision
√ätre le lien entre les √©quipes m√©tier pour les accompagner dans la mise en ≈ìuvre des nouveaux outils
Profil
Pour mener √† bien votre r√¥le, il vous faut
parler SQL couramment
un niveau avanc√© sur Excel et/ou Google Spreadsheet
une ma√Ætrise d'un outil d√©cisionnel comme PowerBI, Qlik, Tableau ou encore Google Data Studio
Vous vous reconnaissez dans ces quelques lignes, alors rencontrons-nous !
Notre plus
Rejoindre la r√©gion Nord-Est, c‚Äôest b√©n√©ficier des avantages d‚Äôun Grand Groupe tout en gardant la proximit√© r√©gionale.
Nous mettrons tout en ≈ìuvre pour vous apporter un √©quilibre vie perso / vie pro. C‚Äôest pourquoi nous vous proposons un rythme hybride (selon les contraintes clients)
Une trajectoire de carri√®re personnalis√©e et adapt√©e √† vos souhaits d'√©volution gr√¢ce √† une implantation √† l‚Äôinternational (26 pays, 7 Fablab), des formations cibl√©es et des projets couvrant l‚Äôensemble de la cha√Æne de valeur IT (+25 fili√®res m√©tiers)
Int√©grer un collectif d‚Äôexperts partageant des valeurs de solidarit√© et d‚Äôexcellence
Int√©grer une entreprise ayant une strat√©gie affirm√©e de certifications de ses collaborateurs
Localisation du poste
Localisation du poste
France, Nord, 59 Nord
Ville
Lille
Crit√®res candidat
Niveau d'√©tudes min. requis
Bac+5
Niveau d'exp√©rience min. requis
Plus de 2 ans
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Flexibilit√©'], 'EnSoftSkils': []}","{'JobDetail': ['Hybride'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '30', '30', '30']}"
Data engineer,Societe Generale,"La D√©fense, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-societe-generale-3918754036?position=10&pageNum=37&refId=3scIT4h7LcxHkowem3t5kA%3D%3D&trackingId=C%2Fki0HYve2YtGbtwssrtHQ%3D%3D&trk=public_jobs_jserp-result_search-card,"24000COX
Vos missions au quotidien
Nous recherchons un(e) alternant(e) en Data Engineering dans le cadre d'un de nos projets au sein de notre direction informatique Corporate Functions Technologies.
Vous contribuerez √† l‚Äôex√©cution d'un chantier majeur de la cha√Æne Credit Risk.
Concr√®tement, vous serez amen√©(e) √† :
Concevoir des solutions pour collecter, nettoyer, organiser et synth√©tiser de gros volumes de donn√©es (pour alimenter bases de donn√©es, datalakes et projets Big Data) ;
Co-√©laborer le design technique du produit d√©livr√© ;
Apporter votre soutien sur les d√©veloppements de votre √©quipe ;
D√©velopper, entretenir et utiliser votre expertise sur la stack Scala, Spark, Hadoop ;
Participer √† l‚Äôindustrialisation du proc√©d√© pour les donn√©es les plus pertinentes dans le cadre du projet pour produire les analyses les plus op√©rationnelles, assurer une veille technologique et d√©montrer un int√©r√™t pour le domaine bancaire.
Et si c‚Äô√©tait vous ?
Vous √™tes un(e) √©tudiant(e) de niveau Bac+4/5 en Universit√©, √©cole de Commerce, d‚ÄôIng√©nieur, avec une sp√©cialisation en Big Data.
Vous maitrisez les technologies Big Data, en particulier l'√©cosyst√®me Hadoop.
Vous poss√©dez de solides connaissances en Spark et Scala.
Vous √™tes attach√©(e) au respect des bonnes pratiques de d√©veloppement.
You're fluent in english ! Vous √™tes notre candidat(e) id√©al(e) !
Pensez √† accompagner votre CV de votre planning de formation!
Plus qu‚Äôun poste, un tremplin
D√®s votre arriv√©e, vous serez int√©gr√© dans nos √©quipes et apprendrez chaque jour aux c√¥t√©s de nos experts qui vous accompagneront dans vos missions.
Progressivement, vous gagnerez en autonomie sur vos projets pour faire de cette exp√©rience un vrai acc√©l√©rateur de carri√®re. Vous d√©couvrirez √©galement toute la diversit√© de nos m√©tiers, dans un secteur qui √©volue et innove en permanence.
A la fin de vos √©tudes ou de votre VIE, diverses opportunit√©s pourront s‚Äôoffrir √† vous, en France et √† l‚Äôinternational.
Pourquoi nous choisir ?
Attentif √† votre qualit√© de vie et conditions de travail, vous b√©n√©ficiez d‚Äôavantages :
Prime de participation et d‚Äôint√©ressement
Jours de t√©l√©travail (selon le rythme de votre service et celui de votre alternance)
Prise en charge de 50% de votre titre de transport
Billetterie √† prix r√©duits de notre Comit√© d‚ÄôEntreprise (concerts, cin√©ma, sport‚Ä¶).
Offre vari√©e de restaurants d‚Äôentreprise et de caf√©t√©rias √† tarifs comp√©titifs ainsi que des titres restaurants d√©mat√©rialis√©s quand vous √™tes en t√©l√©travail
Cr√©er, oser, innover, entreprendre font partie de notre ADN. Si vous aussi vous souhaitez √™tre dans l‚Äôaction, √©voluer dans un environnement stimulant et bienveillant, vous sentir utile au quotidien et d√©velopper ou renforcer votre expertise, nous sommes faits pour nous rencontrer !
Vous h√©sitez encore ?
Sachez que nos collaborateurs peuvent s‚Äôengager quelques jours par an pour des actions de solidarit√© sur leur temps de travail : parrainer des personnes en difficult√© dans leur orientation ou leur insertion professionnelle, participer √† l‚Äô√©ducation financi√®re de jeunes en apprentissage ou encore partager leurs comp√©tences avec une association. Les formats d‚Äôengagement sont multiples.
Nous sommes un
employeur garantissant l'√©galit√© des chances
et nous sommes fiers de faire de la diversit√© une force pour notre entreprise. Le groupe s‚Äôengage √† reconna√Ætre et √†
promouvoir tous les talents
, quels que soient leurs croyances, √¢ge, handicap, parentalit√©, origine ethnique, nationalit√©, identit√© de genre, orientation sexuelle, appartenance √† une organisation politique, religieuse, syndicale ou √† une minorit√©, ou toute autre caract√©ristique qui pourrait faire l‚Äôobjet d‚Äôune discrimination.
Show more
Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data engineer GCP S√©nior,Apside,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-gcp-s%C3%A9nior-at-apside-3825028887?position=1&pageNum=40&refId=PlhdJ%2BvRBuQPyL9EJS3cmw%3D%3D&trackingId=OFv5GAwoVnXsBllV5IoOZA%3D%3D&trk=public_jobs_jserp-result_search-card,"üí•
D√©couvrez la Vie Apsidienne
üìπ
et vous aussi, devenez Apsidien
On aurait pu demander √† Chat GPT de vous d√©montrer en quoi
Apside est l‚ÄôESN qu‚Äôil vous faut,
mais on pr√©f√®re que vous le d√©couvriez vous-m√™mes üëáüòè
üî•
D√©couvrez votre future mission
üëâ
Contexte
Rejoignez notre Practise Cloud/Data, afin d‚Äôintervenir sur des sujets √† haute valeur ajout√©e !
Secteur
: T√©l√©com
M√©thode de travail
: Agile Safe
Notre client a besoin d‚Äôun accompagnement sur leurs projets m√©tiers
Data/IA
accostant sur un cloud public et √† la construction d'outils pour acc√©l√©rer et faciliter cet accostage.
Cela sera r√©alis√© dans un environnement
GCP
et en grande majorit√© sur des
technologies innovantes
pour des services Data & IA. La mission sera partag√© entre le ""build"" des cas d'usage et outils, et le ""run"" de ces derniers.
üòé Mission
Etude et d√©finition des architectures GCP, ainsi que leur impl√©mentation
Mise en application des exigences op√©rationnelles (s√©curit√©, exploitabilit√© et industrialisation)
Aiguillage sur nos outils transverse et pr√©conisations √† l'usage du cloud public
Construction d'outillages facilitant l'accostage de ces des projets m√©tiers DATA-IA
‚Ä¶
Environnement technique
:
GCP
Git
Gitlab
Bash
Docker
Kubernetes
GitlabCI
üí∞
Le package salarial que nous vous proposons
Contrat :
CDI
Avantages groupe :
carte ticket restaurant Swile, prime de mobilit√©, RTT, accord t√©l√©travail, Mutuelle, prime de cooptation, avantages CE, prise en charge de la mutuelle √† 100% etc‚Ä¶
Avantages agence :
int√©gration de la Practise Cloud/Data, afterworks, communaut√© techlead
Formation :
certifications techniques, cours particuliers d‚Äôanglais en interne, acc√®s √† un catalogue de formations gr√¢ce √† notre plateforme e-learning (
Academy by Apside
) ou via nos organismes partenaires.
üîÆ
√î vous futur Apsidien, qui √™tes-vous ?
Au moins 5 ans d'exp√©rience en tant que Data Engineer
Maitrise de l‚Äôenvironnement cloud GCP
Force de proposition, bon relationnel et autonome
üòè
Apside a suscit√© votre curiosit√© ?
Dans un environnement marqu√© par une acc√©l√©ration des √©volutions technologiques, de transformations des usages et de disruptions majeures, Apside est un partenaire de confiance qui accompagne ses clients √† cr√©er de la valeur et √† adresser leurs enjeux strat√©giques en leur mettant √† disposition des expertises technologiques (
Data / IA, Cloud, Cyber
) et une exp√©rience sectorielle (
Industrie, Banque, Assurance, Service, Secteur Public
). Pour un accompagnement global, le groupe propose des offres transverses autour du
Handicap
(Apsid‚ÄôEA), du
Digital Learning
, et du
Conseil
.
ü§î
Et votre place dans tout √ßa ?
üëâ Notre volont√©
est de vous accompagner dans la construction et l‚Äô√©panouissement de votre carri√®re
en nous appuyant notamment
sur 3 piliers :
Une
r√©mun√©ration
√† hauteur de vos investissements et de vos comp√©tences
Une
trajectoire professionnelle
stimulante sur mesure
Un
engagement
autour des valeurs Apsidiennes : la qualit√© de vie et des conditions de travail au c≈ìur de nos enjeux
Engag√©e pour
un monde plus inclusif et plus responsable
, Apside r√©invente l‚ÄôESN et propose l‚ÄôEngagement Soci√©tal et Num√©rique. D√©couvrez notre d√©marche RSE ainsi que notre vision de l‚ÄôEntreprise Engag√©e.
Convaincu ? A vous de jouer, envoyez-nous votre CV !
Rejoignez l‚Äôaventure Apsidienne et d√©couvrez notre vision d‚Äôune ESN singuli√®re et r√©siliente
üöÄ
Show more
Show less","{'ProgLanguage': ['R', 'Bash'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['100'], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
"Big Data Engineer Confirm√© ‚Äì Lille, France (H/F)",Astek,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-confirm%C3%A9-%E2%80%93-lille-france-h-f-at-astek-3839095323?position=2&pageNum=40&refId=PlhdJ%2BvRBuQPyL9EJS3cmw%3D%3D&trackingId=nK8OX75hvZYpbs8abogtpA%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Lille - France
Publi√©e il y a 2 mois
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Nous rejoindre en tant que
Big Data Engineer Confirm√© (H/F),
afin d‚Äôaccompagner un op√©rateur t√©l√©coms, Leader en Europe dans l‚Äôassistance et le support applicatif de niveau 3 (r√©solution des probl√®mes utilisateurs, exploitation des environnements hors production).
Un challenge portant sur des millions d‚Äôutilisateurs dans un environnement technique innovant, strat√©gique et o√π l‚Äôentraide et la bonne humeur priment !
Votre Mission, Si Vous L‚Äôacceptez :
Supervision et d√©tection et r√©solution des probl√®mes utilisateurs (d√©veloppeurs, exploitants et data exploreurs)
D√©veloppement de solutions de self-service ou d‚Äôune solution de r√©solutions automatiques des probl√®mes
Qualifier les donn√©es et les r√©sultats
Conception technique des solutions
Assurer l‚Äôaccompagnement et le d√©ploiement des √©volutions des processus et outils
Accompagner la phase de mise en production
Votre Future √âquipe :
Vous int√©grerez une √©quipe √† la fois technique et fonctionnel, qui ≈ìuvre chaque jour pour d√©velopper et maintenir en conditions op√©rationnelles l‚Äôensemble des solutions IT !
L‚Äô√©quipe est en interaction avec des clients √† la fois internes et externes.
Votre stack de jeu
Syst√®me d‚Äôexploitation : Linux
Outils des distributions : HDP, HDF, ELK
Environnement Big data : Hadoop, Spark,
Langage : Scala, Shell, Python
Cloud computing : GCP ou AWS
Base de donn√©es : No SQL (Cassandra, Mongo DB), Shell, Ansible
Dataviz : Power BI ou Kibana
Des notions en R√©seau et Syst√®mes feront la diff√©rence !
Les Petits Plus Du Projet :
Vous √©voluerez au sein d‚Äôune √©quipe impliqu√©e et r√©active et interviendrez sur un projet polyvalent et √† forte valeur ajout√©e.
Vous ?
Dipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieur ou √©quivalent de niveau Bac+5.
Vous justifiez id√©alement d‚Äôune exp√©rience d‚Äôau moins 3 ans d‚Äôexp√©riences sur un poste similaire ?
Vous faite preuve de proactivit√© et d‚Äôesprit d‚Äô√©quipe, √™tes dot√©(e) d‚Äôun excellent sens de l‚Äôorganisation et vous aimez les challenges et la r√©solution de probl√®me ?
Alors ce poste est fait pour vous, n‚Äôh√©sitez plus et rejoignez l‚Äôaventure ASTEK !
Astek
Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.
Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de
ses 7800 collaborateurs
qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.
Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.
Tous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Notre projet commun vous plait ?
Postulez √† cette annonce, et soyez transparent !
Maud, notre Talent Acquisition Referent, vous contactera pour un premier √©change.
Puis vous rencontrerez Martin, votre futur manager, avec lequel vous √©changerez autour d‚ÄôAstek, de votre parcours, de vos attentes et de votre future mission .
Enfin, vous rencontrerez J√©r√©my, notre Directeur d‚Äôagence avec lequel vous pourrez valider votre int√©r√™t et ad√©quation pour le poste et finaliser les √©l√©ments contractuels.
Nos Plus
Astek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo
Une politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversit√©
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì Hadoop ‚Äì Scala ‚Äì Data
Caract√©ristiques de l'emploi
Cat√©gorie Ing√©nieur
Job Industry T√©l√©com / M√©dia
Postuler en ligne
Nom *
Pr√©nom *
Email *
Un email valide est requis.
T√©l√©phone *
Un num√©ro de t√©l√©phone valide est requis.
Joindre un CV *
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì Hadoop ‚Äì Scala ‚Äì Data
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': ['Confirm√©'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
"Data Engineer ‚Äì Bordeaux, France (H/F)",Astek,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-bordeaux-france-h-f-at-astek-3839091989?position=3&pageNum=40&refId=PlhdJ%2BvRBuQPyL9EJS3cmw%3D%3D&trackingId=y4Kk%2Bf4%2BPQLFNzvLUNrwvw%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Bordeaux - France
Publi√©e il y a 2 mois
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Vous √™tes passionn√© par la Data ?
Vous avez √† c≈ìur d‚Äôaider les entreprises √† mieux g√©rer leurs donn√©es ?
Vous souhaitez contribuer √† la croissance et √† la r√©ussite de nos projets clients ?
Nous aussi !
Rejoignez-nous et intervenez sur toute la cha√Æne de traitement de la donn√©e dans un environnement grand compte : de la r√©cup√©ration, en passant par le traitement, pour en faire l‚Äôaffichage et l‚Äôanalyse.
Votre Mission, Si Vous L‚Äôacceptez :
R√©alisation d‚Äôop√©rations de collecte de donn√©es
Concevoir et d√©velopper des pipelines de donn√©es r√©utilisables pour collecter, nettoyer, extraire et transformer les donn√©es.
Industrialisation et optimisation des jobs data
R√©alisation de contr√¥les qualit√© tout au long des op√©rations,
R√©alisation d‚Äôop√©rations d‚Äôint√©gration de donn√©es et de traitements de masse
Collaborer avec les √©quipes multidisciplinaires pour int√©grer les solutions de donn√©es dans les applications existantes.
Participer √† la veille technologique et recommander des solutions innovantes pour am√©liorer nos pratiques de data engineerin g.
Votre Future √âquipe :
Au sein d‚Äôune √©quipe compos√©e de 4 Data Engineers Astek, vous rejoindrez les √©quipes m√©tiers et techniques de notre client afin de l‚Äôaccompagner dans le traitement de ses donn√©es.
Votre stack de jeu
Langages : Python, Java
Analyse de donn√©es : Talend, Power BI, Qlik
BDD : SQL, PostgreSQL, MongoDB, Oracle
Les Petits Plus Du Projet :
Vous √©voluerez dans un contexte data innovant dans lequel vous progresserez tout en √©tant accompagn√© sur les nouveaux outils.
Vous ?
De formation Ing√©nieur ou √©quivalent (Bac+5), vous avez une premi√®re exp√©rience dans un contexte autour de la Data et vous avez pour objectif de continuer votre mont√©e en comp√©tences.
Vous aimez d√©velopper en Python et √™tes int√©ress√© par les sujets d‚ÄôIA g√©n√©rative.
Ce projet n‚Äôest pas le seul que nous pourrions vous proposer. Prenons le temps d‚Äô√©changer afin de vous pr√©senter les sujets les plus adapt√©s √† vos ambitions.
Astek
Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.
Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de
ses 7800 collaborateurs
qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.
Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.
Tous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Notre projet commun vous plait ?
Postulez √† cette annonce, et soyez transparent !
Mathilde, notre Talent Acquisition Officer, vous contactera pour un premier √©change t√©l√©phonique.
Puis vous rencontrerez Thomas, votre futur manager, avec lequel vous √©changerez autour d‚ÄôAstek, de votre parcours, de vos attentes et de votre future mission.
Enfin, vous rencontrerez Guillaume, notre Directeur de d√©partement, avec lequel vous pourrez valider votre int√©r√™t et ad√©quation pour le poste et finaliser les √©l√©ments contractuels.
Nos Plus
Astek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo
Une politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversit√©
Caract√©ristiques de l'emploi
Cat√©gorie Ing√©nieur
Job Industry A√©rospatial / D√©fense / S√©curit√©, Distribution / Services Internet, Energie / Sciences de la Vie / Autres industries, Finance / Gouvernement, T√©l√©com / M√©dia, Transports Terrestres
Postuler en ligne
Nom *
Pr√©nom *
Email *
Un email valide est requis.
T√©l√©phone *
Un num√©ro de t√©l√©phone valide est requis.
Joindre un CV *
Les Petits Plus Du Projet :
Vous √©voluerez dans un contexte data innovant dans lequel vous progresserez tout en √©tant accompagn√© sur les nouveaux outils.
Vous ?
De formation Ing√©nieur ou √©quivalent (Bac+5), vous avez une premi√®re exp√©rience dans un contexte autour de la Data et vous avez pour objectif de continuer votre mont√©e en comp√©tences.
Vous aimez d√©velopper en Python et √™tes int√©ress√© par les sujets d‚ÄôIA g√©n√©rative.
Ce projet n‚Äôest pas le seul que nous pourrions vous proposer. Prenons le temps d‚Äô√©changer afin de vous pr√©senter les sujets les plus adapt√©s √† vos ambitions.
Astek
Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.
Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de
ses 7800 collaborateurs
qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.
Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.
Tous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Notre projet commun vous plait ?
Postulez √† cette annonce, et soyez transparent !
Mathilde, notre Talent Acquisition Officer, vous contactera pour un premier √©change t√©l√©phonique.
Puis vous rencontrerez Thomas, votre futur manager, avec lequel vous √©changerez autour d‚ÄôAstek, de votre parcours, de vos attentes et de votre future mission.
Enfin, vous rencontrerez Guillaume, notre Directeur de d√©partement, avec lequel vous pourrez valider votre int√©r√™t et ad√©quation pour le poste et finaliser les √©l√©ments contractuels.
Nos Plus
Astek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo
Une politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversit√©
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go'], 'DataBase': ['SQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['PostgreSQL', 'Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
Alternant - Data Engineer H/F,ALLIANCE EMPLOI,"La Couture, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/alternant-data-engineer-h-f-at-alliance-emploi-3913991795?position=4&pageNum=40&refId=PlhdJ%2BvRBuQPyL9EJS3cmw%3D%3D&trackingId=D4Pqp4d97XFIilzjFbjMyQ%3D%3D&trk=public_jobs_jserp-result_search-card,"La campagne "" alternance2024 "" est lanc√©e ! √ätes-vous pr√™t(e) √† monter en comp√©tences et acqu√©rir de l'exp√©rience ? Avec 25 ans d'expertise, 2000 salari√©s et notre r√©seau de 400 entreprises issues des secteurs industriel, agroalimentaire, automobile, m√©tallurgie, pharmaceutique, sid√©rurgie ou encore logistique, nous sommes la destination id√©ale pour celles et ceux qui cherchent une alternance.
Laur√©at 2021 des P√©pites de l'alternance, notre mission est simple : apporter la bonne comp√©tence au bon moment. Et c'est l√† que vous entrez en jeu !
Nous sommes √† la recherche d'un Alternant - Data Engineer (H/F) en alternance pour une entreprise partenaire sp√©cialis√©e dans la chimie pour une dur√©e de 12 √† 24 mois au sein du Utilit√©s qui a en charge la fourniture d'utilit√©s pour l'ensemble du site.
Le poste et les missions ?
Informatique
Modernisation des pratiques de collecte de donn√©es industrielles,
Cr√©ation d'interface saisie d'encours de production
Refonte des rapports d'exploitation
Algorithme de num√©risation des rapports PDF
Automatisation des archivages
Gestion des datas consolid√©es
Statisitques
Int√©gration des statistiques au coeur des syst√®mes de production
Cartes de contr√¥les
Pr√©visions statistiques
Etude d'implantation de machine learning
Algorithme de traitement et nettoyage des donn√©es (analyse de la d√©rive)
Organisationnel
D√©ploiement des solutions de power BI au sein du service
Outils d'affiche, de partage et d'analyse de donn√©es
Analyse fonctionnelle des flux de donn√©es
R√©daction des logigrammes de gestion de donn√©es
R√©daction des bonnes pratiques d'archivage et de traitement de don√©nes
Formation des utilisateurs et propri√©taires
Ce que nous allons aimer chez vous ?.
Vous avez le sens de l'organisation et du service, une capacit√© √† s'int√©grer dans un milieu technique de terrain, vous avez le sens de l'organisation et des priorit√©s, vous √™tes rigoureux
Mais aussi :
Vous pr√©parez un dipl√¥me d'ing√©nieur Bac +4 / 5 en informatique et analyse de donn√©es
Vous ma√Ætrisez le d√©veloppement informatique (base de donn√©es, Python, Java)
Les avantages de rejoindre Alliance Emploi
Contrat : ALTERNANCE de 12 √† 24 mois
D√©but : Septembre 2024
Lieu : LESTREM [ site non accessible en transport en commun]
R√©mun√©ration : Selon le bar√®me de l'alternance
Et aussi : int√©ressement, mutuelle, pr√©voyance, CSE, formations qualifiantes
Et ce n'est pas tout ! En choisissant Alliance Emploi, vous vivrez une exp√©rience bas√©e sur la confiance, la solidarit√© et l'engagement. Vous d√©velopperez vos comp√©tences √† travers une diversit√© de missions et notre r√©seau d'entreprises, et nous nous engageons √† vous proposer un accompagnement personnalis√© pour booster votre carri√®re.
Alors convaincu(e) ?
N'attendez plus pour postuler et venez d√©couvrir la diff√©rence Alliance Emploi !
La diversit√© est une force. Nous sommes engag√©s pour l'inclusion en offrant des opportunit√©s de carri√®re √† toutes les personnes, ind√©pendamment de leur genre ou de leur situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Statistiques'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '25', '25', '25']}"
Data engineer & BI (IT) / Freelance,Free-Work,"Gennevilliers, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-bi-it-freelance-at-free-work-3891617843?position=5&pageNum=40&refId=PlhdJ%2BvRBuQPyL9EJS3cmw%3D%3D&trackingId=ofPaeu5UIMHyncbiJE4gfQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Data engineering : mise √† disposition des donn√©es dans le datalake au format
delta lake (Azure Databricks)
‚ñ™ Conception des flux data
‚ñ™ D√©veloppement des pipelines de donn√©es avec ADF et
Databricks (ingestion Bronze/ Impl√©mentation Silver)
‚ñ™ Mise en ≈ìuvre avec le superviseur des flux du monitoring de ceux-ci
‚ñ™ Int√©gration des tests unitaires
Analyse & BI :
‚ñ™ Analyse des besoins
‚ñ™ Conception, √©laboration et d√©ploiement des rapports et tableaux de bord
sous Power BI √† partir du Gold
‚ñ™ Mod√©lisation des datamarts
‚ñ™ Analyses de donn√©es et Requ√™tages
‚ñ™ Maintenance √©volutive et corrective
Coordination des intervenants SI
R√©daction de sp√©cifications & Documentation
Mise en place des exigences RGPD/SSI
Profil candidat:
Profil confirm√© Technico-Fonctionnel :
Incontournable :
Exp√©rience de mise en ≈ìuvre de data platform Databricks & de projets BI
Connaissances et exp√©riences sur Azure Data Factory et Azure Databricks
SQL (niveau confirm√©)
Power BI, DAX
Force de proposition
Rigoureux et autonome
Appr√©ciables :
SQL Server SSIS, SSRS
Dev Python
Git Azure Devops
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['SQL Server'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Confirm√©'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Alternance Data Engineer (H / F),Servier,"Suresnes, √éle-de-France, France",https://fr.linkedin.com/jobs/view/alternance-data-engineer-h-f-at-servier-3906489264?position=8&pageNum=40&refId=PlhdJ%2BvRBuQPyL9EJS3cmw%3D%3D&trackingId=gFDTjOYYRhDTsVSpW5mpfw%3D%3D&trk=public_jobs_jserp-result_search-card,"Description du poste :
Le Groupe Servier m√®ne une transformation digitale ambitieuse avec un objectif clair de devenir ¬´¬†best in class Digital Performer¬†¬ª. La Data Factory joue un r√¥le central dans cette ambition et a un impact fort √† chaque √©tape de la chaine de valeur. Depuis la recherche de nouvelles mol√©cules, la pr√©diction de leur comportement, l‚Äôanalyse d‚Äôefficacit√© des traitements en passant par l‚Äôoptimisation des processus de production des m√©dicaments, la gestion des stocks et la pr√©vision des ruptures jusqu‚Äô√† l‚Äôapproche omnicanale et personnalis√©e aupr√®s des professionnels de sant√©, le suivi des patients‚Ä¶ : tous ces enjeux s‚Äôappuient sur la Data et sa puissance transformante.
Rattach√©e √† la Direction Digital, Data & IS, la Data Factory ≈ìuvre pour rendre les donn√©es accessibles, les valoriser √† travers des produits data m√©tiers √† base d‚ÄôIA et d‚ÄôAdvanced Analytics, et transformer Servier en un groupe orient√©e data (¬´¬†Data-driven¬†¬ª) o√π tous les collaborateurs connaissent les enjeux de la data.
La cr√©ation des produits Data s‚Äôappuie sur une ¬´‚ÄØplateforme Data ¬ª centrale, cloud-native, s√©curis√©e et performante avec les technologies les plus avanc√©es. Servier a √©tabli un partenariat strat√©gique de cinq ann√©es avec Google Cloud, lui donnant acc√®s √† des technologies innovantes et des liens privil√©gi√©s avec ses experts, et permettant de disposer d‚Äôune puissance de calcul augment√©e, d‚Äôacc√©l√©rer l‚Äôanalyse et de d√©velopper l‚Äôinnovation sur de nombreux d√©fis business et technologiques.
Au sein de la Data Factory, et en lien avec les autres p√¥les de la Data Factory, le Chapter TechLead a pour mission de pourvoir en ing√©nieur les diff√©rentes √©quipes produits et les √©quipes enablers afin de d√©velopper les data pipeline (ingestion, Exposition), outils, software n√©cessaire au produit. Les ing√©nieurs sont aussi responsables de tester, de documenter le code ainsi que le maintien en condition op√©rationnel de ce code.
Afin d‚Äôaccompagner le Global Data Office, vous serez charg√©(e) de¬†:
Ecrire le code n√©cessaire au produit
Tester et documenter le code
D√©ployer le code dans les diff√©rents environnements
Faire de la veille autour des enjeux et opportunit√©s de la Data dans un groupe pharmaceutique,
Contribuer √† votre fa√ßon √† la transformation digitale du groupe, et participer √† la construction dynamique de la Data Factory
Description du profil :
Votre formation :
Ecole d‚Äôing√©nieur en informatique ou/et data science
Vos comp√©tences :
Maitrise des langages de programmation python et SQL
Curiosit√© pour les nouvelles technologies et l‚Äôinnovation au sens large
Ma√Ætrise des outils collaboratifs et de la suite office (Word, Excel, PowerPoint, et SharePoint)
Rigueur, votre sens du d√©tail, capacit√©s d'analyse et de synth√®se, autonomie et bon relationnel
Excellentes aptitudes interpersonnelles, √©coute, empathie, assertivit√©, esprit d‚Äô√©quipe
Ind√©pendance, organisation et capacit√© √† g√©rer plusieurs sujets en m√™me temps
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Empathie', 'Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Staff Data Ops Engineer (x/f/m),Doctolib,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/staff-data-ops-engineer-x-f-m-at-doctolib-3824234041?position=9&pageNum=40&refId=PlhdJ%2BvRBuQPyL9EJS3cmw%3D%3D&trackingId=RX46B7dYVz9kKnrZFyVlog%3D%3D&trk=public_jobs_jserp-result_search-card,"About Doctolib
Doctolib is a purpose-led company that strives for a healthier world with more than 2,800 employees across France, Italy, and Germany. Since 2013, Doctolib has been improving the daily lives of more than 340,000 healthcare professionals by providing them with new-generation technology and services. Doctolib also serves more than 80 million Europeans, offering a fast, frictionless and secure journey for all their care needs.
We are currently looking for a Data Ops to help us build and develop the data architecture that will enable Doctolib to offer its users an ever more efficient service.
An important point at Doctolib: personal data is fully encrypted and anonymized, and security requirements are extreme.
Your tasks
Build and maintain Doctolib's data architecture;
Guarantee the maintainability and scalability of the various components, relying on the services of Doctolib's cloud provider and all Devops best practices;
Adapt the technical stack to anticipate user needs and the limits of existing systems;
Evaluate new market technologies and their potential within the stack;
Collaborate with Data Engineers, Data Scientists, Security teams and developers to develop future Data-driven functionalities within Doctolib products;
Participate in team improvement and agile rituals.
Who you are :
If you don‚Äôt meet all the requirements below but believe this opportunity matches your expectations and experience, we still encourage you to apply!
You have significant experience in the Data world, including at least 3 years in Data Ops / DevOps.
You have an interest in Big Data technologies
You're familiar with Terraform and Docker
You have an interest in code and Python
You have a good knowledge of data transformation tools and AWS services
You like to innovate and make Data architectures evolve towards greater scalability
What we offer
A stock-option program for each Doctoliber
A competitive health insurance paid 100% by the company
A dedicated onboarding program - the Doctolib Academy
Mental health and wellbeing offer in partnership with moka.care
The Doctolib Parent Care Program, including extended parental leave, meet-ups and inspiring conferences
A subsidy from the work council to refund part of the membership to a sport club or a creative class
Subsidy for lunch and various food offers in our offices
A flexible workplace policy offering both hybrid and office-based mode
Flexibility days allowing to work in EU countries and the UK 10 days per year
The interview process
Recruiter Interview
Case study to do at home + technical interview with the team
Team Meeting
Reference check
Offer !
If you would like to find out more about tech life at Doctolib, feel free to read our latest Medium blog articles!
At Doctolib, we believe in improving access to healthcare for everyone - regardless of where you come from, what you look like. This translates into our recruitment process: Doctolib is an equal opportunity employer. We don't just accept diversity at Doctolib, we respect and celebrate it!
The more diverse ideas are heard, the more our product will truly improve healthcare for all. You are welcome to apply to Doctolib, regardless of your gender, religion, age, sexual orientation, ethnicity, disability, or place of origin. If you have a disability, let us know if there's any way we can make the interview process smoother for you!
All the information transmitted via this form is processed by Doctolib for the purpose of managing applications. For more information on how Doctolib processes your application data, click
here
.
If you wish to exercise your rights or if you have any questions about the processing of your data, you can write to us at
hr.dataprivacy@doctolib.com
.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': ['Flexibility']}","{'JobDetail': ['Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer - H/F,MARGO,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-margo-3816671828?position=10&pageNum=40&refId=PlhdJ%2BvRBuQPyL9EJS3cmw%3D%3D&trackingId=dizlXreGGcB%2BlipDGTUbAg%3D%3D&trk=public_jobs_jserp-result_search-card,"Entit√© experte
de Margo Group des probl√©matiques
Data, Cloud et DevOps
cr√©√©e en 2020 par leurs fondateurs Rapha√´l et Mounir. Aujourd‚Äôhui
60 consultants
ont int√©gr√© l'entit√© et nous avons commenc√© √† travailler avec
18 nouveaux clients
(Banque, Industrie, Assurance, √ânergie, E commerce, Sant√©). A leurs c√¥t√©s, vous pourrez √©voluer rapidement et d√©velopper de nouvelles comp√©tences.
Deux ADN fondateurs forts
et sp√©cifiques √† Margo Analytics √† l‚Äôorigine de l‚Äôentit√© :
- Toujours se positionner sur
les plus beaux sujets
et sur les
missions √† fortes valeurs ajout√©es
- Recruter
des
consultants passionn√©s
et
curieux
qui cherchent √† √™tre
challeng√©s
Aujourd‚Äôhui, Margo Analytics poss√®de 4 communaut√©s
de comp√©tences :
- Data engineer
- Data Science/ IA
- Galaxy OPS (devOps, dataOps, cloudOps)
- Architecte Big Data
Ainsi en rejoignant Margo Analytics vous aurez le choix des missions (#consultantfirst) sur lesquelles vous souhaitez travailler. Vous serez accompagn√© par les deux fondateurs ainsi que par le leader de votre communaut√©, dont les r√¥les sont de rechercher le projet qui correspondra le plus √† vos attentes et de vous accompagner dans votre carri√®re.
üéØLes missions Margo Analytics :
Au sein de la communaut√© Data Engineer vos missions
seront
:
-
D√©velopper en mode agile
les cas d‚Äôusages m√©tier
- Mettre en place des
processus de collecte, d‚Äôorganisation, de stockage et de mod√©lisation des donn√©es
- D√©velopper des traitements de transformation et de production de donn√©es
- Assurer la
mise en production des mod√®les de pr√©diction
cr√©√©s par les Data Scientists
- Participer √† l‚Äô
am√©lioration continue
et au refactoring de code
Besoin de projection ? Voici un exemple de mission :
Camille accompagne un grand compte dans le domaine de l‚Äôindustrie sur son projet de mise en place d‚Äôun nouveau datalake en Azure databricks. L‚Äôobjectif de cette mission est d‚Äôassurer la distribution de la donn√©e de mani√®re optimis√©e pour cr√©er une couche de distribution et permettre aux Data Scientists d‚Äôimpl√©menter les use cases. Camille apporte son expertise sur les technologies suivantes : Spark, Scala, Azure, Databricks.
Nos stack Technique :
- Langage : Python/Scala/Java
- Framework : Spark/Hadoop
- Cloud: Azure/ AWS/ GCP
üôå Les avantages :
- Tickets restaurants Swile
- Mutuelle Alan prise en charge √† 100%
- Pass Navigo pris en charge √† 100%
- T√©l√©travail
- Formations illimit√©es
- Locaux en plein coeur de Paris
- Places en cr√®ches
ü§ùNotre processus de recrutement :
Notre processus de recrutement se fait en 3 √©tapes, r√©parties sur 7 √† 15 jours maximum :
- Premi√®re rencontre !
Vous √©changez avec un RH et un dirigeant sur votre parcours, vos aspirations professionnelles ainsi que sur Margo Analytics et les opportunit√©s que nous proposons
-
Challengez-vous
dans le cadre d‚Äôun entretien technique avec l‚Äôun de nos experts. C‚Äôest √©galement l‚Äôoccasion pour vous d‚Äôavoir son retour d‚Äôexp√©rience
- Dernier entretien de motivation
: pour finir, vous rencontrez un membre du board de Margo Analytics pour un entretien final
üîç Vous √™tes un(e) futur(e) Margo Analytics si :
Must-Have
Vous √™tes issu(e) d‚Äôune √©cole d‚Äôing√©nieur ou d‚Äôun cursus universitaire √©quivalent niveau Bac + 5
/ Master
Vous aimez coder et vous √™tes passionn√©(e) d‚Äôinformatique et de Data
Vous √™tes curieux(se) et vous vous int√©ressez aux derni√®res technologies du march√©
Vous justifiez d‚Äôune premi√®re exp√©rience en tant que Data Engineer
Nice to Have
Vous √™tes ambitieux(se) et n‚Äôavez pas peur de travailler sur des projets challengeants dans des environnements √† fortes contraintes techniques . Vous parlez et comprenez l‚Äôanglais.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Backend Data Engineer | Python - AWS | Plateforme SaaS BtoB - Culture et sport | Paris (1 jour sur site/semaine)),Octopus IT - Expert du recrutement tech,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/backend-data-engineer-python-aws-plateforme-saas-btob-culture-et-sport-paris-1-jour-sur-site-semaine-at-octopus-it-expert-du-recrutement-tech-3837199239?position=1&pageNum=42&refId=hZyb1K8CoeqwCyZyTWnF7w%3D%3D&trackingId=rw9KnhS4AN95GIKeUl9F8g%3D%3D&trk=public_jobs_jserp-result_search-card,"La soci√©t√©
Cette Start-up fond√©e par une √©quipe de Data Scientists, a d√©velopp√© un logiciel SaaS BtoB au service des diff√©rentes structures culturelles et sportives.
Les clients (th√©√¢tres, mus√©es, clubs de sport professionnels, salles de spectacles,...)
utilisent la solution afin de mieux comprendre et valoriser leurs donn√©s et de d√©velopper leurs publics de demain.
Novateur, cette solution compl√®te, centralise et automatise les donn√©es venant de la billetterie, cashless, boutique en ligne ...
Elle permet d‚Äôanalyser finement les publics (BI) et de mettre en place des strat√©gies de marketing innovantes. Notre solution, √† la pointe de la technologie, ainsi que l‚Äôaccompagnement de nos clients au quotidien par notre √©quipe d'experts d√©di√©s, nous positionnent comme leader sur le march√© fran√ßais.
Mieux connaitre son client, ses envies et go√ªts est primordial pour s'adresser de mani√®re personnalis√© et percutante √† lui !
La soci√©t√©, est rentable et en forte croissance en 2020 et 2021.
Le poste
Une √©quipe de 20 personnes dont 6 √† la tech passionn√©s qui ne demande qu'√† en accueillir d'autres autour de valeurs fortes et assum√©es : bienveillance, transparence et combativit√©.
Le Backend Engnineer travaillera au sein de l‚Äô√©quipe technique, en synergie avec le CTO.
Les missions du poste
:
Am√©liorer la maintenabilit√© et le monitoring des ETL
Mettre en place et d√©velopper des API
D√©velopper de nouvelles features
D√©veloppement de nouveaux pipelines de donn√©es pour aller r√©cup√©rer la Data n'importe o√π
Optimiser et challenger l'environnement technique existant
Stack : Python (Django, Flask) Vue.js, PostgreSql, AWS
Les √©volutions √† venir d√©pendront majoritairement de vous et de vos pr√©conisations.
Votre profil
Vous avez un esprit vif et √™tes capable d‚Äôapprendre vite de nouvelles technologies ou de nouveaux langages
Vous √™tes √† l'aise avec du Python et du Sql et vous avez √† partir de 2 ans d'exp√©rience
Vous travaillez avec beaucoup de rigueur, vous recherchez l'efficacit√© tout en faisant les choses dans les r√®gles de l'art et avec les bonnes pratiques du d√©veloppement logiciel
Vous avez l'habitude de travailler avec des API
Vous avez une parfaite connaissance de l‚Äôarchitecture d‚Äôune plateforme web
Le plus : connaissance des ETL et technologie de scraping de donn√©es.
Le salaire & avantages
50-55K‚Ç¨ selon exp√©rience
4 jours de remote/ 1 jours de pr√©sentiel
Carte de transport
Carte Swile & mutuelle
Et plus encore‚Ä¶
Ce qu‚Äôon pr√©f√®re
Ambiance start-up, humaine et vivante avec de nombreux √©v√©nements organis√©s
De nombreuses responsabilit√©s sont confi√©es √† tous les postes
M√©thodes Agiles (Scrum) dans une √©quipe qui a une vraie vision agile
Ce poste a √©t√© soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d‚ÄôExperts en Recrutement Tech (CDI et clients finaux uniquement) ‚Äì Visitez nous pour plus d‚Äôopportunit√©s :
www.octopusit.fr
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Remote'], 'TypeContract': ['CDI'], 'Salary': ['50'], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Data Analyst (F/H),FBD Group,"Tremblay-en-France, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-f-h-at-fbd-group-3886652484?position=2&pageNum=42&refId=hZyb1K8CoeqwCyZyTWnF7w%3D%3D&trackingId=7TfIusgG6zvJO9lRTIEq%2Bw%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous aimez :
Conduire le changement dans le secteur de la distribution
Partager les challenges d‚Äôune entreprise agile en forte croissance
L‚Äôesprit d‚Äô√©quipe et l‚Äôambiance qui r√®gnent dans un groupe √† taille humaine (250 collaborateurs)
L‚Äôinnovation, le num√©rique et les nouvelles technologies au service de l‚Äôexp√©rience client
La gestion de projet
Vous aimerez accompagner l‚Äôentreprise dans son √©volution en √©tant un agitateur d'id√©es.
Rattach√©(e) au Responsable Performance, vous aurez pour objectif principal le recueil, l‚Äôanalyse et l‚Äôinterpr√©tation de la donn√©e de l‚Äôentreprise. Ces donn√©es peuvent √™tre li√©es aux clients (CRM), aux produits et √† leurs performances, ou m√™me aux concurrents.
En collaboration √©troite avec les autres p√¥les de la Direction Digitale, les √©quipes Commerce, les √©quipes Marketing, et les √©quipes IT, ainsi que les autres Directions support du Groupe, vous construirez, exploiterez et interpr√©terez les donn√©es pour en d√©gager des observations business utiles.
Missions Principales :
Echanger avec les diff√©rentes √©quipes internes concern√©es pour comprendre leurs besoins et leurs enjeux
D√©finir les indicateurs cl√©s de performance (KPI) avec les parties prenantes pour mesurer la tenue des objectifs
Mettre en place ou optimiser les outils de suivi et de pr√©vision avec la DSI
Analyser les bases de donn√©es
Synth√©tiser les r√©sultats de ces analyses pour les communiquer aux bons interlocuteurs
Proposer des plans d‚Äôaction (mise en place d‚Äôoutils, d√©finition des processus‚Ä¶)
Identifier les probl√®mes et proposer des solutions appropri√©es
Assurer la qualit√© et la fiabilit√© des donn√©es
Etablir une cartographie des donn√©es utilis√©es au sein des analyses pour une meilleure compr√©hension des interlocuteurs
Missions D√©taill√©es :
Recueil des besoins
Echanger avec les diff√©rentes √©quipes internes concern√©es pour comprendre leurs besoins et leurs enjeux
D√©finir les indicateurs cl√©s de performance (KPI) avec les parties prenantes pour mesurer la tenue des objectifs
Mod√©liser les donn√©es n√©cessaires √† l‚Äôanalyse
Collecte des donn√©es
Recueillir et extraire les sources de donn√©es pertinentes (savoir o√π les trouver) et de qualit√©, √† traduire ensuite en donn√©es statistiques
Assurer la qualit√© et la fiabilit√© des donn√©es
Identifier les probl√®mes (donn√©es manquantes, qualit√© insuffisante, stockage, centralisation, etc.) et proposer des solutions appropri√©es en exprimant le besoin associ√© aux √©quipes IT
Traitement
Proposer des plans d‚Äôaction :
Mettre en place des process/requ√™tes et des automatisations
Mettre en place ou optimiser les outils de suivi et de pr√©vision avec la DSI
Trouver de nouvelles fa√ßons de traiter la donn√©e avec l‚Äôappui de nouveaux outils, au vu de l‚Äôaccroissement consid√©rable du nombre de donn√©es
Analyse
D√©finir et g√©rer des outils d‚Äôanalyse et d‚Äôaide √† la d√©cision : pr√©visions et objectifs de vente, tableaux de bord, indicateurs de performance, analyse de la conjoncture et des march√©s, suivi de la performance et appui aux √©quipes commerciales
Analyser les bases de donn√©es, produire des analyses m√©tiers et proposer des recommandations aux managers
S‚Äôassurer de la coh√©rence des r√©sultats par rapport au commerce et √† l‚Äôactivit√© r√©elle en point de vente
Communication
Cr√©er des Dashboard, mettre en place des KPIs et des reportings de performance
Construire et faire √©voluer les rapports issus de la Business Intelligence (BI) & Web Analytics
Synth√©tiser les r√©sultats de ces analyses pour les communiquer aux bons interlocuteurs
Etablir une cartographie des donn√©es utilis√©es au sein des analyses pour une meilleure compr√©hension des interlocuteurs
Diffuser et assurer la bonne interpr√©tation et la bonne compr√©hension des rapports d‚Äôanalyse
Transverse
Faire preuve de proactivit√© pour explorer les donn√©es disponibles et proposer des analyses non sollicit√©es
R√©aliser une veille marketing et commerciale sur la concurrence et proposer des analyses associ√©es
Contribuer √† l‚Äôanalyse des parcours omnicanaux et √† la recherche de leviers de croissance
Explorer les opportunit√©s d‚Äôapplication de l‚ÄôIA dans la Data Analyse
R√©aliser des √©tudes qualitatives sur diff√©rentes probl√©matiques business
Participer √† la mesure √©conom√©trique des campagnes d‚Äôacquisition ainsi qu‚Äô√† la mesure de l‚Äôattribution/contribution des diff√©rents leviers marketing actionn√©s
Exp√©rience : 5 ans minimum en Data analyse, avec des connaissances en data engineering id√©alement dans le secteur du retail
Formation : Bac+5, cursus en math√©matiques, statistiques, √©conomie, marketing ou en informatique (id√©alement Master en statistiques / √©conom√©trie ou Master sp√©cialis√© en Big Data)
La maitrise de l‚Äôanglais courant est n√©cessaire
Savoir-faire & comp√©tences :
Ma√Ætrise des bases de donn√©es business (BigQuery, Snowflake, Redshift‚Ä¶) et du langage SQL
Maitrise de la construction d‚Äôun Datawarehouse
Ma√Ætrise d‚Äôun outil d‚Äôorchestration (DBT, Airflow‚Ä¶) et du langage Python
Ma√Ætrise d‚Äôau moins un outil de dashboarding (Looker, Power BI, Tableau‚Ä¶)
Ma√Ætrise des librairies de manipulation de donn√©es en Python (NumPy, Pandas, Matplotlib, SciPy, Scikit-learn)
Une connaissance des outils tels que Hadoop ou Spark serait un plus
Compr√©hension des enjeux li√©s √† la tra√ßabilit√© des donn√©es (data lineage)
Une connaissance m√©tier, notamment en marketing et relation client est n√©cessaire
Savoir √™tre :
Grande aisance √©crite et orale pour optimiser la compr√©hension et la communication avec les √©quipes
Passion pour les chiffres et les statistiques
Orientation business pour faire des recommandations pertinentes et actionnables
Aisance relationnelle pour emporter l‚Äôadh√©sion des interlocuteurs
Esprit de synth√®se et analytique
Esprit ouvert et comp√©tences transverses pour appr√©hender les probl√©matiques techniques et les restituer de fa√ßon compr√©hensible aux diff√©rents publics
Rigoureux, organis√© et r√©actif
Force de proposition
Prise de recul
Pourquoi nous rejoindre ?
La brigade
Une Direction qui accorde une attention particuli√®re au bien √™tre des collaborateurs : Nous sommes Great Place to Work !
Les ingr√©dients
Vous aurez tous les ustensiles n√©cessaires pour votre recette (ordinateur, t√©l√©phone portable professionnel etc.)
Une r√©mun√©ration fixe + Prime annuelle li√©e √† vos objectifs + Prime de participation
Les assaisonnements
Une mutuelle familiale prise en charge √† 100% par le Groupe FBD
L‚Äôacc√®s √† un Restaurant Interentreprises
2 jours de t√©l√©travail par semaine sans condition d‚Äôanciennet√©
Des locaux √† Roissy √† 200m du RER B et une annexe √† Paris 9√®me
Un r√©seau social Entreprise pour vous mettre au courant et participer √† la vie d‚Äôentreprise
La carte
Notre menu est compos√©e d‚Äôingr√©dients divers et vari√©s, ce qui en fait la richesse de ses plats.
Nous accordons une attention particuli√®re √† lutter contre toute formes de discriminations, raison pour laquelle nous avons adh√©r√© √† l'association A Comp√©tences Egales qui ≈ìuvre dans ce domaine.
La cerise sur le g√¢teau
Boissons chaudes et fruits Bio √† disposition pour bien commencer la journ√©e !
Des activit√©s tous les mois pour les collaborateurs, pr√©par√©s par notre service Com Interne + 2 √©v√®nements groupe par an.
En cuisine, le meilleur reste √† inventer ! Nous vous attendons !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': ['Scikit-Learn'], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI', 'Matplotlib'], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Statistiques'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Engineer,Lyreco France,"Valenciennes, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-lyreco-france-3918198650?position=3&pageNum=42&refId=hZyb1K8CoeqwCyZyTWnF7w%3D%3D&trackingId=HJ%2Fkp3pwyyjqSMpJSYgSXQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Responsible for building systems that collect, manage, and convert raw data into usable information for
data scientists and business analysts to interpret.
The data engineer aims to make data accessible so that the organization can use it to evaluate and
optimize its performance
Are you excited for your new career adventure?
At Lyreco, we offer more than just a job, but a career! Our Data Storage Team is looking for a talented and ambitious new Data Engineer to join in HQ (Marly).
Lyreco is the European leader and the third largest distributor of workplace products and services in the world. A privately owned company since 1926, Lyreco has constantly adapted to the evolutions of workplace thanks to its focus on excellence in customer experience, strong partnerships with renowned suppliers, and efficient logistics.
With more than 12,000 employees, Lyreco directly operates in 25 countries in Europe and Asia and covers 17 additional markets on 4 continents through a network of distribution partners.
YOUR MISSIONS:
Industrialize data integration, data cleansing, data analytics programs or data management processes.
Contribute to the design, development, testing, deployment, performance in production and maintenance of the data-centric software including APIs, cloud-based architectures, libraries, toolbox.
Liaise with the Business Analysts, Data Scientists, Analytics specialist or Architects to understand how data needs to be: extracted, converted/transformed, loaded and exposed; consumed, calculated and updated.
Help the Data Architect to create an overview of the Data Lineage (from data flows, data transformations inside applications).
Provide clear documentation of the business rules embedded in the systems and potentially manage or help solving Data Quality issues.
Adapt to the central/ spokes‚Äô ecosystem and local context and standards
YOUR PROFILE:
Degree in Computer Science or relevant data field
Experience in the area of trade working in projects‚Ä¶ working in projects in Data Engineering, Big Data and/or Cloud environment using Apache Spark
Working experience with Cloudera Data Platform is a plus
Structured yet agile approach ‚Äì with good knowledge of the scrum agile methodology
Languages: SQL; Python
Big Data & Streaming technologies (Hadoop/HDFS, Spark‚Ä¶)
NoSQL Databases (e.g. Hbase, MongoDB‚Ä¶)
Fluency in written and spoken English
REASONS TO JOIN LYRECO :
A full- time job in a dynamic, passionate, international team
Possibility to join internal mobility program
Competitive salary (bonus, benefits)
You will work in hybrid model in Valenciennes/Marly/France
If the above job description interests you and you think you are a good fit, apply now! We look forward to receiving your application in English.
√ätes-vous enthousiaste √† l'id√©e de vivre une nouvelle aventure professionnelle ?
Chez Lyreco, nous offrons plus qu'un emploi, une carri√®re ! Notre √©quipe Data Storage est √† la recherche d'un Data Engineer H/F talentueux et ambitieux pour rejoindre notre √©quipe au si√®ge social.
Lyreco est le leader europ√©en et le troisi√®me distributeur mondial de produits et services pour l‚Äôenvironnement de travail. Soci√©t√© priv√©e depuis 1926, Lyreco s'est constamment adapt√©e aux √©volutions du monde du travail gr√¢ce √† son souci d'excellence en mati√®re d'exp√©rience client, √† ses partenariats solides avec des fournisseurs renomm√©s et √† sa logistique efficace.
Avec plus de 12 000 employ√©s, Lyreco op√®re directement dans 25 pays d'Europe et d'Asie et couvre 17 autres march√©s sur 4 continents par le biais d'un r√©seau de partenaires de distribution.
Lyreco se pr√©occupe des personnes.
Nous nous engageons √† offrir Une Excellente Journ√©e de Travail √† nos clients et √† nos employ√©s.
Cela signifie que chez Lyreco, nous cultivons activement les talents et veillons √† ce que tous nos employ√©s aient une Une Excellente Journ√©e de Travail. Afin de garantir le d√©veloppement de nos employ√©s, nous leur offrons une formation continue et une mobilit√© interne lorsque nous recrutons pour un poste vacant - Chez Lyreco, tout est possible !
Chez Lyreco, nous valorisons l'excellence, la passion, le respect et l'agilit√©. Nous savons que les personnes sont au c≈ìur de tout ce que nous r√©alisons, c'est pourquoi chez Lyreco nous faisons de notre mieux pour soutenir nos employ√©s o√π qu'ils travaillent, quelle que soit leur mission, en leur offrant la meilleure exp√©rience professionnelle possible pour atteindre l'excellence.
CE QUE NOUS PROPOSONS:
Industrialiser les programmes d'int√©gration de donn√©es, de nettoyage de donn√©es, d'analyse de donn√©es ou de gestion des donn√©es.
Contribuer √† la conception, au d√©veloppement, aux tests, au d√©ploiement, √† la performance en production et √† la maintenance des logiciels ax√©s sur les donn√©es, y compris les API, les architectures bas√©es sur le cloud, les biblioth√®ques et les bo√Ætes √† outils.
Collaborer avec les analystes m√©tier, les data scientists, les sp√©cialistes de l'analyse ou les architectes pour comprendre comment les donn√©es doivent √™tre : extraites, converties/transform√©es, charg√©es et expos√©es ; consomm√©es, calcul√©es et mises √† jour.
Aider l'architecte de donn√©es √† cr√©er une vue d'ensemble de la lign√©e des donn√©es (√† partir des flux de donn√©es, des transformations de donn√©es √† l'int√©rieur des applications).
Fournir une documentation claire des r√®gles m√©tier int√©gr√©es dans les syst√®mes et potentiellement g√©rer ou aider √† r√©soudre les probl√®mes de qualit√© des donn√©es.
S'adapter √† l'√©cosyst√®me central ou d√©centralis√© et aux normes locales.
CE QUE NOUS RECHERCHONS:
Formation sup√©rieure en informatique (Bac+4/5) ou en Big Data
Exp√©rience dans le domaine du e-commerce travaillant sur des projets de Data Engineering, Big Data et/ou en environnement Cloud en utilisant Apache Spark Bonnes connaissances de la plateforme de donn√©es Cloudera *
Approche structur√©e mais agile, avec une bonne connaissance de la m√©thodologie agile Scrum
Bonnes connaissances des langages : SQL ; Python Technologies Big Data & Streaming (Hadoop/HDFS, Spark‚Ä¶) , bases de donn√©es NoSQL (par exemple, Hbase, MongoDB‚Ä¶)
Ma√Ætrise de l'anglais √©crit et parl√©
Les ¬´ + ¬ª chez Lyreco Management
Une exp√©rience dans un environnement international.
Prime sur objectifs.
Prime de participation et prime d‚Äôint√©ressement.
Des actions en faveur de l‚Äô√©quilibre vie professionnelle/ vie personnelle (conciergerie d‚Äôentreprise, associations sportives, plateforme de covoiturage, cr√®che d‚Äôentreprise).
¬´‚ÄØLyreco est signataire de la Charte de la diversit√©. Nous garantissons le respect des r√®gles de non-discrimination √† l'embauche et nous nous engageons √† aider les personnes √©loign√©es de l'emploi.‚ÄØ¬ª
T√©l√©travail.
Envie de rejoindre l‚Äôaventure Lyreco Management ? N‚Äôattendez plus, transmettez-nous votre candidature !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': ['Organization']}","{'JobDetail': ['Full'], 'TypeContract': [], 'Salary': ['1926'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (F/H) - Nantes,SFEIR,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-nantes-at-sfeir-3477971987?position=4&pageNum=42&refId=hZyb1K8CoeqwCyZyTWnF7w%3D%3D&trackingId=vCFQNCficndPACYOQbG7LA%3D%3D&trk=public_jobs_jserp-result_search-card,"C'est quoi SFEIR ? ü§î
SFEIR, c'est avant tout une communaut√© de 900 techs en France, en Belgique et au Luxembourg.
Nous aidons nos clients √† :
üîπ √ätre compatible avec le futur en d√©veloppant leurs architectures SI, Cloud et Data ;
üîπ Donner de la valeur √† leurs donn√©es, innover avec l'IA ;
üîπCr√©ateur de valeur gr√¢ce aux API & microservices;
üîπ D√©velopper des applications web et mobiles pour am√©liorer leur exp√©rience client et se connecter partout.
Notre culture d'entreprise est r√©solument tourn√©e vers l'expertise technologique, la transmission de connaissances et le respect de nos valeurs phares :
bienveillance, inclusivit√©, excellence, libert√©, responsabilit√©.
Et Nantes dans tout √ßa ?
SFEIR Nantes c'est :
üîπ Une agence cr√©e en 2018 par @Jean-Fran√ßois Garreau , co-fondateur du DevFest Nantes
üîπ Une trentaine de consultant(e)s qui se connaissent toutes et tous
üîπ 4 Managers qui sont aussi des consultants @Hoani , @Adrien , @Fr√©d√©ric , @Valentin
üîπ Une dizaine de clients actifs en local et une centaine au niveau du groupe
üîπ Des √©v√©nements en interne et en organis√©s chaque mois (afterworks, meetup, formations)
üîπ Une communaut√© active : une cinquantaine de conf√©rences externes donn√©es en 2022 (Devfest, Devoxx, communaut√© JS‚Ä¶)
üîπ Des locaux sur l'√Æle de Nantes dans le b√¢timent totem du num√©rique nantais.
Concr√®tement, quel sera mon job ?
En tant que Data Engineer en mission chez un client, ton r√¥le est d‚Äôappr√©hender son contexte et d'impl√©menter une plateforme pour valoriser sa donn√©e.
Tu es √† l‚Äôaise sur l‚Äôun des langages suivants :
Python, Java, Scala et SQL
; et tu as d√©j√† utilis√© des
frameworks de calculs distribu√©s
(Spark, Beam,‚Ä¶).
Tu connais et utilises les diff√©rentes
solutions de stockage
(SQL, DWH, NoSQL, Search engine,Streaming...).
Tu connais les principes du d√©veloppement Cloud, IaaC et des
cha√Ænes CI/CD
et tu as des connaissances en
machine learning.
Tu es curieux(se) et fais de la veille technologique.
@Arthur et @Paul-Antoine , nos super commerciaux, seront √† ton √©coute pour d√©finir avec toi ta mission id√©ale et tu pourras en changer lorsque tu en auras fait le tour.
Voici des exemples de projets r√©alis√©s par des sfeiriens pour te donner une id√©e :
üîπ
Oussama
a une mission au sein d'un acteur digital native, il s'agit de la mise en place d'une plateforme data (batch et stream) sur Google Cloud pour de l'analytics et du reporting interne (mises en relations, performances des assureurs, comportements utilisateurs...). La stack technique est compos√©e de : Cloud Storage, Dataflow, Bigquery, Cloud Composer (Airflow), Datastudio, Terraform, GitLab.
üîπ
Pascal
a une mission dans le domaine de la sant√©, il s'agit de la mise en place d'une plateforme s'adaptant automatiquement √† la charge de travail sur un Cloud provider pour analyser les donn√©es issues du s√©quen√ßage du g√©nome de patients atteints d'un cancer afin d'aider au diagnostic. La stack technique est compos√©e de : Kubernetes, DataFlow, BigQuery, MongoDB, elastisearch.
Et si je souhaite √©voluer ?
Nous proposons des possibilit√©s d'√©volution verticales et horizontales. Nous pourrons t'accompagner pour te certifier ou √©valuer sur une autre sp√©cialit√©, ou encore devenir
Lead Data ou Data Architecte.
Tu auras √©galement la possibilit√© de prendre des r√¥les en interne si tu le souhaites :
üîπ
√âvaluateur(trice)
dans le processus de recrutement
üîπ
Formateur(trice)
aux Sfeir Schools ou au Sfeir Institute
üîπ
Speaker(euse)
lors de conf√©rences, meetups, talks internes, aupr√®s des √©coles
üîπ
Engineering manager
si tu veux manager une √©quipe tout en restant dans la technique
Et si tu as d'autres envies, on en discute, chacun est diff√©rent et on fait au cas par cas.
Je suis int√©ress√©(e)üôÇ , comment vous rejoindre ?
Si cette annonce a fourni ton attention, il ne te reste plus qu'√† postuler.
@Justine se font un plaisir de t'en dire plus üôÇ. Tu pourras ensuite te frotter √† nos c√©l√®bres
PlayOffs
: 3 tests d'√©valuation technique en pair-programming (algorithmie, langage, framework). Ne t'en fais pas, nos √©valuateur(trice)s sont bienveillant(e)s !
Enfin, tu √©changeras avec Arthur et Paul-Antoine au commerce et Jean-Fran√ßois et @Arnaud , nos directeurs.
Chez Sfeir, la confiance, la bonne humeur et l'inclusion font partie de notre ADN.
En rejoignant notre communaut√©, tu deviendras un(e) Sfeirien(ne) bienveillant(e), libre et responsable.
#L‚ÄôinclusionEstUneForce: Notre process de recrutement inclusif assure une √©galit√© de traitement et de chance aux candidats de tous horizons.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Software Engineer,Orange Logic,France,https://fr.linkedin.com/jobs/view/software-engineer-at-orange-logic-3862540191?position=5&pageNum=42&refId=hZyb1K8CoeqwCyZyTWnF7w%3D%3D&trackingId=T5fgB%2B5g8k%2Bi3gxd161Chg%3D%3D&trk=public_jobs_jserp-result_search-card,"For more than two decades, Orange Logic has empowered a wide range of clients with its digital asset management system, Cortex. We‚Äôve worked with almost every industry, from Finance to NGOs, Media giants to educational institutions, securing and organizing their assets. The Software Engineer will enhance Orange Logic‚Äôs software by participating in the design, development, maintenance and testing process.
What you can expect in your role:
Taking ownership of projects and having the opportunity to further your knowledge by exploring machine learning, security, DevOps, and more.
Developing scalable new features for our software product that exceeds our customer‚Äôs needs.
Building architecture for our platform to ensure optimal performance.
Obtaining requirement feedback from internal teams/clients to maintain/support the product development.
Write the Unit Tests for robust development.
Performing code reviews on other team member‚Äôs work.
You are:
Proficient with English (both verbal and written).
Have 3+ years‚Äô practical experience on a web-based application.
Proficient with any backend programming languages (e.g. .NET, Java, Python, etc.).
A strong fundamental understanding of software development.
An understanding of complex algorithms and data structures, as well as a passion for intellectual challenges.
Strong self-discipline for delivering well-tested, complete features/modules under a tight schedule and the capability for rational thinking.
Experience with the database management tool SQL is a plus, but not mandatory.
Obtained bachelor‚Äôs degree in any relevant major (e.g. Information Technology, Computer Science, etc.).
Perks of joining the team:
Competitive compensation & benefits package
Remote Work Environment
How to get started:
If you‚Äôre up for the challenge to be part of a growing engineering team we‚Äôd like to hear from you. Apply today!
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Orange'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'Machine Learning'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': ['Package'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (H/F/NB) - Paris,Keyrus,"Levallois-Perret, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-nb-paris-at-keyrus-3799373891?position=6&pageNum=42&refId=hZyb1K8CoeqwCyZyTWnF7w%3D%3D&trackingId=FLAgTMnItXbsCuBfCiaawA%3D%3D&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ? Une
success story
dans la
Data
et le
Digital
!
Notre mission ?
Des projets √† forte valeur ajout√©e pour accro√Ætre la performance et la comp√©titivit√© des entreprises, faciliter et acc√©l√©rer leur transformation.
Notre Expertise Depuis Plus De 20 Ans ? Le Conseil Et L'int√©gration De Solutions Innovantes Autour De Trois Domaines
Data Intelligence
Business Intelligence, Big Data & Analytics, Intelligence Artificielle
Digital Experience
Conseil, Strat√©gie & Performance Digitales
Conseil en Management & Transformation
Strat√©gie & Innovation, Pilotage de la Performance & Accompagnement des Projets
Nous sommes plus de 3000 talents sur plus de 20 pays et 4 continents. Notre ADN ? Innover et entreprendre.
Le Job
Les principales missions qui vous seront confi√©es seront les suivantes:
Mettre en ≈ìuvre divers outils de d√©veloppement, de test, d'automatisation et d'infrastructure informatique.
D√©finir et param√©trer les processus de d√©veloppement, de test, de publication, de mise √† jour et de support pour les op√©rations DevOps.
Avoir les comp√©tences techniques pour examiner, v√©rifier et valider le code logiciel d√©velopp√© dans le cadre du projet.
Surveiller les processus tout au long du cycle de vie pour leur adh√©sion et mettre √† jour ou cr√©er de nouveaux processus pour l'am√©lioration et la minimisation du gaspillage.
Encourager et cr√©er des processus automatis√©s dans la mesure du possible.
Identifier et d√©ployer des mesures de cybers√©curit√© en effectuant en permanence une √©valuation des vuln√©rabilit√©s et une gestion des risques.
S'efforcer d'am√©liorer continuellement et de construire une int√©gration continue, un d√©veloppement continu et un pipeline de d√©ploiement constant (CI/CD Pipeline)
Gestion des rapports p√©riodiques sur les progr√®s √† la direction et au client.
Le Profil
Vous avez 5 ans d'exp√©rience.
Vous parlez anglais couramment.
Pourquoi nous rejoindre ?
Pour int√©grer une communaut√© d‚Äôexperts curieux et passionn√©s et √©voluer dans un environnement multiculturel, formateur et favorisant la mobilit√© internationale.
Parce que vous √™tes #DataGeek, #DigitalAddict, #InnovationLover !
#KeyrusRocks #YouRock
Keyrus est une entreprise o√π il fait bon vivre et travailler !
D√©couvrez
La vie chez Keyrus en 60 sec
Keyrus en 3 mots
Nos animations pour nos collaborateurs sur Facebook et sur Instagram.
Notre vid√©o par Welcome To The Jungle
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '20', '20', '20']}"
Ing√©nieur DATA (H/F),Haute Autorit√© de Sant√©,"St.-Denis, √éle-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-h-f-at-haute-autorit%C3%A9-de-sant%C3%A9-3887884957?position=7&pageNum=42&refId=hZyb1K8CoeqwCyZyTWnF7w%3D%3D&trackingId=Et2SHnCydBT9YAzruviS9A%3D%3D&trk=public_jobs_jserp-result_search-card,"Date : 13/02/2024
Poste √† pourvoir Ing√©nieur Data (H/F)
Emploi-rep√®re Chef de projet
Cat√©gorie d‚Äôemploi Cat√©gorie 1
Type de contrat Contrat √† dur√©e ind√©termin√©e / Temps complet
Localisation Saint-Denis (93)
R√©mun√©ration Selon exp√©rience et niveau de formation, par r√©f√©rence aux grilles indiciaires des agences sanitaires en application du d√©cret n¬∞2003-224 du 07 mars 2003 ou selon statut particulier si fonctionnaire (d√©tachement)
Description Du Poste a Pourvoir
Missions g√©n√©rales du poste √† pourvoir Depuis 3 ans, la mission data a mis en place de nombreux projets mobilisant des traitements de donn√©es. Parmi ceux-ci, on peut citer des projets open sources tels que ADEX qui est utilis√© au quotidien par les agents de la HAS et d‚Äôautres agences sanitaires pour analyser les conflits d‚Äôint√©r√™t des experts, open SNDS qui permet de visualiser rapidement des informations sur les consommations de soins, ou la base de donn√©es sur la qualit√© et la s√©curit√© des soins qui alimente l‚Äôespace QualiScope du site internet de la HAS. D‚Äôautres projets ambitieux sont en cours, mobilisant notamment du traitement automatique du langage naturel pour mieux exploiter de gros volumes de retours d‚Äôexp√©riences de patients ou la litt√©rature scientifique.
Ces projets se basent sur une plateforme data, d√©velopp√©e en interne, h√©berg√©e chez un clouder fran√ßais, et homologu√©e pour traiter les donn√©es sensibles de la HAS. Elle comprend notamment une forge logicielle GitLab, un stockage objet MinIO, et des ressources de calcul importantes selon les besoins, notamment des GPU.
Au sein de la mission data, votre mission sera de d√©velopper et maintenir des traitements de donn√©es automatis√©s, pour r√©pondre efficacement aux besoins data de la HAS. Vous travaillerez pour ce faire en synergie avec le responsable technique de la mission data, en bin√¥me par projet avec les autres membres de l‚Äô√©quipe, et de fa√ßon r√©guli√®re avec les data managers et statisticiens des diff√©rents services m√©tiers de l‚Äôinstitution.
Au Fil Des Projets Vous Serez Amen√© √†
D√©velopper des traitements de donn√©es et maintenir en condition op√©rationnelle l‚Äôexistant
Participer √† la rationalisation et l‚Äôam√©lioration constante de la qualit√© technique de nos productions (choix technologiques, promotion des bonnes pratiques, relecture de code)
Contribuer √† des projets open source permettant d‚Äôam√©liorer l‚Äôautonomie des utilisateurs et des citoyens dans l‚Äôexploitation des donn√©es issues de, ou utilis√©es par la HAS
Participer √† la publication en open-data des donn√©es produites par la HAS
Travailler au sein d‚Äôune √©quipe transverse d‚Äôune dizaine de personnes, compos√©e de profils pointus dans leurs domaines (Data, Visualisation, NLP, √©pid√©miologie, etc.)
En tant qu‚Äôing√©nieur data, vous occuperez une position cl√© au sein la mission data, et plus largement des projets data de la HAS. Vous saurez cr√©er une dynamique autour de vos missions, et participer √† la r√©ussite des projets data de la HAS.
Direction et service d‚Äôaffectation
Direction g√©n√©rale
Mission Data
La collecte massive de donn√©es entra√Æne actuellement des transformations majeures dans tous les secteurs d‚Äôactivit√©s. Les syst√®mes de sant√© commencent √† √™tre travers√©s par cette (r)√©volution, qui touche en particulier la production de connaissances et leur usage quotidien. Pour prendre pleinement ce virage, la HAS s‚Äôest dot√©e en 2021 d‚Äôune strat√©gie pluriannuelle d√©di√©e.
Vous travaillerez dans la mission data, rattach√©e au directeur g√©n√©ral, dont le r√¥le est de mettre en euvre cette strat√©gie, par la r√©alisation de projets et d‚Äô√©tudes au service des m√©tiers et missions de l‚Äôinstitution.
La mission data est √† la fois un laboratoire d‚Äôinnovation, un centre d‚Äôexpertise, et un catalyseur de transformations dans l‚Äôusage des donn√©es par la HAS. Elle promeut les dynamiques de connaissance ouverte (open source, open data, open knowledge), conform√©ment aux valeurs de transparence, d‚Äôexpertise et d‚Äôind√©pendance de l‚Äôinstitution.
Profil Recherch√©
Formation Titulaire Bac+5 (Master, dipl√¥me d‚Äôing√©nieur ou dipl√¥me √©quivalent).
Sp√©cialit√© en informatique, data ou DataOps.
Exp√©rience Vous justifiez d‚Äôune exp√©rience professionnelle significative dans le domaine (5 ans minimum) avec la r√©alisation de projets de traitement de donn√©es d‚Äôenvergure, et une app√©tence pour les infrastructures de donn√©es sous-jacentes.
Comp√©tences De nature autonome, vous savez faire preuve d‚Äôinitiative et avez un r√©el sens de l‚Äôorganisation.
Vous √™tes expert des langages, librairies et outils de traitement et de flux de donn√©es (ETL). La pile technologique de la HAS, en √©volution, utilise centralement Python et ses librairies (pandas, dask), mais aussi R, SQL, Spark, GitLab-CI. Une connaissance de plusieurs langages et frameworks de programmation est donc appr√©ci√©e.
Bonne maitrise g√©n√©raliste des syst√®mes de stockage de donn√©es : formats de stockage fichier, bases de donn√©es relationnelles et documents, syst√®mes de fichiers local et distribu√©, stockage objet adapt√© au cloud.
Bonne ma√Ætrise de git, des syst√®mes de tests automatis√©s, d‚Äôint√©gration et de d√©ploiement continu.
Connaissance des syst√®mes LINUX, de virtualisation et de conteneurisation (Podman, Docker).
Participation √† des projets open source et open data appr√©ci√©e.
Enfin, vous √™tes tourn√© vers l‚Äôaction, pragmatique, rigoureux, aimez travailler en √©quipe et faire progresser le collectif en partageant vos comp√©tences.
LA HAUTE AUTORIT√â DE SANT√â
Autorit√© publique ind√©pendante √† caract√®re scientifique, la Haute Autorit√© de sant√© (HAS) vise √† d√©velopper la qualit√© dans les champs sanitaire, social et m√©dico-social, au b√©n√©fice des personnes.
Elle travaille au c√¥t√© des pouvoirs publics dont elle √©claire la d√©cision, avec les professionnels de sant√© pour optimiser leurs pratiques et organisations, et au b√©n√©fice des usagers dont elle renforce la capacit√© √† faire des choix.
Elle Exerce Trois Missions Principales
√©valuer les m√©dicaments, dispositifs et actes en vue de leur remboursement ;
recommander les bonnes pratiques professionnelles, √©laborer des recommandations vaccinales et de sant√© publique ;
mesurer et am√©liorer la qualit√© dans les h√¥pitaux, cliniques, en m√©decine de ville et dans les structures sociales et m√©dico-sociales.
La HAS exerce son activit√© dans le respect de trois valeurs : la rigueur scientifique, l'ind√©pendance et la transparence.
Elle Est Organis√©e Autour
d‚Äôun Coll√®ge de huit membres dont un pr√©sident ;
de commissions sp√©cialis√©es pr√©sid√©es par des membres du Coll√®ge :
de services r√©parties en cinq directions.
Ref : C157O73948
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Analyst H/F,Wewyse,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-wewyse-3811756415?position=8&pageNum=42&refId=hZyb1K8CoeqwCyZyTWnF7w%3D%3D&trackingId=f7%2B8eg2EVVvTYWtksqC2LQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Wewyse
est un cabinet de conseil sp√©cialis√© en
Data et en Intelligence Artificielle
. C'est aussi et surtout une communaut√© de passionn√©s partageant l'ambition de grandir ensemble et d'ouvrir le champ des possibles dans leurs domaines.
Si vous pensez que la Data et l'Intelligence Artificielle ont beaucoup √† offrir au monde de demain, et si vous souhaitez apporter votre contribution √† ce monde, avec humilit√© et enthousiasme, alors vous √™tes un Wyser en puissance.
√ätre
Data Analyst
chez Wewyse c'est :
Int√©grer une communaut√© d‚Äôexperts Data passionn√©s,
Recevoir et partager des connaissances, des savoirs-faire lors de nombreux √©v√®nements internes et acqu√©rir constamment de nouvelles comp√©tences,
Intervenir sur des projets √† la fois techniques et business, souvent dans un contexte international, avec des forts enjeux strat√©giques aupr√®s de nos clients dans tous les secteurs (retail, √©nergie, m√©dias, transports, banque et assurance ‚Ä¶)
Viser l‚Äôexcellence dans la qualit√© et l‚Äôactionnabilit√© des analyses, gr√¢ce √† la ma√Ætrise technique des outils en Data Analytics (d√©veloppement, notebooks, visualisation, techniques de statistiques avanc√©es‚Ä¶) et la bonne compr√©hension des enjeux business de nos clients,
Participer √† des projets innovants, impactants et positifs au sein de notre Datalab, en √©quipe, avec des partenaires acad√©miques (CentraleSupelec, ‚Ä¶) et parfois avec des starts up, afin de laisser exprimer vos valeurs et vos id√©es,
Avoir la possibilit√© de s‚Äôimpliquer dans le d√©veloppement de Wewyse (participer au recrutement, concevoir des formations, donner des masterclass en √©cole d‚Äôing√©nieur, participer √† l‚Äôavant-vente business, piloter des projets au sein du Datalab, d√©velopper de nouveaux partenariats ‚Ä¶)
√ätre encourag√©, conseill√© et accompagn√© dans un parcours de formation adapt√© √† vos ambitions professionnelles et avec un budget d√©di√©,
Faire partie de la famille Wemanity, cr√©er rapidement un r√©seau d‚Äôexperts et de personnes reconnues dans leur domaine, participer aux √©v√®nements communs (voyage annuel, talks, afterworks ...) et b√©n√©ficier des multiples opportunit√©s de carri√®re au sein du Groupe,
Avoir l‚Äôopportunit√© de travailler avec une √©quipe dynamique, dans une ambiance start-up et √† taille humaine dans le centre de Paris (Op√©ra 9√®me arrondissement)
Ce que nous aimons :
Les personnalit√©s ouvertes, curieuses, ambitieuses
Un excellent niveau en
SQL
Une premi√®re exp√©rience en
Python
La ma√Ætrise d‚Äôun outil de Data Visualisation
(PBI, Tableau, Qlik, Looker, Data Studio ‚Ä¶)
Une exp√©rience dans l‚Äôutilisation de
Jupyter Notebook / Databricks Notebook
est fortement appr√©ci√©e
L‚Äôaisance en communication
L‚Äôesprit de synth√®se
L'anglais
Vous vous reconnaissez ? Alors n'h√©sitez pas √† postuler !
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau'], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Statistiques'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (H/F),Euro Information Developpements / EID,"Villeneuve-d‚ÄôAscq, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-euro-information-developpements-eid-3821163420?position=9&pageNum=42&refId=hZyb1K8CoeqwCyZyTWnF7w%3D%3D&trackingId=UMhN2ZF6jgNU3v6cad79RQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Qui sommes nous
Euro-Information, filiale technologique de Cr√©dit Mutuel Alliance F√©d√©rale, con√ßoit, r√©alise, maintient et exploite un syst√®me d‚Äôinformation commun utilis√© par le Groupe.
Les activit√©s de d√©veloppement et de production informatique au niveau national et international sont assur√©es par environ 4000 salari√©s r√©partis sur plusieurs sites g√©ographiques au niveau national : Strasbourg, Nancy, Dijon, Orl√©ans, Lyon, Lille, Cergy, Val de Fontenay, Paris et Nantes.
Premi√®re Banque √† adopter le statut d‚Äôentreprise √† mission, le Cr√©dit Mutuel Alliance F√©d√©rale s‚Äôinvestit et s‚Äôengage dans diff√©rentes missions sociales et environnementales :
L‚Äôaccompagnement de tous par notre organisation coop√©rative et mutualiste reste au c≈ìur de notre ADN.
La technologie au service de l‚Äôhumain est une r√©f√©rence dans notre monde connect√©.
La solidarit√© et l‚Äô√©co-responsabilit√© deviennent des axes cl√©s dans notre d√©veloppement.
Notre raison d‚Äô√™tre : Ensemble, Ecouter et Agir.
Vos missions
Vous souhaitez int√©grer une √©quipe dynamique et √† taille humaine au sein d‚Äôune entreprise solide et d‚Äôun grand groupe en d√©veloppement constant ? Vous souhaitez travailler sur un enjeu d‚Äôaujourd‚Äôhui et plus encore de demain : la donn√©e ? Euro-Information, la Fintech de Cr√©dit Mutuel Alliance F√©d√©rale structure une Data Factory pour :
Acc√©l√©rer la valorisation des donn√©es au travers d‚Äôanalyse de masse et de mod√®les allant jusqu‚Äôau pr√©dictif.
R√©pondre √† la confiance de nos clients en garantissant la s√©curit√© de leurs donn√©es et une utilisation responsable et encadr√©e, respectueuse de leur vie priv√©e.
La Data Factory EI se positionne comme un fournisseur de solutions pour les √©quipes informatiques et pour l‚Äôensemble des entit√©s du groupe et comme un facilitateur d‚Äô√©changes et de mutualisation. Pour mener √† bien ces missions, la relation m√©tier s‚Äôav√®re essentielle. Elle r√©unit :
Des Data Architects. Ils fournissent l‚Äôenvironnement, les outils et s‚Äôassurent de leur performance et de leur constante √©volution.
Des Data Engineers. Ils ont la maitrise des donn√©es, de leur r√©colte √† leur mise √† disposition adapt√©e aux besoins des m√©tiers. Ils con√ßoivent les mod√®les d‚Äôenregistrement des donn√©es.
Des Concepteurs Business Intelligence. Ils simplifient, mutualisent et industrialisent les reportings.
Des Data Scientists. Ils accompagnent les m√©tiers et les entit√©s sur la Data Science, ils r√©alisent √† fa√ßon sur les sujets √† fort enjeu.
Des Data Officers. Ils coordonnent et mutualisent les √©nergies sur les projets Data comme dans le cadre de la Gouvernance et de l‚Äôadministration des donn√©es.
Nous recherchons un(e) Data Engineer.
Vous participerez √† la mise en ≈ìuvre et au maintien du Syst√®me d‚Äôinformation D√©cisionnel du groupe
Pour les banques, les cr√©dits √† consommation et les filiales, en France et √† l‚Äôinternational :
Compr√©hension de l‚Äôactivit√© et des besoins de vos clients, en dialogue avec la MOA
Compr√©hension du SI de production, en dialogue avec les √©quipes MOE
Mod√©lisation du Syst√®me d‚ÄôInformation D√©cisionnel
Conception et r√©alisation
Diagnostic des dysfonctionnements rencontr√©s
Maintenances correctives et √©volutives
Support aupr√®s des diff√©rents m√©tiers
Documentation technique
Suivi des traitements
Pilotage de projets de petite taille en autonomie
Vous travaillerez sur une grande vari√©t√© de projets sur des m√©tiers divers et sur des dizaines d‚Äôentit√©s g√©r√©es sur le SI d‚ÄôEuro-Information : cr√©dit, assurance, commercial, leasing, pr√©vention de la fraude, sujets li√©s √† l‚ÄôIntelligence Artificielle en lien avec la Cognitive Factory, sujets li√©s √† la lecture automatique des documents en lien avec l‚ÄôOCR Factory‚Ä¶
Vous intervenez sur des projets √† dimension internationale sur des environnements Vertica, Hadoop, Stambia, SAS, Business Objects, QlikSense‚Ä¶
Vous participez, coordonnez et menez √† bien des projets de valorisation de donn√©es sur des cas d‚Äôusages concrets :
Participez aux projets de bout en bout : de l‚Äôexpression du besoin jusqu‚Äô√† la r√©alisation et au suivi de sa performance en lien avec la MOA et nos Data Officers
Mobilisez l‚Äôensemble des acteurs : Business, Data scientists, Data engineer, sources de donn√©es ‚Ä¶
Eclairez et participez aux prises de d√©cision.
Mutualisez les travaux et les bonnes pratiques entre les acteurs et les diff√©rents m√©tiers du groupe.
Accompagnez le changement. Au sein de vos projets et au-del√†, vous portez l‚Äôacculturation Data au sein du groupe
Ce que vous allez vivre chez nous
T√©l√©travail (2 jours par semaine)
R√©mun√©ration fixe vers√©e sur 13 mois
RTT
Int√©ressement, participation et abondement
Plan √©pargne entreprise et PERCO
Contrat de sant√© collectif
Pr√©voyance
Retraite suppl√©mentaire prise en charge √† 100% par l‚Äôemployeur
Conditions bancaires et assurances pr√©f√©rentielles
Politique parentale avantageuse
Ce que nous allons aimer chez vous
De formation bac +4/5, vous disposez id√©alement, d‚Äôune exp√©rience significative sur un poste √©quivalent.
Connaissance du monde OPEN
Vous avez la maitrise d‚Äôun ETL, d‚Äôune base de donn√©es orient√©e Analytique, d‚Äôune solution BI. La connaissance de l‚Äôoutil de mod√©lisation PowerDesigner serait un plus
La maitrise de l‚Äôanglais serait √©galement appr√©ci√©e.
Ce qui nous plaira le plus chez vous :
C‚Äôest vous-m√™me ! Alors on vous attend ouvert(e), force de proposition, dot√©(e) d‚Äôun certain sens critique, autonome et respectueux(se) de la confidentialit√© des informations d√©tenues car c‚Äôest ce qui vous permettra de mener au mieux votre mission.
On dit de vous que vous avez une certaine aptitude √† communiquer et le sens du travail en √©quipe.
Vous √™tes motiv√©(e) et vous souhaitez vous investir fonctionnellement et techniquement, n‚Äôh√©sitez plus l‚Äôoffre est faite pour vous.
Autres informations
Le poste bas√© √† Villeneuve-d‚ÄôAscq est √† pourvoir en CDI d√®s que possible.
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (H/F),Extia,"Sophia Antipolis, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-extia-3675382393?position=10&pageNum=42&refId=hZyb1K8CoeqwCyZyTWnF7w%3D%3D&trackingId=7G%2FuGfBxDl2QaW7f%2FCkTIg%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous souhaitez rejoindre une entreprise qui place l‚Äôhumain au c≈ìur de ses pr√©occupations ? On vous attend chez
Extia
!
Soci√©t√© de conseil sp√©cialis√©e dans les m√©tiers de l‚ÄôIT, de l‚Äôing√©nierie et du digital, Extia privil√©gie depuis sa cr√©ation en 2007 une approche qui allie performance et bien-√™tre au travail. Une vision de l‚Äôentreprise partag√©e aujourd‚Äôhui par plus de 2 500 Extiens en France et √† l'international et r√©compens√©e par le label Great Place to Work¬Æ depuis 13 ans, notamment en
2024 o√π les Extiens se hissent √† la premi√®re place du palmar√®s Best Workplaces France
!
Chez Extia, c‚Äôest ¬´ D‚Äôabord qui, ensuite quoi ¬ª alors, allons-y !
D'abord qui
D'abord qui ?
Ing√©nieux, votre imagination d√©bordante vient √† bout de chaque probl√©matique,
Attentif aux d√©tails, vous avez un ≈ìil de Lynx pour rep√©rer les incoh√©rences,
Efficace, vous ne remettez pas √† demain ce qui peut √™tre fait d√®s aujourd‚Äôhui.
Ensuite quoi
Ensuite quoi ?
Vous aurez le r√¥le de support technique aux √©quipes d‚Äôanalyse : structurer les donn√©es, r√©aliser des analyses ¬´ statistiques ¬ª ou ¬´ techniques ¬ª sur les donn√©es, d√©velopper des outils d‚Äôanalyse‚Ä¶ Vous m√®nerez des √©tudes afin d‚Äôidentifier les solutions les plus pertinentes. Vous serez en charge de :
Participer √† la d√©finition des besoins,
Mettre en place des Pipelines de traitement de donn√©es,
D√©velopper de nouvelles features,
Maintenir en condition op√©rationnelle du system legacy de test,
Collaborer avec les Data Scientists au d√©veloppement des modules d‚Äôanalyse de donn√©e,
Int√©grer des sources de donn√©es.
**Profil recherch√© **
Disposant de minimum 2 √† 3 ans d'exp√©rience, vous √™tes habitu√© √† travailler aussi bien avec des m√©ta-donn√©es qu‚Äôavec des donn√©es non-structur√©es. A cet effet vous maitrisez Spark et vous connaissez le langage de programmation Scala. Vous poss√©dez √©galement une affinit√© avec le cloud.
Enfin, vous avez une bonne maitrise de l'anglais, √† l'√©crit comme √† l'oral !
Show more
Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Statistiques', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '13', '13', '13']}"
Data Engineer,Energy Jobline,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-energy-jobline-3892672213?position=1&pageNum=45&refId=helkV5fb1RK2O%2B2D3vOHXQ%3D%3D&trackingId=upuV45Ei8yGufim4hykR%2Fg%3D%3D&trk=public_jobs_jserp-result_search-card,"Do you have Data Engineering experience, and are you seeking a new contract role in Paris? NES Fircroft is helping a collaborative company recruit an agile and passionate Data Engineer for a 12-month contract. Hybrid based, must have 5+ years experience. Please note this position requires you to be fluent in French and English.
As a Data Engineer, you will be responsible for the data architecture's design, development and production. You will also collect business and user requirements, design data pipelines, and push the architecture into production.
In your first few weeks in this Data Engineer role, you can expect to:
Collect business and user requirements
Design the data architecture
Design data pipelines
Put the architecture into production
Ensure the maintenance and evolution of the architecture
Collaborate and participate in activities within the chapter
Attend Communities of Practice (CoPs) meetings.
To apply for this Data Engineer role, your soft skills, expertise, and experience should include:
Experience working with Python/PySpark/Databricks under an Azure Cloud environment
Experience creating data pipelines and putting the architecture into production
Experience in working with data pipelines, maintaining and evolving the architecture.
If you want to positively impact and create change, you'll be rewarded with an excellent contract per day rate for your inclusive and committed approach.
To apply for this contract Data Engineer job in Paris, please contact NES Fircroft today. Please refer any friends or colleagues for this role or direct them to our Careers page on our website.
With over 90 years of combined experience in delivering workforce solutions to the global energy industry, NES Fircroft is proud to be the world‚Äôs leading engineering staffing provider spanning the Oil & Gas, Power & renewable, Infrastructure, and Life Sciences, Mining, Automotive and Chemicals sectors worldwide. We provide tailored staffing solutions, sourced from a global talent pool by a dedicated, discipline-specific team of consultants.
With over 90 years' combined experience, NES Fircroft (NES) is proud to be the world's leading engineering staffing provider spanning the Oil & Gas, Power & Renewables, Chemicals, Construction & Infrastructure, Life Sciences, Mining and Manufacturing sectors worldwide. With more than 80 offices in 45 countries, we are able to provide our clients with the engineering and technical expertise they need, wherever and whenever it is needed. We offer contractors far more than a traditional recruitment service, supporting with everything from securing visas and work permits, to providing market-leading benefits packages and accommodation, ensuring they are safely and compliantly able to support our clients.
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['Package'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (H/F),Extia,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-extia-3841318856?position=2&pageNum=45&refId=helkV5fb1RK2O%2B2D3vOHXQ%3D%3D&trackingId=XzXy52KW1ipP%2BVsyy2ii8A%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous souhaitez rejoindre une entreprise qui place l‚Äôhumain au c≈ìur de ses pr√©occupations ? On vous attend chez
Extia
!
Soci√©t√© de conseil sp√©cialis√©e dans les m√©tiers de l‚ÄôIT, de l‚Äôing√©nierie et du digital, Extia privil√©gie depuis sa cr√©ation en 2007 une approche qui allie performance et bien-√™tre au travail. Une vision de l‚Äôentreprise partag√©e aujourd‚Äôhui par plus de 2 500 Extiens en France et √† l'international et r√©compens√©e par le label Great Place to Work¬Æ depuis 13 ans, notamment en
2024 o√π les Extiens se hissent √† la premi√®re place du palmar√®s Best Workplaces France
!
Chez Extia, c‚Äôest ¬´ D‚Äôabord qui, ensuite quoi ¬ª alors, allons-y !
D'abord qui
Rigoureux, vous ne laissez rien au hasard,
Efficace, vous ne remettez pas √† demain ce qui peut √™tre fait d√®s aujourd‚Äôhui,
Autonome, vous savez mener vos missions √† bien sans aide.
Ensuite quoi
Vous aurez le r√¥le de support technique aux √©quipes d‚Äôanalyse : structurer les donn√©es, r√©aliser des analyses ¬´ statistiques ¬ª ou ¬´ techniques ¬ª sur les donn√©es, d√©velopper des outils d‚Äôanalyse‚Ä¶
Vous m√®nerez des √©tudes afin d‚Äô√©valuer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin d‚Äôidentifier les solutions les plus pertinentes.
Vous serez en charge de :
Participer √† la d√©finition des besoins et √† la r√©daction des User Stories,
Collaborer avec les Data Scientists au d√©veloppement des modules d‚Äôanalyse de donn√©e,
Concevoir et construire des architectures de donn√©es,
Int√©grer des sources de donn√©es,
S'assurer que les donn√©es sont facilement accessibles et que leur exploitation fonctionne comme demand√©, m√™me dans des circonstances hautement √©volutives,
Ex√©cuter des processus ETL (extraire / transformer / charger) √† partir d'ensembles de donn√©es complexes et / ou volumineux.
Profil recherch√© :
Maitrise de l‚Äô√©cosyst√®me Microsoft Azure Data Factory, Azure Data Lake est un plus
Maitrise Technologie autour de la data : Power BI, Spark, Airflow, Python, Scala‚Ä¶
Maitrise des bonnes pratiques de d√©veloppement et m√©thodes agiles
Base de donn√©es : SQL, Postgr√© SQL (Paas) et mod√©lisation de la donn√©e
Connaissance des syst√®mes de gestionnaire de conteneur (Kubernetes,...)
Connaissance des outils de d√©ploiements : Jenkins, Git, maven, Ansible
Qualit√©s relationnelles et capacit√© √† g√©rer nombreuses interactions
Dynamisme, autonomie et envie de d√©couvrir des mani√®res diff√©rentes/innovantes de faire
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': ['Statistiques'], 'CloudComputing': ['Azure'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning', 'Statistiques'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '13', '13', '13']}"
Data Engineer Talend (F/H),Pact&Go,"Montpellier, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-talend-f-h-at-pact-go-3914234996?position=3&pageNum=45&refId=helkV5fb1RK2O%2B2D3vOHXQ%3D%3D&trackingId=7lqBbN6xVdGsLiePECBTYA%3D%3D&trk=public_jobs_jserp-result_search-card,"PACT&GO est un Cabinet de Conseil en Recrutement, ind√©pendant et de proximit√©.
Notre objectif est de d√©mocratiser les services des cabinets de recrutement aupr√®s des Start-Up, TPE & PME, en proposant un service de qualit√©, pour une facturation plus √©quitable : 2x moins ch√®re en moyenne que les prix en vigueur sur le march√© !
De plus, il n'existe aucun risque pour nos clients de solliciter Pact&Go : nous ne demandons pas d'acompte et n'appliquons pas de clause contraignante (ex : clause d'exclusivit√©) : Nous fonctionnons uniquement au succ√®s !
En parall√®le, nous souhaitons nous mettre pleinement aux services de nos candidats, afin de comprendre r√©ellement leurs projets professionnels et pr√©senter LA bonne opportunit√© qui correspondra √† leurs attentes.
Nous sommes sp√©cialis√©s sur les secteurs d'activit√©s suivants dans les R√©gions Occitanie & PACA :
Informatique
Tertiaire
Bureau d'√©tudes & Ing√©nierie
Nos Valeurs
Engagement
Confiance
Pers√©v√©rance
Transparence
Bienveillance
Pour tout compl√©ment d'information, vous pouvez consulter notre site internet : www.pact-go.com
S√©curisez vos recrutements : Confiez vos recherches √† Pact&Go !
Le Poste
Nous recherchons un(e) Data Engineer (F/H) comp√©tent(e) sur Talend pour l'un de nos clients, acteur incontournable dans le secteur IT √† Montpellier.
Il s'agit d'un poste √† pourvoir au sein d'un centre de services d'une ESN r√©put√©e sur Montpellier (depuis + 20 ans), √† taille humaine, et qui prend soin de ses salari√©s (suivi personnalis√© et plan de formation tout au long du parcours).
Missions
Conception et d√©veloppement de processus ETL en utilisant Talend pour int√©grer et transformer les donn√©es en vue de leur utilisation dans un environnement de middleware.
√âcriture et optimisation de requ√™tes SQL pour la manipulation et l'analyse des donn√©es.
Travail en √©troite collaboration avec l'√©quipe de d√©veloppement pour int√©grer les solutions.
Collaboration avec les √©quipes de projet pour comprendre les besoins m√©tiers et traduire ces besoins en solutions techniques efficaces.
R√©alisation de tests pour garantir la qualit√© et la fiabilit√© des donn√©es.
Documentation technique pour assurer une bonne compr√©hension et une maintenance efficace des d√©veloppements.
Profil
De formation Bac+3 √† Bac+5, vous d√©tenez une 1√®re exp√©rience significative sur une fonction similaire.
Vous avez d√©j√† particip√© √† un ou plusieurs projets BI, sur des probl√©matiques de Data Integration (mise en place des bonnes pratiques pour des flux otpimis√©s) ou plus g√©n√©ralement dans la mise en place de Datawarehouses/Datamarts.
Vous attachez une importance particuli√®re √† la qualit√© de vos d√©veloppements (respect de l'architecture, normes de codage, tests unitaires,‚Ä¶).
Vous avez une tr√®s bonne ma√Ætrise de Talend.
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5', 'Bac+3'], 'Experience': ['a', 'n', 's', '20', '20', '20']}"
Data Analyst (H/F),Wemanity Lille,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-wemanity-lille-3890979963?position=4&pageNum=45&refId=helkV5fb1RK2O%2B2D3vOHXQ%3D%3D&trackingId=Ng5MnIpePveHtR6h3PYHtg%3D%3D&trk=public_jobs_jserp-result_search-card,"Fond√©e en 2018, l‚Äôagence
Wemanity Lille
se d√©veloppe d‚Äôann√©e en ann√©e gr√¢ce aux talents qui font de cette aventure une r√©ussite ! üåà‚Äã
3 mots pour la d√©crire ? P√©tillante, √† taille humaine et audacieuse !
Pour suivre cette dynamique nous recherchons des talents ayant l'envie de progresser et de se lancer dans une belle aventure professionnelle et humaine √† nos c√¥t√©s. üå≥
Nous recherchons un(e)
Data Analyst (H/F)
avec un minimum d'exp√©rience de 3/4 ans, qui a envie d'apprendre et de d√©voiler tout son potentiel √† nos c√¥t√©s !
Qui sommes-nous
?
üí°
üé¢ Cabinet de conseil sp√©cialis√© en
transformations digitales et agiles.
üåç Pr√©sent √† l‚Äôinternational :
Paris, Lille, Belgique, Pays-bas, Maroc et Luxembourg.
üë•
600
coop√©rateurs passionn√©s.
üçÉUn p√¥le RSE d√©bordant d‚Äôid√©es qui propose des projets √†
impact
sociaux
et
environnementaux.
üíº‚Äã Pr√©sence du Wemanity Learning Center permettant
formations & certifications.
ü¶∏ Ton profil :
Tu es Data Analyst (H/F)
, tu as une exp√©rience de plus de 3/4 ans et tu souhaites rejoindre une √©quipe de passionn√©s ambitieux?
Tu aimes mettre en valeur les bonnes pratiques, apprendre et partager ? Cette offre est faite pour toi !
üöÄ Tes missions* :
Ma√Ætrise des outils d'analyse de donn√©es.
Exp√©rience avec les outils de visualisation de donn√©es (Tableau, Power BI).
Connaissance des techniques d'analyse statistique et des mod√®les de machine learning.
Utilisation de m√©thodologies Agile/Scrum.
Collaboration avec des √©quipes interfonctionnelles.
*Liste non exhaustive
üåàPourquoi Wemanity ?
Un salaire attractif et de nombreux avantages (RTT, formations & certifications, primes vacances, CE, carte Swile ‚Ä¶) ‚òÄÔ∏è
Des projets vari√©s √† forte valeur ajout√©e üéà
Une vraie mont√©e en comp√©tences avec notre p√¥le formation (formations, certifications) ü™Ñ
L‚Äôopportunit√© d‚Äôint√©grer une communaut√© d‚Äôagilistes soud√©e üöÄ
La possibilit√© d‚Äôint√©grer des squads agiles qui fonctionnent en mode startup pour intervenir sur des projets from scratch en interne ou chez nos clients ü§π‚Äç
La possibilit√© de travailler en r√©elle autonomie (t√©l√©travail) ‚òÄÔ∏è
Une carri√®re √©volutive au sein d‚Äôune entreprise pleine de projets üí™
Une entreprise avec un r√©el engagement RSE üå≥
üìå
Notre processus de recrutement en 3 √©tapes :
1√®re √©tape, ton profil nous int√©resse ! Premier √©change avec l‚Äôun de nos recruteurs passionn√©s pour faire connaissance et en savoir plus sur tes souhaits d‚Äô√©volution.
2√®me √©tape, l‚Äôentretien technique : c‚Äôest le moment d‚Äô√©changes sur la partie technique avec un membre de Wemanity (coop√©rateurs).
Entretien final : Tu rencontreras un commercial afin de d√©terminer le projet et le client chez qui tu pourras √©voluer et t‚Äô√©panouir ! Suite √† ces 3 √©changes, je te souhaite d‚Äôobtenir ton billet d‚Äôentr√©e pour rejoindre l‚Äôaventure Wemanity !
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['3'], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Data Analyst (H/F),moOngy Digital Lab,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-moongy-digital-lab-3890974953?position=5&pageNum=45&refId=helkV5fb1RK2O%2B2D3vOHXQ%3D%3D&trackingId=C6F4wu8iMd3zYQGH%2FQrEKg%3D%3D&trk=public_jobs_jserp-result_search-card,"Web Transition, c‚Äôest qui ?
Fond√©e en 2011,
Web transition
est une entreprise de services num√©riques op√©rant sur le march√© de l‚ÄôIT/Digital !
Constituant une part essentielle de
MoOngy Digital Lab
, Web Transition accompagne ses clients grands comptes sur leurs projets de Webmarketing, de Design, Gestion de projet et √©galement en Data !
Notre objectif : nous implanter comme un acteur principal sur le march√© de la Transformation Digitale en accompagnant et valorisant les comp√©tences de nos collaborateurs !
Nous sommes convaincus que le succ√®s de MoOngy Digital Lab r√©side dans la somme des potentiels de nos √©quipes ü§ù
Ton √©quipe : La tribu Data
Parce qu‚Äôil est indispensable que tu puisses partager tes connaissances mais aussi en acqu√©rir de nouvelles, tu feras partie de l‚Äôune de nos tribus : celle de la Data. De plus, cela te permettra d‚Äô√™tre acteur dans le d√©veloppement et la strat√©gie de Web Transition. Ce syst√®me de co-r√©flexion et co-construction est un fondement essentiel chez nous !
Dans cette aventure, tu :
Optimises
les requ√™tes SQL ;
Construis
les mod√®les de r√©gression ;
Analyses
la rentabilit√© des actions marketing ;
R√©alises
des √©tudes ad hoc sur les comportements clients ;
Produits
et
automatises
le reporting.
Rejoins-nous si tu as :
Une exp√©rience de 3 ans minimum,
Une maitrise technique de GCP / DBT / PowerBI,
Une exp√©rience similaire dans une startup ou dans l‚Äôindustrie serait un plus !
Ton savoir-√™tre :
Ouvert d‚Äôesprit
Respectueux des diff√©rences de chacun
Curieux
Proactif
Par o√π on commence ?
Un premier entretien RH d‚Äô1h pour comprendre ton parcours et tes aspirations
Un second entretien de 45 minutes avec l‚Äôun de nos Business Manager afin de valider tes comp√©tences et qu‚Äôil se projette sur l‚Äôune des missions qu‚Äôil pourrait te proposer
Un troisi√®me entretien de quelques minutes avec notre responsable d‚Äôagence pour te proposer d‚Äôint√©grer notre superbe Team Web !
3 entretiens en peu de temps, si ton profil correspond tu int√®greras tr√®s vite nos √©quipes üòâ
Pr√™t pour embarquer dans notre grande aventure humaine ? Deviens notre futur Weber en postulant √† cette offre ! Voici les avantages qui t‚Äôattendent en tant que Weber :
ü§© Des coll√®gues incroyables
üèÜ Certifi√©e Great Place to Work
üéÆ Des bureaux sympas (o√π vous serez toujours les bienvenus)
üéâ Des teambuilding et √©vents tous les mois
üíª Des tributs m√©tiers pour √©changer entre Weber du m√™me m√©tier
Des missions chez le client qui sont accompagn√©es et coach√©es par ton manager
Un accompagnement dans ton plan de carri√®re et tes envies de re skilling
ü§ì Un catalogue de formations certifiantes ouvert √† tous les salari√©s
üçΩÔ∏è Une carte tickets restaurant MyEdenred
‚ù§Ô∏è Une mutuelle GrasSavoye
üöé Une prise en charge des frais de transport √† 100%
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Analyst,Volvo Group,"V√©nissieux, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-analyst-at-volvo-group-3860811035?position=6&pageNum=45&refId=helkV5fb1RK2O%2B2D3vOHXQ%3D%3D&trackingId=1Xhk0m4PORbq0Y47g5nYQQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Transport is at the core of modern society. Imagine using your expertise to shape sustainable transport solutions for the future? If you seek to make a difference on a global scale, working with next-gen technologies and the sharpest collaborative teams, then we could be a perfect match.
What You Will Do
At DIGITAL&IT DATA you will contribute to the transformation of our company, the transport industry and society at large. You will:
Drive workshops with the business stakeholders to understand their business context and to collect their needs.
Become a Data expert on one or more business domains, to draw conclusions and to provide answers to business stakeholders questions.
Access, manipulate, query, and analyze data using different software, tools and techniques.
Be part of the data modeling process (design and implementation) as well as in the definition of business rules that will ensure data consistency and quality.
Pre-process, clean and structure data to facilitate data exploration and advanced analytics activities.
Design and implement dashboards using advanced visualization tools.
Work in cross functional agile teams to continuously experiment, iterate and deliver on new product objectives.
Be an active member of the Data Analyst Chapter, sharing knowledge and best practices with your peers.
Benefit from dedicated trainings to maintain and develop your Data Analyst skills.
Your Future Team
As Data Analyst, you will be part of A&BI (Analytics & Business Intelligence) Trucks Dealer agile team. You will have opportunity to work on heterogenous topics such as (non exhaustive list):
Paperless NLP: Support Paperless project thanks to NLP (Natural Language Processing) & AI (Artificial Intelligence) processes,
Dealer Quality program: Set of Key Performance Indicators on all Dealer processes to support Sales Area organization,
Set up Data Product on Azure to support smart business services,
Be part of the maintenance team to ensure business process continuity, ...
Who are you?
Do you dream big? We do too, and we are excited to grow together. Are you the one?
Having a master degree or equivalent in IT.
Data & Data Analysis‚ÄØhas been‚ÄØyour‚ÄØworld‚ÄØfor 3-5‚ÄØyears‚ÄØnow.
You are an experienced Data Analyst looking for new challenges in the transport industry. You‚ÄØare‚ÄØproactive‚ÄØproblem‚ÄØsolver‚ÄØwith‚ÄØinnovative‚ÄØthinking‚ÄØwith‚ÄØa strong‚ÄØsense of teamwork.
Writing SQL and doing data modelling are natural activities for you.
You are experienced working on data manipulation and data modeling.
You are experienced designing and developing dashboard using at least one visualization tool (such as PowerBI for example).
You are familiar with Azure Data Analytics Stack (Storage accounts, Databricks, Azure Data Factory, SQL Server, SQL Data base, etc...).
You are familiar writing scripts on Python to do data preparation/cleaning.
You have excellent communication skills in French and English (C1 level)
Ready for the next move?
Are you excited to bring your skills and disruptive ideas to the table? We can‚Äôt wait to hear from you. Apply today!
We value your data privacy and therefore do not accept applications via mail.
Who We Are And What We Believe In
Our focus on Inclusion, Diversity, and Equity allows each of us the opportunity to bring our full authentic self to work and thrive by providing a safe and supportive environment, free of harassment and discrimination. We are committed to removing the barriers to entry, which is why we ask that even if you feel you may not meet every qualification on the job description, please apply and let us decide.
Applying to this job offers you the opportunity to join
Volvo Group.
Every day, across the globe, our trucks, buses, engines, construction equipment, financial services, and solutions make modern life possible. We are almost 100,000 people empowered to shape the future landscape of efficient, safe and sustainable transport solutions. Fulfilling our mission creates countless career opportunities for talents with sharp minds and passion across the group‚Äôs leading brands and entities.
Group Digital & IT
is the hub for digital development within Volvo Group. Imagine yourself working with cutting-edge technologies in a global team, represented in more than 30 countries. We are dedicated to leading the way of tomorrow‚Äôs transport solutions, guided by a strong customer mindset and high level of curiosity, both as individuals and as a team. Here, you will thrive in your career in an environment where your voice is heard and your ideas matter.
‚Äò
Data
‚Äô is a new function within Volvo Digital & IT with the goal to unlock the power of data for the whole Volvo Group to become a fully data-driven company! With data, the core component of our transformation journey, we will, together with our data talents, make the Volvo Group 2030 vision happen. We will take care of all the aspects of Data, how it is quality assured, documented, made available, prepared and consumed through BI, Analytics and Machine Learning. We have an ambitious transformation in front of us, with an implementation of the Data Layer in Azure as well as the reinforcement of Data Governance and Data Management in the full Group.
The ‚ÄòData‚Äô function is a large multi-cultural organization with 600+ employees and contractors located mainly in 7 countries - Sweden, Poland, India, Belgium, Brazil, USA, and France. In this role you will be joining the Data Analyst Chapter team in France.
We collaborate with other parts of the organization, both in Volvo Digital & IT, with Truck Divisions, Business Areas and Group Functions. We foster an environment where ideas, thoughts and opinions can be shared. We are team players with clear common ambitions, and we win together.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['SQL Server'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication', 'Teamwork', 'Organization']}","{'JobDetail': ['Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,DXC Technology,"La D√©fense, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-dxc-technology-3754144852?position=7&pageNum=45&refId=helkV5fb1RK2O%2B2D3vOHXQ%3D%3D&trackingId=%2BvXftRJJ6zT01L49fbFMwQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Job Description
Chez DXC Technology, nous agissons en tant que conseiller ind√©pendant et de confiance dans la num√©risation de l'entreprise du client. Nos employ√©s sont responsables de l'optimisation des processus industriels de nos clients dans de nombreux domaines de march√© diff√©rents ainsi que du d√©veloppement, de la mise en ≈ìuvre et de la gestion de leurs m√©canismes li√©s aux donn√©es informatiques.
DXC Technology conseille, d√©veloppe et met en ≈ìuvre des solutions d'analyse et d'IA modernes en appliquant l'expertise de l'industrie, des solutions et services technologiques et commerciaux, des m√©thodologies √©prouv√©es et des personnes exp√©riment√©es. Gr√¢ce √† nos offres, nos capacit√©s et notre port√©e mondiale, les organisations acc√©l√®rent la transformation num√©rique et produisent en toute confiance des r√©sultats commerciaux reproductibles et aliment√©s par l'IA. Nous travaillons avec nos clients pour convertir les donn√©es en informations, les informations en id√©es et les id√©es en meilleurs r√©sultats commerciaux.
Dans notre √©quipe DXC Technology, nous recherchons actuellement un Data Engineer. Les domaines typiques dans lesquels vous travaillerez sont : les solutions et services d'analyse, les plates-formes Big Data, l'intelligence artificielle et l'IoT.
Fonctions Professionnelles Essentielles
Concevoir et mettre en ≈ìuvre des pipelines d'ingestion de donn√©es par lots et en temps r√©el pour Azure Data Lake ou similaires sur autres Cloud Solution Providers (AWS, GCP)
Mettre en ≈ìuvre des contr√¥les de qualit√© des donn√©es
Mettre en ≈ìuvre des m√©canismes de lignage, d'agr√©gation et de r√©conciliation des donn√©es (y compris des tableaux de bord et des alertes)
Mise en ≈ìuvre du catalogage des donn√©es, de l'archivage et de la reprise apr√®s sinistre
Travailler avec les √©quipes de source de donn√©es et de consommation de donn√©es pour s'aligner sur les structures et les sch√©mas de donn√©es
Comp√©tences
Familiarit√© avec les technologies modernes bas√©es sur le cloud (data lakes, data warehouses, ETL/ELT, Spark)
Exp√©rience de la mise en ≈ìuvre de pipelines d'ingestion de donn√©es / ETLs / ELTs
Connaissance g√©n√©rale d'Azure ou d'une plate-forme et d'un √©cosyst√®me comparables ‚Äì Storage Account, CosmosDB (SQL & Gremlin API), Event Hub, App Services
Exp√©rience avec au moins 3 des technologies de donn√©es Azure suivantes ou des technologies Cloud similaires:
Azure SQL
Azure Data Lake
Azure Databricks (SQL ou Python, Delta Lake)
Azure Data Factory
Azure Analysis Services
Exp√©rience avec SQL, Python
et
Baccalaur√©at ou dipl√¥me sup√©rieur en informatique, en ing√©nierie commerciale, en informatique ou dans une discipline technique connexe
1-3 ans d'exp√©rience sur le terrain dans un r√¥le similaire
Ma√Ætrise du fran√ßais et de l'anglais
Personnalit√©
Concentr√© sur l'avancement du client avec des livrables de qualit√© dont vous pouvez √©galement √™tre fier
Attention aux d√©tails et aux objectifs
Aimer faire partie d'une √©quipe DXC et client
D√©montrer l'appropriation
Un √©tat d'esprit positif
Ce Que Vous Obtiendrez
Un paquet salarial motivant, comprenant des avantages sociaux, des horaires de travail flexibles et la possibilit√© de travailler √† domicile
Faire partie d'une √©quipe ambitieuse et en pleine croissance
Formation en cours d'emploi et acc√®s √† notre plateforme en ligne ‚ÄúDXC-University‚Äù
L'opportunit√© de travailler avec les derni√®res technologies pour un large √©ventail de clients
Recruitment fraud is a scheme in which fictitious job opportunities are offered to job seekers typically through online services, such as false websites, or through unsolicited emails claiming to be from the company. These emails may request recipients to provide personal information or to make payments as part of their illegitimate recruiting process. DXC does not make offers of employment via social media networks and DXC never asks for any money or payments from applicants at any point in the recruitment process, nor ask a job seeker to purchase IT or other equipment on our behalf. More information on employment scams is available here
.
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer (F/H),Groupe SII,"Montpellier, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-groupe-sii-3906253305?position=8&pageNum=45&refId=helkV5fb1RK2O%2B2D3vOHXQ%3D%3D&trackingId=WCihcTF8zDatDHW40GOocw%3D%3D&trk=public_jobs_jserp-result_search-card,"SII Montpellier
accompagne ses clients dans l‚Äôint√©gration des nouvelles technologies, proc√©d√©s et m√©thodes de management de l‚Äôinnovation pour contribuer au d√©veloppement de leurs futurs produits ou services et faire √©voluer leurs syst√®mes d‚Äôinformation. Nous conjuguons de mani√®re durable et vertueuse la satisfaction de nos clients avec le bien-√™tre et l‚Äô√©panouissement de nos collaborateurs tout en d√©livrant un haut niveau de performance.
Au travers de notre entit√© compos√©e d‚Äôune quarantaine de consultants et de leurs expertises li√©es au d√©veloppement applicatif, √† la gestion de projets et d‚Äôinfrastructures, au test et aux enjeux autour de la data et cyber s√©curit√©. Nous intervenons aujourd‚Äôhui sur des projets √† forte valeur ajout√©e, ambitieux et √† l‚Äôinternational autour des secteurs du num√©rique, du t√©l√©com, de la banque/assurance, de l‚Äôindustrie et des services en assistance technique et/ou en engagement (centre de services, centre de comp√©tences, ...). Nous accompagnons de nombreux acteurs locaux (Montpellier et agglom√©ration) vous permettant de trouver plusieurs opportunit√©s proches de chez vous ou depuis chez vous (flexibilit√© / mode de fonctionnement hybride).
Vous rejoindrez une √©quipe soud√©e, talentueuse et engag√©e qui priorise le bien-√™tre au travail, l‚Äôhumilit√© et le partage. Vos comp√©tences techniques et votre savoir-√™tre seront mis en valeur au sein de missions sur des sujets vari√©s allant de la conception et d√©veloppement d‚Äôapplications web, mobile, IHM √† la gestion d‚Äôinfrastructure traditionnelle et Cloud en passant par la gestion de projets agiles.
Rencontrons-nous et valorisons ensemble nos savoir-faire.
Dans le but de r√©pondre aux demandes de nos partenaires, nous ouvrons un poste en qualit√© de
Data Engineer
(F/H), sur
Montpellier
(34).
Vos Missions
Collecter et stocker les donn√©es
Comprendre les besoins des utilisateurs
D√©terminer la coh√©rence des donn√©es
Impl√©menter des outils de pointe pour faciliter l‚Äôusage des donn√©es dans l‚Äôentreprise et am√©liorer l‚Äôefficacit√© op√©rationnelle.
Dipl√¥m√©(e) d'un Master en Informatique, d'une √©cole d'Ing√©nieur ou √©quivalent, vous disposez d'une exp√©rience de
minimum 5 ans
sur des comp√©tences similaires en DATA. Vos comp√©tences techniques sur SSAS, SSIS, SSRS seront un vrai plus !
La rigueur, la patience et la curiosit√© sont vos points forts. Vous disposez d'un important esprit d‚Äô√©quipe et faites preuve de bienveillance au quotidien.
Le Groupe SII est une soci√©t√© d‚Äôing√©nierie et de conseils en technologies (ICT) et une entreprise de services num√©riques (ESN).
Nous sommes au c≈ìur de l'innovation au service de grands comptes dans des secteurs d'ing√©nierie vari√©s.
En 2023, pour la
6e ann√©e cons√©cutive
, SII France a obtenu le label
Great Place To Work
¬Æ.
Nous avons √©t√© reconnus
3e entreprise de ¬´ + de 2500 salari√©s ¬ª
o√π il fait bon vivre.
Nous sommes tr√®s fiers d‚Äôobtenir cette reconnaissance de nos salari√©s !
Ce succ√®s est le reflet de notre culture bas√©e sur notre volont√© de proposer √† tous nos salari√©s un cadre de travail √©panouissant pour le d√©veloppement de leurs comp√©tences et carri√®res.
En fonction de la mission, il est possible de r√©aliser jusqu'√†
50 % de t√©l√©travail
gr√¢ce √† notre accord d√©di√©. Rejoignez le
mouvement #fungenieur
dans lequel la passion pour la technologie, la cr√©ativit√©, la proximit√© et l‚Äôesprit d‚Äô√©quipe sont mis √† l‚Äôhonneur.
Le Groupe SII est une soci√©t√© handi-accueillante, signataire de la Charte de la diversit√© en entreprise.
Alors si ces valeurs vous parlent, rejoignez-nous !
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Cr√©ativit√©', 'Flexibilit√©'], 'EnSoftSkils': []}","{'JobDetail': ['Hybride'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Senior Data Engineer,Harnham,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-at-harnham-3903984738?position=9&pageNum=45&refId=helkV5fb1RK2O%2B2D3vOHXQ%3D%3D&trackingId=7ERt5GvD3YB7YI%2FhPxHcXQ%3D%3D&trk=public_jobs_jserp-result_search-card,"SENIOR DATA ENGINEER
PARIS (75)
75-80K EUR
Cette entreprise sp√©cialis√©e dans le marketing et la publicit√© mobile recherche activement un(e) Senior Data Engineer. Le Machine Learning constitue le c≈ìur de son expertise, avec des solutions technologiques novatrices visant √† am√©liorer la performance publicitaire sur smartphones et tablettes.
VOTRE MISSION :
Assurer le bon fonctionnement de l‚Äôinfrastructure de donn√©es.
Superviser le traitement, le stockage, et l‚Äôagr√©gation des donn√©es.
Proposer de nouvelles id√©es pour am√©liorer les outils et les flux de travail.
G√©rer les algorithmes de data science.
Collaborer √©troitement avec l‚Äô√©quipe SCRUM.
Rationaliser les processus de donn√©es pour une efficacit√© maximale.
VOTRE PROFIL :
Diplome d‚Äôune √©cole d‚Äôing√©nieur / Master
Au moins 4 ans d‚Äôexp√©rience (minimum hors stage et alternance)
Comp√©tences solides en Spark, Scala, Kafka et Python (obligatoire)
Miatrise de la gestion des syst√®mes Big Data.
Connaissance d‚ÄôAWS ou GCP
Anglais: Fluent obligatoire
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Data Analyst H/F,GECO RECRUTEMENT,"Pontivy, Brittany, France",https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-geco-recrutement-3915127710?position=10&pageNum=45&refId=helkV5fb1RK2O%2B2D3vOHXQ%3D%3D&trackingId=oZ0%2FOs6rk3MLsRzAQbCLcQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Geco est un cabinet de recrutement ind√©pendant.
Nous intervenons aupr√®s des cabinets et des entreprises dans la recherche de profils cibl√©s.
Nous accompagnons les candidats dans leurs recherches d'emploi et s'assurons que leurs souhaits professionnels se r√©alisent.
En lien permanent avec l'entreprise et le candidat tout au long du processus de recrutement, l'√©coute et la disponibilit√© vont guider nos interventions afin de r√©pondre au mieux √† l'int√©r√™t des deux parties.
Nous recherchons actuellement un Data Analyst H/F pour rejoindre une √©quipe dynamique au sein d'une industrie en pleine croissance situ√©e √† proximit√© de Pontivy.
En Tant Que Data Analyst, Vous Serez Responsable De L'analyse Des Donn√©es Afin D'optimiser Les Processus Et De Fournir Des Informations Cl√©s √† L'entreprise. Vos Principales Missions Seront Les Suivantes
Collecter, nettoyer et organiser les donn√©es provenant de sources diverses
Analyser les donn√©es pour identifier des tendances, des corr√©lations et des insights
Cr√©er des tableaux de bord et des rapports pour pr√©senter les r√©sultats de mani√®re claire et compr√©hensible
Collaborer avec les diff√©rents d√©partements de l'entreprise pour r√©pondre √† leurs besoins en termes d'analyse de donn√©es
Participer √† l'am√©lioration des outils et des processus li√©s √† l'analyse de donn√©es
Veiller √† la s√©curit√© et √† la confidentialit√© des donn√©es
Issu(e) d'une formation Bac +3, vous justifiez d'une exp√©rience sur des fonctions similaires d'au moins 1 an.
Vous avez une expertise dans l'utilisation, l'administration et le d√©veloppement de QlikView / QlikSense ainsi que de Power BI.
Possibilit√© de t√©l√©travail 2 jours par semaine.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Ing√©nieur Data SPARK/SCALA (H/F),DHM IT,"Neuilly-sur-Seine, √éle-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-spark-scala-h-f-at-dhm-it-3664561715?position=1&pageNum=47&refId=ulU0mGztWnF4llUcE%2BYHkw%3D%3D&trackingId=MDVOaMAeHhMiqmI8Ki21tA%3D%3D&trk=public_jobs_jserp-result_search-card,"Dans le cadre de notre croissance et Afin de renforcer notre Squad Data, nous recherchons plusieurs Ing√©nieurs Data Spark/Scala
Int√©gr√©.e au sein de nos √©quipes bas√©es √† Neuilly Sur Seine et/ou la r√©gion parisienne, vous pourrez mettre en pratique vos acquis et d√©velopper de nouvelles comp√©tences techniques.
MISSIONS:
Au sein de l'√©quipe projet Business Intelligence & Big Data, l'ing√©nieur SPARK/SCALA aura les activit√©s suivantes :
Conception d√©taill√©e, fonctionnelle et technique.
D√©veloppements SPARK / SCALA
Contribution √† la formalisation des plans de tests, ex√©cution des tests unitaires et d'un premier niveau de tests d'int√©gration.
R√©solution des anomalies pendant les phases d‚Äôint√©gration fonctionnelle et de recette utilisateur.
Packaging et d√©ploiement en pre-production et production.
Optimisation des traitements afin de garantir la qualit√© de service standards du DWG.
Mise en ≈ìuvre des solutions industrielles et de r√©entrance permettant une reprise optimum des traitements en cas d‚Äôincident en production.
Mise en service et accompagnement au d√©ploiement.
Suivi des environnements.
PROFIL:
Une connaissance d'Oracle est n√©cessaire
Une exp√©rience >5 ans sur des technologies SPARK & SCALA est n√©cessaire
Une connaissance de contexte technologique similaire est un plus
SOFT SKILLS:
Passionn√©.e par les technologies innovantes;
D√©sireux.se de t‚Äôinvestir dans des projets challengeants et gagner rapidement en responsabilit√©s;
P√©dagogue, emphatique et ""Problem Solver"";
Dot√©.e d‚Äôun excellent relationnel, d‚Äôun sens prononc√© du service et de la qualit√©;
Excellent niveau de Fran√ßais √† l'oral et √† l'√©crit, l'Anglais serait un v√©ritable plus.
AVANTAGE / CONTEXTE :
Entreprise de nouvelle g√©n√©ration √† taille humaine, DHM IT s‚Äôengage fortement dans la mouvance RSE en proposant √† ses consultants et salari√©s un cadre de travail sain o√π chacun pourra s‚Äô√©panouir, se former et progresser √† son rythme et selon ses aspirations.
R√©mun√©ration attractive;
Un fort esprit Startup nouvelle g√©n√©ration;
Participation dans notre strat√©gie RSE;
Formation, certification, Workshop, DHM University;
Carte resto, Titre de transport, Mutuelle et pr√©voyance;
Team buildings, Events, Sport Collectif;
Travail remote friendly;
Un environnement de travail 100% Agile / Cloud;
Des challenges, des nouvelles exp√©riences et des projets innovants;
Une‚ÄØhi√©rarchie‚ÄØSmart.
Show more
Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Pricing Data Engineer,Luko,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/pricing-data-engineer-at-luko-3914821636?position=2&pageNum=47&refId=ulU0mGztWnF4llUcE%2BYHkw%3D%3D&trackingId=00Usttp0bRUbWMGJLkCsxw%3D%3D&trk=public_jobs_jserp-result_search-card,"Your mission in the team:
Luko x Allianz Direct has a mission to create insurance products which meet each user needs, transparent and quickly available, with a fair price.
As a Pricing Data Engineer, your job is build & transform the data and develop the tooling required for pricing analysis, strategies, and operations.
You will work closely with the Pricing team as well as with the Product team.
Your main missions will be:
Create and refine our pricing data infrastructure, laying the groundwork for continually improving analytics capabilities and helping create the best data models for modern insurance pricing
Develop and maintain our pricing monitoring and testing tools, including automating processes and integrating interfaces with product teams to enhance testing efficiency and streamline rollout productivity
Implement live reporting mechanisms to effectively communicate pricing monitoring results, while actively contributing to steering the company towards its profitability objectives through data-driven insights and strategic pricing adjustments
Design and implement scalable data models and control structures to encompass all products and channels, ensuring seamless integration and adaptability across the entire spectrum of our operations
Participate on developments related to the pricing engine
Your profile:
üìç Role based in Paris
To excel in this role, we recommend the following qualifications and attributes:
Professional Experience: 2 to 5 years of experience as a Data Engineer or Analyst.
Education: A Master's degree in Data Science, Statistics, or Computer Science is preferred but not mandatory.
Specialization: Prior experience in Data & Analytics is highly desirable.
Analytical Skills: Exceptional analytical and synthesis abilities.
Technical Proficiencies:
Proficient in data processing platforms, specifically DBT.
Strong programming skills in Jinja and SQL.
Familiarity with version control systems, particularly GitLab.
Languages: Proficiency in English is required; French proficiency would be an asset.
Personal Attributes: Must be a collaborative team player, detail-oriented, and well-organized. Should also demonstrate proactivity and the ability to work independently.
What is in it for you?
This is an opportunity to join a company in the process of scaling up, a team on a human scale and to work with Allianz Direct's European subsidiaries to exchange best practices and deal with cross-functional issues, and why not benefit from group mobility in Europe?
International and friendly team & Office in Paris
Group mobility in Europe
Meal vouchers
Health Insurance
Remote-friendly policy
Free book policy
Our recruitment process:
First interview/ Introduction call with your future manager Alexis (Lead Pricing Manager)
Case study + debrief with Alexis and Julien (Chief Actuary)
Technical interview with Gautier (Backend Developer)
Lukofit interview with a member of the People team
Allianz Direct France x Luko, Who are we?
We created Luko with a simple vision.
50% of consumers don‚Äôt trust their insurer, yet it is mandatory in many cases and it is the
only stakeholder you can turn to when damage occurs in your home. So we decided to
reinvent insurance to make it finally customer-centric like we believe it was meant to be.
We started by creating the most transparent and useful insurance company out there:
one that you can finally trust, because its business model was designed for positive impact and because its product experience is meant to empower users rather than mislead them.
We created the most intuitive and user-obsessed insurance experience you can wish
for:
subscription in 2 minutes, a simple offer, customisable coverages, no hidden fees, policies without any engagement, termination in 3 clicks.
In 6 years, we have convinced over 400,000 users to trust us. We rapidly became the online home insurance market, putting technology at the service of customer satisfaction and operational efficiency: by 2022, 25% of home insurance policies sold online in France were Luko policies; and nearly one in two new Luko customers took out a policy on the
recommendation of friends and family.
In February 2024, Luko joins Allianz Direct, the digital pan-European subsidiary of the
Allianz Group, with the aim of becoming the market leader in direct home insurance in
France. This makes Luko emerging the strongest neo-insurer.
Together, and because Luko and Allianz Direct share a common vision and DNA, we will continue our mission to shake up the market by offering the best value for money and even more simplicity and transparency.
Allianz Direct DNA
Becoming part of the Allianz Direct organisation means that you have a match with our DNA. We have the following 6 core values:
Customer obsessed
Communicative
Data-driven
Agility
Team player
Open-minded
You‚Äôve read all the way, you may as well apply!
Our company-wide communication language is English (written & spoken).
We would therefore appreciate it if you could send us your application‚Äôs content (CV, cover letter, portfolio‚Ä¶) in English.
Belonging: Diversity, Inclusion & Equity
We believe inclusion is the result of ongoing commitment. We want to build an authentic environment, open to everyone regardless of nationality, physical ability, family structure, age, socio-economics, civil status, sexual orientation, gender identity, ethnic origin, religion, belief or anything else that makes your life experience unique. We are continuously working to create a diverse, equitable and inclusive environment, where everyone has a space to thrive.
Show more
Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistics'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['ML'], 'FrSoftSkills': ['Communication', 'Organisation'], 'EnSoftSkils': ['Communication', 'Adaptability']}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
CDI - Ing√©nieur Data (H/F),Herm√®s,"Pantin, √éle-de-France, France",https://fr.linkedin.com/jobs/view/cdi-ing%C3%A9nieur-data-h-f-at-herm%C3%A8s-3850308968?position=3&pageNum=47&refId=ulU0mGztWnF4llUcE%2BYHkw%3D%3D&trackingId=aDeaStLnXo4DASVbz%2FiWIA%3D%3D&trk=public_jobs_jserp-result_search-card,"Contexte
Au sein de la DSI Groupe de la Maison Herm√®s, la Direction des Infrastructures et des Op√©rations fournit et supporte l‚Äôensemble des services d‚Äôinfrastructure avec les niveaux d‚Äôexpertise requis. Elle construit et s√©curise le fonctionnement des plates-formes applicatives afin de fournir une infrastructure technologique stable et efficace pour les clients internes au niveau du groupe et en local.
Activit√©s principales
En tant qu'Ing√©nieur Data (H/F), vous √™tes responsable d‚Äôun ou plusieurs services technologiques sur les plateformes DATA (BDD, Data Lake, Data Streaming).
Ce domaine d√©signe l‚Äôensemble des services visant √† assurer la collecte, le stockage, la valorisation et la mise √† disposition des donn√©es. Le p√©rim√®tre Data int√®gre notamment la gestion des bases de donn√©es (relationnelles et non relationnelles), solutions de donn√©es non structur√©es (Data cloud), flux temps r√©el (Data Streaming) ainsi que les outils de r√©plication et de synchronisation.
Vos principales responsabilit√©s sont de :
Assurer le Build et le Run des services de votre p√©rim√®tre
D√©finir le planning de d√©veloppement, les exigences et les pr√©requis au d√©ploiement des services de votre p√©rim√®tre
√ätre responsable du d√©veloppement global et du packaging d'un service
Construire et g√©rer les socles et les services technologiques de votre p√©rim√®tre et en d√©finir la strat√©gie d‚Äô√©volution en collaboration avec l‚Äô√©quipe Architecture & Innovation
Piloter et monitorer la performance et la disponibilit√© des socles et services
Assurer la gestion sur l‚Äôensemble du cycle de vie de vos socles et services (√©volution, licences, maintenance, d√©commissionnement, etc.), g√©rer leur obsolescence et r√©duire la dette technique.
Fournir un support technique N2/N3 sur votre p√©rim√®tre
Profil souhait√©
Dipl√¥m√©(e) d'un Bac + 5, vous disposez d'au moins 5 ans d'exp√©rience dans la construction, l'int√©gration, le d√©ploiement d'infrastructure syst√®me/r√©seau dans des environnements Cloud et hybrides.
Vous maitrisez les technologies de bases de donn√©es relationnelles (MSSQL, Oracle, PostGreSQL) et non relationnelles (MongoDB). Vous poss√©dez de solides comp√©tences dans le d√©veloppement et la mise en place de pipeline de donn√©es, notamment le Data Streaming. Les technologies de plateformes Data Modernes, Cloud et On Premise, n'ont plus de secrets pour vous.
Orient√©(e) client et esprit d'√©quipe, vous √™tes capables de traduire et analyser les exigences business en exigences techniques en gardant un discours impactant. Vous savez appr√©hender et g√©rer les risques et recherchez √† monter rapidement en comp√©tences sur de nouvelles technologies et proc√©dures.
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['PostgreSQL', 'Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Hybride'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Analyst Junior,Unlimitail,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-junior-at-unlimitail-3912999630?position=4&pageNum=47&refId=ulU0mGztWnF4llUcE%2BYHkw%3D%3D&trackingId=DFtU9h6mBh4XTShonIKYVQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Unlimitail
is a joint venture between
Carrefour
Group and
Publicis
Group, intending to become the leader of the
retail media market in Europe and Latin America
. It combines the power of Carrefour Links' in-store and e-commerce assets and traffic with Publicis
Citrus Ad and Epsilon's
on-site and off-site retail media technologies. The goal of Unlimitail is to become the premier retail media player in Continental Europe and South America for both in-store and digital channels.
Missions
Within the Product team, your mission will be to participate in the development of Unlimitail‚Äôs analytics capabilities. Your environment will be millions of transactional data coming from major retailers on the market to analyze and improve the performance of online and offline marketing campaigns.
As we work with both retailers (providing media inventory) and brands (buying media inventory), you will have the opportunity to gain a deep understanding of the retail media ecosystem.
You will work with different teams (Ad Operations, Marketing, Sales) in different countries and on a wide variety of topics:
- Perform e-commerce campaigns analysis to provide detailed insights
- Conduct end-to-end ad hoc analysis to help retailers best monetize their inventory
- Participate in the design and maintenance of databases, using SQL to store and manage data efficiently
- Work on automating data analysis and data visualization capabilities
- Work on Unlimitail‚Äôs customer lifetime value calculation capability
- Participate in the development of new, cutting-edge abilities to create the best
Requirements
:
¬∑ Master's degree in Data Analysis, business analytics, Computer Science, Statistics, Mathematics, Engineering, or a related field.
¬∑ Data Analysis: Proven ability to analyze large datasets, identify trends, and extract actionable insights through using strong SQL skills for querying and data extraction.
¬∑ Programming Languages: Python and SQL are mandatory. Any other is a plus
¬∑ Data Visualization: previous experience in creating interactive and insightful visualizations, using tools like Power BI or Looker is a big plus
¬∑ Knowledge of GCP or Azure environment is a plus
¬∑ Problem-solving: Adept at approaching analytical problems and proposing effective solutions.
¬∑ Good communication skills in English. Another language (Spanish, Portuguese) is a plus.
¬∑ Strong team player with the ability to collaborate effectively
Benefits
:
¬∑ 2 days of WFH
¬∑ 90% reimbursement of public transportation fees
¬∑ Office located in central Paris (Chatelet)
¬∑ Swile card of 10‚Ç¨/working days
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': ['Statistics'], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': [], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Consultant Data Engineer / Data Management F/H,VISEO,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/consultant-data-engineer-data-management-f-h-at-viseo-3111089632?position=5&pageNum=47&refId=ulU0mGztWnF4llUcE%2BYHkw%3D%3D&trackingId=t3x0qD06L2z9%2FHONHHn2cA%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous avez une forte app√©tence pour
l'int√©gration de donn√©e et le d√©veloppement
?
Vous souhaitez travailler sur des technologies du
Cloud et des solutions innovantes
?
Vous¬†√™tes adepte¬†de la
veille¬†technologique
?
Au sein de¬†VISEO¬†nous recherchons un
Consultant Data Engineer / Data Management¬†F/H
pour intervenir¬†sur¬†nos projets et contribuer au d√©veloppement de notre Practice ¬´ Data Management ¬ª
VISEO¬†organise¬†et sponsorise¬†de¬†nombreux¬†√©v√©nements techniques¬†en interne et en externe¬†:¬†MixIT, Webinar,¬†TechAnHour,¬†Snowcamp...¬†Participer √† ces √©v√®nements sont pour nous un moyen¬†d‚Äôanimer la communaut√© et¬†de¬†conserver¬†un haut niveau d‚Äôexpertise.
Vos missions :
Analyser
et
comprendre
les besoins des utilisateurs en termes de
collecte
,
stockage
,
valorisation de la donn√©e
Proposer une architecture adapt√©e
(On Premise, Cloud, hybrides, etc.)
Concevoir les mod√®les de donn√©es
et
les processus
(data flows, Workflows, etc.)
Mettre en ≈ìuvre
la plateforme de
Data Management
et les
d√©veloppements n√©cessaire pour l‚Äôint√©gration
(ETL),
la valorisation
(Data Quality),
l‚Äôadministration
(Data Governance),
la distribution
(Data Hub) et
le stockage de la donn√©e
Tester¬†l‚Äôarchitecture et
les d√©veloppements
.
V√©rifier
la coh√©rence
fonctionnelle
des donn√©es en collaboration avec les
r√©f√©rents m√©tiers
D√©ployer¬†la solution
en environnement de recette utilisateurs et √©ventuellement, en environnement de
production
Dans le cadre de projets
Data
, vous accompagnerez nos¬†clients autour de la
mise en place de¬†solutions
qui auront pour
objectif la valorisation des donn√©es
comme
capital strat√©gique
de l‚Äôentreprise.
Pour cela vous serez amen√©(e) √† utiliser les
plateformes de Data Management modernes
de nos
partenaires
tel que
Microsoft, Alteryx, Informatica, Talend, SAP, Microsoft Azure, Boomi, etc.
Ces activit√©s pourront √™tre men√©es dans des modes de
collaboration diff√©rents
(forfait, r√©gie, mode Agile, m√©thodologie sp√©cifique‚Ä¶).
Votre profil :
Vous poss√©dez une¬†exp√©rience sur tout ou partie des activit√©s d√©crites pr√©c√©demment, en particulier sur les
phases de¬†conception et de d√©veloppement¬†de projets Data
.
Une exp√©rience acquise autour
d‚Äôactions concr√®tes d‚Äôoptimisation
(technique ou fonctionnelle) serait un plus.
Vous ma√Ætrisez tout ou partie d‚Äôune ou plusieurs
des solutions ETL classiques
(Informatica Power Center, Talend Studio, Microsoft SSIS, Alteryx, etc.)
et\ou IPaaS
(Azure Data Factory, Informatica IICS, Talend Cloud, Boomi, etc‚Ä¶)
Vous ma√Ætrisez tout ou partie d‚Äôune ou plusieurs solutions de
stockages de donn√©es
(Snowflake, Redshift, PostgreSQL, Oracle, etc.)
L‚Äôutilisation
d‚Äôoutils de reporting / data visualisation
(Tableau, Power BI, QlikSence...)¬†est √©galement appr√©ciable.
Vous
appr√©ciez la relation client
(interlocuteur technique, contact utilisateur‚Ä¶) et poss√©dez un v√©ritable
sens du service
avec cette double comp√©tence technico-fonctionnelle.
Vous √™tes
rigoureux(se), dynamique et dot√©(e) d‚Äôune curiosit√©, d‚Äôune agilit√© et d‚Äôun esprit d‚Äô√©quipe
vous permettant de vous adapter √† diff√©rents contextes.
Int√©grer nos √©quipes au quotidien, √ßa veut dire quoi ?
Vous ferez partie de¬†la
communaut√©¬†Data
: la proximit√© et la taille humaine de notre organisation vous permettront de rendre visible vos initiatives et d‚Äô√©voquer facilement vos projets. En parall√®le, le dynamisme de l‚Äôentreprise et sa croissance perp√©tuelle multiplieront vos opportunit√©s d‚Äô√©volution.
Vous b√©n√©ficierez d‚Äôun¬†management de proximit√©¬†par votre mentor tout au long de votre parcours chez VISEO : Votre mentor, consultant exp√©riment√© de votre practice, viendra r√©guli√®rement √©changer avec vous sur les challenges de votre mission, faire chaque semestre le bilan de vos r√©alisations et √©voquer vos ambitions futures et les moyens de les r√©aliser.
Vous disposerez
de multiples moyens pour¬†monter en comp√©tences¬†et d√©couvrir de nouveaux domaines¬†: formations, certifications, Brown Bag Lunchs, ateliers,¬†meet-ups, rencontre d‚Äôexperts, s√©minaires techniques‚Ä¶
#VISEO SPIRIT :
Un programme d‚Äôapprentissage en e-learning : acc√®s digital¬†academy¬†et 7-speaking
Un accompagnement pour le bien-√™tre‚ÄØ: Sophrologie, Yoga,¬†Gymlib,¬†IKV√©lo¬†‚Ä¶
Deux jours de t√©l√©travail par semaine
Du mat√©riel informatique puissant et un double √©cran
Des locaux agr√©ables¬†proches du parc de la Cit√© de l'Espace
N‚Äôattendez plus, rejoignez VISEO. Devenez un #PositiveDigitalMaker !
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['PostgreSQL', 'Oracle', 'Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Cloud'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration', 'Initiative']}","{'JobDetail': ['Hybride'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer & Architect 100% T√©l√©travail avec Quelques D√©placements √† Lyon H/F,Proxiel,"Montpellier, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-architect-100%25-t%C3%A9l%C3%A9travail-avec-quelques-d%C3%A9placements-%C3%A0-lyon-h-f-at-proxiel-3913995274?position=6&pageNum=47&refId=ulU0mGztWnF4llUcE%2BYHkw%3D%3D&trackingId=LrBkKjeQvUt5UD52y8KOhQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Depuis 1999, PROXIEL accompagne des entreprises dans leur d√©veloppement en assurant des prestations de conseil et d'ing√©nierie dans le domaine des technologies.
Proxiel : C'est plusieurs p√¥les d'activit√©s.
Nous mettons un point d honneur √† associer votre bien-√™tre - adaptabilit√© en fonction de vos contraintes (possibilit√© de t√©l√©travail). Des solutions alternatives, peuvent √™tre envisag√©es, dans la mesure o√π elles sont compatibles avec le business que nous entreprenons. Nous souhaitons que chacun de nos salari√©s s investissent dans nos projets et que notre entreprise soit anim√©e par un projet commun : la r√©ussite de chacun !
Notre approche est simple alors restons transparents dans nos √©changes.
Notre si√®ge est implant√© √† Montpellier PROXIEL. Nous disposons √©galement d une agence sur Paris
Vous pr√©sentez des comp√©tences dans les nouvelles technologies en qualit√© de techniciens d√©veloppeurs ing√©nieurs, cot√© d√©veloppement ou r√©seau, vous √™tes bas√©s ou mobile sur MONTPELLIER PARIS LYON TOULOUSE MARSEILLE AIX EN PROVENCE, NICE rejoignez-nous !
Bonjour,
Nous recherchons pour notre partenaire un Data Engineer & Architect (100% t√©l√©travail) avec quelque d√©placement √† Lyon :
Vous √™tes en charge de la conception et de la construction de pipelines de donn√©es √©volutifs permettant de r√©cup√©rer, d'agr√©ger et de pr√©traiter efficacement les donn√©es provenant de diff√©rentes sources, tout en garantissant une fiabilit√© et des performances √©lev√©es.
Vous √™tes en charge de la conception des mod√®les de donn√©es, des solutions de stockage et des sch√©mas d'acc√®s.
Vous avez la possibilit√© de collaborer avec les parties prenantes pour comprendre les besoins et pour d√©finir et faire √©voluer la strat√©gie d'architecture des donn√©es, y compris la mod√©lisation des donn√©es, le stockage et les sch√©mas d'acc√®s.
Vous travaillez avec une √©quipe agile interfonctionnelle pour int√©grer des donn√©es provenant de divers syst√®mes et sources, effectuer des processus d'extraction, de transformation et de chargement (ETL) et maintenir l'int√©grit√© des donn√©es tout au long du pipeline, en it√©rant sur les solutions et en communiquant sur les progr√®s r√©alis√©s.
Ma√Ætrise des langages de programmation
Une solide compr√©hension des technologies de base de donn√©es (par exemple, SQL, NoSQL), des entrep√¥t de donn√©es et d'Azure
Exp√©rience en architecture de donn√©es la conception de mod√®les de donn√©es, la d√©finition de solutions de stockage et les sch√©mas d'acc√®s aux donn√©es.
Familiarit√© avec le Machine learning, les concepts de traitement du langage naturel (NLP) et la G√©n√©ration Augment√©e de R√©cup√©ration (RAG) est un plus.
Vous avez d'excellentes comp√©tences en mati√®re de communication et de collaboration, et √™tes capable de travailler efficacement dans un environnement d'√©quipe et dans le cadre de projets agiles.
Bac +5 ou √©quivalent
minimum : 3 ans d'exp√©rience
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Communication', 'Adaptabilit√©', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
ALTERNANCE - DATA Engineer (F/H) - LILLE,BPCE Solutions informatiques,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/alternance-data-engineer-f-h-lille-at-bpce-solutions-informatiques-3913916322?position=7&pageNum=47&refId=ulU0mGztWnF4llUcE%2BYHkw%3D%3D&trackingId=FY8M2DqNOomcT8cTtN9c0g%3D%3D&trk=public_jobs_jserp-result_search-card,"Description de l'entreprise
BPCE Solutions informatiques, c‚Äôest un acteur IT de r√©f√©rence implant√© au c≈ìur des territoires. Ce sont pr√®s de 2 600 femmes et hommes au service des Banques Populaires, des Caisses d‚ÄôEpargne et de plusieurs m√©tiers sp√©cialis√©s du Groupe BPCE, 2e acteur bancaire en France.
Nous imaginons et d√©veloppons des solutions IT innovantes pour faciliter le quotidien de nos utilisateurs. Chaque jour, ce sont pr√®s de 1 Fran√ßais sur 2 qui utilisent nos solutions !
Entreprise inclusive et engag√©e, ce sont vos comp√©tences qui font la diff√©rence.
Le t√©l√©travail et les horaires flexibles vous permettent de pr√©server votre √©quilibre de vie. Et en pr√©sentiel, vous b√©n√©ficiez d‚Äôun environnement innovant et responsable.
Notre vision de l‚Äôalternance ? üöÄ
Vous √™tes accompagn√©(e) et encourag√©(e) par une √©quipe bienveillante
Vous travaillez sur des projets d‚Äôenvergure au service de nos clients
Vous apprenez du savoir-faire de personnes passionn√©es par leur m√©tier
Vous d√©ployez votre potentiel et consolidez votre projet professionnel
Alors, rejoignez-nous pour profiter de la diversit√© du terrain de jeu que propose BPCE Solutions informatiques !
‚ö°
Poste et missions
Int√©grez la Plateforme Distribution et Data au sein de BPCE Solutions informatiques !
Au sein de
l'√©quipe Produit DATA ""Socle D√©cisionnel MYSYS""
de BPCE-SI, sous la direction du Scrum Master d'une des squads du produit, nous recherchons notre alternant(e).
Le patrimoine technologique du produit est Oracle, AIX/Linux/Windows, VTOM, PowerBI/Business Object, semarchy, Angular, JSP, Java, python, shells, VBA, Power Designer.
Gestion en mode Agile (Scrum/Kanban)
En tant que
DATA Engineer
(F/H) en alternance, vous aurez pour missions :
Prendre en charge des induits projet pour alimenter des entrep√¥ts de pilotage DATA du SI MYSYS des Caisses d'Epargne avec l'ETL Semarchy. Vous assurez l'int√©gration de donn√©es, qui seront exploit√©es par les √©tablissements bancaires. Vous mettrez en place les flux pour r√©pondre au besoin des etablissements.
Il sera demand√© √©galement de compl√©ter des informations fonctionnelles concernant le patrimoine des tables du produit.
Lors De Votre Alternance, Vous Vous Formerez Aux Techniques D'alimentation De La Squad Bas√©es Sur L'√©cosyst√®me Suivant
ELT SEMARCHY
SGBD Oracle/Exadata
Ordonnanceur VTOM
Syst√®me AIX/Linux
Profil et comp√©tences requises
Vous recherchez une alternance dans le cadre de vos √©tudes sup√©rieures en informatique de niveau
Bac+3 √† Bac+5
.
Vous avez envie d‚Äôapprendre et d‚Äôint√©grer une entreprise dynamique et agile qui vous permettra d‚Äôacqu√©rir un r√©seau et une premi√®re exp√©rience solide.
Vous avez √† c≈ìur d'accompagner vos clients dans des projets d'envergure.
Vous √™tes rigoureux(se) avec une bonne capacit√© d'analyse et de synth√®se.
Vous avez un bon relationnel et un esprit positif, vous √™tes curieux(se) et vous appr√©ciez travailler en √©quipe.
Comp√©tences Et Connaissances Techniques
Exig√© :
Connaissance du SQL
compr√©hension du fonctionnel
Souhait√©
principes architecturaux DATA.
Connaissance d'un Syst√®me d'exploitation ""Unix-like""
Informations Compl√©mentaires
Date de d√©marrage souhait√©e :
Rentr√©e 2024
Rythme d'alternance souhait√© :
Semaines compl√®tes
Dur√©e de l'alternance souhait√©e :
1 an ou 2 ans
Notre processus de recrutement se compose de deux entretiens : un entretien RH avec Dana, puis un entretien op√©rationnel avec Martial et Paul-Aziz.
Informations compl√©mentaires sur le poste
ü§ùBPCE SI, c'est un cadre de travail agr√©able avec un accompagnement de proximit√©, des formations, de multiples √©volutions possibles au sein du groupe.
üöâ 80% de prise en charge des frais de transports en commun !
‚òÄÔ∏è Environ 9 semaines de cong√©s annuels (cong√©s et RTT).
üíª T√©l√©travail hybride ! 30 jours de t√©l√©travail par trimestre et flexibilit√© des horaires.
üé≥ Un CSE actif ! Des locaux attractifs et des comit√©s d'animations par site.
üéñ Entreprise Partenaire premium des JO2024 et engag√©e sportivement !
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux', 'Windows'], 'DBMS': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Flexibilit√©'], 'EnSoftSkils': []}","{'JobDetail': ['Hybride'], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5', 'Bac+3'], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Data Analyst F/H,SOFTEAM,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-f-h-at-softeam-3587086987?position=8&pageNum=47&refId=ulU0mGztWnF4llUcE%2BYHkw%3D%3D&trackingId=EqEhNZbVAIsxTMGqS%2BjVhA%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous √©voluez dans le domaine de la Data et souhaitez int√©grer
un leader de la transformation num√©rique sp√©cialis√© dans les secteurs de la Banque, du Luxe, de l'Assurance, de la Finance, de l'Energie et la possibilit√© d'√©voluer au sein du Groupe Docaposte !
Softeam est labellis√© ""HappyIndex¬Æ AtWork "" 2022 pour la 5√®me ann√©e cons√©cutive !
Nos collaborateurs
travaillent en ¬´ mode projet ¬ª et accompagnent de bout en bout nos clients sur des probl√©matiques de Gouvernance.
CE QUE NOUS RECHERCHONS
Data Analyst
pour intervenir sur nos projets et contribuer au d√©veloppement de notre Practice ¬´ Augmented analytics ¬ª
CE QUE NOUS ATTENDONS DE VOUS
Vos missions :
Ma√Ætriser les outils statistiques et les informations n√©cessaires √† la mise en place d'une base de donn√©es,
G√©rer parfaitement les diff√©rentes technologies sp√©cifiques au big data,
Extraire les donn√©es du syst√®me source,
Extraire et traduire des donn√©es business en donn√©es statistiques,
Mod√©liser et assurer les mises √† jour r√©guli√®res de la base de donn√©es,
Contr√¥ler la qualit√© des donn√©es,
Mettre en ≈ìuvre une data warehouse
Synth√©tiser et vulgariser les informations pour les rendre accessibles aux utilisateurs.
VOUS ETES
Ing√©nieur(e) de formation avec une sp√©cialit√© Business Analytics, Big Data, Applications des Masses de Donn√©es (IAMD), Syst√®mes D√©cisionnels..
vous disposez d'une exp√©rience de
3 ans minimum
en tant que
Data Analyst/Data Miner
..
Vous avez une expertise sur un ou plusieurs des outils d'alimentation et de traitement suivants :
SQL, Alteryx, Dataiku, Python
..
Vous avez une expertise sur un ou plusieurs des outils de data visualisation suivants :
Power BI, Looker/GCP, Qlik, Tableau Software,
Bon(ne) communicant(e), curieux(se) et adaptable, v
ous √™tes dot√©(e) d'une grande capacit√© d‚Äôanalyse et de synth√®se et d'un bon esprit d'√©quipe,
Votre ma√Ætrise de l'
anglais
vous permet d'√©voluer dans un contexte international.
NOUS VOUS OFFRONS
Des
missions engageantes
aupr√®s des grands acteurs du march√©.
Un management de proximit√© avec
Gilles SALVADOR, Directeur du Centre d'Expertise Data
, toujours bienveillant et √† √† l'√©coute et avec qui vous pourrez √©changer au quotidien sur les enjeux de votre mission et √©voquer vos futurs projets afin que nous puissions vous aider √† les r√©aliser.
La possibilit√© d‚Äô√©voluer et de monter en comp√©tences gr√¢ce √† des
formations et √† des certifications aupr√®s de nos clients et de nos consultants
, des
12@13
, notre Entit√©
Softeam Institute, Organisme de formation interne
de renomm√© qui d√©livre des formations aupr√®s de nos clients...
QUI SOMMES-NOUS ?
SOFTEAM DATA
est une marque de
DOCAPOSTE
sp√©cialis√©e dans l'informatique d√©cisionnelle et les nouvelles technologies. Nous apportons notre expertise √† nos clients, principalement des Grands Comptes de la place financi√®re fran√ßaise, dans des projets de transformation digitale et cognitive.
2000 Softeamien.nes
sont d√©di√©.es √† la transformation m√©tier et digitale de nos clients et ont g√©n√©r√© 200 M‚Ç¨ de chiffre d‚Äôaffaires en 2020.
SOFTEAM SPIRIT
Des
communaut√©s d'expertises sur les sujets de la Data
De
super nouveaux locaux qui sont en plus accessibles facilement
Une
√©cole de formation int√©gr√©e
Des
√©v√®nements : des soir√©es avec les consultants, des 12@13...
Une entreprise
labellis√©e ""Happy at Work"" pour la 5√®me ann√©e cons√©cutive
.
N‚Äôattendez plus, rejoignez SOFTEAM et venez nous rencontrer dans nos nouveaux locaux situ√©s √† la D√©fense #DevenezSofteamien !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Statistiques'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
"Consultant Data Engineer, PYTHON, JAVA & SCALA ‚Äì H/F",Cat-Amania,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/consultant-data-engineer-python-java-scala-%E2%80%93-h-f-at-cat-amania-3888905331?position=9&pageNum=47&refId=ulU0mGztWnF4llUcE%2BYHkw%3D%3D&trackingId=8jIqzUqg0HTQbf6m4t9bGw%3D%3D&trk=public_jobs_jserp-result_search-card,"Cat-Amania
Cr√©√©e en 1999, Cat-Amania fait partie des ESN les plus comp√©titives dans les r√©gions o√π elle est implant√©e et se sp√©cialise sur des projets d‚Äôenvergure orient√©s m√©tiers : Banque, Assurance, Grande Distribution et Protection sociale mais aussi Energie, Industrie, Secteur Public.
En 2023, Cat-Amania c‚Äôest 90,8 millions d‚Äô‚Ç¨ de chiffre d‚Äôaffaires, 1100 collaborateurs r√©partis sur 15 agences en France et 6 agences √† l‚Äôinternational : Maroc, Luxembourg, Canada et Suisse.
Aujourd'hui, l‚Äôobjectif est de conforter le d√©veloppement de nos agences et d‚Äôouvrir de nouveaux pays en Europe, conserver notre croissance pour atteindre 100 millions d'‚Ç¨ de CA en 2024.
L‚ÄôAgence de Paris
Fort de nos r√©f√©rencements et pr√©sente depuis 1999 l‚Äôagence Cat-Amania Paris b√©n√©ficie d‚Äôune croissance solide et dynamique permettant d'offrir de nombreuses opportunit√©s √† nos collaborateurs. Avec plus de 200 consultants, nous avons su gagner la confiance de nos clients et la conserver gr√¢ce √† l‚Äôinvestissement de chacun, car Cat-Amania c‚Äôest avant tout une approche humaine avec la volont√© d‚Äôentretenir des liens √©troits au sein de ses √©quipes.
Le poste
Participer √† la r√©alisation de projets d√©cisionnels et au d√©veloppement des processus d‚Äôint√©gration de Data Hub, de DataWarehouses ou Data Lakes en architecture On Premise ou Cloud & Hadoop.
Accompagner les M√©tiers dans l‚Äôexpression de leurs besoins en termes de conception de flux de donn√©es et mod√©lisation des traitements.
D√©finir et produire les dossiers de conception fonctionnelle et technique des flux de donn√©es et des traitements.
D√©finir et produire les scripts de traitements de donn√©es structur√©es ou NO-SQL: Data Prep, Data Quality Management, Calculs et traitements de donn√©es en mode batch et/ou real-time, interfaces exports/imports, interfaces API ‚Ä¶
D√©finir et produire les processus d‚Äôexploitation IT des traitements de donn√©es : supervision, scheduling, s√©curit√©, gestion des log ‚Ä¶
Concevoir les protocoles de tests. Organiser et r√©aliser les plans de tests. R√©aliser des tests unitaires et de recettes
R√©diger des manuels utilisateurs et former les utilisateurs
D√©velopper des requ√™tes PYTHON et/ou JAVA et/ou SCALA
√ätre en support aux Data Analystes pour r√©aliser des √©tudes statistiques et des √©chantillons : profil et segmentation client, analyse de questionnaires ‚Ä¶
Votre profil
Dipl√¥m√©¬∑e d‚Äôun cursus ing√©nieur en Informatique, vous justifiez d‚Äôune premi√®re exp√©rience de plus de 3 ans dans les activit√©s de Data Int√©gration, Data Ing√©nierie et de d√©veloppement PYTHON, JAVA, SCALA
Vous ma√Ætriser le framework HADOOP, SPARK
Vous ma√Ætriser les outils Big Data suivants : YARN, PIG, HIVE, KAFKA ; FLINK, SPLUNK
Vous avez con√ßu, d√©velopp√© et d√©ploy√© en production des traitements de diff√©rentes natures : Processus d‚Äôexport, Processus d‚Äôimport, Migration/reprise d‚Äôhistorique
Vous ma√Ætriser les probl√©matiques de Data Int√©gration dans un contexte multi-technologie : DB2, ORACLE, SQL SERVER, HDFS ‚Ä¶
Vous ma√Ætriser les probl√©matiques de Data Int√©gration dans un contexte multi-technologie NOSQL : MONGODB, NEO4J, COUCHBASE, HBASE, CASSANDRA
Une premi√®re exp√©rience des m√©thodes agiles & Devops serait un plus
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB', 'Cassandra', 'Neo4j', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['Oracle', 'SQL Server'], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Statistiques', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Stagiaire Data Engineer (H/F),V and B,"Ch√¢teau-Gontier-sur-Mayenne, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/stagiaire-data-engineer-h-f-at-v-and-b-3863792436?position=10&pageNum=47&refId=ulU0mGztWnF4llUcE%2BYHkw%3D%3D&trackingId=hhvsUc9971uvM8ZELL4SlQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Rejoignez la team V and B !
Mission
V and B a cr√©√© un nouveau concept bas√© sur des lieux, des produits et une communaut√© int√©grant tous ses acteurs (si√®ge, franchis√©s et clients). Notre mission : Proposer et d√©velopper le go√ªt des bons moments √† partager de mani√®re simple et responsable, avec des √©v√©nements de plus en plus grands comme le V and B Fest‚Äô ou notre participation au Vend√©e Globe. Notre r√©seau compte aujourd‚Äôhui 278 magasins qui ≈ìuvrent chaque jour √† se d√©marquer pour offrir la meilleure satisfaction client, le tout avec une touche d‚Äôimpr√©vu.
Le/la Stagiaire Data Engineer Sera Int√©gr√©/√©e √† L'√©quipe En Charge Du Projet De Gestion Des Erreurs Des Flux D'int√©gration De Donn√©es, De L'analyse Des Logs, Et Du Monitoring De L'√©tat Des Flux. Sous La Supervision Du Responsable DATA, Vos Principales Missions Sont Les Suivantes
Aider √† identifier, analyser et r√©soudre les anomalies et erreurs dans les flux d'int√©gration
Proposer des solutions techniques pour optimiser la qualit√© et la fiabilit√© des flux
Participer √† la mise en place des proc√©dures d'analyse des logs pour d√©tecter les tendances, les anomalies et les opportunit√©s d'optimisation
Collaborer avec l'√©quipe pour interpr√©ter les informations tir√©es des logs et recommander des actions correctives
Participer √† la conception et la mise en ≈ìuvre un syst√®me de monitoring en temps r√©el pour suivre l'√©tat des flux d'int√©gration
Aider au d√©veloppement des alertes automatis√©es pour signaler les dysfonctionnements potentiels
Profil
Vous √™tes √©tudiant/te d‚Äôune √©cole d‚Äôing√©nieur ou d‚Äôun √©quivalent universitaire ?
Vous montrez un int√©r√™t pour le domaine des projets Data, √† travers vos exp√©riences professionnelles, stages, cours ou projets personnels impliquant les flux d‚Äôint√©gration de donn√©es par API, l‚Äôutilisation d‚Äôun ETL, l'automatisation et l‚Äôorchestration des pipelines de donn√©es ?
Vous avez une bonne connaissance des technologies de l‚ÄôAPI REST
Vous avez d√©j√† pratiqu√© un ETL (Informatica est un plus)
Vous avez une forte app√©tence pour l'optimisation et l‚Äôing√©nierie des flux de donn√©es
Vous avez une tr√®s bonne compr√©hension des bases de donn√©es et de SQL
Vous ma√Ætrisez l'anglais technique
Vous souhaitez vous impliquer et vous √©panouir dans une ambiance motiv√©e et conviviale ? Si rigueur, esprit d'√©quipe, organisation et dynamisme sont des qualit√©s qui vous caract√©risent, alors venez r√©v√©ler et d√©velopper votre talent au sein de notre √©quipe !
Stage d‚Äôune dur√©e de 6 mois et bas√© au Si√®ge social situ√© √† Ch√¢teau-Gontier (53).
A comp√©tences √©gales, une attention particuli√®re sera apport√©e aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Analyst H/F,Lincoln France,"Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-lincoln-france-3827765148?position=1&pageNum=50&refId=feC9wifmdVTgZ6xVoBIeng%3D%3D&trackingId=A0JQT3D0MGPHTe%2BVb2xN7Q%3D%3D&trk=public_jobs_jserp-result_search-card,"DATA ANALYST H/F
CDI
3 ans minimum
Chez Lincoln
, nous formons une communaut√© d'innovateurs passionn√©s qui red√©finissent l'analyse de donn√©es depuis
plus de 30 ans
. En tant que
Pure Player Data
, notre expertise est reconnue dans les domaines
de la Modern BI, du Big Data et de la Science des donn√©es
.
Notre mission ?
Transformer les donn√©es en solutions concr√®tes pour nos clients grands comptes dans divers secteurs tels que la banque, le retail, les t√©l√©coms, l'industrie, la sant√©, etc.
Description de poste
Nous recherchons un
Data Analyst H/F
pour accompagner nos clients dans leurs projets strat√©giques.
Vos missions
Collecter, nettoyer et traiter les donn√©es provenant de diff√©rentes sources.
Analyser les donn√©es pour identifier des tendances, des corr√©lations et des anomalies.
Concevoir et d√©velopper des tableaux de bord et des rapports pour pr√©senter les r√©sultats de mani√®re claire et concise.
Collaborer avec les √©quipes clients pour comprendre leurs besoins et recommander des solutions adapt√©es.
Pr√©requis :
Ma√Ætrise avanc√©e des langages de programmation
(SQL, Python, R, etc.).
Connaissance approfondie des bases de donn√©es relationnelles et non relationnelles.
Exp√©rience pratique avec des outils d'analyse de donn√©es
(Tableau, Power BI, Looker, Qlik etc.).
Fortes comp√©tences analytiques et capacit√© √† transformer les donn√©es brutes en insights exploitables.
Exp√©rience de travail en
m√©thode Agile
pour la gestion de projet et le d√©veloppement de solutions.
Capacit√© √† travailler de mani√®re autonome et en √©quipe.
Excellentes comp√©tences en communication et en pr√©sentation.
Les plus du poste
Environnement Collaboratif
: projets innovants favorisant le partage des connaissances.
Accompagnement individualis√© et de proximit√©
: formations certifiantes, attribution d‚Äôun Career Manager pour vous orienter dans votre trajectoire professionnelle, opportunit√©s d‚Äô√©volution de carri√®re.
Flexibilit√© du Travail
: T√©l√©travail et horaires flexibles pour votre √©quilibre vie professionnelle-personnelle.
R√©mun√©ration Comp√©titive
: Salaire comp√©titif avec des avantages sociaux attrayants.
Mobilit√©
: Possibilit√© de mobilit√© √† Paris, Lyon ou Aix-en-Provence offrant des exp√©riences diversifi√©es au sein de Lincoln.
Notre processus de recrutement :
Un entretien RH (1h) et entretien technique (1h)
Cette annonce n‚Äôest pas faite pour vous si :
Vous √™tes freelance et vous comptez le rester !
Toujours l√† ? Postulez et rejoignez nos
400 experts en Data
üòâ.
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Communication', 'Flexibilit√©'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['400'], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Cloud Engineer,SELLIA,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/cloud-engineer-at-sellia-3902686769?position=2&pageNum=50&refId=feC9wifmdVTgZ6xVoBIeng%3D%3D&trackingId=oCyxHxImDX7MWux2XkmZZw%3D%3D&trk=public_jobs_jserp-result_search-card,"Nous recherchons un Ops Senior en environnement Kubernetes sur du cloud Azure pour prendre en charge l‚Äôautomatisation du d√©ploiement de nos applications, le suivi de notre infrastructure et l‚Äôoptimisation des co√ªts des environnements.
Les missions :
et d√©ployer des infrastructures pour applications cloud (y compris sur les services de CI/CD)
en place des outils de s√©curisation, monitoring, backup, r√©partition des charges, etc
les processus et architectures
au processus de certification ISO (documentation, tests, etc)
√† la conception et au d√©veloppement des architectures cloud en utilisant les meilleures pratiques et les services adapt√©s (Azure).
en place et g√©rer des clusters Kubernetes pour le d√©ploiement d'applications et de micro-services.
avec les √©quipes de data science pour int√©grer les donn√©es et mod√®les selon une approche MLOps.
les bases de donn√©es relationnelles (postgreSQL) et MongoDB dans les solutions architecturales, en tenant compte des exigences de performances et de disponibilit√©.
Votre profil :
ann√©es d‚Äôexp√©riences minimum sur des projets similaires
certifications Azure MS devops engineer expert serait un plus
moins une exp√©rience significative sur Kubernetes.
des bases de donn√©es relationnelles et exp√©rience avec MongoDB.
approfondie des principes d'architecture logicielle, de la conception de syst√®mes √©volutifs et de la s√©curit√© des applications.
√† communiquer efficacement et √† travailler en √©quipe, tout en faisant preuve d'autonomie.
compr√©hension des m√©thodologies Agile et des pratiques DevOps.
Les technologies suivantes n‚Äôont pas de secret pour vous :
: Windows, Linux (ubuntu, WSL2), r√©seaux
: JavaScript/TypeScript, Python, Shell
de donn√©es : postgreSQL , mongoDB
: Docker/Podman, Kubernetes (AKS/EKS) : Helm, ISTIO,
: Cloud functions
GitOps, Serverless, Terraform, Helm, Ansible, Packer
Deployment: Cloud CI/CD
: Github, Consul, NGINX, WebPack, AWS Kinesis, Keycloak, Azure Devops
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go', 'JavaScript'], 'DataBase': ['SQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': ['Linux', 'Windows'], 'DBMS': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'ML', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,L-Acoustics,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-l-acoustics-3826015735?position=3&pageNum=50&refId=feC9wifmdVTgZ6xVoBIeng%3D%3D&trackingId=h701WLuvM55ngg0K4lj6rQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Join our passionate and dedicated teams who are shaping the future of sound!
Membre de l‚Äô√©quipe IT & Digital, vous intervenez au c≈ìur des diff√©rents projets de d√©veloppement du Groupe sur un p√©rim√®tre international (3 BU Business EMEA, AMERICAS & APAC ‚Äì 3 centres R&D France, Royaume-Uni & Allemagne ‚Äì 4 sites industriels France & Allemagne).
Pour accompagner notre niveau 2 du mod√®le data-drive, avec l‚Äôaccompagnement d‚Äôun manager et un architecte donn√©e. Un plan de formation et d‚Äôaccompagnement est pr√©vu pour int√©grer la ressource et l‚Äôaccompagner dans son d√©veloppement.
Dans le respect de la strat√©gie IT √©tablie par le DSI, votre mission consiste √† :
Responsabilit√©s
Analyser les besoins fonctionnels.
Localiser les donn√©es de production.
D√©terminer les sp√©cifications techniques.
Mod√©liser les datawarehouse (entrep√¥ts de donn√©es) et les datamarts (magasins de donn√©es) d√©di√©s √† une fonction particuli√®re dans l‚Äôentreprise.
Accompagner le client dans la r√©alisation du projet.
Maintenir les sources de donn√©es √† jour
Mettre √† disposition les donn√©es aux m√©tiers
D√©velopper le dictionnaire de donn√©es
Stack Technique
Power BI / DAX
Azure Pureview
Azure Data Factory
Azure Synapse Datawarehouse
Data Lake, Logical Datawarehouse
Microsoft Fabric
Int√©gration et la livraison continue (CI/CD)
Savoir-faire
Rigueur et respect de planning
Esprit de synth√®se
Capacit√©s d‚Äôanalyse
Autonomie
Ma√Ætrise de l‚Äôanglais
Envie d‚Äôapprendre et d‚Äô√©voluer
Veille technologique
R√©diger la documentation technique
Bonne communication √©crite et orale
Votre Profil
Dipl√¥m√© d‚Äôun Bac + 5 (√©cole d'ing√©nieur ou universitaire), vous justifiez d‚Äôune exp√©rience de 5 ans minimum dans des fonctions similaires.
Vous avez une exp√©rience significative sur les domaines :
Plateforme donn√©es de Microsoft Azure (Microsoft Fabric/Lakehouse/Synapse)
Exp√©rience sur des projets d'int√©gration et d√©ploiement
D√©veloppement et int√©gration des API
D√©veloppement et gouvernance des rapports dans Power BI
Connaissance de base des technologies d‚Äôintelligence artificielle
Join our passionate and dedicated teams who are shaping the future of sound!
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['CI/CD'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Senior data engineer,Harnham,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-at-harnham-3917047907?position=4&pageNum=50&refId=feC9wifmdVTgZ6xVoBIeng%3D%3D&trackingId=w%2BSECXFbLwwSLeezM5MFkw%3D%3D&trk=public_jobs_jserp-result_search-card,"Senior Data Engineer
Paris - 3 Jours de t√©l√©travail
Up to 80K‚Ç¨ fixe
CDI - Pas ouvert au freelance
Scala - Spark - Kafka
üí° L'entreprise
Une entreprise sp√©cialis√©e dans le marketing et la performance des publicit√©s mobiles recherche un Senior Data Engineer. G√©rant un volume important de donn√©es, le Machine Learning est au coeur de son offre. L'entreprise propose des solutions technologiques innovantes pour am√©liorer la performance des campagnes publicitaires sur smartphone et tablettes tout en proposant une strat√©gie et des algorithmes sur mesure √† ses clients.
üéØ Le poste
En tant Senior Data Engineer, vous rejoindrez l'√©quipe reporting en charge de tous les sujets li√©s √† la data. Vos missions seront les suivantes :
Assurer le bon fonctionnement de l'infrastructure de donn√©es : g√©rer les magasins de donn√©es, les processus et la planification
S'assurer que les donn√©es sont toujours disponibles : superviser le traitement, le stockage, l'agr√©gation et le d√©veloppement d'API
Apporter des nouvelles id√©es pour am√©liorer les outils
Sugg√©rer des solutions nouvelles et int√©ressantes pour mettre √† niveau l'infrastructure de donn√©es
G√©rer les algorithmes de data science (garantir leur √©volutivit√© et leur bon fonctionnement)
Travailler en √©troite collaboration avec l'√©quipe SCRUM
Garder un ≈ìil sur l'√©chelle des syst√®mes de donn√©es, en s'assurant qu'ils peuvent r√©pondre aux besoins croissants
Rationaliser les processus de donn√©es en int√©grant des tests, une surveillance, des alertes et une r√©cup√©ration d‚Äôerreur efficaces
üîç Profil Recherch√© :
Dipl√¥me d'ing√©nieur en data engineering
Minimum 4 ans d'exp√©rience sur un poste similaire
Solide connaissance du code en Scala/Spark
Sp√©cialiste de la data streaming (ma√Ætrise de Kafka pour g√©rer des donn√©es en temps r√©el)
Connaissance d'au moins un cloud provider (AWS, GCP ou Azure)
Connaissance des pipelines et les outils CI/CD (un vrai plus)
Pro de Python, avec une connaissance de Redis et Cassandra
Anglais courant
Pour postuler
Merci de me faire part de votre CV et je vous recontacterai au plus vite.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Senior'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Senior Data Engineer,Pentalog,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-at-pentalog-3747758363?position=5&pageNum=50&refId=feC9wifmdVTgZ6xVoBIeng%3D%3D&trackingId=K2snjFw5ATMJtJNoo%2B38cQ%3D%3D&trk=public_jobs_jserp-result_search-card,"France
(Paris)
Full time
Job perks: Professional team; AI software
About The Project
How we hire:
At Pentalog, excellence is what you'll do. We're guided by a mission to positively impact the software development world.
Are you ready to be part of a revolutionary team that is reimagining content creation and using cutting-edge technology to drive the future of the creator economy? Our client is using technology, data and expertise to turn today's talented video creators into tomorrow's digital icons.
As a
Senior Data Engineer
, you'll be working on one or more key projects that drive innovation in content creation. Your role will empower creators to reach their full potential across social platforms such as Facebook, Instagram, Pinterest, Snapchat, TikTok, YouTube and beyond.
The majority tech stack is: Python/FastAPI and React with some projects in Node.js, Rust, React Native. Mandatory knowledge: Git, Docker. Nice to haves: AWS, Terraform.
Job Requirements
At least 6 years of experience in similar environments;
Proficiency in Python and familiarity with the data engineering tool landscape, particularly tools such as Airflow and DBT;
Knowledge of SQL and NoSQL databases;
Streaming pipeline experience with Kafka, Kinesis, Beam or Flink;
Big data infrastructure deployment experience, with proven ability to use tools such as Terraform on platforms such as AWS;
Familiarity with managed services such as S3, Redshift, EMR or others;
Architecture and systems design experience;
Experience with platforms such as Spark and Hadoop is a plus;
Rigorous, resourceful and curious, with a flair for problem solving;
Good communicator, with the ability to teach others;
Good team working skills;
Fluent in English.
Amazon Web Services (AWS) AWS Kafka AWS Kinesis AWS Redshifht Hadoop Node.Js NoSQL Python React js React native Rust SPARK SQL
Responsibilities
Develop, deploy, and maintain ETL processes in Python and Spark;
Implement and manage data pipelines utilizing tools such as Airflow, AWS Glue, and Kinesis;
Oversee and manage the data stores, including Redshift and RDS;
Implement and maintain data lake archiving strategies using S3, Parquet, and Iceberg;
Drive data modeling initiatives and implement schema governance tooling to ensure data integrity and consistency.
Benefits
Foreign language classes;
Competitive salary and bonuses;
Free pass to learning platforms;
A multicultural, friendly work environment;
Working in a company with an Agile mindset: continuous knowledge sharing and validated learning;
The possibility to bring your own creative and innovative ideas to life;
Mentorship programs that encourage and enable your professional development;
Great career development opportunities;
Improvement of your hard and soft skills through workshops, knowledge sharing sessions and presentations on multiple IT-related topics.
About Pentalog
As a leading European Software Services company operating internationally in France, Romania, Germany, Moldova, UK, Vietnam, Mexico, Morocco and USA, we employ over 1,300 engineers and IT experts who work in a very dynamic, multicultural working environment.
At Pentalog, your talents & ambitions are recognized and rewarded; we offer plenty of opportunities to develop, both individually, as well as a professional, and we reward our collaborators who understand the importance of self-improvement.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': [], 'EnSoftSkils': ['Problem Solving', 'Initiative']}","{'JobDetail': ['Full', 'Senior'], 'TypeContract': [], 'Salary': ['1,300'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Analyst H/F,Lincoln France,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-lincoln-france-3892483893?position=7&pageNum=50&refId=feC9wifmdVTgZ6xVoBIeng%3D%3D&trackingId=Vqm8X77go1MCC4UqQc%2FGVg%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
üìä
3 ans minimum
Chez Lincoln
, nous formons une communaut√© d'innovateurs passionn√©s qui red√©finissent l'analyse de donn√©es depuis
plus de 30 ans
. En tant que
Pure Player Data
, notre expertise est reconnue dans les domaines
de la Modern BI, du Big Data et de la Science des donn√©es
.
Notre mission ?
Transformer les donn√©es en solutions concr√®tes pour nos clients grands comptes dans divers secteurs tels que la banque, le retail, les t√©l√©coms, l'industrie, la sant√©, etc.
Description du poste
Nous recherchons un
Data Analyst H/F
pour accompagner nos clients dans leurs projets strat√©giques.
Vos missions
Collecter, nettoyer et traiter les donn√©es provenant de diff√©rentes sources.
Analyser les donn√©es pour identifier des tendances, des corr√©lations et des anomalies.
Concevoir et d√©velopper des tableaux de bord et des rapports pour pr√©senter les r√©sultats de mani√®re claire et concise.
Collaborer avec les √©quipes clients pour comprendre leurs besoins et recommander des solutions adapt√©es.
Pr√©requis :
Ma√Ætrise avanc√©e des langages de programmation (
SQL, Python, R
, etc.).
Connaissance approfondie des bases de donn√©es relationnelles et non relationnelles.
Exp√©rience pratique avec des outils d'analyse de donn√©es (
Tableau, Power BI
, etc.).
Fortes comp√©tences analytiques et capacit√© √† transformer les donn√©es brutes en insights exploitables.
Exp√©rience de travail en
m√©thode Agile
pour la gestion de projet et le d√©veloppement de solutions.
Capacit√©s √† travailler de mani√®re autonome et en √©quipe.
Excellentes comp√©tences en communication et en pr√©sentation.
Les plus du poste
Environnement Collaboratif
: projets innovants favorisant le partage des connaissances.
Accompagnement individualis√© et de proximit√©
: formations certifiantes, attribution d‚Äôun Career Manager pour vous orienter dans votre trajectoire professionnelle, opportunit√©s d‚Äô√©volution de carri√®re.
Flexibilit√© du Travail
: T√©l√©travail et horaires flexibles pour votre √©quilibre vie professionnelle-personnelle.
R√©mun√©ration Comp√©titive
: Salaire comp√©titif avec des avantages sociaux attrayants.
Mobilit√©
: Possibilit√© de mobilit√© √† Lille, Lyon ou Aix-en-Provence offrant des exp√©riences diversifi√©es au sein de Lincoln.
Notre processus de recrutement :
Un entretien RH (1h) et entretien technique (1h)
Cette annonce n‚Äôest pas faite pour vous si :
Vous √™tes freelance et vous comptez le rester !
Toujours l√† ? Postulez et rejoignez nos
400 experts en Data
üòâ.
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Communication', 'Flexibilit√©'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['400'], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer - data factory (H/F),Euro Information Developpements / EID,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-data-factory-h-f-at-euro-information-developpements-eid-3878343308?position=8&pageNum=50&refId=feC9wifmdVTgZ6xVoBIeng%3D%3D&trackingId=PMsSi4Y%2BeHJQ9msDAp5EBw%3D%3D&trk=public_jobs_jserp-result_search-card,"Qui sommes nous
Euro-Information, filiale technologique de Cr√©dit Mutuel Alliance F√©d√©rale, con√ßoit, r√©alise, maintient et exploite un syst√®me d‚Äôinformation commun utilis√© par le Groupe.
Les activit√©s de d√©veloppement et de production informatique au niveau national et international sont assur√©es par environ 4000 salari√©s r√©partis sur plusieurs sites g√©ographiques au niveau national : Strasbourg, Nancy, Dijon, Orl√©ans, Lyon, Lille, Cergy, Val de Fontenay, Paris et Nantes.
Premi√®re Banque √† adopter le statut d‚Äôentreprise √† mission, le Cr√©dit Mutuel Alliance F√©d√©rale s‚Äôinvestit et s‚Äôengage dans diff√©rentes missions sociales et environnementales :
L‚Äôaccompagnement de tous par notre organisation coop√©rative et mutualiste reste au c≈ìur de notre ADN.
La technologie au service de l‚Äôhumain est une r√©f√©rence dans notre monde connect√©.
La solidarit√© et l‚Äô√©co-responsabilit√© deviennent des axes cl√©s dans notre d√©veloppement.
Notre raison d‚Äô√™tre : Ensemble, Ecouter et Agir.
Vos missions
Vous souhaitez int√©grer une √©quipe dynamique et √† taille humaine au sein d‚Äôune entreprise solide et d‚Äôun grand groupe en d√©veloppement constant ? Vous souhaitez travailler sur un enjeu d‚Äôaujourd‚Äôhui et plus encore de demain : la donn√©e ?
Euro-Information, la Fintech de Cr√©dit Mutuel Alliance F√©d√©rale structure une Data Factory pour :
Acc√©l√©rer la valorisation des donn√©es au travers d‚Äôanalyse de masse et de mod√®les allant jusqu‚Äôau pr√©dictif.
R√©pondre √† la confiance de nos clients en garantissant la s√©curit√© de leurs donn√©es et une utilisation responsable et encadr√©e, respectueuse de leur vie priv√©e.
La Data Factory EI se positionne comme un fournisseur de solutions pour les √©quipes informatiques et pour l‚Äôensemble des entit√©s du groupe et comme un facilitateur d‚Äô√©changes et de mutualisation. Pour mener √† bien ces missions, la relation m√©tier s‚Äôav√®re essentielle. Elle r√©unit :
Des Data Architects. Ils fournissent l‚Äôenvironnement et les outils et s‚Äôassurent de leur performance et de leur constante √©volution.
Des Data Engineers. Ils ont la maitrise des donn√©es, de leur r√©colte √† leur mise √† disposition adapt√©e aux besoins des m√©tiers. Ils con√ßoivent les mod√®les d‚Äôenregistrement des donn√©es.
Des Concepteurs Business Intelligence. Ils simplifient, mutualisent et industrialisent les reportings.
Des Data Scientists. Ils accompagnent les m√©tiers et les entit√©s sur la Data Science, ils r√©alisent √† fa√ßon sur les sujets √† fort enjeu.
Des Data Officers. Ils coordonnent et mutualisent les √©nergies sur les projets Data comme dans le cadre de la Gouvernance et de l‚Äôadministration des donn√©es.
Nous recherchons un(e) Data Engineer.
Vous participerez √† la mise en ≈ìuvre et au maintien du Syst√®me d‚Äôinformation D√©cisionnel du groupe
.
Pour les banques, les organismes de cr√©dits √† la consommation et les filiales, en France et √† l‚Äôinternational :
Compr√©hension de l‚Äôactivit√© et des besoins de vos clients, en dialogue avec la MOA
Compr√©hension du SI de production, en dialogue avec les √©quipes MOE
Mod√©lisation du Syst√®me d‚ÄôInformation D√©cisionnel
Conception et r√©alisation
Diagnostic des dysfonctionnements rencontr√©s
Maintenances correctives et √©volutives
Support aupr√®s des diff√©rents m√©tiers
Documentation technique
Suivi des traitements
Pilotage de projets
Vous travaillerez sur une grande vari√©t√© de projets et √† l‚Äô√©chelle de l‚Äôensemble des entit√©s g√©r√©es sur le SI d‚ÄôEuro-Information .
Vous intervenez sur des projets √† dimension internationale sur des environnements Vertica, Semarchy, WebFOCUS, SAP Business Objects, QlikSense‚Ä¶
Vous participerez, coordonnerez et m√®nerez √† bien des projets de valorisation de donn√©es sur des cas d‚Äôusages concrets :
Des projets de bout en bout : de l‚Äôexpression du besoin jusqu‚Äô√† la r√©alisation et au suivi de sa performance en lien avec la MOA et nos Data Officers
En mobilisant l‚Äôensemble des acteurs : Business, Data Scientists, Data Engineer, sources de donn√©es ‚Ä¶
Avec participation aux prises de d√©cision
En mutualisant les travaux et les bonnes pratiques entre les acteurs et les diff√©rents m√©tiers du groupe
Dans vos projets et au-del√†, vous porterez l‚Äôacculturation Data au sein du groupe.
Ce que vous allez vivre chez nous
T√©l√©travail (2 jours par semaine)
R√©mun√©ration fixe vers√©e sur 13 mois
RTT
Int√©ressement, participation et abondement
Plan √©pargne entreprise et PERCO
Contrat de sant√© collectif
Pr√©voyance
Retraite suppl√©mentaire prise en charge √† 100% par l‚Äôemployeur
Conditions bancaires et assurances pr√©f√©rentielles
Politique parentale avantageuse
Ce que nous allons aimer chez vous
De formation bac +4/5, vous disposez id√©alement d‚Äôune exp√©rience significative sur un poste √©quivalent.
La maitrise de l‚Äôanglais serait un plus.
Connaissance du monde OPEN
Vous avez la maitrise d‚Äôun ETL, d‚Äôune base de donn√©es orient√©e Analytique, d‚Äôune solution BI.
La connaissance de l‚Äôoutil de mod√©lisation PowerDesigner serait un plus.
Connaissance du monde Host
Une exp√©rience mettant en ≈ìuvre des technologies mainframe (MVS, JCL, Cobol, SGBD DB2, OPC) serait un plus.
Ce qui nous plaira le plus chez vous :
C‚Äôest vous-m√™me ! Alors on vous attend ouvert(e), force de proposition, dot√©(e) d‚Äôun certain sens critique, autonome et respectueux(se) de la confidentialit√© des informations d√©tenues car c‚Äôest ce qui vous permettra de mener au mieux votre mission.
On dit de vous que vous avez une certaine aptitude √† communiquer et le sens du travail en √©quipe.
Vous √™tes motiv√©(e) et vous souhaitez vous investir fonctionnellement et techniquement, n‚Äôh√©sitez plus l‚Äôoffre est faite pour vous.
Autres informations
Le poste est √† pourvoir d√®s que possible sur Nantes.
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
ALTERNANCE - Data Engineer H/F,Cr√©dit Agricole Group Infrastructure Platform,"Montpellier, Occitanie, France",https://fr.linkedin.com/jobs/view/alternance-data-engineer-h-f-at-cr%C3%A9dit-agricole-group-infrastructure-platform-3903710929?position=9&pageNum=50&refId=feC9wifmdVTgZ6xVoBIeng%3D%3D&trackingId=n3SsDOZU2EIJMkzwnoo%2Fww%3D%3D&trk=public_jobs_jserp-result_search-card,"Cr√©dit Agricole ‚Äì Group Infrastructure Platform (CA-GIP),
acteur majeur de la production informatique du groupe Cr√©dit Agricole, recherche ses Jeunes Talents de demain en alternance et en stage !
L‚Äô√©quipe Data souhaite int√©grer son futur
alternant Data Engineer H/F
√†
Montpellier (34)
.
üöÄ Vos missions :
Le socle Natif Data Cloud con√ßoit et op√®re des plateformes ¬´ as a service ¬ª facilitant la mise en place d‚Äôarchitectures modernes, distribu√©es et hautement r√©silientes pour l‚Äôensemble des entit√©s du groupe Cr√©dit Agricole.
Au sein de cette √©quipe, vous aurez les missions suivantes :
Mettre en ≈ìuvre op√©rationnellement et techniquement la plateforme Streaming ;
Participer au daily meeting anim√© par le Squad Lead, √† l‚Äôensemble des rituels agiles de la Squad (R√©tro, D√©mos, PI Planning) ainsi qu‚Äôaux r√©unions de co-construction de la roadmap et de mise en ≈ìuvre de celle-ci ;
Mettre en ≈ìuvre les √©l√©ments de la Backlog.
Les + de cette mission :
monterez en comp√©tences au sein d‚Äôune
√©quipe de 40 personnes
soit de 20 clusters Kafka et serez accompagn√© par
Paul BERNARD
, responsable squad Streaming.
Si vous souhaitez acqu√©rir de
v√©ritables comp√©tences en DevOps et en Kafka
, alors cette mission est faite pour vous.
‚úÖ Votre profil :
Vous int√©grerez √† partir de septembre 2024 un cursus de niveau
Bac+4 / M1
en informatique,
de pr√©f√©rence en √©cole d‚Äôing√©nieurs.
Vous justifiez d'un
niveau d'anglais
professionnel
.
Comp√©tences attendues :
Force de proposition ;
Rigueur ;
Animation et facilitation ;
Capacit√© de synth√®se ;
Autonomie.
Environnements techniques:
Kafka ;
Ansible ;
Flink.
üèÜ Pourquoi devenir un Jeune Talent CA-GIP ?
Pour devenir partenaire des grandes √©volutions technologiques et mettre vos comp√©tences au service des 53 millions de clients du groupe Cr√©dit Agricole ;
Pour √©voluer dans un environnement √† la pointe de la technologie (DevOps, Cloud Hybride, Digital Workplace, Cybers√©curit√©, T√©l√©communications, R√©seau...) ;
Pour rejoindre une entreprise certifi√©e Top Employer, et donc reconnue comme employeur de r√©f√©rence ;
Pour b√©n√©ficier de missions responsabilisantes et d√©velopper vos comp√©tences au sein d‚Äôun environnement de travail aussi bienveillant que challengeant, une exp√©rience id√©ale pour lancer votre carri√®re (46% de nos Jeunes Talents en alternance et stage embauch√©s en CDI en 2023).
‚≠ê Nos petits plus !
Vous b√©n√©ficierez d‚Äôun remboursement de vos frais de transport en commun de 90% !
Vous souhaitez vous rapprocher de votre lieu de travail ? CA-GIP a conclu un partenariat avec l‚Äôorganisme ViaHumanis ! Pour en savoir plus, cliquez ici.
Vous aurez acc√®s √† toutes les prestations de notre CSE !
CA-GIP est une entreprise handi-accueillante
: vous avez des besoins sp√©cifiques, nous sommes l√† pour vous accompagner.
CA-GIP est signataire de la Charte de la Diversit√© depuis 2023
: en agissant chaque jour dans l‚Äôint√©r√™t de la soci√©t√©, nous sommes un Groupe engag√© en faveur des diversit√©s et de l‚Äôinclusion. Pour en savoir plus sur la Politique des Diversit√©s.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Hybride'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Ing√©nieur data Spark (F/ H),Thales,"V√©lizy-Villacoublay, √éle-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-spark-f-h-at-thales-3831274678?position=10&pageNum=50&refId=feC9wifmdVTgZ6xVoBIeng%3D%3D&trackingId=U%2BQniftly41O7LDODp8s1g%3D%3D&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?
Au sein du site de V√©lizy, nos √©quipes hautement qualifi√©es con√ßoivent et produisent des amplificateurs de puissance (tubes √† ondes progressives, klystrons, gyrotrons, sous-syst√®mes pour les Grandes Infrastructures de Recherche, etc.) √† destination des march√©s D√©fense, S√©curit√©, Spatial et Scientifique. Chaque jour nos cadres, ing√©nieurs, techniciens et op√©rateurs mettent en commun leurs savoir-faire unique au service de l‚Äôinnovation.
QUI SOMMES-NOUS ?
Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr√©sents sur tous les continents. Le Groupe investit dans les innovations du num√©rique et de la ¬´ deep tech ¬ª ‚Äì big data, intelligence artificielle, connectivit√©, cybers√©curit√© et quantique ‚Äì pour construire un avenir de confiance, essentiel au d√©veloppement de nos soci√©t√©s, en pla√ßant l‚Äôhumain au c≈ìur des d√©cisions.
Thales propose des solutions, services et produits qui aident ses clients ‚Äì entreprises, organisations, Etats ‚Äì dans cinq grands march√©s vitaux pour le fonctionnement de nos soci√©t√©s : identit√© et s√©curit√© num√©riques, d√©fense, a√©ronautique, espace, et transport.
QUI ETES-VOUS ?
Dipl√¥m√© d‚Äôun Bac+5 en √©cole d‚Äôing√©nieur ou √©quivalent universitaire avec une sp√©cialisation en informatique, vous avez au moins 3 ans d'exp√©rience dans les technologies Big Data.
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
En tant que Data Engineer, vous jouerez un r√¥le cl√© dans la conception, le d√©veloppement et la maintenance de notre infrastructure de donn√©es, ainsi que dans la transformation et la gestion des flux de donn√©es.
VOS MISSIONS :
Concevoir, d√©velopper et d√©ployer des solutions Big Data en utilisant les technologies Spark.
Mettre en place des pipelines de donn√©es performants pour l'ingestion, le traitement et le stockage des donn√©es massives.
Collaborer √©troitement avec les √©quipes m√©tier pour comprendre leurs besoins en mati√®re d'analyse de donn√©es et proposer des solutions adapt√©es.
Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn√©es.
Assurer la qualit√© et la fiabilit√© des donn√©es trait√©es, en mettant en place des processus de validation et de nettoyage.
Identifier et r√©soudre les probl√®mes li√©s √† l'infrastructure Big Data et proposer des am√©liorations.
Travailler en √©troite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents √† partir des donn√©es.
Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.
Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
